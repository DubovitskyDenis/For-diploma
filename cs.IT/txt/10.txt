capacity
online
causal
q-ary
error-erasure
channels
chen
jaggi
langberg
abstract
q-ary
online
causal
channel
coding
model
sender
wishes
communicate
message
receiver
transmitting
codeword
symbol
symbol
via
channel
limited
errors
and/or
cid:63
erasures
channel
online
sense
ith
step
communication
channel
decides
whether
corrupt
ith
symbol
based
view
far
i.e.
decision
depends
transmitted
symbols
contrast
classical
adversarial
channel
corruption
chosen
channel
full
knowledge
sent
codeword
work
study
capacity
q-ary
online
channels
combined
corruption
model
channel
may
impose
errors
cid:63
erasures
transmitted
codeword
online
channel
error
erasure
case
seen
number
recent
studies
present
upper
lower
bounds
capacity
work
give
full
characterization
capacity
function
cid:63
∗department
electrical
computer
engineering
university
maryland
college
park
chenztan
umd.edu
†department
information
engineering
chinese
university
hong
kong
jaggi
ie.cuhk.edu.hk
‡department
electrical
engineering
state
university
new
york
buﬀalo
mikel
buffalo.edu
introduction
reliable
communication
diﬀerent
types
channels
extensively
studied
electrical
engi-
neering
computer
science
one
frequently
used
communication
channel
model
binary
erasure
channel
bit
zero
one
either
transmitted
intact
erased
speciﬁcally
erased
bit
visible
error
denoted
special
symbol
identiﬁed
directly
receiver
another
fre-
quently
studied
channel
model
binary
bit-ﬂip
channel
bits
ﬂipped
complement
generalization
channel
alphabet
size
leads
general
q-ary
channels
two
broad
approaches
model
erasure
error
corruptions
imposed
channel
shannon
approach
model
channel
stochastic
process
hamming
approach
combinatorial
approach
model
channel
adversarial
process
manipulate
parts
transmitted
codeword
arbitrarily
subject
limit
number
corrupted
symbols
interesting
classify
hamming
model
adversarial
channel
terms
adversary
knowledge
codeword
examples
include
standard
adversarial
channel
also
referred
omniscient
adversary
e.g.
1–3
causal
online
adversary
e.g.
4–9
oblivious
adversary
e.g.
10–12
strongest
adversarial
power
weakest
one
extreme
omniscient
adversarial
model
a.k.a
classical
adversarial
model
assumes
channel
full
knowledge
entire
codeword
based
knowledge
channel
maliciously
decide
corrupt
codeword
extreme
oblivious
adversarial
model
model
channel
clueless
codeword
generates
corruptions
manner
independent
codeword
transmitted
causal
adversarial
model
intermediate
model
two
extremes
channel
decides
whether
tamper
particular
symbol
codeword
based
symbols
transmitted
far
signiﬁcant
diﬀerences
diﬀerent
adversarial
models
classiﬁed
respect
capacity
elaborate
diﬀerences
shortly
work
focus
causal
adversaries
study
reliable
communication
q-ary
causal
adversarial
channels
speciﬁcally
consider
following
communication
scenario
sender
alice
wishes
transmit
message
receiver
bob
q-ary
causal
adversarial
channel
encoding
codeword
···
···
length
however
channel
governed
causal
adversary
calvin
observe
impose
errors
cid:63
erasures
importantly
calvin
decides
whether
tamper
i-th
symbol
codeword
based
symbols
···
transmitted
thus
far
roughly
qnr
distinct
messages
sent
using
codewords
length
say
code
achieves
rate
interested
maximum
achievable
rate
capacity
channel
see
section
precise
deﬁnitions
1.1
results
work
characterize
capacity
q-ary
causal
channels
function
alphabet
size
error
capability
erasure
capability
cid:63
speciﬁcally
propose
analyze
attack
strategy
similar
binary
cases
described
detail
shortly
gives
upper
bound
capacity
coding
scheme
similar
one
given
implies
lower
bound
capacity
matching
upper
bound
main
result
summarized
following
theorem
theorem
1.1.
capacity
q-ary
causal
adversarial
channels
symbol
errors
erasures
cid:104

min
¯p∈
cid:16
cid:16
cid:17
cid:17
cid:105
cid:104
q−1
cid:105
cid:63
cid:104
cid:105
q−1
otherwise
cid:63
q−1
q−1
q−1
cid:63
fact
direct
by-products
analysis
coding
scheme
show
even
calvin
small
lookahead
capacity
essentially
unchanged
precisely
constant
calvin
decides
whether
tamper
i-th
symbol
codeword
based
symbols
···
min
i+n
capacity
corresponding
n-lookahead
less
corresponding
show
theorems
1.1
continuous
provide
rough
argument
support
claim
remark
end
section
1.2
previous
work
start
brieﬂy
summarizing
state-of-the-art
erasure
error
adversarial
channels
omniscient
oblivious
adversaries
optimal
rate
communication
binary
omniscient
adver-
sarial
channels
erasure
error
long
standing
open
problems
coding
theory
best
known
lower
bounds
problems
derive
gilbert-varshamov
codes
bound
1,2
tightest
upper
bounds
mrrw
bounds
work
mceliece
literature
arbitrarily
varying
channels
avcs
e.g.
implies
capacity
binary
oblivious
adversarial
error
channel
oblivious
adversarial
erasure
channels
match
well-known
capacities
corresponding
random
noise
channels
bits
ﬂipped
erased
bernoulli
attainable
even
noise
patterns
chosen
overall
constraint
p-fraction
corruptions
adversary
full
knowledge
codebook
knowledge
actually
transmitted
codeword.1
alternate
proof
capacity
binary
oblivious
bit-ﬂip
channel
presented
langberg
computationally
eﬃcient
scheme
achieving
rate
presented
guruswami
smith
turn
causal
setting
causal
adversary
never
better
omniscient
adversary
least
well
oblivious
one
upper
bounds
capacity
oblivious
adversaries
speciﬁed
act
upper
bounds
causal
case
well
lower
bounds
capacity
omniscient
adversaries
act
lower
bounds
causal
case
binary
causal
adversarial
bit-ﬂip
channel
bounds
improved
speciﬁcally
ﬁrst
nontrivial
upper
bound
min
given
langberg
later
tightest
upper
bound
given
continuing
work
dey
best
lower
bound
described
haviv
langberg
slightly
improves
bound
binary
causal
adversarial
erasure
channel
trivial
upper
bound
improved
bassily
smith
also
present
improved
lower
bounds
separate
achievable
rate
causal
adversarial
erasures
rates
achievable
omniscient
adversarial
erasures
recently
capacities
binary
causal
adversarial
erasures
errors
fully
characterized
demonstrate
equals
theorem
1.1
case
case
cid:63
respectively
related
results
include
study
binary
delayed
adversaries
dey
provide
character-
ization
capacity
case
delays
arbitrarily
small
constant
fraction
code
block
length
n.2
value
corresponds
adversarial
model
decision
1in
fact
even
shown
alice
allowed
use
stochastic
encoding
choosing
one
multiple
possible
codewords
randomly
message
wants
transmit
even
maximal
probability
error
metric
vanishingly
small
probability
error
attained
capacity
achieving
codes
exists
sequence
codes
whose
rates
asymptotically
achieve
corresponding
capacity
every
message
transmitted
alice
every
corruption
pattern
imposed
calvin
decoded
correctly
bob
codewords
corresponding
message
2while
presented
work
techniques
used
show
capacity
holds
even
delay
polylog
rather
whether
corrupt
ith
codeword
bit
depends
xi−d
overall
constraint
number
bits
corrupted
interesting
note
case
well
oblivious
one
capacity
bit-ﬂip
bit-erasure
channels
matches
corresponding
random
noise
capacities
hand
mentioned
causal
lookahead
settings
strictly
lower
approximately
matching
capacities
seems
imply
knowledge
present
critical
calvin
signiﬁcantly
depress
capacity
random
noise
capacity
discussion
relates
problem
binary
alphabets
work
dey
considered
large
alphabet
channels
alphabet
size
signiﬁcantly
larger
block-length
causal
symbol
errors.3
complete
capacity
characterization
presented
corresponding
computationally
eﬃcient
codes
attaining
capacity
demonstrated
capacity
problem
equals
capacity
omniscient
adversary
attained
reed-solomon
codes
impossibility
higher
rates
singleton
bound
demonstrates
penalty
imposed
causality
condition
calvin
diminishes
increasing
alphabet
size
also
related
work
study
mazumdar
capacity
memoryless
channels
adversary
makes
decisions
based
value
currently
transmitted
bit
addressed
note
causal
model
also
variant
avc
model
however
previous
works
avcs
capacity
characterizations
relate
directly
study
hand
causal
adversaries
1.3
proof
technique
prove
theorem
1.1
demonstrate
two
results
converse
analyzing
attack
strategy
similar
presented
7,8,13
coding
scheme
follows
lines
presented
major
novelty
lies
extending
proof
techniques
hold
q-ary
causal
adversarial
channels
general
adversary
able
impose
errors
erasures
codewords
throughout
denote
encoder
alice
decoder
bob
adversarial
causal
jammer
calvin
1.3.1
converse
prove
theorem
1.1
must
present
strategy
calvin
allow
communication
rate
higher
matter
encoding/decoding
scheme
used
alice
bob
speciﬁcally
strategy
present
allow
calvin
enforce
constant
probability
error
bounded
away
zero
whenever
alice
bob
communicate
rate
higher
calvin
uses
two-phase
babble-and-push
strategy
ﬁrst
phase
calvin
babbles
behaving
like
q-ary
symmetric
channel
¯pn
symbols
changed
adversarial
attack
calvin
strongest
optimal
depends
setting
cid:63
fact
accounts
minimization
capacity
term
given
theorem
1.1.
value
also
determines
length
denoted
babble
phase
namely
calvin
stops
behaving
like
q-ary
symmetric
channel
starts
second
push
phase
taken
ﬁrst
phase
calvin
uses
error
capabilities
erase
symbols
second
phase
channel
uses
calvin
randomly
selects
codeword
alice
bob
codebook
consistent
bob
received
far
namely
codeword
bob
3the
capacity
large
alphabet
causal
symbol
erasures
essentially
omniscient
large
alphabet
symbol
erasures
turn
equals
capacity
random
symbol
erasures
rates
directly
attained
reed-solomon
codes
matching
converses
obtained
calvin
merely
randomly
erasing
symbols
changing
cid:48
perspective
may
transmitted
taking
account
calvin
attack
calvin
pushes
remaining
part
alice
codeword
towards
selected
codeword
push
phase
includes
errors
erasures
calvin
behalf
speciﬁcally
calvin
ﬁrst
imposes
error
probability
1/2
every
entry
transmitted
codeword
diﬀers
chosen
calvin
cid:48
operation
pushes
transmitted
codeword
towards
codeword
selected
calvin
calvin
exhausted
budget
errors
moves
erasures
erases
entry
diﬀers
cid:48
calvin
cid:63
budget
allows
erase
symbols
symmetrization
techniques
e.g.
show
constant
probability
bob
unable
determine
whether
alice
transmitted
codeword
one
chosen
calvin
causing
decoding
error
probability
1/2
case
prove
bound
remaining
budget
calvin
errors
erasures
must
suﬃce
push
codeword
alice
half
distance
towards
chosen
calvin
using
q-ary
plotkin
bound
additional
ideas
one
show
constant
probability
distance
two
codewords
locations
push
phase
1/q
implying
calvin
needs
remaining
budget
last
channel
uses
number
erasures
plus
twice
number
errors
least
1/q
roughly
speaking
calculations
show
every
corresponding
threshold
calvin
budget
suﬃces
push
phase
however
one
would
like
long
enough
setting
small
shorten
babble
phase
clavin
increase
block
length
push
phase
increase
budget
needed
calvin
overcome
potential
distance
1/q
alice
codeword
long
babble
phase
makes
calvin
attack
look
similar
output
random
channel
resulting
weaker
outer
bound
threshold
set
minimal
value
possible
still
leaves
calvin
suﬃcient
push
budget
given
cid:63
parameter
set
roughly
value
speciﬁed
theorem
1.1
implies
babble
phase
behaves
like
q-ary
symmetric
channel
error
parameter
¯p/αq
recall
babble
phase
calvin
changing
¯pn
randomly
chosen
locations
locations
phase
hence
upper
bound
obtained
case
rate
corresponding
q-ary
symmetric
channel
block
length
exactly
stated
term
theorem
1.1.
see
shortly
achievability
scheme
setting
rate
upper
bound
optimal
allows
overcome
calvin
pushing
capabilities
allows
successful
communication
implying
tight
characterization
capacity
online
model
1.3.2
achievability
codes
encoder
alice
uses
internal
randomness
known
bob
calvin
choice
transmitted
codeword
designed
allow
high
probability
successful
communication
matter
message
alice
sending
bob
use
chunked
random
codes
described
shortly
pick
codes
uniformly
random
random
ensemble
speciﬁed
section
prove
w.h.p
code
distribution
code
chosen
random
allows
reliable
communication
decoder
involves
two
major
phases
list
decoding
phase
decoder
obtains
short
list
messages
include
one
transmitted
unique
decoding
phase
list
reduced
single
message
roughly
bob
decoding
process
divides
received
word
two
parts
symbols
received
given
time
cid:63
symbols
received
afterwards
list
decoding
done
using
ﬁrst
part
received
word
process
unique
decoding
list
done
using
second
part
consider
ﬁrst
special
case
erasures
case
given
parameter
cid:63
speciﬁes
fraction
symbols
erased
adversary
received
word
decoder
bob
pin-point
value
cid:63
allow
successful
decoding
speciﬁcally
adversarial
behavior
show
existence
value
cid:63
one
hand
allows
bob
obtain
small
list
messages
ﬁrst
part
received
word
guarantees
fraction
symbols
erased
adversary
second
part
received
word
suﬃce
confuse
bob
two
messages
list
holds
notice
duality
parameter
upper
bound
parameter
cid:63
upper
bound
show
rate
matter
code
shared
alice
bob
exists
threshold
bob
uniquely
decoding
based
ﬁrst
received
symbols
calvin
suﬃcient
remaining
budget
cause
decoding
error
remaining
symbols
lower
bound
rate
suggest
coding
scheme
show
exists
threshold
cid:63
bob
list
decode
based
ﬁrst
cid:63
received
symbols
calvin
suﬃcient
budget
left
cause
decoding
error
remaining
cid:63
symbols
rate
list
decoding
lower
bound
resembles
q-ary
symmetric
channel
upper
bound
obtain
tight
results
ability
list
decode
obtained
using
standard
probabilistic
arguments
take
account
block
length
cid:63
number
erasures
cid:63
ﬁrst
part
received
word
ability
uniquely
decode
obtained
list
involves
delicate
analysis
uses
stochastic
nature
encoding
causality
constraint
calvin
particular
use
fact
secret
symbols
used
encoding
ﬁrst
part
codeword
position
cid:63
independent
used
second
part
independence
useful
separating
two
decoding
phases
sense
casual
adversary
time
cid:63
acting
knowledge
whatsoever
secret
symbols
used
alice
time
cid:63
lack
knowledge
sets
stage
unique
decoding
phase
accommodate
diﬀerent
potential
values
cid:63
designing
stochastic
encoding
process
diﬀerent
parts
codewords
rely
independent
secret
symbols
alice
namely
divide
coding
process
chunks
chunk
random
stochastic
code
length
small
parameter
uses
independent
randomness
alice
ﬁnal
code
alice
concatenation
chunks
setting
small
enough
allows
enough
ﬂexibility
manage
possible
value
cid:63
chosen
bob
decoder
encoding
decoding
process
channel
presence
errors
erasures
follow
line
analysis
speciﬁed
erasure
case
one
major
signiﬁcant
diﬀerence
bob
know
symbols
transmitted
codeword
error
thus
studying
received
word
bob
able
identify
location
cid:63
desired
properties
overcome
diﬃculty
design
iterative
decoding
process
bob
starts
small
value
performs
attempt
decode
decoding
process
ﬁrst
list
decodes
using
ﬁrst
part
received
word
uniquely
decodes
list
decoding
done
according
certain
guessed
value
ˆpt
fraction
symbol
errors
ﬁrst
part
received
word
ˆpt
carefully
designed
function
also
referred
trajectory
ﬁxed
known
parties
involved
communication
trajectory
ˆpt
chosen
way
guarantees
successful
decoding
location
ˆpt
equals
fraction
symbols
actually
changed
calvin
location
respect
unerased
positions
speciﬁcally
ˆpt
guarantees
bob
able
obtain
small
list
messages
list
decoding
position
uniquely
decode
list
remaining
corruption
power
calvin
limited
analyzing
conditions
gives
range
possible
trajectories
ˆpt
depicted
figure
denotes
number
erasures
bob
receives
channel
uses
set
ˆpt
otherwise
set
ˆpt
cid:63
cid:17
cid:16
cid:63
q−1
cid:63
increases
grows
note
since
bounded
cid:63
therefore
ranges
quantity
always
takes
possible
integer
values
least
cid:63
q−1
cid:63
cid:17
q−1
cid:63
cid:17
value
ˆpt
cid:16
q−1
q−1
cid:63
cid:17
q−1
q−1
cid:16
cid:16
cid:17
cid:16
t−λt
figure
range
trajectory
ˆpt
shaded
function
1/8
bounds
analytical
however
plot
made
numerically
using
000.
curves
extremal
curves
calvin
true
corruption
fraction
curves
bound
region
ˆpt
horizontal
lines
¯popt
optimal
upper
bound
given
references
calvin
follow
attack
given
upper
bound
proof
n¯popt
red
horizontal
line
decoding
scheme
ˆpt
point
topt
topt
red
vertical
line
values
location
ˆpt
diﬀer
ˆpt
show
iterative
decoding
bob
successful
threshold
location
indeed
ˆpt
otherwise
show
unique
decoding
phase
fail
sense
bob
receive
message
decoding
process
identifying
failure
decoding
process
bob
increases
repeats
decoding
attempt
crux
analysis
lies
proof
eventually
matter
behavior
calvin
value
denoted
cid:63
ˆpt
cid:63
approximately
cid:63
decoding
succeeds
establishing
existence
trajectory
ˆpt
discussed
proving
point
must
close
central
part
proof
1.4
structure
section
formally
present
channel
model
encoder
decoding
process
addition
present
careful
description
adversarial
behavior
section
presents
overview
00.511.522.533.54
cid:1
cid:1
10400.10.20.30.40.50.60.70.80.91
cid:2
cid:1
cid:1
cid:3
cid:2
cid:1
1243
cid:2
cid:4
cid:1
cid:2
cid:3
cid:2
cid:1
cid:1
cid:3
cid:2
cid:1
cid:1
cid:2
cid:3
cid:2
cid:1
code
analysis
proof
achievability
theorem
1.1.
due
space
limitations
technical
claims
proofs
appear
appendix
model
output
alphabet
channel
adv
cid:8
advi|i
cid:9
sequence
mappings
represents
channel
model
positive
integer
let
denote
set
···
transmission
duration
symbols
q-ary
causal
adversarial
error-erasure
channel
characterized
two
triples
cid:63
adv
cid:63
fractions
symbol
errors
symbol
erasures
calvin
impose
codeword
···
···
input
adversarial
behavior
time
step
precisely
map
advi
i×y
i−1
function
time
transmitting
i-th
symbol
maps
sequence
channel
inputs
time
···
together
sequence
previous
channel
outputs
time
···
yi−1
i−1
output
symbol
functions
advi
must
satisfy
adversarial
power
constraint
namely
point
time
total
number
errors
erasures
exceed
cid:63
respectively
proof
use
random
code
distribution
deﬁne
distribution
codes
distribution
claim
existence
ﬁxed
code
allows
reliable
communication
alice
bob
channel
model
code
construction
denotes
code
rate
private
secret
rate
encoder
deﬁned
explicitly
shortly
quantization
parameter
speciﬁed
let
cid:2
qnr
cid:3
denote
alice
message
set
cid:2
qns
cid:3
set
private
random
secrets
available
alice
encoder
randomness
neither
shared
receiver
adversary
let
uniform
distribution
stochastic
codes
let
···
c1/θ
stochastic
codes
i.i.d
according
probability
distribution
speciﬁcally
1/θ
corresponding
stochastic
code
map
chosen
distribution
cid:0
s1/θ
cid:1
encoder
given
message
1/θ
secrets
···
s1/θ
codeword
length
respect
message
1/θ
secrets
deﬁned
concatenation
1/θ
chunks
sub-codewords
···
c1/θ
i-th
sub-codeword
entire
codeword
denotes
concatenation
two
chunks
sub-codewords
distinguish
concatenated
code
code
chunk
call
···
c1/θ
sub-codes
hereafter
code
analysis
focuses
two
diﬀerent
parts
entire
code
deﬁned
follows
deﬁnition
2.1.
let
code
block-length
consist
1/θ
sub-codes
i.e.
···
c1/θ
let
2nθ
···
code
preﬁx
respect
concatenation
ﬁrst
sub-codes
deﬁnition
2.2.
let
code
block-length
consist
1/θ
sub-codes
i.e.
···
c1/θ
let
2nθ
···
code
suﬃx
respect
concatenation
last
sub-codes
analysis
convenient
describe
encoding
scheme
alice
causal
manner
namely
assume
secret
value
corresponding
encoding
i-th
chunk
chosen
alice
immediately
i-th
chunk
transmitted
sooner
mentioned
show
positive
probability
code
chosen
random
based
distribution
certain
properties
allow
reliable
communication
channel
model
cid:16
cid:17
decoding
process
decoding
process
bob
done
iterative
manner
speciﬁcally
upon
receiving
entire
codeword
errors
erasures
ﬁxed
bob
identiﬁes
smallest
value
corresponding
end
location
chunk
attempts
correctly
decode
transmitted
message
based
codeword
preﬁx
suﬃx
respect
position
decoding
process
terminated
message
decoded
bob
otherwise
value
increased
chunk
size
bob
attempts
decode
process
continues
reaches
approximately
end
codeword
decodings
succeeds
decoder
error
declared
q−1
cid:63
q−1
9q2
cid:17
cid:63
cid:63
cid:16
q−1
cid:1
messages
phase
bob
obtains
list
show
list
size
consists
cid:0
attempt
decoding
divided
two
phases
first
position
bob
chooses
estimate
ˆpt
fraction
errors
respect
unerased
positions
used
calvin
codeword
preﬁx
knθ
proof
come
show
ˆpt
satisﬁes
two
important
conditions
list-decoding
condition
energy
bounding
condition
see
claim
b.7
list-decoding
condition
allows
bob
decode
codeword
preﬁx
···
list
decoder
list
size
messages
case
ˆpt
equals
true
fraction
symbol
errors
respect
unerased
positions
holds
transmitted
message
next
second
phase
energy
bounding
condition
states
ˆpt
equals
symbol
errors
codeword
suﬃx
respect
position
therefore
show
bob
use
natural
consistency
decoder
deﬁned
determine
whether
stop
continue
decoding
process
precisely
decoding
process
continues
consistency
decoder
fails
return
message
stops
message
decoded
messages
decoder
also
stops
reached
size
q−1
cid:63
number
erasures
position
deﬁnition
2.3.
let
let
cid:48
suﬃx
consistent
word
suﬃx
cid:48
q−1
agree
cid:48
deﬁnition
2.4.
consistency
decoder
applied
code
suﬃx
ck+1◦ck+2◦···◦c1/θ
respect
position
knθ
list
decoder
takes
word
suﬃx
received
word
cid:48
returns
unique
message
list
one
whose
codeword
suﬃxes
consistent
cid:48
one
message
exists
decoding
error
declared
n−t
two
word
suﬃxes
respect
position
word
fraction
unerased
positions
n−t−np
cid:63
+λt
9q2
cid:63
appear
analysis
let
cid:16
cid:17
cid:16
formally
decoder
process
bob
described
follows
essentially
use
following
deﬁnition
ˆpt
estimate
calvin
error
corruption
fraction
respect
unerased
positions
time
used
bob
slightly
revised
later
deﬁnition
b.3
robust
slight
slacknesses
ˆpt
otherwise
q−1
q−1
cid:63
cid:17
cid:16
q−1
value
ˆpt
q−1
cid:63
cid:17
cid:63
ˆpt
cid:63
q−1
cid:17
cid:16
cid:17
t−λt
grows
q−1
cid:63
increases
constant
design
parameter
considered
arbitrarily
small
description
recall
cid:16
q−1
cid:63
cid:17
identify
position
k0nθ
integer
smallest
integer
cid:16
q−1
cid:16
λt0
q−1
q−1
cid:63
cid:17
list-decode
code
preﬁx
···
respect
position
obtain
list
messages
size
list-decoding
radius
ˆpt
precisely
message
list
codeword
corresponding
unerased
symbols
codeword
preﬁx
respect
position
distance
ˆpt
corresponding
unerased
symbols
received
word
preﬁx
verify
codeword
suﬃxes
respect
position
corresponding
messages
list
consistency
decoder
compares
symbols
unerased
positions
speciﬁcally
consider
hamming
balls
radius
equal
cid:63
centered
codeword
suﬃx
codeword
corresponding
messages
list
corresponding
received
word
suﬃx
outside
balls
increase
goto
step
received
word
suﬃx
lies
exactly
one
balls
decode
message
corresponding
center
ball
received
word
suﬃx
lies
one
ball
decoding
error
declared
cid:16
q−1
cid:17
cid:63
9q2
every
message
bob
decodes
correctly
estimate
equals
bob
decodes
correctly
cid:63
codeword
suﬃx
codewords
corresponding
messages
list
consistent
received
word
corresponds
message
show
indeed
happens
w.h.p
random
secrets
n−t
cid:63
used
alice
codeword
suﬃx
respect
position
cid:63
bob
estimate
equal
bob
said
make
decoding
error
probability
error
message
deﬁned
probability
alice
private
secrets
bob
decodes
incorrectly
probability
error
code
deﬁned
maximum
probabilities
error
message
messages
rate
said
achievable
every
every
suﬃciently
large
exists
code
block
length
allows
alice
communicate
r−β
distinct
messages
bob
probability
error
supremum
achievable
rates
capacity
channel
adversarial
behavior
behavior
calvin
speciﬁed
channel
model
particular
interested
calvin
corrupts
codeword
errors
characterized
function
deﬁned
speciﬁes
many
errors
ejected
calvin
up-to
position
normalized
number
unerased
positions
refer
trajectory
note
exact
trajectory
used
calvin
known
decoder
bob
deﬁnition
2.5
calvin
trajectory
let
codeword
length
consist
1/θ
chunks
sub-
codewords
let
2nθ
···
let
actual
fraction
symbol
errors
respect
unerased
positions
codeword
preﬁx
respect
position
analysis
assume
calvin
certain
capabilities
may
beyond
available
causal
adversary
without
loss
generality
studying
lower
bounds
achievable
rate
work
assume
trajectory
ˆpt
bob
uses
decoding
process
known
calvin
implies
show
calvin
knows
position
cid:63
bob
eventually
stops
decoding
process
addition
assume
list
messages
obtained
bob
list
decoding
process
determined
explicitly
calvin
moreover
assume
calvin
knows
message
priori
every
list-decoding
position
knθ
stress
subsequent
secrets
namely
sk+1
sk+2
···
s1/θ
codeword
suﬃx
unknown
calvin
indeed
given
causal
nature
alice
encoding
secrets
even
chosen
alice
point
time
fact
secrets
hidden
calvin
implies
sk+1
sk+2
···
s1/θ
completely
independent
list
obtained
bob
list
decoding
determined
calvin
fact
crucial
analysis
also
strengthen
calvin
allowing
choose
symbols
corrupt
position
cid:63
cid:63
non-causally
namely
assume
calvin
chooses
corruption
pattern
looking
ahead
remaining
symbols
transmitted
codeword
show
matter
corruptions
chosen
codeword
suﬃx
cid:63
cid:63
cid:63
symbols
error
fact
distribution
cid:63
cid:63
···
s1/θ
independent
list
allow
show
bob
succeeds
decoding
cid:16
q−1
cid:17
cid:63
9q2
code
analysis
due
space
limitations
technical
details
proof
appear
entirely
appendix
follows
give
roadmap
proof
including
major
high-level
arguments
used
appendix
throughout
constant
design
parameter
considered
arbitrarily
small
existence
trajectory
ˆpt
analysis
bob
decoding
begins
selecting
decoding
reference
trajectory
ˆpt
deﬁnition
b.3
proxy
trajectory
calvin
trajectory
recall
fraction
errors
respect
unerased
positions
codeword
preﬁx
accordingly
ˆpt
fraction
symbols
respect
unerased
positions
bob
assumes
errors
general
trajectories
ˆpt
equal
show
claim
b.7
position
q−1
selected
decoding
reference
trajectory
ˆpt
satisﬁes
two
important
conditions
list-decoding
condition
energy
bounding
condition
introduced
q−1
cid:63
cid:16
cid:17
ˆpt
ˆpt
9q2
cid:63
list
decoding
condition
guarantees
small
list
size
decoding
done
radius
ˆpt
energy
bounding
condition
restricts
remaining
errors
adversary
codeword
suﬃx
bob
estimate
ˆpt
approximately
correct
prove
correctness
decoding
procedure
must
introduce
new
trajectory
˜pt
closely
related
counterpart
ˆpt
sense
˜pt
approximately
equals
ˆpt
former
slightly
smaller
latter
parameter
introduced
allow
robustness
analysis
absorbs
certain
slacknesses
result
code
construction
analysis
technique
e.g.
fact
chunk
size
made
small
give
precise
deﬁnitions
times
better
understood
intuitively
reader
keeps
discussion
mind
notation
given
table
existence
position
cid:63
ˆpt
cid:63
cid:39
cid:63
next
analysis
chooses
integer
position
k0nθ
cid:39
λt0
benchmarking
position
separate
analysis
two
cases
based
whether
pt0
greater
ˆpt0
use
following
classiﬁcation
q−1
cid:63
q−1
cid:16
cid:17
deﬁnition
3.1
high
type
trajectory
trajectory
calvin
consider
values
ˆpt
position
pt0
ˆpt0
calvin
trajectory
high
type
trajectory
deﬁnition
3.2
low
type
trajectory
trajectory
calvin
consider
values
ˆpt
position
pt0
ˆpt0
calvin
trajectory
low
type
trajectory
high
type
trajectory
calvin
show
claim
b.8
always
intersects
ˆpt
point
matter
corruption
pattern
chosen
calvin
i.e.
point
bob
estimate
ˆpt
equal
actual
amount
errors
moreover
claim
b.9
claim
b.10
implies
value
cid:63
chunk
end
falls
immediately
intersection
point
guaranteed
remaining
error
budget
calvin
low
sense
number
errors
calvin
introduce
codeword
suﬃx
respect
cid:63
less
cid:63
cid:63
cid:63
hand
low
type
trajectory
calvin
already
know
approximately
ˆpt
point
nearly
thus
show
claim
b.11
setting
cid:63
equal
guaranteed
remaining
error
budget
calvin
low
sense
number
errors
calvin
introduce
codeword
suﬃx
respect
cid:63
less
cid:63
cid:63
cid:63
cid:63
formally
cid:16
q−1
cid:17
cid:63
cid:16
q−1
cid:17
9q2
9q2
deﬁnition
3.3.
let
9q2
let
2nθ
···
pt0
ˆpt0
cid:63
k0nθ
pt0
ˆpt0
cid:63
smallest
value
cid:63
−nθ
ˆpt
cid:63
−nθ
cid:63
ˆpt
cid:63
success
bob
decoding
bob
starts
decoding
position
continues
decode
subsequent
chunk
ends
message
returned
consistency
decoder
bob
reaches
end
received
word
claim
b.12
corollary
b.13
via
list
decoding
condition
guarantee
bob
ﬁrst
phase
decoding
always
obtain
list
messages
list
size
cid:0
cid:1
list
decoder
cid:63
9q2
n−t−np
cid:63
+λt
fraction
remaining
part
unerased
symbols
codeword
matter
position
currently
considered
analysis
claim
b.12
corollary
b.13
claims
come
w.h.p
random
code
construction
moreover
energy
bounding
condition
implies
case
cid:39
ˆpt
unused
errors
left
calvin
less
q−1
start
studying
case
current
iteration
bob
satisﬁes
cid:63
implies
cid:39
ˆpt
claim
b.17
claim
b.18
claim
b.20
show
cid:63
calvin
remaining
error
budget
suﬃcient
mislead
consistency
decoder
allow
unique
decoding
list
messages
bob
holds
namely
show
high
probability
secret
random
symbols
alice
used
encoding
process
code
design
guarantees
message
list
consistent
transmitted
codeword
one
transmitted
alice
precisely
consider
consistency
checking
phase
bob
iteration
cid:63
iteration
know
via
energy
bounding
condition
number
unused
errors
calvin
less
q−1
n−t−np
cid:63
+λt
fraction
remaining
part
unerased
symbols
codeword
point
time
bob
holds
small
list
messages
implicitly
determined
calvin
via
consistency
decoder
wishes
ﬁnd
unique
message
list
transmitted
transmitted
message
list
small
guarantee
high
probability
code
design
codeword
suﬃxes
corresponding
roughly
distance
n−t
q−1
codeword
suﬃx
message
list
turn
implies
given
bound
calvin
remaining
error
budget
decoding
succeed
however
analysis
misleading
one
must
overcome
adversarial
choice
establishing
correct
decoding
note
na¨ıve
use
union
bound
suﬃce
overcome
potential
lists
successful
decoding
regardless
calvin
adversarial
behavior
use
randomness
alice
stochastic
encoding
known
priori
calvin
fact
calvin
causal
recall
every
9q2
cid:63
message
encoded
several
codewords
based
randomness
alice
let
slef
sright
collection
alice
random
symbols
used
position
cid:63
respectively
calvin
perhaps
partially
determines
list
may
assume
full
knowledge
slef
however
causal
nature
knowledge
regarding
sright
list
obtained
position
cid:63
bob
may
take
advantage
fact
independent
randomness
sright
used
alice
speciﬁcally
instead
considering
single
codeword
analysis
corresponds
consider
family
codewords
one
hand
share
speciﬁc
slef
corresponds
calvin
view
position
cid:63
diﬀerent
sright
calvin
perspective
position
cid:63
codewords
family
equivalent
completely
match
view
far
using
family
codewords
independent
analysis
allowing
decoding
fail
small
fraction
enables
amplify
success
rate
decoding
procedure
extent
used
needed
union
bound
full
analysis
given
claim
b.17
claim
b.18
claim
b.20
address
case
cid:54
cid:63
claim
b.10
case
previous
discussions
holds
high
type
trajectory
calvin
ˆpt
˜pt
cid:54
cid:63
show
decoding
process
bob
return
codewords
messages
list
fail
consistency
test
case
continue
next
value
next
chunk
end
summarize
properties
code
claim
b.21
properties
established
bob
iterative
decoder
show
claim
b.23
bob
able
correctly
decode
transmitted
message
w.h.p
randomness
alice
finally
theorem
b.24
show
channel
capacity
claimed
indeed
achievable
depict
ﬂow
claims
corollaries
theorems
proof
achievability
figure
remark
scenario
wherein
calvin
lookahead
also
handled
via
codes
roughly
back
rate
trajectory
ˆpt
gets
shifted
left
sacriﬁce
symbols
calvin
demanding
stringent
energy-bounding
condition
satisﬁed
block
length
second
part
succeeding
cid:63
reduced
tweaks
remainder
analysis
n-lookahead
codes
identical
causal
codes
discussed
references
gilbert
comparison
signalling
alphabets
bell
system
technical
journal
:504–522
1952
varshamov
estimate
number
signals
error
correcting
codes
dokl
acad
nauk
117:739–741
1957
mceliece
rodemich
rumsey
welch
new
upper
bounds
rate
ieee
transactions
information
theory
code
via
delsarte-macwilliams
inequalities
:157–166
1977
dey
jaggi
langberg
codes
online
adversaries
part
large
alphabets
ieee
transactions
information
theory
:3304–3316
2013
langberg
jaggi
dey
binary
causal-adversary
channels
ieee
international
symposium
information
theory
proceedings
isit
pages
2723–2727
2009
haviv
langberg
beating
gilbert-varshamov
bound
online
channels
ieee
international
symposium
information
theory
proceedings
isit
pages
1392–1396
2011
dey
jaggi
langberg
sarwate
improved
upper
bounds
capacity
binary
channels
causal
adversaries
ieee
international
symposium
information
theory
proceedings
isit
pages
681–685
2012
bassily
smith
causal
erasure
channels
proceedings
acm-siam
symposium
discrete
algorithms
soda
pages
1844–1857
2014
chen
jaggi
langberg
characterization
capacity
online
causal
binary
channels
proceedings
forty-seventh
annual
acm
symposium
theory
computing
pages
287–296
acm
2015
lapidoth
narayan
reliable
communication
channel
uncertainty
ieee
transactions
information
theory
:2148–2177
1998
langberg
oblivious
channels
capacity
ieee
transactions
information
theory
:424–429
2008
guruswami
smith
codes
computationally
simple
channels
explicit
constructions
optimal
rate
proceedings
51st
annual
ieee
symposium
foundations
computer
science
focs
pages
723–732
ieee
2010
dey
jaggi
langberg
sarwate
upper
bounds
capacity
binary
channels
causal
adversaries
ieee
transactions
information
theory
:3753–3763
2013
dey
jaggi
langberg
sarwate
coding
delayed
adversaries
ieee
international
symposium
information
theory
proceedings
isit
pages
285–289
2010
mazumdar
capacity
memoryless
adversary
arxiv
preprint
arxiv:1401.4642
2014
blackwell
breiman
thomasian
capacities
certain
channel
classes
random
coding
annals
mathematical
statistics
pages
558–567
1960
blake
mullin
introduction
algebraic
combinatorial
coding
theory
academic
press
inc.
1976
csiszar
narayan
capacity
arbitrarily
varying
channel
revisited
positivity
constraints
ieee
transactions
information
theory
:181–193
1988
guruswami
list
decoding
error-correcting
codes
lecture
notes
computer
science
volume
3282-2005
springer
2001.
appendices
converse
start
summarizing
several
deﬁnitions
claims
detailed
presentations
claims
followed
summary
depict
ﬂow
claims
theorems
figure
summary
event
deﬁnitions
figure
organization
claims
theorems
converse
event
babble-attacked
word
preﬁx
suﬃcient
entropy
alice
message
conditioned
babble-attacked
word
preﬁx.event
𝐸𝐸4
push-attacked
word
suﬃx
roughly
distance
away
corresponding
codewordsuﬃxes
alice
message
calvin
message.event
𝐸𝐸1
certain
number
messages
drawn
conditional
distribution
messages
given
babble-attacked
word
preﬁx
distinct.event
𝐸𝐸3
hamming
distance
codewordsuﬃxes
corresponding
alice
message
calvin
message
large.event
𝐸𝐸2
calvin
chosen
message
diﬀerent
alice
message.claim
a.2ℙ𝐸𝐸is
bounded
away
zero
theorem
a.1
plotkinbound
codewordsin
code
large
minimum
distance
lemma
a.3the
probability
i.i.d
random
variables
nonzero
entropy
distinct
bounded
away
zero
theorem
a.7under
babble-and-push
attack
strategy
average
error
probability
bounded
away
zero.claim
a.6ℙ𝐸𝐸4𝐸𝐸2𝐸𝐸3is
large.claim
a.4ℙ𝐸𝐸1𝐸𝐸is
bounded
away
zero.claim
a.5ℙ𝐸𝐸2𝐸𝐸3𝐸𝐸is
bounded
away
zero
event
babble-attacked
word
preﬁx
suﬃcient
entropy
alice
message
i.e.
transmitted
message
conditioned
babble-attacked
word
preﬁx
event
certain
number
messages
drawn
conditional
distribution
messages
given
babble-attacked
word
preﬁx
distinct
event
calvin
chosen
message
diﬀerent
alice
message
event
hamming
distance
codeword
suﬃxes
respect
pushing
phase
attack
corresponding
alice
message
calvin
message
large
event
resulting
word
suﬃx
respect
pushing
phase
attack
roughly
distance
away
codeword
suﬃxes
respect
pushing
phase
attack
corresponding
alice
message
calvin
message
summary
claims
theorems
theorem
a.1
codewords
code
large
minimum
distance
claim
a.2
probability
happens
bounded
away
zero
lemma
a.3
probability
i.i.d
random
variables
nonzero
entropy
distinct
bounded
away
zero
claim
a.4
probability
e1|e
happens
bounded
away
zero
claim
a.5
probability
e2e3|e
happens
bounded
away
zero
claim
a.6
probability
e4|e2e3
happens
large
theorem
a.7
babble-and-push
attack
strategy
average
error
probability
bounded
away
zero
let
let
cid:16
q−1
fraction
symbol
errors
cid:63
cid:16
cid:17
q−1
cid:17
q−1
erasures
let
following
unless
otherwise
speciﬁed
refers
source
entropy
symbols
q-ary
entropy
obtained
normalizing
standard
binary
entropy
factor
log
refers
q-ary
entropy
function
namely
logq
logq
logq
q−1
cid:63
fraction
symbol
babble-and-push
attack
babble
let
cid:0
cid:1
position
transmitted
codeword
calvin
adopts
babble
strategy
calvin
chooses
random
subset
n¯p
indices
uniformly
set
n¯p-sized
subset
calvin
changes
symbol
precisely
chosen
calvin
uniformly
···
push
let
ﬁrst
symbols
transmitted
alice
ﬁrst
symbols
resulting
calvin
babble
attack
namely
···
···
calvin
constructs
set
pairs
encodings
close
speciﬁcally
set
constructed
calvin
ﬁrst
symbols
next
calvin
chooses
element
cid:48
cid:48
byb
uniformly
random
considers
corresponding
encoding
cid:48
cid:48
cid:48
cid:48
···
cid:48
cid:48
byb
n¯p
cid:54
cid:48
probability
half
calvin
uses
errors
calvin
uses
errors
calvin
erases
subsequent
symbols
whenever
cid:54
cid:48
calvin
uses
cid:63
erasures
calvin
sets
cid:48
theorem
a.1
q-ary
plotkin
bound
qdmin
qdmin−
q−1
codewords
q-ary
code
block
length
minimum
distance
dmin
cid:16
cid:17
let
random
variable
corresponding
alice
input
message
random
variable
cor-
responding
alice
input
codeword
random
variable
corresponding
output
channel
let
random
variables
corresponding
respectively
let
cid:8
cid:8
u|yb
cid:9
cid:9
claim
a.2
let
cid:0
cid:1
babble-and-push
attack
proof
considering
entropy
u|yb
u|yb
cid:18
cid:19
cid:17
cid:17
cid:16
n¯p
cid:17
cid:18
cid:18
cid:19
cid:19
cid:18
cid:17
cid:18
cid:19
cid:19
cid:16
cid:19
cid:17
cid:18
cid:18
cid:19
cid:19
cid:18
cid:19
cid:19
follows
data-processing
inequality
follows
substituting
cid:0
cid:0
follows
assuming
monotonic
increasing
function
variate
therefore
expected
value
u|yb
least
applying
markov
inequality
random
variable
u|yb
follows
fact
xhq
cid:16
cid:17
cid:17
cid:16
maximum
value
u|yb
cid:105
u|yb
cid:1
cid:1
cid:16
cid:16
cid:18
cid:18
cid:16
cid:104
therefore
cid:104
u|yb
cid:105
follows
fact
lemma
a.3
let
random
variable
discrete
ﬁnite
set
entropy
let
···
i.i.d
copies
···
distinct
cid:18
logq
logq
cid:19
k−1
logq
|v|
proof
fix
let
···
···
let
vi+1
denotes
indicator
function
write
distribution
vi+1
vi+1
v|wi
cid:88
0,1
bound
entropy
vi+1
vi+1|wi
cid:88
logq
logq
|v|
logq
0,1
vi+1
v|wi
since
hence
logq
logq
|v|
logq
logq
logq
logq
|v|
logq
logq
logq
|v|
event
distinct
equivalent
event
···
vi+1
implies
claim
a.4
let
ρu|yb
conditional
distribution
given
babble-and-push
attack
let
···
random
variables
drawn
i.i.d
according
ρu|yb
let
···
distinct
large
enough
e1|e
cid:16
cid:17
k−1
proof
claim
a.2
given
event
u|yb
|v|
cid:18
logq
logq
cid:19
k−1
e1|e
lemma
a.3
setting
large
enough
thus
logq
logq
cid:17
k−1
e1|e
cid:16
let
cid:48
random
choice
calvin
message
cid:48
random
variable
codeword
corre-
sponding
cid:48
let
xb+1
xb+2
···
remaining
part
input
codeword
push
phase
corresponding
random
variable
similarly
cid:48
part
codeword
chosen
calvin
push
phase
cid:48
let
denote
hamming
distance
function
two
vectors
corresponding
random
variable
b+2
···
cid:48
cid:48
b+1
cid:48
claim
a.5
let
cid:110
cid:0
cid:48
cid:54
cid:48
cid:1
cid:63
cid:111
babble-and-push
attack
e2e3|e
proof
claim
a.4
setting
lower
bound
probability
holds
given
e2|e
distribution
ρu|yb
distinct
least
cid:0
general
claim
a.4
shows
probability
messages
drawn
conditional
shows
exist
q-ary
codes
block
length
minimum
distance
qd−
q−1
n−b
codewords
let
byb
set
mutually
independent
pairs
uniformly
byb
setting
exist
codewords
cid:48
corresponding
pairs
cid:48
cid:48
bybwith
distance
satisfying
cid:1
k−1
hand
plotkin
bound
theorem
a.1
cid:1
k−1
claim
a.4
theorem
a.1
together
imply
probability
least
cid:0
solving
using
cid:0
cid:1
cid:63
cid:18
cid:19
cid:63
cid:63
cid:63
let
cid:63
probability
selection
set
event
hold
let
fraction
pairs
byb
satisfy
cid:54
k2γ
cid:35
cid:18
cid:19
codewords
corresponding
pairs
set
corresponding
message
random
variables
however
probability
···
distance
less
distinct
least
one
pair
codewords
···
distinct
cid:34
cid:91
cid:34
cid:91
cid:110
cid:111
cid:35
cid:17
cid:16
since
event
analyzed
includes
cid:16
cid:17
cid:16
cid:17
hence
deﬁnition
e2e3|e
claim
a.6
let
hamming
distance
chosen
alice
cid:48
corresponding
part
word
received
bob
resulting
calvin
push
attack
let
chosen
calvin
let
cid:26
cid:18
cid:19
cid:27
babble-and-push
attack
e4|e2e3
2−ω
n2
proof
assume
calvin
erases
cid:63
symbols
push
phase
let
cid:63
hamming
distance
cid:48
without
considering
positions
corresponding
erasures
constraints
calvin
error
budget
calvin
would
change
locations
expectation
conditioned
event
event
cid:63
4this
actually
corresponds
calvin
strongest
attack
babble
phase
uses
fraction
budget
symbols
errors
push
phase
potentially
uses
remainder
symbol
error
budget
also
cid:63
erasure
budget
assume
probability
half
calvin
changes
original
symbol
intended
symbol
cid:48
bound
probability
number
changes
symbols
deviates
expectation
push
attack
2−ω
n2
chernoﬀ
theorem
a.7
code
stochastic
encoding
rate
babble-and-push
strategy
average
error
probability
lower
bounded
cid:16
cid:17
cid:17
cid:1
symbols
drawn
cid:0
cid:48
cid:16
proof
idea
behind
proof
conditioned
events
calvin
symmetrize
channel
calvin
corrupt
symbols
manner
bob
unable
distinguish
two
possible
codewords
cid:48
corresponding
two
diﬀerent
messages
cid:48
calvin
ensuring
probability
bounded
away
zero
word
received
bob
equally
likely
decoded
either
cid:48
corresponding
messages
cid:48
let
cid:48
cid:48
joint
distribution
received
word
end
babble
phase
alice
message
randomness
calvin
chosen
message
randomness
cid:48
cid:48
al-
ice
uniform
choice
calvin
attack
let
y|yb
cid:48
cid:48
conditional
distribution
calvin
attack
let
probabilistic
map
namely
mapping
random
variable
taking
values
error
probability
written
cid:88
cid:0
cid:48
cid:48
cid:1
cid:88
cid:0
y|yb
cid:48
cid:48
cid:1
cid:54
cid:48
cid:48
let
set
tuples
cid:48
cid:48
satisfying
events
claims
a.2
a.5
show
cid:0
cid:48
cid:1
suﬃciently
small
cid:48
cid:48
cid:54
cid:48
assuming
holds
since
calvin
change
symbol
diﬀerent
cid:48
half
corresponding
part
received
word
may
result
either
cid:48
thus
conditional
distribution
symmetric
probability
equal
probability
claim
a.6
cid:48
cid:48
cid:0
y|yb
cid:48
cid:48
cid:1
cid:0
y|yb
cid:48
cid:48
cid:1
cid:88
cid:0
yp|yb
cid:48
cid:48
cid:1
2−ω
n2
returning
overall
error
probability
let
unconditional
probability
bob
receiving
babble
phase
probability
alice
uniform
choice
calvin
babble
attack
since
posteriori
distributions
cid:48
cid:48
given
independent
uniform
byb
joint
distribution
written
cid:0
cid:48
cid:48
cid:1
|byb|2
cid:0
cid:48
cid:48
cid:1
therefore
yp|yb
cid:48
cid:48
yp|yb
cid:48
cid:48
hence
2¯
cid:88
cid:0
cid:48
cid:48
cid:1
cid:0
yp|yb
cid:48
cid:48
cid:1
cid:2
cid:54
cid:48
cid:3
cid:88
cid:0
yp|yb
cid:48
cid:48
cid:1
cid:54
cid:88
cid:0
cid:48
cid:48
cid:1
cid:88
cid:0
yp|yb
cid:48
cid:48
cid:1
cid:0
cid:54
cid:2
cid:54
cid:48
cid:3
cid:1
cid:88
cid:0
cid:48
cid:48
cid:1
cid:88
cid:0
yp|yb
cid:48
cid:48
cid:1
cid:16
2−ω
n2
cid:17
cid:88
achievability
start
summarizing
several
deﬁnitions
claims
detailed
presentations
deﬁnitions
claims
followed
summary
depict
ﬂow
claims
corollaries
theorems
figure
preliminary
deﬁnitions
technical
claims
deﬁnition
b.1
deﬁnes
calvin
trajectory
respect
unerased
positions
number
symbol
errors
normalized
number
unerased
positions
deﬁnition
b.2
deﬁnes
bob
guess
random
noise
¯pt
deriving
deﬁnition
decoding
reference
trajectory
ˆpt
deﬁnition
b.3
deﬁnes
bob
decoding
reference
trajectory
ˆpt
revision
deﬁni-
tion
given
section
deﬁnition
b.4
deﬁnes
two
types
trajectory
calvin
according
ˆpt0
deﬁnition
b.5
deﬁnes
energy
bounding
trajectory
˜pt
delimits
smallest
value
meets
energy
bounding
condition
lemma
b.6
technical
lemma
gives
certain
upper
bound
q-ary
entropy
function
list
decoding
energy
bounding
properties
claim
b.7
central
claim
shows
decoding
reference
trajectory
ˆpt
satisﬁes
list-decoding
condition
energy
bounding
condition
establishing
existence
correct
decoding
point
claim
b.8
calvin
trajectory
always
intersects
decoding
reference
trajectory
ˆpt
later
second
last
chunk
claim
b.9
high
type
trajectory
value
chunk
end
immediately
intersection
decoding
reference
trajectory
ˆpt
satisﬁes
energy
bounding
condition
recall
ˆpt
deﬁned
respect
unerased
positions
figure
organization
claims
corollaries
theorems
achievability
claim
b.7list-decoding
condition
energy
bounding
conditionhigh
type
trajectory
𝑝𝑝𝑡𝑡0≥�𝑝𝑝𝑡𝑡0
low
type
trajectory
𝑝𝑝𝑡𝑡0
�𝑝𝑝𝑡𝑡0
claim
b.10𝑝𝑝𝑡𝑡∗satisfies
energy
bounding
conditionclaim
b.9𝑝𝑝𝑡𝑡∗is
�𝑝𝑝𝑡𝑡∗and
�𝑝𝑝𝑡𝑡∗claim
b.8existence
intersection
point
𝑝𝑝𝑡𝑡and
�𝑝𝑝𝑡𝑡existence
correct
decoding
point
𝒕𝒕∗existence
correct
decoding
point
𝒕𝒕∗=𝒕𝒕𝟎𝟎claim
b.11𝑝𝑝𝑡𝑡0satisfies
energy
bounding
conditionlemma
b.6bounding
𝐻𝐻𝑞𝑞
list
decoding
message
list
size
𝓞𝓞𝟏𝟏𝝐𝝐claim
b.12list
size
code
prefix
corollary
b.13list
size
every
code
prefixexistence
good
code
suffixclaim
b.20
w.h.p
every
code
suffix
good
w.r.t
every
message
every
list
codewordsuffices
sequences
secretsclaim
b.18
w.h.p
code
suffix
good
w.r.t
message
list
codewordsuffices
sequences
secretsclaim
b.17
w.h.p
code
suffix
good
w.r.t
message
list
codewordsuffices
sequence
secretstheorem
b.24channel
capacityclaim
b.21good
properties
code
designclaim
b.23probability
decoding
error
claim
b.10
larger
˜pt
point
satisﬁes
energy
bounding
condition
claim
b.11
point
pt0
approximately
ˆpt0
satisﬁes
energy
bounding
condi-
tion
list
decoding
properties
claim
b.12
code
preﬁx
list
decoded
list
messages
size
cid:0
corollary
b.13
every
code
preﬁx
list
decoded
list
messages
size
cid:0
cid:1
high
cid:1
probability
high
probability
utilizing
energy
bounding
condition
deﬁnition
b.14
deﬁnes
distance
codeword
suﬃx
list
codeword
suﬃxes
deﬁnition
b.15
deﬁnes
certain
goodness
properties
code
suﬃx
respect
message
list
codeword
suﬃxes
messages
excluding
transmitted
message
sequence
secrets
deﬁnition
b.16
deﬁnes
σ-goodness
property
code
suﬃx
respect
message
list
codeword
suﬃxes
messages
excluding
transmitted
message
sequences
secrets
claim
b.17
code
suﬃx
good
respect
message
list
codeword
suﬃxes
messages
excluding
transmitted
message
sequence
secrets
claim
b.18
code
suﬃx
σ-good
respect
message
list
codeword
suﬃxes
messages
excluding
transmitted
message
claim
b.20
every
code
suﬃx
σ-good
respect
every
transmitted
message
every
list
codeword
suﬃxes
messages
excluding
transmitted
message
summary
proof
theorem
1.1
claim
b.21
high
probability
code
possesses
needed
properties
claim
b.23
high
probability
bob
succeeds
decoding
theorem
b.24
rephrasing
theorem
1.1
channel
capacity
cid:17
fraction
symbol
errors
cid:63
cid:16
cid:17
q−1
q−1
let
let
cid:16
symbol
erasures
cid:63
q−1
9q2
let
2nθ
···
let
assume
received
word
symbol
errors
cid:63
erasures
let
number
erasures
position
let
k0nθ
smallest
integer
λt0
let
θ3/q2
secret
rate
namely
qns
size
set
secrets
available
alice
q−1
cid:63
q−1
cid:16
cid:17
fraction
b.1
preliminaries
deﬁnition
b.1
calvin
trajectory
let
actual
fraction
symbol
errors
respect
unerased
positions
codeword
preﬁx
respect
position
deﬁnition
b.2
bob
guess
random
noise
¯pt
¯pt
cid:63
cid:18
cid:19
deﬁnition
b.3
bob
decoding
reference
trajectory
ˆpt
let
¯pt
¯pt
deﬁnition
b.2
q−1
¯pt
q−1
cid:63
cid:104
cid:104
cid:16
cid:16
cid:17
cid:16
q−1
cid:63
q−1
cid:63
cid:17
cid:16
q−1
cid:63
cid:17
cid:105
q−1
q−1
cid:63
cid:17
cid:17
q−1
q−1

¯pt
9q2α2
¯pt
ˆpt
¯pt
9q2α2
deﬁnition
b.4
trajectory
type
trajectory
calvin
consider
values
ˆpt
position
pt0
ˆpt0
calvin
trajectory
high
type
trajectory
otherwise
low
type
trajectory
deﬁnition
b.5
energy
bounding
trajectory
˜pt
let
¯pt
deﬁnition
b.2
q−1
¯pt
q−1
cid:63
¯pt
lemma
b.6
let
logq
logq
logq
1/q
1/2
¯pt
˜pt
¯pt
9q2
proof
prove
lemma
ﬁrst
show
log
log
cid:2
cid:1
cid:3
cid:0
since
cid:0
hand
cid:0
cid:2
cid:1
let
log
cid:48
cid:0
cid:1
cid:2
cid:1
cid:48
cid:0
cid:1
log
therefore
cid:1
cid:48
1−x
solving
cid:48
obtain
cid:3
log
cid:0
log
cid:1
thus
replacing
log
since
concave
namely
second
derivative
negative
1/q
therefore
cid:19
cid:19
cid:18
cid:18
cid:18
cid:18
logq
log
log
log
log
logq
log
log
cid:19
logq
cid:19
log
log
log
log
log
log
log
log
cid:19
monotonically
increasing
follows
follows
note
x−1√
1/2
x−1√
hence
follows
cid:18
cid:18
cid:18
cid:16
log
cid:19
log
cid:19
cid:17
log
b.2
list
decoding
energy
bounding
properties
cid:20
cid:19
cid:19
cid:21
q−1
cid:63
let
q−1
claim
b.7
let
cid:18
cid:104
q−1
exists
ˆpt
1/q
following
conditions
satisﬁed
cid:18
min
¯p∈
cid:16
q−1
cid:63
ˆpt
ˆpt
9q2
cid:63
cid:17
cid:16
q−1
cid:63
cid:17
cid:105
2/4
proof
first
note
exists
cid:104
cid:104
q−1
cid:63
cid:17
cid:105
cid:16
cid:16
q−1
q−1
¯pt
q−1
cid:63
cid:17
q−1
cid:63
cid:17
nαq
¯pt
dividing
sides
obtain
cid:16
cid:16
q−1
q−1
cid:63
cid:17
cid:16
q−1
cid:63
cid:17
cid:105
¯pt
substituting
¯pt
obtain
nαq
¯pt
next
replacing
nαq
¯pt
substitute
ˆpt
left
hand
side
lhs
get
cid:33
9q2α2
¯pt
cid:33
9q2α2
¯pt
cid:18
¯pt
9q2α2
¯pt
¯pt
¯pt
cid:18
¯pt
cid:32
cid:32
cid:18
cid:18
cid:20
cid:18
¯pt
ˆpt
¯pt
cid:18
¯pt
cid:18
¯pt
cid:18
¯pt
cid:18
¯pt
¯pt
¯pt
¯pt
9q2α2
¯pt
cid:115
cid:115
cid:19
cid:19
cid:19
cid:19
cid:19
cid:19
cid:19
cid:19
cid:18
qαq
¯pt
cid:19
cid:19
cid:21
¯pt
¯pt
¯pt
min
¯p∈
follows
lemma
b.6
follows
2+ln
q−1
cid:104
cid:16
cid:17
cid:16
q−1
cid:63
q−1
q−1
cid:63
cid:17
cid:17
q−1
cid:63
ˆpt
cid:19
cid:19
cid:18
ˆpt
9q2α2
cid:18
qαq
cid:19
cid:18
cid:18
cid:18
cid:18
cid:20
cid:19
cid:19
cid:18
cid:19
cid:18
cid:19
cid:18
min
¯p∈
cid:18
cid:19
cid:19
cid:19
cid:21
qαq
follows
lemma
b.6
2+ln
q−1
thus
far
satisﬁed
condition
claim
see
condition
substitute
ˆpt
lhs
note
cid:104
q−1
cid:63
cid:17
cid:105
q−1
cid:63
cid:17
q−1
cid:16
cid:16
¯pt
therefore
cid:18
¯pt
cid:19
9q2α2
¯pt
¯pt
9q2
n22
9q2
9q2
n¯pt
n¯pt
cid:63
cid:63
ˆpt
9q2α2
cid:17
monotonically
q−1
¯pt
¯pt
q−1
cid:63
cid:17
cid:17
cid:19
9q2α2
¯pt
9q2
cid:16
follows
substituting
¯pt
cid:104
increasing
cid:104
cid:16
q−1
cid:63
cid:16
¯pt
let
¯pt
q−1
¯pt
9q2α2
cid:17
9q2α2
¯pt
9q2α2
therefore
9q2α2
9q2
follows
cid:16
q−1
q−1
q−1
cid:63
cid:17
cid:17
cid:17
cid:16
q−1
q−1
cid:63
q−1
cid:63
cid:18
¯pt
¯pt
cid:63
b.3
establishing
existence
correct
decoding
point
first
show
ˆpt
must
eventually
greater
claim
b.8
proof
since
cid:104
cid:16
q−1
cid:63
ˆpt
q−1
cid:63
cid:17
cid:105
q−1
cid:63
cid:17
q−1
cid:16
hence
ˆpt
¯pt
¯pt
9q2α2
¯pt
ˆpt
n¯pt
n¯pt
n22
9q2
n2
9q2
n2
9q2
n2
9q2
follows
¯pt
follows
substituting
expression
¯pt
cid:17
cid:16
q−1
cid:63
cid:17
cid:105
pt−nθ
q−1
cid:63
q−1
cid:16
q−1
cid:63
cid:17
cid:105
cid:16
cid:16
ˆpt−nθ
˜pt
claim
b.9
cid:104
q−1
cid:63
cid:17
proof
cid:104
ˆpt
ˆpt
λt−nθ
pt−nθ
ˆpt
λt−nθ
ˆpt−nθ
cid:19
cid:18
¯pt
q−1
9q2α2
¯pt
¯pt
¯pt−nθ
¯pt
¯pt−nθ
¯pt
λt−nθ
cid:18
n22
9q2
cid:18
¯pt−nθ
¯pt−nθ
9q2α2
¯pt−nθ
cid:19
λt−nθ
cid:19
follows
using
fact
pn−nθ
ˆpn−nθ
following
substituting
expression
ˆpt
follows
¯pt
follows
substituting
expression
¯pt
hand
since
˜pt
¯pt
¯pt
n−t
ˆpt
˜pt
n2
9q2
9q2
t−λt
9q2
n22
9q2
t−λt
ˆpt
n22−
n−t
t−λt
n22
9q2
9q2
9q2
ˆpt
n2
follows
since
ˆpt
˜pt
ˆpt
follows
˜pt
show
˜pt
cid:104
cid:104
cid:16
cid:16
¯pt
q−1
cid:63
q−1
¯pt
¯pt
9q2α2
cid:16
cid:17
cid:17
q−1
cid:63
q−1
cid:63
cid:17
q−1
cid:63
q−1
q−1
cid:16
q−1
cid:17
let
monotonically
increasing
q−1
ˆpt
therefore
q−1
cid:63
cid:17
cid:17
cid:16
cid:17
ˆpt
˜pt
˜pt
n22
9q2
cid:104
cid:104
cid:16
cid:16
q−1
q−1
cid:17
q−1
cid:16
cid:16
cid:17
q−1
cid:63
cid:17
q−1
cid:63
q−1
cid:63
cid:17
cid:17
cid:17
ˆpt
ˆpt
λt−nθ
ˆpt−nθ
q−1
q−1
cid:63
next
consider
diﬀerence
ˆpt
ˆpt
9q2α2
thus
ˆpt
λt−nθ
ˆpt
cid:17
q−1
cid:63
cid:17
cid:104
cid:16
q−1
ˆpt
q−1
q−1
cid:63
cid:17
cid:16
ˆpt
ˆpt
λt−nθ
ˆpt−nθ
cid:19
ˆpt
λt−nθ
cid:18
¯pt
9q2α2
¯pt
¯pt
λt−nθ
cid:18
¯pt−nθ
¯pt−nθ
cid:19
¯pt−nθ
9q2α2
cid:16
q−1
ˆpt
˜pt
follows
˜pt
hence
cid:104
position
cid:104
q−1
cid:63
cid:16
t−λt
claim
b.10
let
portion
symbol
errors
codeword
respect
unerased
positions
˜pt
q−1
q−1
cid:63
q−1
cid:63
cid:17
q−1
cid:16
cid:17
cid:17
q−1
cid:63
cid:17
cid:105
cid:17
cid:16
ˆpt
q−1
9q2
cid:63
n−t−np
cid:63
+λt
proof
deﬁnition
np−
t−λt
n−np
cid:63
−t+λt
since
˜pt
˜pt
cid:63
cid:63
cid:63
9q2
cid:18
n¯pt
cid:18
9q2
cid:19
cid:63
cid:63
cid:63
cid:108
1−2pq/
q−1
cid:63
q−1
−2/4
cid:109
cid:19
9q2
follows
¯pt
follows
λt0
k0nθ
pt0
ˆpt0
claim
b.11
let
ˆpt0
9q2α2
λt0
pt0
proof
since
k0nθ
cid:0
2pq/
cid:63
2/4
cid:1
λt0
9q2
cid:63
λt0
cid:18
2pq
cid:18
2pq
cid:18
cid:18
cid:19
cid:19
cid:63
cid:19
cid:19
cid:63
cid:63
λt0
n2
9q2
λt0
pt0
9q2
b.4
list
decoding
properties
claim
b.12
let
θ3/q2
let
cid:104
q−1
cid:63
knθ
ˆpt
code
···
list-decodable
ˆpt
symbol
errors
list
size
q−1
cid:16
cid:17
probability
least
q−∆
code
design
cid:16
q−1
cid:63
cid:17
cid:105
ˆpt
nθ2/q2
radius
number
potential
codewords
chunks
cid:0
qnθ
cid:1
qknθ
ˆpt
1/q
number
proof
proof
follows
ideas
thm
10.3
modiﬁed
slightly
correspond
stochastic
codes
stress
although
code
stochastic
message
corresponds
several
codewords
analyze
number
diﬀerent
messages
codewords
fall
hamming
ball
limited
words
length
hamming
ball
radius
ˆpt
t−λt
ˆpt
cid:88
cid:18
cid:19
i=0
t−λt
ˆpt
study
number
diﬀerent
messages
corresponding
codewords
may
lie
ball
message
corresponds
qns/θ
codewords
since
encoding
message
independent
messages
probability
exist
messages
corresponding
codewords
length
lie
hamming
ball
radius
ˆpt
centered
received
word
length
cid:18
qnr
cid:19
cid:16
qns/θ
cid:17
l+1
cid:32
t−λt
ˆpt
t−λt
cid:33
l+1
cid:32
t−λt
ˆpt
t−λt
cid:33
l+1
nr+nθ2/q2
l+1
thus
probability
received
word
chunks
list-decoded
list
size
greater
nr+nθ2/q2
t−λt
1−hq
ˆpt
l+1
t−λt
nr+nθ2/q2
t−λt
1−hq
ˆpt
l+1
quantify
study
cid:2
cid:0
nθ2/q2
cid:1
ˆpt
cid:3
since
ˆpt
ˆpt
nθ2/q2
hence
solving
ˆpt
nθ2/q2
therefore
satisﬁes
code
c1◦c2◦···◦ck
l-list
decodable
probability
least
1−q−∆
corollary
b.13
let
logq
let
cid:104
cid:16
cid:17
cid:16
q−1
cid:63
cid:17
cid:105
q−1
knθ
probability
least
code
···
l-list
decodable
ˆpt
symbol
errors
list
size
code
design
t−λt
ˆpt
q−1
cid:63
cid:19
cid:18
logq
ˆpt
nθ2/q2
proof
claim
b.12
probability
q−3
logq
code
···
l-list
decodable
list
size
logq
ˆpt
nθ2/q2
therefore
probability
code
decoded
list
size
greater
q−3
logq
since
ˆpt
probability
code
···
l-list
decodable
chunks
least
cid:0
/4
θ2/q2
cid:1
thus
obtain
addition
since
ˆpt
ˆpt
nθ2/q2
cid:17
cid:16
logq
/4
θ2/q2
cid:18
cid:19
cid:0
s1/θ
cid:0
s1/θ
number
chunks
1/θ
cid:1
distance
cid:1
suﬃx
given
set
least
b.5
utilizing
energy
bounding
condition
unless
otherwise
speciﬁed
2nθ
···
integer
preﬁx
code
codeword
respect
position
integer
1/θ
number
chunks
suﬃx
code
codeword
respect
position
deﬁnition
b.14
codeword
suﬃx
ck+1
sk+1
ck+2
sk+2
···
c1/θ
set
codeword
suﬃxes
hamming
distance
suﬃx
ck+1
sk+1
◦ck+2
sk+2
···
c1/θ
follows
deﬁne
properties
code
respect
list
codeword
suﬃxes
list
consists
codeword
suﬃxes
corresponding
messages
obtained
bob
list
decoding
phase
decoding
excluding
true
message
alice
wishes
communicate
bob
indeed
list
may
ˆpt
consideration
hence
size
qnsl
true
message
qnsl
true
message
deﬁnition
b.15
code
suﬃx
ck+1
ck+2
···
c1/θ
good
respect
list
code-
ck+1
sk+1
ck+2
sk+2
···
c1/θ
list
deﬁnition
b.16
code
suﬃx
ck+1
ck+2
···
c1/θ
σ-good
respect
list
codeword
suﬃxes
message
code
suﬃx
ck+1
ck+2
···
c1/θ
good
respect
message
list
portion
sequences
secrets
set
claim
b.17
let
sk+1
sk+2
···
s1/θ
sequence
1/θ
secrets
probability
greater
q−δ
n−t
code
design
code
suﬃx
ck+1
ck+2
···
c1/θ
good
respect
message
list
secrets
sk+1
sk+2
···
s1/θ
θ2/q2
θ3/q2
word
suﬃxes
message
sequence
secrets
cid:0
sk+1
sk+2
···
s1/θ
cid:1
distance
n−t
q−1
cid:1
codeword
suﬃx
cid:0
s1/θ
n−t
22
9q3
proof
let
cid:8
···
cid:9
list
codeword
suﬃxes
note
qnsl
cid:0
cid:1
deﬁne
forbidden
region
respect
list
cid:91
hamming
ball
center
radius
n−t
q−1
notion
forbidden
region
figure
n−t
22
9q3
depict
i=1
figure
three
realizations
forbidden
regions
realization
shaded
disks
correspond
forbidden
region
isolated
red
point
codeword
suﬃx
outside
forbidden
region
since
size
list
number
words
length
forbidden
region
determined
cid:18
cid:19
cid:88
i=0
cid:16
q−1
cid:17
22
cid:17
9q3
2θ2
q−1
cid:16
n−t
cid:16
cid:16
logq
n−t
n−t
2θ2
q−1
n−t
cid:17
cid:17
follows
taylor
series
q-ary
entropy
function
neighborhood
1/q
i.e.
q−1
substitution
9q2
q−1
2i−1+1
cid:17
cid:80
2i−1
q−1
cid:16
i=1
suﬃciently
large
θ3/q2
constant
follows
2θ2
logq
logq
cid:18
2θ2
logq
c/
cid:19
2θ2
substituting
cid:18
cid:88
i=0
cid:19
n−t
1−δ
θ2/q2
bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb
cid:1
codeword
suﬃx
corresponding
message
let
ck+1
sk+1
◦ck+2
sk+2
◦···◦c1/θ
codeword
suﬃx
region
deﬁnition
b.15
code
suﬃx
ck+1◦ck+2◦···◦c1/θ
cid:0
s1/θ
cid:1
good
respect
message
list
secrets
sk+1
sk+2
···
s1/θ
therefore
probability
ck+1◦ck+2◦···◦c1/θ
codeword
suﬃx
ck+1
sk+1
◦ck+2
sk+2
◦···◦c1/θ
lie
forbidden
region
cid:0
s1/θ
cid:2
ck+1
sk+1
ck+2
sk+2
···
c1/θ
cid:0
s1/θ
cid:1
cid:3
qn−t
n−t
1−δ
qn−t
n−t
claim
b.18
probability
larger
q−n2
code
design
code
suﬃx
ck+1
ck+2
···
c1/θ
length
1/θ
σ-good
respect
message
list
q−nθ4
proof
let
cid:2
qns
cid:3
set
integers
qns
start
considering
partition
set
codeword
suﬃxes
corresponding
message
l−1
disjoint
subsets
speciﬁcally
partition
set
secrets
l−1
disjoint
sets
set
indexed
element
sk+2
s1/θ
l−1
set
ss∗
corresponding
1/θ
equals
cid:110
ss∗
1/θ
cid:2
qns
cid:3
cid:111
addition
done
modulo
qns
holds
k+2
k+2
cid:91
ss∗
s∗∈sl−1
1/θ
k+1
cid:48
cid:0
s1/θ
cid:1
correspond-
let
l−1
analysis
use
fact
two
l-tuples
sk+1
sk+2
s1/θ
1/θ
appear
ss∗
property
coordinates
diﬀer
k+2
cid:48
cid:48
cid:48
k+1
s1/θ
cid:54
cid:48
namely
sk+1
cid:54
cid:48
consider
set
qns
codeword
suﬃxes
ck+1
sk+1
◦ck+2
sk+2
◦···◦c1/θ
ing
l-tuples
sk+1
sk+2
s1/θ
certain
set
ss∗
partition
speciﬁed
codeword
suﬃx
consists
chunks
construction
set
qns
codeword
suﬃxes
corresponding
sk+1
sk+2
s1/θ
ss∗
independent
uniformly
distributed
follows
directly
code
construction
property
ss∗
discussed
thus
sk+1
sk+2
s1/θ
1/θ
ss∗
event
code
suﬃx
ck+1◦ck+2◦···◦c1/θ
good
respect
cid:48
cid:48
message
list
secrets
sk+1
sk+2
···
s1/θ
independent
event
code
suﬃx
ck+1
ck+2
···
c1/θ
good
respect
message
list
secrets
cid:48
k+1
cid:48
claim
b.17
code
suﬃx
ck+1◦ck+2◦···◦c1/θ
good
respect
message
list
sequence
secrets
sk+1
sk+2
···
s1/θ
probability
less
n−t
thus
probability
code
suﬃx
ck+1◦ck+2◦···◦c1/θ
good
respect
message
list
certain
portion
sequences
secrets
set
ss∗
less
k+2
···
cid:48
k+2
cid:48
k+1
cid:48
1/θ
cid:16
n−t
cid:17
σqns
n−t
δσqns
number
possible
σ-portions
set
ss∗
cid:18
qns
cid:19
σqns
2qns
2qns·
−2σ
log
follows
−2σ
log
1/2
say
code
suﬃx
ck+1
ck+2
···
c1/θ
σ-good
respect
message
list
codeword
suﬃxes
secret
set
ss∗
code
suﬃx
ck+1
ck+2
···
c1/θ
good
respect
message
list
portion
sequences
secrets
set
ss∗
probability
code
design
code
suﬃx
ck+1
ck+2
···
c1/θ
σ-good
respect
message
list
secrets
ss∗
cid:2
ck+1
ck+2
···
c1/θ
σ-good
w.r.t
ss∗
cid:3
n−t
δ·σqns
2qns·
−2σ
log
qσqns
n−t
δ−2
log
logq
qσqns
−nθδ−2
log
logq
nθ3/q2−nθ4
−nθ3/q2+2nθ4
q−n3
follows
substituting
θ2/q2
θ3/q2
q−nθ4
follows
suﬃciently
large
union
bounding
sets
ss∗
partition
get
suﬃciently
large
cid:2
∃s∗
ck+1
ck+2
···
c1/θ
σ-good
w.r.t
ss∗
cid:3
q−n3
qns
l−1
q−n2
finally
notice
σ-good
respect
message
list
codeword
suﬃxes
secret
set
ss∗
partition
implies
σ-good
respect
message
list
hence
probability
code
design
code
suﬃx
ck+1
ck+2
···
c1/θ
σ-good
respect
message
list
cid:2
ck+1
ck+2
···
c1/θ
σ-good
w.r.t
cid:3
q−n2
remark
b.19
goodness
code
suﬃx
guarantees
consistency
check
decoding
process
succeeds
speciﬁcally
code
good
respect
certain
list
certain
message
addition
codeword
suﬃx
received
errors
message
list
w.h.p
unique
element
passes
consistency
checking
phase
bob
list
consistency
checking
phase
bob
return
message
w.h.p.
claim
b.20
let
q−nθ4
probability
greater
q−n
code
design
every
message
every
list
every
chunk
end
code
suﬃx
σ-good
respect
message
list
proof
number
possible
lists
obtained
certain
chunk
end
position
depends
set
messages
size
c/
constant
thus
size
qcnr/
cid:18
qnr
cid:19
c/
claim
b.18
know
q−nθ4
probability
code
suﬃx
ck+1
ck+2
···
c1/θ
σ-good
respect
message
list
every
chunk
end
position
least
qnr
qcnr/
1/θ
q−n2
q−n2+3cn/
q−n
suﬃciently
large
b.6
summary
claim
b.21
probability
least
following
properties
satisﬁed
q−n
code
design
exists
good
code
size
cid:0
adversarial
error
erasure
patterns
exists
position
cid:63
cid:63
code
preﬁx
respect
position
cid:63
···
cid:63
list
decodable
cid:63
cid:63
ˆpt
cid:63
errors
list
corresponding
cid:1
transmitted
message
let
list
codeword
suﬃxes
adversarial
error
erasure
patterns
position
cid:63
received
word
suﬃx
respect
position
total
amount
erasures
plus
twice
amount
er-
rors
bounded
total
amount
errors
bounded
cid:63
moreover
code
suﬃx
ck+1
ck+2
···
c1/θ
σ-good
respect
cid:16
q−1
cid:16
q−1
22
cid:17
cid:63
transmitted
message
list
q−nθ4
cid:17
9q2
9q2
proof
consider
possible
error
erasure
patterns
adversary
analyzing
calvin
possible
trajectories
precisely
given
erasure
pattern
analyze
calvin
possible
behaviors
unerased
symbol
positions
mentioned
possible
trajectories
calvin
classiﬁed
two
types
high
type
trajectory
low
type
trajectory
cid:63
9q2
cid:0
cid:1
probability
low
type
trajectory
pt0
ˆpt0
let
k0nθ
integer
notice
choice
ˆpt
list-decoding
condition
always
satisﬁed
therefore
corollary
b.13
list
decoding
radius
λt0
ˆpt0
code
preﬁx
···
ck0
list
decodable
errors
list
size
code
design
addition
since
λt0
pt0
λt0
ˆpt0
far
ﬁrst
property
stated
claim
satisﬁed
low
type
trajectory
claim
b.11
pt0
satisﬁes
energy
bounding
condition
deﬁnition
b.5
pt0
˜pt0
claim
b.10
received
word
suﬃx
respect
position
fraction
q−1
n−t0−np
cid:63
+λt0
unerased
symbols
error
moreover
since
cid:63
λt0
cid:17
cid:16
q−1
erasures
received
word
suﬃx
total
amount
erasures
twice
amount
22
errors
suﬃx
cid:63
λt0
cid:63
λt0
claim
b.20
code
suﬃx
ck0+1
◦ck0+2
◦···◦c1/θ
σ-good
respect
message
list
probability
q−n
code
design
hence
low
type
trajectory
code
design
possesses
two
properties
stated
claim
moreover
case
cid:63
high
type
trajectory
pt0
ˆpt0
claim
b.8
given
trajectory
high
type
trajectory
always
intersects
ˆpt
later
position
λt+n−
q−1
cid:63
−nθ
let
cid:63
chunk
end
immediately
intersection
point
cid:63
ˆpt
cid:63
implies
cid:63
−nθ
ˆpt
cid:63
−nθ
˜pt
cid:63
−nθ
let
knθ
cid:63
position
corollary
b.13
list
decoding
radius
ˆpt
code
cid:16
q−1
22
n−t0−np
cid:63
+λt0
9q2
cid:17
cid:63
9q2
preﬁx
···
list
decodable
errors
list
size
cid:0
cid:1
probability
cid:16
q−1
9q2
22
design
also
cid:63
since
cid:63
cid:63
cid:63
cid:63
cid:63
ˆpt
cid:63
transmitted
message
list
since
cid:63
−nθ
ˆpt
cid:63
−nθ
claim
b.9
cid:63
˜pt
cid:63
claim
b.10
trajectory
high
type
cid:63
received
word
suﬃx
respect
position
fraction
q−1
n−t0−np
cid:63
+λt0
unerased
symbols
error
cid:63
cid:63
9q2
claim
b.20
code
suﬃx
respect
position
ck+1
ck+2
···
c1/θ
σ-good
respect
message
list
probability
q−n
code
design
thus
far
high
type
trajectory
properties
claim
also
satisﬁed
code
design
conclusion
probability
code
possesses
two
properties
least
cid:16
q−1
22
n−t−np
cid:63
+λt
cid:17
cid:17
cid:63
cid:63
9q2
code
q−n
remark
b.22
note
using
code
claim
b.21
position
cid:63
found
bob
iterative
decoding
process
starting
position
therefore
decoding
process
bob
stop
cid:63
correctly
precisely
claim
b.21
ensures
every
time
bob
obtains
list
codewords
matter
transmitted
message
list
code
suﬃx
respect
position
cid:63
σ-good
respect
message
list
codeword
suﬃxes
words
strictly
smaller
cid:63
consistency
decoding
bob
return
message
cid:63
consistency
decoding
return
correct
message
high
probability
randomness
alice
thus
bob
correctly
determine
whether
continue
decoding
process
claim
b.23
let
q−1
cid:20
q−1
cid:63
let
cid:19
cid:19
cid:21
cid:18
cid:18
min
¯p∈
message
corresponding
encoding
using
code
established
claim
b.21
encoder
section
decoding
procedures
described
section
allows
bob
correctly
decode
message
probability
least
nq−nθ4
random
secrets
available
alice
proof
decoding
error
occurs
consistency
decoder
fails
return
single
message
decoder
returns
message
equal
transmitted
message
strictly
less
cid:63
claim
b.21
property
claim
b.21
remark
b.22
deﬁnition
step
decoding
procedure
consistency
check
decoding
process
return
message
probability
randomness
encoding
precisely
deﬁnition
3.3
deﬁnition
iterative
decoding
process
strictly
less
cid:63
ˆpt
since
list-decoding
radius
tˆpt
tpt
list
obtain
list-decoding
phase
include
transmitted
message
consistency
decoder
return
message
high
probability
addition
cid:63
probability
consistency
check
decoding
process
return
correct
message
speciﬁcally
cid:63
cid:54
claim
b.9
cid:63
˜pt
cid:63
cid:63
claim
b.11
energy
bounding
condition
satisﬁed
pt0
deﬁnition
b.5
cid:63
˜pt
cid:63
energy
bounding
condition
satisﬁed
cid:63
cid:63
˜pt
cid:63
claim
b.10
amount
errors
codeword
suﬃx
bounded
therefore
deﬁnition
consistency
decoder
claim
b.20
consistency
decoder
return
correct
message
high
probability
cases
success
probability
obtained
probability
sequence
secrets
used
codeword
suﬃx
chosen
particular
portion
may
cause
decoding
failure
claim
b.20
q−nθ4
therefore
probability
successful
decoding
least
nq−nθ4
theorem
b.24
capacity
q-ary
causal
adversarial
channels
symbol
errors
erasures
cid:20
cid:18
min
¯p∈
cid:18
cid:19
cid:19
cid:21
q−1
cid:63
q−1
proof
let
converse
proven
section
namely
code
stochastic
achievability
encoding
rate
average
error
probability
lower
bounded
proof
follows
claim
b.23
section
speciﬁcally
suﬃciently
large
holds
claim
b.23
decoding
error
bounded
addition
suﬃciently
small
continuity
q-ary
entropy
function
code
rate
claim
b.23
least
therefore
suﬃciently
large
qnr
c−β
distinct
messages
reliably
transmitted
channel
error
probability
hence
channel
capacity
q-ary
causal
adversarial
channels
symbol
errors
erasures
cid:16
cid:17
discussion
special
cases
section
discuss
several
special
cases
q-ary
causal
adversarial
channels
c.1
symbol
error
channel
q-ary
causal
adversarial
channels
symbol
errors
analysis
get
modiﬁed
setting
cid:63
obtain
corresponding
capacity
cid:20
cid:18
cid:18
cid:19
cid:19
cid:21
min
¯p∈
q−1
c.2
symbol
erasure
channel
q-ary
causal
adversarial
channels
erasures
need
decoding
reference
trajectory
ˆpt
since
erasures
visible
corresponding
list-decoding
condition
becomes
shown
exists
cid:104
following
energy-bounding
condition
satisﬁed
cid:16
cid:63
q−1
cid:63
9q2
cid:17
cid:16
q−1
cid:63
q−1
cid:17
cid:105
modiﬁed
conditions
decoder
bob
pin-point
value
cid:63
modiﬁed
conditions
satisﬁed
therefore
bob
also
able
determine
list
decoding
radius
cid:63
corresponding
capacity
cid:63
c.3
large
alphabet
suﬃciently
large
cid:63
cid:17
obtain
cid:16
cid:19
cid:19
cid:21
cid:18
cid:19
cid:21
cid:20
cid:20
cid:18
cid:18
min
¯p∈
min
¯p∈
min
¯p∈
min
¯p∈
cid:63
cid:63
hence
suﬃciently
large
alphabets
adversary
erasure
budget
i.e.
cid:63
capacity
matches
one
given
hand
adversary
erasure
budget
i.e.
capacity
cid:63
also
depict
special
cases
discussed
figure
comparison
binary
online
setting
bounds
figure
binary
adversarial
erasure
channels
bound
1−p
blue
corresponds
capacity
binary
obliv-
ious
erasure
channel
mrrw
bound
bound
dotted
black
best
known
upper
lower
bounds
binary
omniscient
erasure
chan-
nels
lower
bound
binary
causal
erasure
channels
bassily
smith
plotted
green
binary
adversarial
bit-ﬂip
channels
bound
blue
corresponds
binary
oblivious
bit-ﬂip
channel
mrrw
bound
bound
best
upper
lower
bounds
dotted
black
binary
omniscient
bit-ﬂip
channels
binary
causal
bit-ﬂip
channels
previous
lower
bound
haviv
langberg
slight
improvement
bound
figure
bounds
capacity
binary
online
adversarial
channels
00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91pcapacitybassily−smith
lower
bound
causal
erasure
channels
capacity
causal
erasure
channelscapacity
oblivious
erasure
channelslower
bound
omniscient
erasure
channelsupper
bound
omniscient
erasure
channels00.050.10.150.20.250.30.350.40.450.500.10.20.30.40.50.60.70.80.91pcapacitycapacity
oblivious
bit−flip
channelscapacity
causal
bit−flip
channelsupper
bound
omniscient
bit−flip
channelslower
bound
omniscient
bit−flip
channels
online
q-ary
erasure
channels
online
q-ary
error
channels
online
binary
error-erasure
channels
online
ternary
error-erasure
channels
figure
capacity
number
online
q-ary
channels
00.20.40.60.81p*00.10.20.30.40.50.60.70.80.91capacityq=2q=
cid:1
q=64q=300.10.20.30.40.5p00.10.20.30.40.50.60.70.80.91capacityq=64q=3q=2q=
cid:1
10.80.250.50.20.60.15capacity0.10.40.4p0.050.200.30p*0.20.1010.80.6capacity0.30.250.40.20.60.150.1p0.20.05000.4p*0.20
symbol
description
equality/range
table
table
parameters
capacity
block
length
fraction
codeword
changed
fraction
codeword
erased
quantization
parameter
cid:16
cid:16
cid:17
cid:17
q−1
q−1
9q2
code
rate
private
secret
rate
message
set
secret
set
input
alphabet
output
alphabet
set
chunk
ends
random
variable
input
message
random
variable
input
codeword
random
variable
output
word
message
codeword
secret
secret
length
preﬁx
number
erasures
position
number
chunks
preﬁx
w.r.t
position
number
chunks
suﬃx
w.r.t
position
adversary
trajectory
guess
random
noise
decoding
reference
trajectory
energy
bounding
trajectory
list
messages
list
codeword
suﬃxes
excluding
suﬃxes
corresponding
list
size
list
size
θ3/q2
cid:2
qnr
cid:3
cid:2
qns
cid:3
···
···
2nθ
···
1/θ
cid:0
cid:1
qnsl
cid:0
cid:1
cid:63
¯pt
ˆpt
˜pt
