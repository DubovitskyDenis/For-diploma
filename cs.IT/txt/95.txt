remark
channels
transceiver
distortion
wenyi
zhang
abstract—information
transmission
channels
transceiver
distortion
investigated
via
generalized
mutual
in-
formation
gmi
gaussian
input
distribution
nearest-
neighbor
decoding
canonical
transceiver
structure
channel
output
processed
minimum
mean-squared
error
estimator
decoding
established
maximize
gmi
well-known
bussgang
decomposition
shown
heuristic
consistent
gmi
linear
output
processing
index
terms—bussgang
decomposition
correlation
ratio
generalized
mutual
information
minimum
mean-squared
error
transceiver
distortion
introduction
common
phenomenon
information
transmission
channel
transmitter
receiver
undergo
various
forms
distortion
usually
nonlinear
example
quantization
clipping
saturation
i/q
imbalances
phase
oscillation
simple
popular
approach
handling
channels
linearization
namely
treating
channel
output
linear
superposition
channel
input
appropriate
scaling
disturbance
idea
linearization
originates
well-known
result
originally
identiﬁed
bussgang
later
recognized
special
case
price
theorem
continuous-time
stationary
gaussian
input
process
memoryless
non-
linearity
output
process
indicates
cross-correlation
function
simply
scaled
version
autocorrelation
function
rxx
i.e.
rxy
rxy
rxx
rxx
direct
consequence
output
process
may
linearized
rxy
rxx
disturbance
process
uncorrelated
input
process
considering
information
transmission
channel
channel
output
longer
deterministic
function
channel
input
described
memoryless
nonlinearity
nevertheless
basic
idea
linearization
extensively
exploited
example
clipping
process
ofdm
systems
directly
linearized
following
author
key
laboratory
wireless-optical
communications
chinese
academy
sciences
department
electronic
engineering
information
science
university
science
technology
china
hefei
230027
china
email
wenyizha
ustc.edu.cn
work
supported
national
natural
science
foundation
china
grant
61379003
e.g.
residual
quantization
error
due
analog-to-
digital
conversion
adc
linearized
following
e.g.
furthermore
general
linearized
model
modeling
composite
effect
various
forms
transceiver
distortion
adopted
wherein
disturbance
assumed
uncorrelated
also
independent
channel
input
paper
address
following
questions
first
information-theoretic
interpretation
bussgang
decomposition
like
second
decomposition
improves
upon
approach
based
analysis
generalized
mutual
information
gmi
achievable
rate
information
transmission
mismatched
decoding
metrics
i.e.
mismatched
decoding
see
e.g.
references
therein
memoryless
distortion
preliminary
subsection
brieﬂy
review
main
result
consider
discrete-time
channel
whose
real-valued
input
sequence
input
under-
goes
memoryless
stochastic
transformation
yield
corresponding
real-valued
output
transmission
block
length
information
rate
2nr
messages
codeword
message
drawn
uniformly
gaussian
ensemble
variance
i.e.
esin
upon
receiving
channel
output
sequence
decoder
nearest-neighbor
decoder
implements
arg
min
...
,2nr
axk
xk=1
index
transmitted
message
transmitted
symbol
m-th
codeword
time
additionally
parameter
included
optimizing
transmission
rate
note
transmission
system
described
nearest-neighbor
decoder
generally
maximum-
likelihood
decoder
i.e.
decoder
mismatched
chan-
nel
mismatched
decoding
problems
determining
maximally
achievable
information
rate
still
open
prob-
lem
achievable
lower
bounds
established
see
e.g.
references
therein
generalized
mutual
information
gmi
achievable
information
rate
indeed
maximally
achievable
information
rate
average
probability
decoding
error
asymptotically
van-
ishes
transmission
block
length
grows
without
bound
codewords
randomly
drawn
speciﬁed
ensemble
see
e.g.
1121-1122
tractable
expression
gmi
obtained
follows
proposition
prop
transmission
system
described
channel
input
follows
inde-
pendent
identically
distributed
i.i.d
gaussian
ensemble
mean
zero
variance
channel
output
undergoes
nearest-neighbor
decoder
gmi
igmi
log
cid:18
ese
cid:19
correlation
ratio
canonical
receiver
instead
using
raw
channel
output
process
using
mapping
modify
distance
metric
xk=1
axk
direct
application
proposition
following
result
proposition
setting
proposition
except
channel
output
mapped
fed
nearest-neighbor
decoder
gmi
igmi
log
cid:18
ese
cid:19
hence
natural
problem
optimize
maximize
igmi
equivalent
maximizing
interestingly
square
root
maximum
exactly
so-
called
correlation
ratio
quantity
introduced
pearson
studied
r´enyi
relationship
detailed
following
deﬁnition
eqn
1.7
two
random
variables
correlation
ratio
deﬁned
vare
u|v
varu
varu
exists
strictly
positive
clear
lies
zero
one
taking
value
one
borel-measurable
function
taking
value
zero
independent
furthermore
r´enyi
established
following
relationship
lemma
thm
two
random
variables
mean
variance
exist
sup
cid:12
cid:12
cid:12
cid:12
cid:12
pvaruvarg
cid:12
cid:12
cid:12
cid:12
cid:12
runs
borel-measurable
real
functions
mean
variance
exist
supremum
fig
canonical
transceiver
structure
attainable
u|v
arbitrary
constants
back
setting
proposition
applying
lemma
deﬁnition
x|y
maximized
max
vare
x|y
clearly
x|y
minimum
mean-squared
error
mmse
estimate
upon
observing
let
thus
intro-
duce
following
canonical
decomposition
x|y
estimation
error
uncorrelated
mmse
estimate
x|y
interpret
term
∆g/
inside
logarithm
effective
signal-to-noise
ratio
snr
maximally
achievable
effective
snr
max
vare
x|y
vare
x|y
vare
x|y
mmse
var
mmse
use
mmse
denote
mmse
var
therefore
following
result
proposition
maximally
achievable
effective
snr
transmission
system
section
ii-a
given
simply
ratio
power
mmse
estimate
power
estimation
error
i.e.
mmse
achieved
canonical
transceiver
structure
shown
figure
remark
interesting
note
unlike
data
processing
inequality
asserts
processing
channel
output
increase
input-output
mutual
information
gmi
preceding
analysis
reveals
processing
channel
output
may
beneﬁcial
remark
special
case
linear
gaussian
channels
i.i.d.
readily
veriﬁed
canonical
transceiver
structure
proposition
leads
maxg
∆g/
es/σ2
thus
restoring
classical
additive
white
gaussian
noise
awgn
channel
capacity
result
also
consistent
well-known
fact
mmse
estimation
information
lossless
linear
gaussian
channels
remark
result
obtained
also
leads
special
case
estimation
counterpart
fano
inequality
noting
gmi
lower
bound
mutual
information
written
residual
uncorrelated
instead
decompose
channel
input
rather
channel
output
nevertheless
view
additive
noise
channel
adopt
nearest-neighbor
decoder
/es
i.e.
channel
coefﬁcient
prop
choice
exactly
achieves
performance
proposition
i.e.
questions
section
bussgang
decomposition
information-
theoretic
interpretation
i.i.d
gaussian
in-
put
nearest-neighbor
decoder
viewing
decomposed
channel
model
additive
noise
channel
achieves
gmi
effective
snr
possible
improve
upon
bussgang
decompo-
sition
following
canonical
transceiver
structure
figure
includes
mmse
estimator
channel
output
nearest-neighbor
decoder
improved
performance
described
proposition
iii
distortion
memory
analysis
section
extended
general
case
transceiver
distortion
memory
modeling
transceivers
whose
responses
time-varying
con-
sider
discrete-time
channel
whose
real-valued
input/output
sequence
xk/yk
setup
similar
section
except
i.i.d
gaussian
input
leads
stationary
ergodic
output
process
decoder
modiﬁed
nearest-neighbor
decoder
implements
arg
xk=1
min
...
,2nr
axk
idea
exploiting
channel
memory
process
channel
input/output
sequences
segments
length
mapping
maps
length-l
another
length-l
vector
note
modiﬁed
nearest-neighbor
decoder
views
channel
uses
length-l
super-symbols
thus
resulting
gmi
needs
scaled
investigate
performance
optimized
proposition
consider
transmission
system
described
channel
input
follows
i.i.d
gaussian
ensemble
mean
zero
variance
channel
output
process
undergoes
modiﬁed
nearest-neighbor
normalized
mmse
decoder
assume
estimating
upon
observing
limit
i.e.
1/l
x|y
mmse
lim
l→∞
gmi
optimized
mmse
cid:19
mmse
log
cid:18
igmi
fig
transceiver
structure
linear
output
processing
log
cid:18
mmse
cid:19
mmse
i.e.
mmse
ese−2i
e2h
x|y
e2h
e2h
x|y
2πe
exactly
conditional
estimation
counterpart
fano
inequality
cor
thm
8.6.6
specialized
linear
processing
bussgang
decomposition
practice
linear
estimator
often
employed
since
com-
puting
nonlinear
mmse
estimate
typically
complicated
even
intractable
scalar
channel
output
mapping
linear
i.e.
scaling
constant
coefﬁcient
readily
veriﬁed
value
proposition
always
proposition
particular
following
result
holds
proposition
setting
proposition
except
mapping
restricted
linear
scaling
channel
output
gmi
proposition
effective
snr
lmmse
lmmse
use
lmmse
denote
mean-squared
error
linear
mmse
estimator
upon
observing
proof
straightforward
calculation
shows
lmmse/es
lmmse/es
proposition
readily
follows
cid:3
comparing
loss
due
linear
processing
revealed
exactly
due
loss
replacing
mmse
estimator
linear
mmse
estimator
channels
nonlinear
transceiver
distortion
two
estimators
different
loss
may
noticeable
relationship
clear
decompose
channel
input
i.e.
sum
linear
mmse
estimate
estimation
error
effective
snr
expression
thus
ratio
power
linear
mmse
estimate
power
estimation
error
i.e.
lmmse
corresponding
transceiver
structure
illustrated
figure
remark
address
questions
regarding
bussgang
decomposition
introduced
section
buss-
gang
decomposition
input-output
relationship
achieved
gopt
x|y
effective
snr
thus
gopt
gopt
mmsel
mmsel
mmsel
1/l
x|y
normalized
mmse
estimating
upon
observing
letting
hence
completes
proof
cid:3
acknowledgement
stimulating
discussions
dongning
guo
vincent
poor
cong
shen
gratefully
acknowledged
references
bussgang
crosscorrelation
functions
amplitude-distorted
gaus-
sian
signals
technical
report
216
research
laboratory
elec-
tronics
massachusetts
institute
technology
cambridge
usa
mar
1952
price
useful
theorem
nonlinear
devices
gaussian
inputs
ire
trans
inform
theory
69-72
jun
1958
rowe
memoryless
nonlinearities
gaussian
inputs
elementary
results
bell
syst
tech
1519-1525
sep.
1982
ochiai
imai
performance
analysis
deliberately
clipped
ofdm
signals
ieee
trans
commun.
89-101
jan.
2002
orhan
erkip
rangan
low
power
analog-to-digital
conversion
millimeter
wave
systems
impact
resolution
band-
width
performance
proc
information
theory
applications
ita
workshop
2015
bj¨ornson
hoydis
kountouris
debbah
massive
mimo
systems
non-ideal
hardware
energy
efﬁciency
estimation
capacity
limits
ieee
trans
inform
theory
7112-7139
nov.
2014
lapidoth
narayan
reliable
communication
channel
uncertainty
ieee
trans
inform
theory
2148-2177
oct.
1998
zhang
general
framework
transmission
transceiver
distortion
applications
ieee
trans
commun.
384-
399
feb.
2012
lapidoth
shamai
shitz
fading
channels
perfect
need
perfect
side
information
ieee
trans
inform
theory
1118-
1134
may
2002
r´enyi
new
version
probabilistic
generalization
large
sieve
acta
math
acad
sci
hung.
218-226
1959
cover
thomas
elements
information
theory
wiley-
interscience
new
york
usa
2nd
ed.
2006.
proof
proof
essentially
follows
line
thm
3.0.1
prop
fix
without
loss
generality
assume
transmitted
message
distance
metric
satisﬁes
lim
n→∞
cid:2
axk2
cid:3
gmi
given
a.s.
igmi
sup
lim
n→∞
cid:8
cid:2
axk2
cid:3
cid:9
log
ehenθdg
expectation
evaluated
following
−ax
l−ax
yk=1
ehenθdg
eheθ
yk=1
yk=1
2θa2es
eheθkg
2θa2es
cid:19
exp
cid:18
2θa2es
−nl/2
exp
xk=1
xl=1
yl=1
yl=1
2θa2es
leading
θpn
k=1
2θa2es
log
2θa2es
cid:2
cid:3
2θa2es
gmi
scaling
log
2θa2es
a.s.
igmi
sup
cid:26
θ/l
cid:2
axk2
cid:3
log
2θa2es
2θa2es
θ/l
cid:2
cid:3
maximizing
igmi
vector
extension
problem
solved
eqn
solution
procedure
essentially
identical
optimal
aopt
xtg
les
max
igmi
log
cid:18
cid:8
xtg
cid:9
lese
cid:19
proof
lemma
thm
applies
maximiza-
tion
leading
max
cove
x|y
les
