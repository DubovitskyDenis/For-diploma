carbon
copy
onto
dirty
paper
channel
statistically
equivalent
states
stefano
rini
shlomo
shamai
shitz
national
chiao-tung
university
hsinchu
taiwan
e-mail
stefano
nctu.edu.tw
technion-israel
institute
technology
haifa
israel
e-mail
sshlomo
ee.technion.ac.il
abstract—costa
writing
dirty
paper
capacity
result
establishes
full
state
pre-cancellation
attained
gel
fand-pinsker
channel
additive
state
additive
gaus-
sian
noise
carbon
copy
onto
dirty
paper
channel
extension
costa
model
compound
setting
receivers
observe
sum
channel
input
gaussian
noise
one
gaussian
state
sequences
attempt
decode
common
message
state
sequences
non-causally
known
transmitter
attempts
simultaneously
pre-
code
transmission
channel
state
affecting
output
correspondence
derive
capacity
within
2.25
bits-per-channel-use
carbon
copying
onto
dirty
paper
channel
state
sequences
statistically
equivalent
variance
pairwise
correlation
channel
capacity
approached
letting
channel
input
superposition
two
codewords
base
codeword
simultaneously
decoded
user
top
codeword
pre-coded
state
realization
user
portion
1/m
time
outer
bound
relies
recursive
bounding
incremental
side
information
provided
receiver
result
represents
signiﬁcant
ﬁrst
step
toward
determining
capacity
general
carbon
copy
onto
dirty
paper
channel
state
sequences
appearing
different
channel
outputs
jointly
gaussian
distribution
index
terms—gel
fand-pinsker
problem
compound
state-
dependent
channel
carbon
copying
onto
dirty
paper
gel
fand-pinsker
channel
output
point-to-point
channel
obtained
random
function
channel
input
state
sequence
provided
non-causally
encoder
unknown
decoder
costa
writing
dirty
paper
wdp
channel
gaussian
version
channel
channel
output
obtained
linear
combination
input
state
sequence
iid
gaussian-distributed
noise
perhaps
surpris-
ingly
costa
showed
capacity
wdp
channel
capacity
point-to-point
channel
state
present
channel
output
words
transmitter
fully
pre-code
transmissions
channel
state
thus
presence
channel
state
affect
capacity
carbon
copying
onto
dirty
paper
ccdp
channel
extension
channel
compound
scenario
model
transmitter
wishes
communicate
message
receivers
observe
channel
output
summation
channel
input
iid
gaussian
noise
one
state
sequences
state
sequences
provided
non-causally
transmitter
unknown
receivers
correspondence
derive
capacity
ccdp
channel
number
users
case
states
statically
equivalent
gaussian-distributed
variance
pairwise
correlation
ﬁrst
show
approximate
capacity
case
independent
channel
states
generalize
result
case
independent
channel
states
lastly
show
approximate
capacity
correlation
ccdp
special
case
compound
channel
unfortunately
many
results
available
literature
achievable
region
two-user
compound
channel
presented
shown
using
common
message
potentially
improves
extensions
capacity
achieving
strategy
channel
channel
input
pre-coded
channel
states
ccdp
ﬁrst
proposed
authors
consider
binary
gaussian
versions
-user
compound
channel
derive
ﬁrst
inner
outer
bounds
models
previously
considered
case
two
users
derived
approximate
capacity
certain
set
correlations
among
circularly-
symmetric
gaussian
state
sequences
model
related
ccdp
channel
state-dependent
broadcast
channel
common
message
model
obtained
ccdp
channel
introducing
two
privates
message
commu-
nicated
transmitter
users
ﬁrst
achievable
region
channel
obtained
combining
coding
strategies
channel
broadcast
channel
steinberg
studies
channel
one
users
provided
state
sequence
user
observes
degraded
channel
output
capacity
channel
obtained
using
bounding
techniques
inspired
proof
degraded
broadcast
channel
capacity
remainder
paper
organized
follows
sec
introduce
channel
model
sec
present
relevant
results
available
literature
sec
iii
derive
approximate
capacity
case
independent
channel
states
sec
present
approximate
capacity
case
independent
channel
states
sec
present
approximate
capacity
case
pairwise
correlation
sec
concludes
paper
sketches
proofs
provided
main
text
full
proofs
found
appendix
dec.
cwm
rout
dec.
enc
...
dec.
...
fig
carbon
copying
dirty
paper
ccdp
channel
model
-user
carbon
copying
dirty
paper
ccdp
channel
also
depicted
fig
compound
channel
channel
outputs
obtained
csn
iid
gaussian
sequence
zero
mean
unitary
variance
iid
jointly
gaussian
sequence
zero
mean
covariance
matrix
var
var
var
n=1
assumed
without
loss
generality
transmit-
ter
anti-causal
knowledge
subject
average
power
constraintpn
cid:2
|xn|2
cid:3
following
focus
ccdp
state
unitary
variance
two
states
correlation
term
model
carbon
copying
dirty
paper
equivalent
states
ccdp-es
since
channel
states
statistically
equivalent
range
feasible
values
correlation
shown
next
lemma
lemma
i.1
let
matrix
equal
ρ1m
=
...

identity
matrix
size
matrix
ones
size
positive
deﬁned
−1/
proof
see
app
lemma
i.2
capacity
ccdp
channel
decreasing
proof
see
app
result
rather
intuitive
since
capacity
increase
reduce
variance
state
related
results
carbon
copy
onto
dirty
paper
ccdp
channel
channel
model
originally
introduced
authors
derive
number
inner
outer
bounds
capacity
theorem
ii.1
inner
outer
bounds
2-ccdp
channel
independent
states
consider
ccdp
channel
i2,2
capacity
upper
bounded
cw1
cw2
...
c2/4+1
cid:17
log
cid:16
1+p
cid:16
1+p
+c2+2c√p
log
log
2c√p
log
cid:17
c2/4+1
c2/2+1
cid:17
c2/2
log
cid:16
log
cid:16
+c2/2+1
cid:17
log
cid:16
log
cid:17
c2/2
c2/2


lower
bounded
rin
powerful
bounding
techniques
introduced
derive
outer
bound
inner
bound
obtained
transmitter
pre-code
two
linear
combinations
state
sequences
outer
bounding
technique
case
also
extended
case
general
theorem
ii.2
outer
bounds
m-ccdp
channel
independent
states
consider
ccdp
channel
capacity
upper
bounded
rout
log
cid:16
2c√p
cid:17
log
cid:20
log
cid:18
cid:19
cid:21
log
inner
outer
bounds
case
close
small
values
otherwise
capacity
characterization
possible
using
bounds
ii.1
generalizing
inner
bound
show
inner
outer
bound
close
small
values
compound
compound
general
channel
model
ccdp
attainable
rate
region
model
obtained
rin
max
min
cid:26
u2|v
cid:27
variable
common
message
decoded
receivers
pre-coded
respectively
channel.
2.55
2.5
2.45
2.4
original
outer
bound
ii.1
optimized
outer
bound
fig
graphical
representation
capacity
approaching
scheme
iii.1
iii
2-ccdp
channel
independent
equal-variance
states
fig
outer
bound
begin
deriving
approximate
capacity
2-ccdp-
allows
illustrate
main
inner
outer
bounding
techniques
deferring
complex
derivations
latter
sections
derivation
inner
bound
consider
attainable
strategy
also
depicted
fig
channel
input
obtained
superposition
three
codewords
bottom
common
codeword
san
san
state
noise
power
carries
message
wsan
rate
rsan
treats
state
sequences
additional
noise
two
top
private
codewords
pas−2
pas
pre-
power
pre-
coded
state
coded
respectively
transmitted
half
time
since
var
var
codeword
san
decoded
receivers
simultaneously
pas−i
decoded
receiver
since
hand
pre-coded
state
order
decoders
decode
amount
common
information
codewords
carry
message
wpas
rate
rpas
result
consideration
receivers
able
correctly
decode
wsan
wpas
thus
attaining
transmission
rate
pas−1
rin
log
cid:18
cid:19
log
expression
maximized
ratio
power
common
private
codewords
optimal
value
c2−1
corresponds
ﬁxing
power
private
codewords
power
state
sequence
instead
power
allocated
private
codewords
scheme
reduces
pre-coding
receiver
half
time
pre-coding
receiver
remaining
portion
time
respect
outer
bound
able
improve
result
ii.1
using
observation
lem
i.2
note
outer
bound
expression
decreasing
increasing
shown
fig
reason
possible
improve
outer
bound
considering
channel
parameter
min
channel
larger
capacity
original
channel
provides
tighter
outer
bound
comparing
inner
outer
bound
expressions
bound
capacity
within
bpcu
theorem
iii.1
approximate
capacity
2-ccdp
independent
equal-variance
states
consider
2-ccdp-is
channel
fig
i2,2
outer
bound
capacity
rout

log
log
log
log
exact
capacity
within
gap
bpcu
outer
bound
proof
see
app
result
iii.1
somewhat
expected
states
2-ccdp
channel
independent
best
strategy
send
common
codeword
power
level
larger
channel
state
decoded
users
private
codeword
user
pre-coded
state
realization
corresponding
channel
output
order
private
codeword
communicate
message
two
receiver
codeword
must
time-shared
two
receivers
major
difﬁculty
proving
theorem
therefore
deriving
outer
bound
matches
intuitively
optimal
solution
showing
approximate
capacity
ccdp-es
ﬁrst
show
extend
result
thm
iii.1
case
case
number
users

log
log
cid:16
1+c2
cid:17
log
cid:0
cid:1
log
m−1
exact
capacity
within
gap
2.25
bpcu
outer
bound
proof
see
app
interesting
notice
pure
time-sharing
common
codeword
approximatively
optimal
state
variance
roughly
times
stronger
transmit
power
occurs
intuitively
pre-log
rate
codeword
san
1/2
pre-log
codewords
xpas−m
1/2m
ccdp-es
channel
section
ﬁnally
derive
approximate
capacity
ccdp-es
channel
result
relies
high-level
viewpoint
two
observations
positive
correlation
among
states
implies
exists
common
component
pre-coded
common
codeword
san
negative
correlation
among
states
allow
improvement
attainable
rates
respect
case
independent
channel
states
illustrate
points
note
output
2-ccdp-es
equivalently
expressed
cid:16
asn
cid:17
aesn
+r1
a2esn
14a
14b
es1
es2
iid
choice
=p|ρ|
makes
term
scaling
channel
outputs
case
positive
correlation
term
simultaneously
pre-coded
receivers
wdp
channel
negative
correlation
since
common
term
appears
opposite
sign
two
outputs
coding
advantage
possible
theorem
v.1
approximate
capacity
general
ccdp-es
consider
general
2-ccdp
channel
state
covariance
matrix
satisfying
capacity
upper
bounded
rout
log
log
c2ρ+
c2ρ+
log
ρ+c2
log
c2ρ+
c2ρ
max
exact
capacity
within
2.25
bpcu
outer
bound
proof
see
app
outer
bound
obtained
providing
common
state
side
information
receiver
resulting
channel
model
iii.1

fig
graphical
representation
capacity
approaching
scheme
iii.1
m-ccdp
channel
independent
equal-variance
states
approximate
capacity
m-ccdp
channel
independent
equal-variance
states
obtained
appropriate
extension
inner
outer
bounds
sec
iii
generalization
inner
bound
fig
case
number
users
rather
straightforward
modify
attainable
strategy
fig
shown
fig
employ
one
common
codeword
san
power
time-
shared
codewords
pas−m
power
codewords
pre-coded
state
sequence
pas−m
convey
message
wpas
receiver
decodes
codeword
pas−m
end
transmission
decoders
correctly
decode
wsan
wpas
rate
attain
strategy
san
rin
log
cid:18
cid:19
log
maximized
case
optimal
value
max
cid:26
min
cid:26
cid:27
cid:27
scheme
reduces
simple
time-sharing
costa
pre-coding
generalization
outer
bound
iii.1
rather
involved
accomplished
establishing
recursive
bounding
mutual
information
terms
obtained
fano
inequality
using
carefully-chosen
genie
side
information
decoder
refer
interested
reader
app
complete
proof
observation
lem
i.2
employed
tighten
outer
bound
expression
optimizing
state
gain
theorem
iv.1
approximate
capacity
m-user
ccdp
independent
equal-variance
states
consider
m-ccdp-is
channel
fig
outer
bound
capacity
rout
case
rely
fact
outer
bound
iii.1
adapted
case
correlated
states
increasing
parameter
thus
case
provides
looser
outer
bound
case
achievability
proof
case
achievability
proof
iii.1
since
scheme
affected
correlation
among
states
case
adapt
scheme
iii.1
common
codeword
san
pre-coded
common
state
sequence
c√ρsn
decomposition
channel
outputs
terms
common
component
extended
case
users
distinction
positive
negative
pairwise
correlation
becomes
clearer
context
case
positive
correlation
common
term
variance
extracted
channel
outputs
representing
channel
states
√ρsc
+p1
ρesm
esm
iid
proof
v.1
transmitter
simultaneously
pre-code
term
√ρsc
users
wdp
channel
case
negative
correlation
intriguing
since
case
channel
states
represented
m−1xj=1
nxj=m+1
√ρbsmj
representation
provides
intuition
result
lem
i.1
order
two
states
√ρbsjm
+p1
ρesm
bsmj
esm
negatively
correlated
must
share
term
bsjk
states
must
contain
terms
bsmj
bsjm
appear
must
case
otherwise
term
would
affect
correlation
among
since
must
negatively
correlated
variance
|ρ|
given
variance
equal
one
necessarily
|ρ|
−1/
considerations
ﬁnally
state
main
result
paper
theorem
v.2
approximate
capacity
m-ccdp-es
consider
m-ccdp
channel
fig
satisfying
capacity
upper
bounded
rout
log
cid:16
c2ρ
log
1+ρc2
cid:17
log
cid:0
ρc2
cid:1
log
m−1
c2ρ
ρc2
max
exact
capacity
within
2.25
bpcu
outer
bound

proof
app
approximate
capacity
m-ccdp
gaussian
independent
states
difﬁculty
extending
result
v.2
case
correlation
matrix
lays
fact
case
decoders
different
decoding
capabilities
therefore
number
ways
set
public
bits
transmitted
receiver
accomplished
varying
time-sharing
ratio
private
codeword
receiver
scheme
fig
optimization
quickly
becomes
untractable
deriving
matching
outer
bound
challenging
conclusion
paper
study
capacity
carbon
copying
onto
dirty
paper
channel
equivalent
states
variation
classic
dirty
paper
channel
transmitted
message
decoded
receivers
observing
linear
combination
input
gaussian
noise
one
pos-
sible
state
sequences
state
sequences
non-causally
known
transmitter
statistically
equivalent
jointly
gaussian-distributed
unitary
variance
iden-
tical
pairwise
correlation
although
inner
outer
bounds
capacity
channel
available
literature
characterization
capacity
known
derive
capacity
model
within
2.25
bits-per-channel-use
channel
pairwise
correlation
among
states
model
capacity
approached
rather
simple
strategy
input
composed
superposition
two
codewords
bottom
common
codeword
decoded
users
top
private
codeword
decoded
receiver
portion
1/m
time
pre-coded
channel
state
experienced
given
receiver
major
contribution
paper
derivation
outer
bound
closely
approaches
intuitive
inner
bound
despite
progress
capacity
channel
states
jointly
gaussian
distribution
remains
unknown
references
gel
fand
pinsker
coding
channel
random
parame-
ters
probl
contr
inform
theory
vol
19–31
1980
costa
writing
dirty
paper.
ieee
trans
inf
theory
vol
439–441
1983
khisti
erez
lapidoth
wornell
carbon
copying
onto
dirty
paper
ieee
trans
inf
theory
vol
1814–1827
may
2007
nair
gamal
y.-k.
chia
achievability
scheme
compound
channel
state
noncausally
available
encoder
arxiv
preprint
arxiv:1004.3427
2010
rini
shamai
impact
phase
fading
dirty
paper
channel
arxiv
preprint
arxiv:1401.4236
2014
steinberg
shamai
achievable
rates
broadcast
channel
transmitter
proceedings
international
states
known
symposium
information
theory
2005.
isit
2005.
2005
marton
coding
theorem
discrete
memoryless
broadcast
channel
ieee
trans
inf
theory
vol
306–311
may
1979
steinberg
coding
degraded
broadcast
channel
random
parameters
causal
noncausal
side
information
information
theory
ieee
transactions
vol
2867–2877
2005
rini
shamai
impact
phase
fading
dirty
paper
coding
channel
information
theory
isit
2014
ieee
international
symposium
ieee
2014
2287–2291
carbon
copy
onto
dirty
paper
channel
statistically
equivalent
states
arxiv
preprint
2016
appendix
proof
lem
i.1
matrix
leading
principal
minor
obtained
matrix
determinant
lemma
non-negative
det
ρ11
m1m,1
cid:18
cid:19
consequently
leading
principal
minors
matrix
positive
min
cid:26
cid:27
equation
together
fact
necessarily
bonded
one
obtain
condition
given
state
sequence
vector
appendix
proof
lem
i.2
represent
sequence
obtained
i.i.d
ρσs
i.i.d
ρσs
provided
side
information
transmitter
receivers
capacity
channel
must
necessarily
larger
capacity
original
channel
since
extra
consider
channel
set
sequences
csn
csn
statistically
equivalent
channel
knowledge
ignored
mth
receiver
enhanced
channel
produce
sequence
eym
sequence
state
sequence
appropriately
scaled
holds
considering
equivalent
channel
output
capacity
channel
model
state
gain
isec
implies
capacity
increases
decreases
sequences
acts
common
information
transmitter
receivers
thus
increase
capacity
observations
conclude
capacity
model
state
gain
side
information
equivalent
c√ρ
thus
concludes
proof
appendix
proof
iii.1
achievable
point
consider
case
gap
bpcu
attained
either
treating
state
noise
simple
considering
trivial
outer
bound
derivation
initially
follows
steps
similar
successively
improved
using
observation
lem
i.2
inner
bound
substantially
inner
bound
relies
superposition
coding
binning
base
codeword
treats
state
noise
two
top
codewords
transmitted
half
time
ﬁrst
codeword
pre-coded
channel
state
observed
one
user
second
codeword
pre-coded
state
observed
second
user
capacity
outer
bound
capacity
channel
upper
bounded
min
1,2
cid:0
cid:1
sum
positive
entropy
terms
bounded
25a
25b
26a
26b
26c
28a
28b
28c
28d
30a
30b
30c
log
2c√p
log
2πe
log
2πe
log
2c√p
log
2πe
26b
follows
gaussian
maximizes
entropy
gme
property
26c
follows
fact
sum
negative
entropy
terms
28c
used
transformation
cid:21
cid:20
cid:21
cid:20
cid:21
jacobian
equal
one
continue
series
inequalities
|sn
|sn
cid:20
since
obtain
two
inequalities
establish
outer
bound
log
2πe
2c2
log
2πe
log
2πe
cid:19
log
2πe
cid:19
cid:18
cid:18
log
cid:0
cid:1
log
cid:0
cid:1
rout
since
capacity
channel
decreasing
shown
lem
i.2
optimize
outer
bound
set
order
match
boundaries
optimization
inner
outer
bound
choose
loosen
outer
bound
rout
ﬁrst
derivative
log
cid:0
cid:1
log
cid:0
cid:1
∂c2
zero
second
derivation
positive
therefore
set
min
obtain
channel
larger
capacity
tighter
expression
outer
bound
result
optimization
correspond
bound
note
case
use
trivial
outer
bound
log
since
variance
state
contribution
state
channel
output
minimal
case
capacity
inner
bound
consider
transmission
scheme
channel
input
comprised
superposition
following
codewords
base
codeword
top
codewords
additionally
san
san
state
noise
treats
state
noise
pas−i
pre-coded
state
pre-coded
sequence
pas−1
transmitted
ﬁrst
half
time
pas−2
transmitted
second
half
time
codewords
pas−i
codewords
iid
gaussian-distributed
common
codeword
san
attain
rate
rsan
xsan
pas−i
superimposed
codeword
san
san
power
xpas−i
power
san
receiver
jointly
decodes
log
cid:18
cid:19
used
communicate
messages
wsan
rsan
users
simultaneously
two
private
codewords
xpas−1
xpas−2
attain
rate
encode
message
rpas
note
message
sent
twice
since
reliably
communicated
ﬁrst
users
ﬁrst
half
transmission
second
user
second
half
transmission
combining
rate
common
private
message
conclude
overall
attainable
rate
rpas
u1|xsan
u2|xsan
.the
optimization
yields
optimal
value
corresponding
optimal
rates
rin
cid:19
log
log
cid:18
=
c2+1
cid:17
log
cid:16
log
cid:0
cid:1
log
c2−1
log
rin
=
gap
inner
outer
bound
case
notice
distance
inner
outer
bound
1/2
bpcu
using
simple
considerations
shape
capacity
region
remaining
cases
inner
outer
bounds
compared
directly
gap
bpcu
also
bpcu
case
therefore
conclude
regardless
channel
parameters
outer
bound
attained
within
bpcu
appendix
proof
iv.1
proof
extension
proof
iii.1
thus
relies
similar
inner
outer
bounding
techniques
ﬁrst
part
outer
bound
derivation
follows
derivation
later
employ
recursive
bounding
mutual
information
terms
come
tighter
bounding
hand
inner
bound
rather
straight
forward
extension
bound
iii.1
bottom
codeword
multiple
top
pre-coded
codewords
used
communicate
common
message
proof
app
need
consider
case
since
capacity
region
smaller
1bpcu
otherwise
capacity
outer
bound
app
3.c
write
min
...
mxm=1
max
...
mxi=1
log
2c√p
n|w
log
2πe
mxm=1
39a
39b
39c
39d
proceed
establishing
recursion
deﬁning
term
allows
rewrite
39d
mxi=m
term
rewritten
log
2c√p
log
2πe
−t1
seen
difference
bounded
follows
since
noise
terms
indented
identically
distributed
−t1
−t1
|sn
|sn
log
2c2
log
2c2
|sn
|sn
log
2c2
|sn
log
2c2
log
2c2
|sn
|sn
cid:19
log
cid:18
|sn
log
2c2
write
i−1
kxi=2
kxi=2
kxi=2
c∆n
|∆n
i−1
|∆n
tk+1
c∆n
|∆n
i−1
yk|∆n
yk+1|w
tk+2
c∆n
|∆n
i−1
yk+1|∆n
tk+2
proceeding
manner
come
bound
c∆n
|∆n
i−1
|∆n
c∆n
|∆n
i−1
i−1
left
evaluate
intermediate
terms
summation
c∆n
|∆n
log
2πe
c∆n
i−1
log
|∆n
i−1
−t1
mxi=2
mxi=2
mxi=2
|∆n
recursion
established
lines
bound
terms
summation
let
deﬁne
44a
44b
44c
44d
44e
44f
44g
46a
46b
46c
47a
47b
47c
correlation
matrix
among
entries
vector
...
...
σ∆n

...
...
...
...

thus
conclude
|∆n
i−1
...
...
...

·
...


log2
·
log
cid:18
cid:19
log
50b
follows
properties
symmetric
tri-diagonal
matrices
bounding
obtain
outer
bound
rout
log
log
log
log
log
2πe
cid:18
cid:19
proof
iii.1
outer
bound
optimized
interval
derivative
equal
zero
second
derivative
positive
point
c2∗
minimum
outer
bound
obtain
outer
bound
expression
interval
bound
expression
follows
log
log
log
log
cid:18
log
cid:18
log
cid:18
log
cid:18
log
cid:18
cid:19
cid:19
cid:19
cid:19
cid:19
log
log
log
log
2c2
log
53b
follows
assumption
53e
fact
x−1
log
maximum
integer
valued
combining
results
obtain
desired
outer
bound
capacity
inner
bound
consider
inner
bound
extends
inner
iii.1
inner
bound
composed
superposition
two
codewords
base
codeword
top
codewords
san
san
state
noise
treats
state
noise
pas−i
pre-coded
state
pre-coded
sequence
50a
50b
50c
53a
53b
53c
53d
53e
transmitted
portion
1/m
time
rate
achieved
user
scheme
optimization
yields
achievable
rate
rin
max
0,1
log
cid:18
1+c2
cid:17
log
cid:16
log
log
cid:0
cid:1
m−1
log
rin
=
cid:19
log
gap
inner
outer
bound
consider
case
compare
expression
gap
bpcu
case
bpcu
also
1/2m
largest
gap
inner
outer
bound
2.25
bpcu
attained
lets
consider
case
positive
negative
correlation
separately
since
require
separate
derivation
appendix
proof
v.1
approximate
capacity
outer
bound
simply
consider
outer
bound
obtained
providing
decoders
term
stripped
channel
output
receivers
obtain
model
iii.1
state
smaller
variance
instead
absorbing
factor
obtain
outer
bound
san
pre-coded
state
inner
bound
consider
generalization
inner
bound
app
base
codeword
rate
transmitted
rate
rsan
log
cid:18
cid:19
adjustment
attainable
scheme
iii.1
see
region
attained
within
bpcu
approximate
capacity
note
correlation
affects
derivation
outer
bound
app
derivation
term
30c
noted
decreasing
correlation
log
cid:0
2c2
cid:1
accordingly
outer
bound
independent
states
outer
bound
case
negatively
correlated
states
negative
correlation
also
affect
inner
bound
iii.1
rate
attainable
two
considerations
see
capacity
case
negative
correlation
approached
manner
case
independent
states
appendix
proof
v.2
case
positive
correlation
straightforwardly
extends
proof
v.1
app
case
negative
correlation
shall
show
recursion
affected
negative
correlation
value
entropy
term
decreasing
value
correlation
note
covariance
matrix
affected
correlation
since
equivalently
var
var
si−1
∆i∆i+1
si−1
si+1
∆i∆j
si−1
sj−1
|∆n
i−1
log
cid:18
cid:18
cid:19
cid:19
log
expression
increasing
thus
obtain
outer
bound
negative
correlation
upper
bounded
outer
bound
independent
states
proof
v.1
app
inner
bound
affected
negative
correlation
therefore
conclude
capacity
case
negative
correlated
states
bounded
manner
v.2
