low-rank
positive
semideﬁnite
matrix
recovery
corrupted
rank-one
measurements
yuanxin
student
member
ieee
yue
sun
yuejie
chi
member
ieee⋆
abstract—we
study
problem
estimating
low-rank
positive
semideﬁnite
psd
matrix
set
rank-one
measurements
using
sensing
vectors
composed
i.i.d
standard
gaussian
entries
possibly
corrupted
arbitrary
outliers
problem
arises
applications
phase
retrieval
covariance
sketching
quantum
space
tomography
power
spectrum
estimation
ﬁrst
propose
convex
optimiza-
tion
algorithm
seeks
psd
matrix
minimum
ℓ1-
norm
observation
residual
advantage
algorithm
free
parameters
therefore
eliminating
need
tuning
parameters
allowing
easy
implementations
establish
high
probability
low-rank
psd
matrix
exactly
recovered
soon
number
measurements
large
enough
even
fraction
measurements
corrupted
outliers
arbitrary
magnitudes
moreover
recovery
also
stable
bounded
noise
additional
information
upper
bound
rank
psd
matrix
propose
another
non-convex
algorithm
based
subgradient
descent
demonstrates
excellent
empirical
performance
terms
computational
efﬁciency
accuracy
index
terms—rank-one
measurements
low-rank
psd
matrix
estimation
outliers
introduction
many
emerging
applications
science
engineering
interested
estimating
low-rank
positive
semidef-
inite
psd
matrix
rn×n
set
nonnegative
magnitude
measurements
0ai
haiat
denotes
inner
product
quadratic
sensing
operator
measurement
vector
linear
sensing
matrix
rank-one
one
hand
magnitude
aiat
measurements
could
arise
due
physical
limitations
e.g
incapability
capturing
phases
phase
retrieval
optical
imaging
intensity
measurements
squared
intensity
linear
measurements
signal
recorded
|hai
x0i|2
cid:0
x0xt
cid:1
0ai
chi
department
electrical
computer
engineer-
ing
ohio
state
university
columbus
43210
usa
e-mails
li.3822
chi.97
osu.edu
sun
department
electronics
engineering
tsinghua
university
beijing
china
part
work
done
sun
visiting
ohio
state
university
work
supported
part
nsf
grant
ccf-1422966
eccs-
1462191
afosr
grant
fa9550-15-1-0205
corresponding
e-mail
chi.97
osu.edu
date
april
2018.
preliminary
results
paper
presented
part
ieee
inter-
national
conference
acoustics
speech
signal
processing
shanghai
china
march
2016.
xlxt
0ai
xl=1
|hai
xli|2
x0xt
lifted
rank-one
matrix
signal
interest
hand
could
arise
design
covariance
sketching
scheme
considered
aggregated
squared
intensity
measure-
ments
data
samples
zero-mean
ergodic
data
stream
∞l=1
xl=1
xlxt
corresponds
covariance
matrix
data
sufﬁciently
large
goal
covariance
sketching
recover
covariance
matrix
i=1
many
applications
set
measurements
array
signal
processing
network
trafﬁc
monitoring
covariance
matrix
data
well
approximated
low-rank
psd
matrix
variance
explained
top
principal
components
last
least
measurements
low-rank
psd
matrices
form
also
occur
number
applications
quantum
state
tomography
compressive
power
spectrum
estimation
non-coherent
direction-of-arrival
estimation
magnitude
measurements
synthetic
aperture
radar
imaging
natural
ask
possible
recover
low-rank
psd
matrix
information-theoretically
op-
timal
number
measurements
computationally
efﬁcient
manner
popular
approach
based
convex
relaxation
seeks
psd
matrix
smallest
trace
norm
satisfying
observation
constraint
shown
algorithm
exactly
recovers
rank-r
psd
matrices
soon
number
measurements
exceeds
order
absence
noise
recovery
stable
bounded
noise
well
goal
contributions
paper
focus
robust
recovery
low-
rank
psd
matrix
measurements
fur-
ther
corrupted
outliers
possibly
adversarial
arbitrary
amplitudes
signal
processing
applications
outliers
somewhat
inevitable
may
caused
sensor
failures
malicious
attacks
reading
errors
application
covariance
sketching
sufﬁcient
aggregation
length
necessary
order
measurement
well
approximated
measurements
aggregated
large
enough
may
regarded
outliers
therefore
becomes
critical
address
robust
recovery
presence
outliers
fortunately
reasonable
assume
number
outliers
usually
much
smaller
number
total
measurements
making
possible
leverage
sparsity
outliers
faithfully
recover
low-rank
psd
matrix
interest
ﬁrst
propose
convex
optimization
algorithm
seeks
psd
matrix
minimizes
ℓ1-norm
mea-
surement
residual
ℓ1-norm
adopted
promote
outlier
sparsity
proposed
convex
program
free
tuning
parameters
eliminates
need
trace
minimization
popular
convex
surrogate
low-rank
matrix
recovery
enforcing
psd
constraint
neither
require
knowledge
outliers
even
existence
sensing
vectors
composed
i.i.d
standard
gaussian
entries
establish
ﬁxed
rank-r
psd
matrix
long
number
measurements
exceeds
order
nr2
proposed
convex
program
exactly
recover
high
probability
even
fraction
order
1/r
measurements
arbitrarily
corrupted
measurement
complexity
order-wisely
near-optimal
factor
near-optimal
rank-one
case
constant
factor
furthermore
recovery
also
stable
additive
bounded
noise
proposed
convex
program
coincides
version
phaselift
algorithm
studied
literature
phase
retrieval
work
provides
ﬁrst
theoretical
performance
guarantee
recover
low-rank
psd
matrices
presence
arbitrary
outliers
moreover
show
proposed
approach
easily
extended
recover
low-rank
toeplitz
psd
matrices
via
numerical
simulations
reduce
computational
burden
facing
large-scale
problems
next
develop
non-convex
algorithm
based
subgradient
descent
rank
psd
matrix
upper
bound
known
priori
since
rank-r
psd
matrix
uniquely
decomposed
rn×r
orthonormal
trans-
formations
sufﬁcient
recover
without
constructing
psd
matrix
explicitly
subgradient
descent
algorithm
iteratively
updates
estimate
descending
along
subgradient
ℓ1-norm
measurement
residual
using
properly
selected
step
size
spectral
initialization
conduct
extensive
numerical
experiments
demonstrate
excellent
empirical
performance
compare
convex
program
proposed
well
alternative
approaches
literature
organization
rest
paper
organized
section
presents
proposed
convex
optimization
algorithm
corresponding
performance
guarantee
detailed
com-
parisons
related
work
presented
section
iii
describes
proposed
non-convex
subgradient
descent
algorithm
computationally
efﬁcient
excellent
empirical
perfor-
mance
numerical
examples
provided
section
proof
main
theorem
given
section
finally
conclude
section
parameter-free
convex
relaxation
problem
formulation
let
rn×n
rank-r
psd
matrix
set
measurements
may
corrupted
either
arbitrary
outliers
bounded
noise
represented
0ai
cid:9
linear
mapping
rn×n
deﬁned
cid:8
ith
sensing
vector
composed
i.i.d
standard
gaussian
entries
vector
denotes
outlier
vector
assumed
sparse
whose
entries
arbitrarily
large
fraction
nonzero
entries
deﬁned
kβk0
moreover
vector
denotes
additive
noise
assumed
bounded
kwk1
goal
robustly
recover
measurements
i=1
recovery
via
convex
relaxation
motivate
algorithm
consider
case
outlier
vector
present
rank
known
one
may
seek
rank-r
psd
matrix
minimizes
cardinality
measurement
residual
motivate
outlier
sparsity
given
argminx
cid:23
0kz
however
cardinality
minimization
rank
constraint
np-hard
general
making
method
compu-
tationally
infeasible
common
approach
resort
convex
relaxation
relax
cardinality
minimization
convex
relaxation
i.e
ℓ1-norm
meanwhile
drop
rank
constraint
yielding
rank
s.t
robust-phaselift
argminx
cid:23
0kz
denote
convex
program
robust-phaselift
algorithm
since
coincides
phaselift
algorithm
studied
phase
retrieval1
advantage
robust-phaselift
require
prior
knowledge
noise
bound
rank
sparsity
level
outliers
free
regularization
parameter
also
worth
emphasizing
due
special
rank-
one
measurement
operator
possible
honor
psd
constraint
motivate
low-rank
structure
explicitly
via
example
trace
minimization2
encouragingly
demonstrate
algorithm
admits
robust
recovery
rank-r
psd
matrix
soon
number
measurements
large
enough
even
fraction
arbi-
trary
outliers
theorem
best
knowledge
ﬁrst
theoretical
performance
guarantee
robustness
respect
arbitrary
outliers
low-rank
setting
main
theorem
given
1note
different
versions
phaselift
literature
outlier-robust
therefore
rename
robust-phaselift
emphasis
2the
interested
readers
invited
look
fig
intuitive
geometric
interpretation
noise-free
outlier-free
case
theorem
suppose
kwk1
kβk0
assume
support
selected
uniformly
random
signs
nonzero
entries
generated
rademacher
distribution
sgn
sgn
1/2
supp
ﬁxed
rank-r
psd
matrix
rn×n
exist
absolute
constants
long
c1nr2
solution
satisﬁes
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
probability
exceeding
exp
−γm/r2
con-
stants
theorem
following
consequences
exact
recovery
outliers
theorem
suggests
recovery
exact
using
robust-phaselift
i.e
even
fraction
measurements
arbitrarily
corrupted
long
number
measure-
ments
order
nr2
given
least
unknowns
measurement
complexity
near-optimal
factor
stable
recovery
bounded
noise
presence
bounded
noise
theorem
suggests
recovery
performance
decreases
gracefully
increase
frobenius
norm
reconstruction
error
proportional
per-entry
noise
level
measure-
ments
phase
retrieval
problem
degenerates
case
phase
retrieval
theorem
recovers
existing
results
outlier-robust
phase
retrieval
measurement
complexity
order
optimal
scaling
factor
let
denote
argminrank
cid:23
zkf
best
rank-r
psd
matrix
approximation
solution
theorem
suggests
estimate
well
approximated
rank-r
psd
matrix
since
rkf
0kf
long
number
measurements
sufﬁciently
large
furthermore
0kf
ˆxr
ˆxkf
0kf
0kf
2c2
indicating
provides
accurate
estimate
exactly
rank-r
psd
comparisons
related
work
absence
outliers
phaselift
algorithm
following
form
s.t
min
cid:23
denotes
trace
proposed
solve
phase
retrieval
problem
later
algorithm
employed
recover
low-rank
psd
matrices
order
measurements
obtained
i.i.d
sub-gaussian
sensing
vectors
shown
guarantee
exact
recovery
noise-free
case
stable
recovery
bounded
noise
one
problem
algorithm
noise
bound
assumed
known
furthermore
amenable
handle
outliers
since
kz−a
arbitrarily
large
outliers
consequently
ground
truth
quickly
becomes
infeasible
proposed
algorithm
studied
variant
phaselift
phase
retrieval
corresponding
case
x0xt
rank-one
shown
i.i.d
gaussian
sensing
vectors
algorithm
succeeds
high
probability
compared
algo-
rithm
eliminates
trace
minimization
leads
easier
algorithm
implementations
note
also
considers
regularization-free
algorithm
psd
matrix
estimation
minimizes
ℓ2-norm
residual
unfortunately
handle
outliers
robust-phaselift
hand
ﬁrst
considered
robustness
robust-phaselift
algorithm
presence
outliers
phase
retrieval
establishing
guarantee
holds
even
constant
fraction
outliers
work
extends
performance
guarantee
general
low-rank
psd
matrix
case
broadly
speaking
problem
related
low-rank
matrix
recovery
under-determined
linear
system
linear
measurements
drawn
inner
products
rank-one
sensing
matrices
due
special
structure
sensing
matrices
eliminate
trace
minimization
consider
feasibility
constraint
psd
matrices
standard
approaches
separating
low-rank
sparse
components
via
convex
optimization
given
min
cid:23
λkβk1
s.t
βk1
regularization
parameter
requires
tuned
properly
contrast
formulation
parameter-free
iii
non-convex
subgradient
descent
algorithm
section
propose
another
algorithm
robust
low-rank
psd
matrix
recovery
corrupted
rank-one
mea-
surements
assuming
rank
upper
bound
psd
matrix
known
priori
case
decompose
rn×r
instead
directly
recovering
may
aim
recovering
orthogonal
transforms
since
orthonormal
matrix
rr×r
consider
relaxing
loss
function
keeping
rank
constraint
obtain
following
problem
argminx
cid:23
0kz
since
rank-r
psd
matrix
written
rn×r
equivalently
reformulated
rank
argminu∈rn×r
s.t
outliers
modest
outlier
amplitudes
large
outlier
amplitudes
2mkz
4mkz
fig
illustrations
objective
function
log
ℓ2-norm
counterpart
log
negative
logarithmic
scales
different
corruption
scenarios
r2×1
number
measurements
100
i.i.d
gaussian
sensing
vectors
fraction
outliers
0.2
uniformly
selected
support
amplitudes
drawn
unif
unif
100
interesting
observe
large
outliers
completely
distort
proposed
objective
quite
robust
ground
truth
global
optima
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
xi=1
cid:12
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
clearly
longer
convex
illustrate
ﬁrst
row
fig
plots
value
objective
function
negative
logarithmic
scale
i.e
log
different
corruption
scenarios
r2×1
comparison
second
row
fig
shows
loss
function
evaluated
ℓ2-norm
4mkz
motivated
recent
non-convex
approaches
solving
quadratic
systems
propose
subgradient
descent
algorithm
solve
effectively
working
non-smooth
function
note
subgradient
respect
given
robust
outliers
xi=1
sgn
cid:18
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:19
aiat
sign
function
sgn
deﬁned
sgn
=
subgradient
descent
algorithm
proceeds
de-
note
estimate
tth
iteration
rn×r
first
initialized
best
rank-r
approximation
following
matrix
respect
frobenius
norm
cid:16
cid:17
secondly
t+1
iteration
apply
subgradient
descent
reﬁne
estimate
argminrank
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
xi=1
ziaiat
t+1
step
size
adaptively
set
0.05
maxn2−t/1000
10−6o
provide
accurate
estimates
using
fewer
iterations
numerical
simulations
procedure
summarized
alg
stopping
rule
alg
simply
put
maximum
number
iterations
algorithm
subgradient
descent
solving
parameters
rank
number
iterations
tmax
step
size
input
measurements
sensing
vectors
i=1
initialization
initialize
rn×r
via
tmax
end
output
tmax
update
t+1
via
main
advantage
alg
low
memory
computational
complexity
given
construct
full
psd
matrix
memory
complexity
simply
size
order
computational
complexity
per
iteration
also
low
order
mnr
linear
parameters
demonstrate
excellent
empirical
performance
alg
section
iv-c.
100
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
600
200
500
number
measurements
300
400
0.05
0.1
percent
outliers
0.15
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.2
numerical
examples
performance
convex
relaxation
ﬁrst
examine
performance
robust-phaselift
let
40.
randomly
generate
low-rank
psd
matrix
rank-r
rn×r
composed
i.i.d
standard
gaussian
variables
sensing
vectors
also
composed
i.i.d
standard
gaussian
variables
monte
carlo
simulation
called
successful
normalized
estimate
error
satisﬁes
ˆx−x0kf/kx0kf
10−6
denotes
solution
cell
success
rate
calculated
averaging
100
monte
carlo
simulations
100
200
500
number
measurements
300
400
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
600
100
200
500
number
measurements
300
400
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
600
fig
phase
transitions
low-rank
psd
matrix
recovery
respect
number
measurements
rank
trace
minimization
without
trace
minimization
noise-free
measurements
40.
fig
shows
success
rates
algorithms
respect
number
measurements
rank
trace
minimization
without
trace
minimiza-
tion
proposed
robust-phaselift
noise-free
measurements
seen
performance
two
algorithms
almost
equivalent
conﬁrming
similar
numerical
observation
phase
retrieval
problem
also
holds
low-rank
setting
trace
minimization
may
eliminated
low-rank
psd
matrix
recovery
using
rank-
one
measurements
fig
shows
success
rates
robust-
phaselift
algorithm
respect
number
measure-
ments
rank
measurements
selected
uniformly
random
corrupted
standard
gaussian
variables
respect
percent
outliers
rank
ﬁxed
number
measurements
600.
also
suggests
possible
room
improvements
theoretical
guarantee
numerical
results
indicate
required
measurement
complexity
successful
recovery
seemingly
linear
relationship
fig
phase
transitions
low-rank
psd
matrix
recovery
respect
number
measurements
rank
measurements
corrupted
standard
gaussian
variables
percent
outliers
rank
number
measurements
600
40.
convex
relaxation
additional
toeplitz
structure
next
consider
robust
recovery
low-rank
toeplitz
psd
matrices
allow
complex-valued
sensing
vectors
i=1
complex-valued
toeplitz
psd
matrices
estimating
low-rank
toeplitz
psd
matrices
great
interests
array
signal
processing
modify
incorporating
toeplitz
constraint
xai
argminx
cid:23
0kz
s.t
toeplitz
let
toeplitz
psd
matrix
generated
cn×r
vander-
monde
matrix
ej2πfi
ej2π
n−1
unif
diag
unif
fig
shows
phase
transitions
toeplitz
psd
matrix
recovery
respect
number
measurements
rank
without
outliers
measurements
selected
uniformly
random
corrupted
standard
gaussian
variables
seen
low-rank
toeplitz
psd
matrix
robustly
recovered
sub-
linear
number
measurements
due
additional
toeplitz
structure
note
different
covariance
sketching
scheme
considered
estimating
low-rank
toeplitz
covariance
matrices
though
directly
comparable
measurement
scheme
may
beneﬁt
similar
parameter-
free
convex
optimization
handle
outliers
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
number
measurements
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
number
measurements
fig
phase
transitions
low-rank
toeplitz
psd
matrix
recovery
respect
number
measurements
rank
without
outliers
measurements
corrupted
standard
gaussian
variables
64.
performance
non-convex
subgradient
descent
next
examine
performance
non-convex
sub-
gradient
descent
algorithm
alg
number
iterations
set
tmax
104
large
value
guarantee
convergence
terminated
denote
solution
alg
monte
carlo
simulation
deemed
successful
normalized
estimate
error
satisﬁes
0kf/kx0kf
10−6
estimated
low-rank
psd
matrix
cell
success
rate
calculated
averaging
100
monte
carlo
simulations
100
200
500
number
measurements
400
300
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
600
fig
phase
transitions
low-rank
psd
matrix
recovery
respect
number
measurements
rank
proposed
alg
using
noise-free
measurements
40.
fig
shows
success
rate
alg
respect
number
measurements
rank
setup
fig
noise-free
measurements
40.
indeed
empirically
alg
performs
similarly
convex
algorithms
much
lower
computational
cost
moreover
proposed
alg
allows
perfect
recovery
even
presence
outliers
comparison
implement
extension
wirtinger
flow
algorithm
low-
rank
case
minimizes
squared
ℓ2-norm
residual
update
rule
per
iteration
becomes
t+1
+µwf
xi=1
cid:16
aik2
cid:17
aiat
0.1/
0k2
using
initialization
step
size
set
fig
shows
success
rates
µwf
alg
respect
percent
outliers
rank
setup
fig
performance
even
better
convex
counterpart
contrast
algorithm
performs
poorly
even
outliers
shown
success
rate
plot
fig
loss
function
used
robust
outliers
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.2
0.05
0.1
percent
outliers
0.15
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.2
0.05
0.1
percent
outliers
0.15
fig
phase
transitions
low-rank
psd
matrix
recovery
respect
percent
outliers
rank
using
proposed
alg
algorithm
600.
bounded
noise
i.i.d
drawn
unif
−4/m
4/m
thus
kwk1
fig
depicts
mean
squared
error
ˆx−x
0k2
different
algorithms
respect
number
measurements
estimated
psd
matrix
subgradient
descent
algorithm
alg
various
ranks
used
prior
information
corresponding
correct
rank
underestimate
r−1
overestimate
seen
alg
works
well
long
given
rank
provides
upper
bound
true
rank
performs
much
better
algorithm
outlier-robust
hand
phaselift
algorithm
admit
favorable
performance
various
constraint
parameters
expected
since
outliers
fall
prescribed
noise
bound
fact
fails
return
feasible
solution
number
amplitudes
outliers
large
simulation
contrast
robust-phaselift
allows
stable
recovery
even
additional
bounded
noise
performs
comparably
alg
correct
model
order
104
102
100
10-2
10-4
10-6
100
200
robust-phaselift
alg
alg
r+1
alg
r-1
wirtinger
flow
phaselift
phaselift
phaselift
300
400
number
measurements
500
600
comparisons
additional
bounded
noise
alg
finally
compare
two
proposed
algorithms
robust-
phaselift
algorithm
phaselift
algorithm
measurements
cor-
rupted
outliers
bounded
noise
fix
rank-r
psd
matrix
sensing
vectors
well
outliers
generated
similarly
earlier
fraction
outliers
set
moreover
entry
fig
comparisons
mean
squared
errors
using
different
algorithms
respect
number
measurements
outliers
bounded
noise
proof
main
theorem
section
prove
theorem
roadmap
proof
section
v-a
ﬁrst
provide
sufﬁcient
conditions
approximate
dual
certiﬁcate
certiﬁes
optimality
proposed
algorithm
lemma
section
v-b
records
lemmas
show
satisﬁes
required
restricted
isometry
properties
dual
certiﬁcate
constructed
validated
ﬁxed
low-
rank
psd
matrix
section
v-c.
finally
proof
concluded
section
v-d.
first
introduce
additional
notations
let
subset
complement
respect
mapping
operator
con-
strained
deﬁned
cid:8
xai
cid:9
i∈s
denote
adjoint
operator
=pm
i=1
µiaiat
ith
entry
use
kxk
kxkf
kxk1
denote
spectral
norm
frobenius
norm
nuclear
norm
matrix
respectively
use
kxkp
denote
ℓp-norm
vector
let
singular
value
decomposition
ﬁxed
rank-r
psd
matrix
symmetric
tangent
space
denoted
=nu
rn×ro
denote
orthogonal
projection
onto
orthogonal
complement
respectively
no-
tational
simplicity
denote
h−pt
symmetric
matrix
rn×n
moreover
represent
absolute
constants
whose
values
may
change
according
context
approximate
dual
certiﬁcate
following
lemma
suggests
certain
appropriate
restricted
isometry
preserving
properties
properly
constructed
dual
certiﬁcate
guarantee
faithful
recovery
proposed
algorithm
lemma
approximate
dual
certiﬁcate
denote
subset
|s|m
13√2r⌉
constant
support
satisﬁes
supp
suppose
mapping
obeys
symmetric
matrices
cid:18
|s|
kas
cid:18
cid:19
kxk1
cid:19
kxk1
matrices
|s⊥|
kas⊥
cid:18
cid:19
kxkf
as⊥
operator
constrained
respectively
exists
matrix
satisﬁes
tkf
13r
cid:22
cid:26
sgn
|µi|
supp
supp
solution
satisﬁes
constant
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
proof
denote
solution
0+h
cid:23
cid:23
furthermore
wk1
inequality
follows
optimality
since
feasible
since
β+w
kas
−β−wsk1+kas⊥
−ws⊥k1
wk1
wsk1
kws⊥k1
kas⊥
kas⊥
ws⊥k1
kws⊥k1
wk1
kas
wsk1
kws⊥k1
wsk1
kas
wsk1
2kws⊥k1
kas
2kws⊥k1
last
inequality
follows
triangle
inequality
could
bound
kas⊥
kas⊥
kas⊥
kas
kas⊥
2kws⊥k1
kas
kas
kas⊥
2kws⊥k1
kas
2kws⊥k1
assumptions
imply
cid:19
cid:18
kas⊥
kas
2kws⊥k1
|s⊥|
cid:18
ﬁrst
inequality
follows
due
⊥k1
cid:23
second
inequality
follows
last
inequality
follows
gives
cid:19
tkf
|s|
cid:19
tk1
cid:18
cid:18
|s⊥|
|s|
√2r
cid:19
tkf
use
inequality
tk1
√2rkh
tkf
hand
since
9/m
subgradient
ℓ1-norm
kβk1
wk1
kβk1
kwk1
simple
transformation
mkwk1
cid:19
kwk1
cid:18
kµk∞
18ǫ
get
18ǫ
tkf
tkf
13rkh
tkf
rhh
lemma
suppose
sensing
vectors
composed
i.i.d
sub-gaussian
entries
exist
pos-
itive
universal
constants
provided
c3nr
matrices
rank
one
cid:0
δlb
cid:1
kxkf
cid:0
δub
probability
exceeding
c1e−c2m
δlb
δub
deﬁned
rip-ℓ2/ℓ1
constants
operator
represents
linear
transformation
maps
rn×n
m/2
2i−1
a2iat
i=1
rm/2
ha2i−1at
cid:1
kxkf
third
condition
easily
validated
lower
bound
setting
δlb
appropriately
since
mpm/2
2ka
i=1
cid:0
cid:12
cid:12
ha2i−1at
2i−1
cid:12
cid:12
cid:12
cid:12
ha2iat
cid:12
cid:12
cid:1
gives
construction
dual
certiﬁcate
tkf
18rǫ
combining
know
cid:18
|s⊥|
|s|
since
|s⊥|6m
|s|m
lemma
√2r
cid:19
tkf
√2r−
tkf
18rǫ
assumption
|s|m
tkf
20rǫ
cid:16
|s⊥|6m
|s|m
√2r
cid:17
ﬁxed
constant
finally
0kf
tkf
⊥kf
tkf
cid:18
cid:19
tkf
constant
18rǫ
restricted
isometry
ﬁrst
two
conditions
lemma
supplied
straightforwardly
following
lemma
long
cnr
|s|
c1m/r
c2n
constants
lemma
fix
psd
matrices
one
assume
20δ−2n
kxk1
kxk1
probability
exceeding
2e−mǫ2/2
right
hand
side
holds
symmetric
matrices
third
condition
lemma
obtained
using
mixed-norm
rip-ℓ2/ℓ1
provided
long
cnr
|s|
c1m
constants
notational
simplicity
let
|z|≤3
0.9707
|z|≤3
2.6728
|z|≤3
11.2102
standard
gaussian
random
variable
indicator
function
respect
event
consider
singular
value
decomposition
psd
matrix
rank
represented
inspired
construct
i=1
λiuiut
xj∈s⊥h
xi=1
cid:12
cid:12
cid:12
cid:12
ajat
xj∈s⊥
cid:18
mxj∈s
χjajat
xi=1
cid:12
cid:12
cid:12
cid:12
cid:19
xj∈s⊥
ui|≤3
|at
mxj∈s
χjajat
ui|≤3
ajat
|at
ajat
set
sgn
supp
otherwise
i.i.d
rademacher
random
variables
1/2
construction
immediately
indicates
satisﬁes
show
satisﬁes
high
proability
follows
separate
constructed
two
parts
consider
bounds
respectively
cid:22
first
standard
results
random
matrix
theory
corollary
5.35
proof
|s⊥|
cid:18
cid:13
cid:13
cid:13
cid:13
40r
cid:19
cid:13
cid:13
cid:13
cid:13
probability
least
2e−γ|s⊥|/r2
constant
provided
cid:12
cid:12
cid:12
cid:12
cnr2
constant
particular
40r
13r
let
cid:16
cid:17
proof
tkf
cid:16
cid:17
projection
onto
orthogonal
complement
gives
cid:13
cid:13
cid:13
cid:13
|s⊥|
cid:18
cid:19
cid:13
cid:13
cid:13
cid:13
let
a′j
projection
onto
orthogonal
complement
column
space
cid:16
a′j
i.i.d
copies
zero-mean
isotropic
sub-gaussian
random
vector
satisﬁes
ǫǫt
α0i
following
theorem
5.39
ǫjǫt
xj∈s⊥
ui|≤3
cid:17
1/2
i=1
cid:12
cid:12
cid:12
cid:12
|at
α0i
cid:13
cid:13
cid:13
cid:13
|s⊥|
40r
cid:13
cid:13
cid:13
cid:13
probability
least
2e−γ|s⊥|/r2
constant
provided
cid:12
cid:12
cid:12
cid:12
cnr2
constant
result
cnr2
large
constant
|s|
c1m
constant
small
enough
probability
least
1−e−γm/r2
exists
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
|s⊥|
30r
60r
|s⊥|
|s|
next
let
theorem
5.39
9χjajat
mpj∈s
check
9χjajat
since
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
|s|
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
9χjajat
10r
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
probability
least
exp
−γm/r
long
cnr2
|s|
c1m/r
c2nr
constants
particular
gives
10r
cid:13
cid:13
cid:13
putting
together
obtain
cnr2
|s|
c1m/r
c2nr
constants
probability
least
e−γm/r2
cid:13
cid:13
cid:13
cid:13
1.7
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:18
0.11
cid:19
1.7
0.25
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
|s|
xj∈s
cid:19
φck
cid:13
cid:13
cid:13
kth
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
column
expressed
explicitly
cid:13
cid:13
cid:13
first
consider
term
cid:16
cid:17
xj∈s⊥
xi=1
cid:12
cid:12
cid:12
cid:12
cid:1
cid:16
cid:17
cid:0
rr×|s⊥|
constructed
r|s⊥|
composed
one
expressed
ui|≤3
cid:18
|at
ui|≤3
cid:18
cid:19
cid:0
cid:1
cid:1
xi=1
cid:12
cid:12
cid:12
cid:12
cid:0
cid:0
cid:0
cid:1
cid:13
cid:13
cid:13
constant
according
cid:13
cid:13
cid:13
p
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
2r2
xj∈s⊥
cid:0
shows
long
|s|
c1m
constants
i.i.d
sub-exponential
random
variables
2exp
cid:1
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
corollary
5.17
cid:12
cid:12
cid:12
cid:12
cid:1
ec2
note
|at
4.07
4.07
4.1m
kckk2
holds
probability
least
e−γm/r2
furthermore
ﬁxed
vector
r|s⊥|
obeying
kxk2
kφxk2
distributed
chi-square
random
variable
degrees
freedom
lemma
kφxk2
12000r2
probability
least
e−γm/r2
provided
cnr2
sufﬁciently
large
constant
therefore
obtain
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
yields
cid:13
cid:13
cid:13
cid:13
kckk2
cid:13
cid:13
cid:13
cid:13
xk=1
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
kckk2
2700r3
2700r2
probability
least
e−γm/r2
cnr2
|s|
c1m
bound
second
term
could
adopt
techniques
kth
column
expressed
explicitly
cid:16
cid:17
xj∈s⊥
xi=1
cid:12
cid:12
cid:12
cid:12
cid:16
cid:17
xj∈s⊥
ja′j
ψck
ui|≤3
cid:18
|at
cid:19
rn×|s⊥|
constructed
a′j
reminder
projection
onto
orthog-
onal
complement
column
space
a′j
cid:16
cid:17
equivalently
cid:16
cid:17
rn×|s⊥|
constructed
ﬁxed
vector
r|s⊥|
obeying
kxk2
kψxk2
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
kaxk2
distributed
chi-square
random
variable
degrees
freedom
lemma
tells
kaxk2
kψxk2
kaxk2
12000r2
probability
exceeding
e−γm/r2
provided
cnr2
sufﬁciently
large
constant
hence
2700r3
leads
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
kckk2
cid:13
cid:13
cid:13
cid:13
kckk2
cid:13
cid:13
cid:13
cid:13
xk=1
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
combining
know
cid:13
cid:13
cid:13
next
let
check
′k2
2700r2
written
30r
ﬁrst
term
kth
column
formulated
explicitly
mxj∈s
cid:16
cid:17
rr×|s|
constructed
r|s|
composed
one
expressed
cid:1
cid:16
cid:17
9χj
cid:0
¯φdk
9χj
cid:0
cid:1
81.
note
i.i.d
sub-exponential
based
corollary
5.17
cid:13
cid:13
cid:13
constant
random
variables
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
p
|s|
cid:1
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
|s|
cid:19
indicates
|s|
cm/r
constant
2exp
cid:18
−c1
ed2
|s|
|s|
|s|
holds
probability
least
e−γm/r
ﬁxed
also
chi-
vector
r|s|
obeying
kxk2
cid:13
cid:13
square
random
variable
degrees
freedom
¯φx
cid:13
cid:13
xj∈s
cid:0
kdkk2
probability
least
e−γm/r2
provided
c1nr2
sufﬁciently
large
constant
thus
2700δ0cr2
¯φx
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
kdkk2
cid:13
cid:13
cid:13
cid:13
xk=1
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
gives
kdkk2
2700r3
2700r2
probability
least
e−γm/r2
c1nr2
|s|
cm/r
appropriate
constants
consider
second
term
′k2
kth
column
expressed
explicitly
cid:16
cid:17
cid:16
cid:17
9χj
a′j
¯ψdk
mxj∈s
mxj∈s
constructed
a′j
also
rn×|s|
decompose
cid:16
cid:17
rn×|s|
constructed
ﬁxed
vector
r|s|
obey-
cid:13
cid:13
cid:13
cid:16
cid:17
¯ax
cid:13
cid:13
cid:13
ing
kxk2
cid:13
cid:13
¯ax
cid:13
cid:13
chi-square
random
variable
cid:13
cid:13
degrees
freedom
well
since
already
know
provided
c1nr2
sufﬁciently
large
constant
¯ψx
cid:13
cid:13
probability
exceeding
e−γm/r2
2700r3
result
2700δ0cr2
¯ax
cid:13
cid:13
cid:13
cid:13
¯ax
cid:13
cid:13
¯ψx
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
kdkk2
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
xk=1
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
kdkk2
cid:13
cid:13
cid:13
2700r2
30r
combining
leads
finally
obtain
cnr2
|s|
c1m/r
constants
probability
least
e−γm/r2
tkf
cid:13
cid:13
cid:13
proof
theorem
15r
cid:13
cid:13
cid:13
required
restricted
isometry
properties
linear
mapping
supplied
section
v-b
valid
appropriate
dual
certiﬁcate
constructed
section
v-c
therefore
the-
orem
straightforwardly
obtained
lemma
section
v-a
conclusion
paper
address
problem
estimating
low-
rank
psd
matrix
rn×n
rank-one
measurements
possibly
corrupted
arbitrary
outliers
bounded
noise
problem
many
applications
covariance
sketching
phase
space
tomography
noncoherent
detection
communications
shown
order
nr2
random
gaussian
sensing
vectors
psd
matrix
rank-r
robustly
recovered
minimizing
ℓ1-norm
observation
residual
within
semideﬁnite
cone
high
probability
even
fraction
measurements
adversarially
corrupted
convex
formulation
eliminates
need
trace
minimization
tuning
parameters
without
prior
knowledge
outliers
moreover
non-
convex
subgradient
descent
algorithm
proposed
excel-
lent
empirical
performance
additional
information
rank
psd
matrix
available
future
work
would
interesting
theoretically
justify
proposed
non-convex
algorithm
finally
note
recently
one
authors
proposed
median-truncated
gradient
descent
algorithm
phase
retrieval
constant
proportion
outliers
provable
performance
guarantees
might
possible
extend
problem
robust
low-
rank
psd
matrix
recovery
considered
paper
pursued
elsewhere
acknowledgement
thank
anonymous
reviewers
valuable
sug-
gestions
greatly
improved
quality
paper
references
fienup
reconstruction
object
modulus
fourier
transform
optics
letters
vol
27–29
1978
candes
strohmer
voroninski
phaselift
exact
stable
signal
recovery
magnitude
measurements
via
convex
pro-
gramming
communications
pure
applied
mathematics
vol
1241–1274
2013
candes
eldar
strohmer
voroninski
phase
retrieval
via
matrix
completion
siam
journal
imaging
sciences
vol
199–225
2013
waldspurger
aspremont
mallat
phase
recovery
maxcut
complex
semideﬁnite
programming
mathematical
programming
vol
149
1-2
47–81
2015
schniter
rangan
compressive
phase
retrieval
via
generalized
approximate
message
passing
signal
processing
ieee
transactions
vol
1043–1055
2015
shechtman
eldar
cohen
chapman
miao
segev
phase
retrieval
application
optical
imaging
contemporary
overview
signal
processing
magazine
ieee
vol
87–109
2015
chen
chi
goldsmith
exact
stable
covariance
esti-
mation
quadratic
sampling
via
convex
programming
information
theory
ieee
transactions
vol
4034–4059
july
2015
scharf
statistical
signal
processing
addison-wesley
reading
1991
vol
lakhina
papagiannaki
crovella
diot
kolaczyk
taft
structural
analysis
network
trafﬁc
ﬂows
acm
sigmetrics
performance
evaluation
review
vol
acm
2004
61–72
gross
y.-k.
liu
flammia
becker
eisert
quantum
state
tomography
via
compressed
sensing
physical
review
letters
vol
105
150401
2010
ariananda
leus
compressive
wideband
power
spectrum
estimation
signal
processing
ieee
transactions
vol
4775–4789
2012
kim
haimovich
eldar
non-coherent
direction
arrival
estimation
magnitude-only
measurements
signal
process-
ing
letters
ieee
vol
925–929
2015
mason
i.-y
son
yazici
passive
synthetic
aperture
radar
imaging
using
low-rank
matrix
recovery
methods
selected
topics
signal
processing
ieee
journal
vol
1570–1582
2015
candes
solving
quadratic
equations
via
phaselift
many
equations
unknowns
foundations
computational
mathematics
vol
1017–1026
2014
demanet
hand
stable
optimizationless
recovery
phase-
less
linear
measurements
journal
fourier
analysis
applications
vol
199–221
2014
hand
phaselift
robust
constant
fraction
arbitrary
errors
applied
computational
harmonic
analysis
2016
kabanava
kueng
rauhut
terstiege
stable
low-rank
matrix
recovery
via
null
space
properties
arxiv
preprint
arxiv:1507.07184
2015
recht
fazel
parrilo
guaranteed
minimum-rank
solutions
linear
matrix
equations
via
nuclear
norm
minimization
siam
review
vol
471–501
2010
dai
milenkovic
kerman
subspace
evolution
transfer
set
low-rank
matrix
completion
signal
processing
ieee
transactions
vol
3120–3132
2011
wang
tang
unique
nonnegative
solution
underdetermined
system
vectors
matrices
signal
processing
ieee
transactions
vol
1007–1016
2011
candès
wright
robust
principal
component
analysis
journal
acm
vol
11:1–11:37
jun
2011
chandrasekaran
sanghavi
parrilo
willsky
rank-sparsity
incoherence
matrix
decomposition
siam
journal
optimization
vol
572–596
2011
wright
ganesh
min
compressive
principal
component
pursuit
information
inference
vol
32–68
2013
compressed
sensing
matrix
completion
constant
proportion
corruptions
constructive
approximation
vol
73–
2013
mateos
giannakis
robust
pca
bilinear
decomposition
outlier-sparsity
regularization
signal
processing
ieee
transac-
tions
vol
5176–5190
2012
candès
soltanolkotabi
phase
retrieval
via
wirtinger
ﬂow
theory
algorithms
information
theory
ieee
transactions
vol
1985–2007
2015
chen
candès
solving
random
quadratic
systems
equations
nearly
easy
solving
linear
systems
arxiv:1505.05114
may
2015
white
ward
sanghavi
local
convexity
solving
quadratic
equations
arxiv
preprint
arxiv:1506.07868
2015
abramovich
gray
gorokhov
spencer
positive-deﬁnite
toeplitz
completion
doa
estimation
nonuniform
linear
antenna
arrays
fully
augmentable
arrays
signal
processing
ieee
transactions
vol
2458–2471
1998
qiao
pal
generalized
nested
sampling
compressing
low
rank
toeplitz
matrices
ieee
signal
processing
letters
vol
1844–1848
2015
romero
ariananda
tian
leus
compressive
co-
variance
sensing
structure-based
compressive
sensing
beyond
sparsity
ieee
signal
processing
magazine
vol
78–93
2016
romero
lópez-valcarce
leus
compression
limits
random
vectors
linearly
parameterized
second-order
statistics
ieee
transactions
information
theory
vol
1410–
1425
2015
zheng
lafferty
convergent
gradient
descent
algorithm
rank
minimization
semideﬁnite
programming
random
linear
measurements
advances
neural
information
processing
systems
2015
109–117
vershynin
introduction
non-asymptotic
analysis
random
matrices
compressed
sensing
theory
applications
210
268
2012
laurent
massart
adaptive
estimation
quadratic
functional
model
selection
annals
statistics
1302–1338
2000
zhang
chi
liang
provable
non-convex
phase
retrieval
outliers
median
truncated
wirtinger
ﬂow
international
con-
ference
machine
learning
icml
new
york
2016
