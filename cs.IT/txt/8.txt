wireless
caching
technical
misconceptions
business
barriers
georgios
paschos
cid:5
ejder
ba¸stu˘g
cid:63
ingmar
land
cid:5
giuseppe
caire†
mérouane
debbah
cid:5
cid:5
huawei
technologies
france
research
center
mathematical
algorithmic
sciences
lab
quai
point
jour
boulogne-billancourt
92100
france
cid:63
large
networks
systems
group
laneas
centralesupélec
université
paris-saclay
rue
joliot-curie
91192
gif-sur-yvette
france
†technische
universität
berlin
electrical
engineering
computer
science
einsteinufer
10587
berlin
germany
georgios.paschos
ingmar.land
merouane.debbah
huawei.com
ejder.bastug
centralesupelec.fr
giuseppe.caire
tu-berlin.de
research
partly
supported
erc
starting
grant
305123
advanced
mathematical
tools
complex
network
engineering
project
bestcom
june
2016
draft
wireless
caching
technical
misconceptions
business
barriers
abstract
caching
hot
research
topic
poised
develop
key
technology
upcoming
wireless
networks
successful
implementation
caching
techniques
however
crucially
depends
joint
research
developments
different
scientiﬁc
domains
networking
information
theory
machine
learning
wireless
communications
moreover
exist
business
barriers
related
complex
interactions
involved
stakeholders
users
cellular
operators
internet
content
providers
article
discuss
several
technical
misconceptions
aim
uncover
enabling
research
directions
caching
wireless
systems
ultimately
make
speculative
stakeholder
analysis
wireless
caching
index
terms
edge
caching
wireless
networks
introduction
caching
mature
idea
domains
web
caching
content
delivery
networks
memory
optimization
operating
systems
caching
still
active
topic
discussion
90s
trafﬁc
web
exploded
leading
inventor
sir
tim
berners-lee
declare
network
congestion
one
main
challenges
internet
future
congestion
caused
dotcom
boom
speciﬁcally
due
client-server
model
connectivity
whereby
webpage
downloaded
network
server
every
internet
user
world
challenge
ultimately
resolved
invention
content
delivery
networks
cdns
exploitation
web
caching
latter
replicates
popular
content
many
geographical
areas
saves
bandwidth
avoiding
unnecessary
multihop
retransmissions
byproduct
also
decreases
access
time
latency
decreasing
distance
two
communicating
entities
today
years
later
reviving
challenge
wireless
domain
latest
report
cisco
predicts
massive
increase
internet
devices
connected
wireless
june
2016
draft
access
warns
steep
increase
mobile
trafﬁc
expected
reach
2018
roughly
total
network
trafﬁc
majority
video
wireless
system
designers
strive
fortify
wireless
networks
higher
access
rates
one
hand
increased
densiﬁcation
network
infrastructure
last
three
decades
two
approaches
responsible
majority
network
capacity
upgrade
per
unit
area
successfully
absorbing
wireless
trafﬁc
growth
however
explosion
access
rates
number
base
stations
backhaul
wireless
networks
also
become
congested
motivates
use
caching
store
popular
reusable
information
base
stations
reduce
load
backhaul
furthermore
recent
technique
combined
caching
coding
revolutionized
goodput
scales
bandwidth-limited
networks
therefore
caching
potential
become
third
key
technology
wireless
systems
sustainability
research
community
converging
enabling
architecture
one
described
figure
network
future
memory
units
installed
gateway
routers
wireless
network
internet
e.g
called
s-gw
base
stations
different
sizes
small
regular
size
cells
end-user
devices
e.g
mobile
phones
laptops
routers
etc
article
discuss
important
topics
characteristics
cacheable
content
affects
caching
technologies
wireless
install
memory
differences
wireless
caching
legacy
caching
techniques
last
focus
business
barriers
must
overcome
successful
adoption
wireless
caching
industry
dealing
massive
content
network
trafﬁc
cacheable
interactive
applications
gaming
voice
calls
remote
control
signals
examples
information
objects
reusable
hence
cached
nevertheless
network
trafﬁc
today
estimated
deemed
cacheable
refer
cacheable
information
objects
content
article
since
performance
caching
inherently
connected
speciﬁcs
contents
section
dedicated
understanding
speciﬁcs
particular
focus
following
misconceptions
static
irm
model
sufﬁcient
experimentation
user
information
used
popularity
estimation
due
vast
number
users
iii
security
issues
precludes
caching
edge
june
2016
draft
figure
illustration
caching
future
wireless
networks
contents
available
origin
server
cached
base
stations
user
devices
ofﬂoading
backhaul
wireless
links
insufﬁciency
static
popularity
models
standard
approach
design
analyze
caching
systems
involves
model
generating
content
requests
replace
actual
request
traces–this
approach
often
several
orders
magnitude
faster
facto
model
performance
analysis
web
caching
inde-
pendence
reference
model
irm
content
requested
according
independent
poisson
process
rate
λpn
refers
content
popularity
modelled
power
law
i.e.
n−α
well-established
model
thrives
due
simplicity
two
parameters
namely
control
rate
requests
control
skewness
popularity
numerous
studies
irm
real
trafﬁc
satisfactory
results
need
change
irm
assumes
content
popularity
static
course
true
trending
tweets
breaking
news
next
episode
game
thrones
examples
ephemeral
content
rapidly
changing
popularity
appear
become
increasingly
popular
gradually
become
unpopular
fact
considers
large
youtube
video
demand
vod
datasets
discovers
time-varying
models
accurate
irm
respect
caching
performance
analysis–
figure
reproduces
comparison
ﬁtting
youtube
data
shows
superiority
june
2016
draft
base
station
fog
controller
centralroutercore
routerstorageunitcaching
edge
downlink/uplinkbackhaul
linkmobile
userterminalcontent
delivery
serverorigin
contentserver/website
small
base
stationbasestationd2d
link
modeling
popularity
time-varying
inhomogeneous
poisson
model
proposed
content
associated
pulse
whose
duration
reﬂects
content
lifespan
whose
height
denotes
instantaneous
popularity–the
model
called
shot
noise
model
snm
mirroring
poisson
noise
electronics
shape
pulse
important
study
observes
strong
correlations
popularity
duration
apparently
popular
contents
prosper
longer
finally
class-based
model
conveniently
capture
spatio-
temporal
correlations
allowing
analytical
tractability
mobile
users
especially
keen
downloading
ephemeral
content
thus
expected
case
wireless
content
improvement
modeling
accuracy
even
greater
figure
hit
probability
comparison
best
irm
snm
youtube
traces
optimize
cache
one
needs
track
changes
content
popularity
example
classical
web
caching
systems
adopt
dynamic
eviction
policies
like
least-recently-used
lru
order
combat
time-varying
content
popularity
heuristic
manner
however
joint
consideration
popularity
variations
wireless
systems
reveals
new
challenge
renders
lru
policies
inefﬁcient
typical
cdn
cache
normally
receives
requests/content/day
corresponding
ﬁgure
base
station
cache
may
low
0.1
requests/content/day
small
number
requests
fast
variations
popularity
become
difﬁcult
tracked
june
2016
draft
hit
probabilitycache
size
videos
10410310200.050.10.150.2irm
cid:31
tsnm
cid:31
toriginal
trace
classical
lru
schemes
fail
development
motivates
novel
caching
techniques
employ
learning
methodologies
accurately
track
evolution
content
popularity
time
recent
study
analyzes
snm
model
gives
optimal1
policy
joint
caching
popularity
estimation
additionally
proposes
alternative
solution
use
lru
preﬁlters
track
popularity
variations
since
content
popularity
time-varying
caching
operations
optimized
fresh
view
system
maintained
requires
massive
data
collection
processing
statistical
inference
data
complex
task
handle
additionally
user
privacy
concern
limit
potential
collecting
information
timely
gather
information
wireless
network
consider
users
subscribed
telecom
operator
caches
placed
network
e.g.
base
stations
locations
caches
capability
storing
contents
contents
catalog
let
matrix
rk×n
model
content
access
statistics
rows
users
columns
contents
words
entry
rating
matrix
quantiﬁes
popular
content
user
popularity
matrix
large
sparse
partially
known
practice
continuously
estimated
order
enable
correct
cache
decisions
base
stations
ﬁrst
seems
impossible
feat
deal
complexity
handling
matrix
possible
use
machine
learning
tools
estimate
unknown
entries
estimation
particularly
efﬁcient
matrix
low
spectral
dimension
system
described
small
number
features
fortunately
popularity
correlation
induces
behaviour
matrices
obtained
real
data
instance
low-rank
matrix
factorization
methods
i.e.
rr×k
rr×n
factor
matrices
employed
construct
r-rank
version
matrix
using
fact
users
interests
correlated
predictable
small
additionally
allows
store
collected
statistics
compact
way
result
big
1the
optimality
established
restricted
case
homogeneous
rectangularly-shaped
pulses
asymptotically
large
content
catalogs
june
2016
draft
data
platform
installed
operator
network
provide
efﬁcient
collection
processing
user
access
patterns
several
locations
evidenced
development
novel
machine
learning
tools
clustering
techniques
needed
improve
estimation
time-evolving
content
popularity
matrix
i.e.
base
station
may
differ
base
station
base
station
worth
noting
caching
system
requirements
similar
recommendation
system
example
well-known
netﬂix
movie
recommendation
system
exploits
information
user
past
activity
order
predict
movie
likely
scored
high
user
similarly
caching
system
exploits
request
sequence
predict
contents
popular
enough
cached
context
user
privacy
regulations
may
affect
collection
valuable
data
key
topic
research
direction
privacy-preserving
mechanisms
enable
sufﬁcient
sampling
time-evolving
location
dependent
popularity
matrix
with-
compromising
user
privacy
moreover
interesting
consider
learning
enhancement
approaches
transfer
information
caching
domain
domains
transfer
learning
security
kind
death
common
anti-caching
argument
relates
operation
caching
secure
environment
secure
counterpart
http
protocol
called
https
originally
used
provide
end-
to-end
e2e
encryption
securing
sensitive
information
like
online
banking
transactions
authentication
owing
recent
adoption
trafﬁc
giants
netﬂix
youtube
https
protocol
growing
numbers
soon
exceed
total
network
trafﬁc
content
encryption
poses
unsurmountable
obstacle
in-network
operations
including
caching
since
encrypting
data
makes
unique
reusable
caching
even
statistically
process-
ing
encrypted
content
impossible
ironically
statement
security
kind
death
tennessee
williams
seems
squarely
apply
wireless
caching
security
deﬁnitely
precious
good
everyone
welcomes
although
securing
video
stream
might
seem
excessive
measure
cases
may
well
justiﬁed
unfortunately
e2e
encryption
clearly
berners-lee
spirit
since
prevents
operators
optimizing
networks
reanimates
server-client
ghost
congestion
reality
equally
june
2016
draft
one
overlook
fact
modern
cdn
systems
resolve
issue
representatives
content
provider
edge
internet
representatives
trusted
entities
hold
user
keys
able
decrypt
requests
perform
standard
caching
operations
ultimately
methodology
neither
entirely
secure
user
efﬁcient
network
need
make
system
sustainable
ﬁnally
overrules
need
e2e
encryption
argument
https
video
delivery
given
however
situation
realistically
push
caching
deeper
wireless
access
currently
content
providers
install
caching
boxes
operator
network
intercept
related
encrypted
content
requests
deeper
wireless
access
network
examples
include
google
global
cache
saguna
solution
cachebox
appli-
ansys
approach
boxes
controlled
operator
leads
several
limitations
caching
boxes
perform
complex
tasks
difﬁcult
apply
learning
techniques
without
context
information
operator
caching
approach
similar
cdns
therefore
exploit
performance
opportunities
speciﬁc
wireless
caching
discuss
new
security
protocols
proposed
enable
operators
perform
caching
encrypted
requests
leads
interesting
research
direction
combine
user
security
privacy
facilitation
network
management
operations
crucial
sustainability
future
wireless
systems
iii
towards
unified
network
memory
proposition
information
centric
networking
icn
candidate
future
internet
also
risen
subject
install
network
memory
icn
approach
proposed
equip
routers
caches
allow
content
replication
everywhere
network
recent
work
came
striking
conclusions
icn
approach
caching
beneﬁts
icn
obtained
caching
edges
network
using
existing
cdns
extra
caching
core
network
brings
negligible
improvements
high
costs
wireless
domain
however
question
remains
relevant
make
sense
cache
even
closer
user
cdn
commonly
believed
caching
inefﬁcient
near
user
thus
done
cdn
explain
main
reasons
inefﬁciency
argue
june
2016
draft
overcome
caching
deeper
cdn
mitigating
backhaul
wireless
link
overload
requires
going
beyond
cdn
caching
base
stations
mobile
users
however
efﬁcient
operation
caches
challenging
particular
two
main
challenges
caches
used
wireless
networks
typically
small
compared
cdn
caches
popularity
proﬁle
trafﬁc
highly
unpredictable
non-aggregated
popularity
sum
cid:80
understand
point
consider
effectiveness
cache
measured
hit
probability
i.e.
fraction
requests
found
cache
upper
bounded
n=1
ordered
popularity
distribution
denoting
probability
request
popular
ﬁle
power-law
popularity
sum
approximated
m/n
1−α
power-law
exponent
small
ratio
m/n
means
hit
probability
becomes
vanishingly
small
example
caching
netﬂix
12.5pb
mobile
phone
10gb
m/n
10−6
0.8
hit
probability
less
however
base
stations
equipped
disk
array
40tb
extremely
effective
caching
contents
mobile
vod
application
table
provides
indicative
numbers
memory
types
available
catalogue
sizes
reasonable
applications
context
three
promising
research
directions
choose
part
catalog
cache
maintaining
network
neutrality
store
parts
content
using
partial
caching
techniques
iii
install
massive
memory
edge
form
small-sized
datacenters
third
option
realized
fog
computing
paradigm
understand
unpredictable
nature
sparse
requests
formulated
challenge
consider
example
delivery
breaking
e-news
city
served
single
cdn
node
users
download
news
cdn
system
quickly
detect
rising
popularity
news
since
receive
many
requests
short
time
frame
point
view
mobile
user
however
detection
popularity
trending
news
becomes
difﬁcult
news
requested
given
user
example
shows
2the
entire
catalogue
anecdotally
measured
contain
3.14pb
content
2013
however
multiply
since
video
available
multiple
formats
june
2016
draft
netﬂix
catalogue
12.5pb
torrents
1.5pb
wireless
vod
catalogue
1tb
disk
2tb
disk
array
40tb
0.01
0.3
data
center
150pb
0.1
100
100
100
100
table
typical
data
size
values
normalized
cache
size
m/n
taken
study
practice
anticipated
wireless
trafﬁc
80-20
mix
torrent-like
trafﬁc
live
vod
trafﬁc
tailored
wireless
device
capabilities
detection
efﬁciency
depends
number
requests
aggregated
popularity
learner
illustrate
figure
shows
optimal
hit
probability
hierarchy
base
stations
learning
global
cdn
cache
shown
detect
variations
times
faster
local
caches
remedy
situation
possible
use
architecture
combines
information
obtained
different
aggregation
layers
figure
optimal
hit
probability
comparison
observing
aggregate
request
process
cdn-level
global
observing
individual
request
process
base
station
cache
local
refreshing
catalogue
hit
probability
performance
depends
fast
time-varying
popularities
learnt
global
faster
local
june
2016
draft
catalog
refresh
timehit
probabilitylocalglobal10-510-310110310510.10.20.30.40.50.60.7cache
withlocal
learningcontent
deliverynetworkbase
stationcontrollerbasestationcentralroutercache
withglobal
learningdistance
memory
cheap
free
although
cost
small
cache
dwarfed
base
station
cost
total
amount
installed
memory
mobile
network
considerable
therefore
deciding
install
wireless
caching
requires
careful
cost
analysis
compute
optimal
size
memory
install
location
one
needs
know
cost
coefﬁcients
skewness
content
popularity
local
trafﬁc
distribution
cells
predicting
evolve
quite
challenging
survey
may
determine
good
set
parameters
given
time
literature
extensively
based
grid
models
case
future
wireless
networks
might
signiﬁcant
factor
accurate
models
recently
introduced
ﬁeld
stochastic
geometry
cache-enabled
base
stations
distributed
according
spatial
point
process
often
chosen
poisson
thus
enabling
handle
problem
analytically
validity
modelling
compared
regular
cellular
models
veriﬁed
using
extensive
simulations
additional
insights
deployment
cache-enabled
base
stations
obtained
analytically
characterizing
performance
metrics
outage
probability
average
delivery
rate
given
set
parameters
given
number
base
stations
storage
size
skewness
distribution
transmit
power
target
signal-to-interference-plus-noise
ratio
sinr
addition
initially
studied
single-tier
network
detailed
modeling
analysis
heterogeneous
networks
online
caching
policies
uniform
caching
power
consumption
markovian
mobility
recent
examples
direction
therefore
although
storage
units
become
increasingly
cheaper
question
much
storage
place
location
studied
jointly
topological
models
stochastic
geometry
tractable
realistic
example
modelling
analysis
network
cache-enabled
base
stations
provided
figure
wireless
cid:54
wired
web
caching
traditionally
studied
networking
community
common
miscon-
ception
says
caching
network
layer
technique
hence
web
caching
approaches
sufﬁcient
wireless
caching
well
june
2016
draft
figure
example
base
station
deployment
caching
capabilities
illustrates
snapshot
topology
users
cache-enabled
base
stations
distributed
according
poisson
point
processes
ppps
shows
theoretical
performance
gains
deployment
validation
results
done
via
simulations
however
following
fundamental
work
maddah-ali
niesen
idea
caching
penetrated
information
theory
community
new
twist
termed
coded
caching
promises
unprecedented
gains
following
discuss
differences
wired
wireless
caching
wireless
caching
lies
network
phy
layers
suppose
base
station
wants
deliver
information
users
rate
1mbps
i.e.
streaming
video
video
users
broadcast
video
might
possible
arbitrarily
large
number
users
example
base
station
could
use
omni-directional
antenna
exploit
broadcast
characteristic
wireless
medium
transmit
1mbps
users
simultaneously
videos
different
clearly
possible
base
station
needs
multiplex
users
frequency
time
codes
resource
block
associated
single
user
since
resource
blocks
ﬁnitely
many
ultimately
base
station
serve
1mbps
videos
maximum
number
users
kmax
resources
exhausted
increase
kmax
physical
layer
researchers
propose
ways
increase
resource
blocks
given
spectrum
i.e.
increase
spectral
efﬁciency
june
2016
draft
10.80.60.40.20.20.40.60.810002448100.20.40.60.81.0outage
probabilitycache
size
nats
unit
distanceunit
distance
basestationmobileuservoronoitesselation0.40.20.1target
bitrate
nats/sec/hz
simulationtheory
install
base
stations
resource
blocks
per
unit
area
referred
network
densiﬁcation
novel
paradigm
shows
surprising
fact
exploiting
caching
smart
way
unbounded
number
users
watching
different
videos
accomodated
made
possible
off-peak
operation
network
users
cheaply
populate
caches
parts
popular
contents
perfectly
reasonable
assumption
since
question
sustainability
caching
trying
tackle
refers
hours
day
network
experiences
trafﬁc
peak
content
parts
appropriately
chosen
according
caching
code
ensures
symmetric
properties
request
time
coding
technique
called
index
coding
employed
minimize
number
transmissions
satisfy
users.3
combination
schemes
shown
yield
required
resource
blocks
equal
m/n
km/n
number
users
cache
size
catalog
size
hence
cacheable
fraction
catalog
m/n
kept
ﬁxed
required
number
resource
blocks
increase
number
users
veriﬁed
taking
limit
whereby
quantity
converges
constant
result
pictorially
summarized
figure
promising
idea
sprung
wealth
research
efforts
parallel
right
device-to-device
d2d
networks
non-uniform
content
popularities
online
caching
policies
multi-servers
multi-library
multihop
wireless
networks
cooperative
caching
recently
shown
order
achieve
order
gain
conventional
unicast
possible
legacy
uncoded
caching
systems
content
objects
must
split
exp
number
subpackets
networks
practical
size
gain
achievable
optimal
tradeoff
coded
caching
gain
content
object
size
interesting
topic
current
research
implementation
point
view
promising
research
directions
include
extensions
capture
system
aspects
popularity
skewness
asynchronous
requests
iii
content
objects
ﬁnite
size
cache
sizes
scale
slower
assuming
practical
challenges
resolved
caching
wireless
systems
become
intertwined
physical
3in
fact
ﬁnding
optimal
index
code
difﬁcult
problem
hence
proposed
approach
resorts
efﬁcient
heuristics
june
2016
draft
figure
required
resource
blocks
mobile
users
unicast
demands
caches
catalog
coded
caching
serve
arbitrarily
large
population
users
ﬁxed
number
resource
blocks
layer
techniques
employed
base
station
handheld
one
cache
analysis
sufﬁcient
contemporary
mobile
receives
signal
base
stations
simultaneously
future
densiﬁed
cellular
networks
mobile
connected
several
femto-
pico-
nano-
cells
phenomenon
wireless
multi-access
opens
new
horizon
caching
exploitation
since
user
retrieve
requested
content
many
network
endpoints
neighboring
caches
cooperate
avoid
storing
objects
multiple
times
content
placement
optimizations
wireless
caching
typically
boil
set
cover
problem
bipartite
graph
connecting
users
reachable
caches
therefore
ﬁnding
contents
store
cache
difﬁcult
problem
even
popularities
assumed
known
possible
relax
problem
convex
optimization
use
distributed
storage
codes
cache
stores
coded
combinations
contents
obtaining
fractional
placement
time
sharing
different
integral
placements
ideas
lead
several
interesting
algorithms
literature
cooperative
caching
june
2016
draft
users
required
resource
blocks
log
scaling
coded
caching
phy
layer
legacy
uncoded
caching
network
layer
gain
approaches
cooperative
caching
typically
saves
space
cache
avoiding
caching
popular
contents
neighboring
caches
equivalently
may
think
multiplying
cache
size
small
number
best
say
gain
3-5.
respect
hit
probability
correspond
different
levels
gain
depending
value
m/n
due
skewness
popularity
distribution
marginal
hit
probability
gain4
high
m/n
small
small
m/n
large
since
wireless
expect
former
high
gains
expected
cooperative
wireless
caching
current
proposals
cooperative
caching
assume
static
popularity
therefore
promis-
ing
direction
research
along
lines
design
caching
schemes
combine
cooperation
learning
time-varying
popularity
time
search
retrieve
content
nearby
cache
may
also
signiﬁcant
hence
intelligent
hash-based
ﬁltering
routing
schemes
required
stakeholder
analysis
wireless
caching
business
wireless
caching
involves
three
key
stakeholders
together
form
complex
ecosystem
users
telecommunication
services
primarily
customers
consumers
content
case
wireless
caching
also
active
stakeholders
users
might
requested
help
form
contributing
resource
example
case
coded
caching
memory
processing
d2d
caching
also
relaying
transmissions
end
spending
energy
beneﬁt
better
performance
hand
one
could
envision
users
employing
d2d
technology
enable
caching
without
participation
stakeholders
due
complexities
mentioned
however
efﬁcient
wireless
caching
require
heavy
coordination
extensive
monitoring/processing
hence
d2d
approaches
limited
restricted
environments
operators
telecommunication
networks
well
placed
wireless
caching
due
particularities
coded
caching
multi-access
caching
operators
unique
position
implement
new
protocols
base
stations
affect
standards
new
mobile
devices
develop
big
data
processing
infrastructure
realize
wireless
caching
nevertheless
4gain
obtained
hit
probability
increasing
slightly
june
2016
draft
reasons
related
encryption
privacy
global
popularity
estimation
operators
might
able
install
technologies
without
cooperation
two
stakeholders
providers
internet
content
champions
trust
user
community
apart
security
keys
also
hold
extensive
expertise
implementing
caching
techniques
core
networks
advantageous
position
positively
affect
progressive
evolution
caching
wireless
networks
hand
content
provider-only
solutions
unleash
full
potential
wireless
caching
since
limited
alienated
boxes
operator
network
perform
caching
legacy
cdn
techniques
deeper
caches
wireless
network
less
efﬁcient
stick
legacy
cdn
techniques
figure
stakeholder
analysis
summarize
stakeholder
offers
needs
figure
prospects
required
collaboration
among
stakeholders
operators
content
providers
seeking
best
friends
forever
union
order
mutually
harvest
beneﬁts
digital
june
2016
draft
userstelecomoperatorscontentprovidersprivacyresources/energyperformanceloadreductionaccess
todatahostingdatacollectionstandardscheaptransporttrustcontent
deliverynetworkswhat
needwhat
cid:31
value
chain
keeping
users
happy
favorable
environment
scenario
wireless
caching
fact
telecom
operators
enable
caching
capabilities
edge
network
infrastructure
become
sustainable
gain
access
new
business
models
hand
content
providers
beneﬁt
caching
collaboration
since
trafﬁc
intercepted
earlier
content
transport
cost
reduced
user
demand
held
back
sustainability
issues
costs
associated
deployment
large
memory
units
avoided
able
reach
closer
users
extend
computing
infrastructures
fog
paradigm
last
foreseeable
situations
role
content
provider
wireless
operator
may
converge
references
cisco
cisco
visual
networking
index
global
mobile
data
trafﬁc
forecast
update
2014–2019
white
paper
2015
online
available
http
//goo.gl/tz6qmk
ba¸stu˘g
bennis
debbah
living
edge
role
proactive
caching
wireless
networks
ieee
communications
magazine
vol
august
2014
wang
chen
taleb
ksentini
leung
cache
air
exploiting
content
caching
delivery
techniques
systems
ieee
communications
magazine
vol
131–139
february
2014
maddah-ali
niesen
fundamental
limits
caching
ieee
transactions
information
theory
vol
2856–2867
may
2014
breslau
cao
fan
phillips
shenker
web
caching
zipf-like
distributions
evidence
implications
ieee
infocom
mar
1999
traverso
ahmed
garetto
giaccone
leonardi
niccolini
temporal
locality
today
content
caching
matters
model
acm
sigcomm
2013
leconte
paschos
gkatzikis
draief
vassilaras
chouvardas
placing
dynamic
content
caches
small
population
ieee
infocom
2016
s.-e.
elayoubi
roberts
performance
cost
effectiveness
caching
mobile
access
networks
proceedings
2nd
international
conference
information-centric
networking
ser
icn
acm
2015
79–88
ba¸stu˘g
bennis
zeydan
kader
karatepe
debbah
big
data
meets
telcos
proactive
caching
perspective
journal
communications
networks
special
issue
big
data
networking-challenges
applications
vol
549–558
december
2015
ba¸stu˘g
bennis
debbah
transfer
learning
approach
cache-enabled
wireless
networks
international
symposium
modeling
optimization
mobile
hoc
wireless
networks
wiopt
d2d
workshop
mumbai
india
may
2015
carnavalet
mannan
killed
proxy
analyzing
client-end
tls
interception
software
2016
maisonneuve
gurbani
fossati
security
pendulum
managing
radio
networks
encrypted
world
marnew
workshop
2015
online
available
https
//goo.gl/jp2tyv
june
2016
draft
naylor
schomp
varvello
leontiadis
blackburn
lópez
papagiannaki
rodriguez
steenkiste
multi-context
tls
mctls
enabling
secure
in-network
functionality
tls
acm
sigcomm
2015
google
global
cache
ggc
online
available
https
//goo.gl/vhuinf
saguna
online
available
http
//goo.gl/0wkgrj
appliansys
cachebox
online
available
http
//goo.gl/jbw82d
roberts
sbihi
exploring
memory-bandwidth
tradeoff
information-centric
network
itc
2013
fayazbakhsh
lin
tootoonchian
ghodsi
koponen
maggs
sekar
shenker
less
pain
gain
incrementally
deployable
icn
acm
sigcomm
2013
kocak
kesidis
fdida
network
neutrality
content
caching
effect
access
pricing
smart
data
pricing
47–66
2013
maggi
gkatzikis
paschos
leguay
adapting
caching
audience
retention
rate
video
chunk
store
arxiv
preprint
arxiv:1512.03274
2015
bioglio
gabry
land
optimizing
mds
codes
caching
edge
ieee
global
communications
conference
globecom
san
diego
usa
december
2015
bonomi
milito
zhu
addepalli
fog
computing
role
internet
things
proceedings
ﬁrst
edition
mcc
workshop
mobile
cloud
computing
acm
2012
13–16
ba¸stu˘g
bennis
kountouris
debbah
cache-enabled
small
cell
networks
modeling
tradeoffs
eurasip
journal
wireless
communications
networking
february
2015
yang
yao
chen
xia
analysis
cache-enabled
wireless
heterogeneous
networks
ieee
transactions
wireless
communications
vol
1–1
2015
chen
lee
quek
kountouris
cooperative
caching
transmission
design
cluster-centric
small
cell
networks
arxiv
preprint
arxiv:1601.00321
2016
zaidi
ghogho
mclernon
information
centric
modeling
two-tier
cache
enabled
cellular
networks
ieee
international
conference
communications
workshop
icc
workshop
2015
80–86
blaszczyszyn
giovanidis
optimal
geographic
caching
cellular
networks
arxiv
preprint
arxiv:1409.7626
2014
perabathini
ba¸stu˘g
kountouris
debbah
conte
caching
edge
green
perspective
networks
ieee
international
conference
communications
workshop
icc
workshop
london
june
2015
poularakis
tassiulas
exploiting
user
mobility
wireless
content
delivery
ieee
international
symposium
information
theory
proceedings
isit
ieee
july
2013
1017–1021
caire
molisch
fundamental
limits
caching
wireless
d2d
networks
arxiv
preprint
arxiv
1405.5336
2014
s.-w.
jeon
s.-n.
hong
caire
capacity
multihop
device-to-device
caching
networks
ieee
information
theory
workshop
itw
ieee
2015
1–5
tulino
llorca
caire
order-optimal
rate
caching
coded
multicasting
random
demands
arxiv
preprint
arxiv
1502.03124
2015
pedarsani
maddah-ali
niesen
online
coded
caching
arxiv
preprint
arxiv
1311.3646
2013
shariatpanahi
motahari
khalaj
multi-server
coded
caching
arxiv
preprint
arxiv
1503.00265
2015
sahraei
gastpar
multi-library
coded
caching
arxiv
preprint
arxiv:1601.06016
2016.
june
2016
draft
gitzenis
paschos
tassiulas
asymptotic
laws
joint
content
replication
delivery
wireless
networks
ieee
transactions
information
theory
vol
2760–2776
may
2013
golrezaei
shanmugam
dimakis
molisch
caire
femtocaching
wireless
video
content
delivery
distributed
caching
helpers
ieee
transactions
information
theory
vol
8402–8413
2013
poularakis
iosiﬁdis
tassiulas
approximation
algorithms
mobile
data
caching
small
cell
networks
ieee
transactions
communications
vol
3665–3677
2014
naveen
massoulie
baccelli
carneiro
viana
towsley
interaction
content
caching
request
assignment
cellular
cache
networks
proceedings
5th
workshop
things
cellular
operations
applications
challenges
acm
2015
37–42
zhang
elia
fundamental
limits
cache-aided
wireless
interplay
coded-caching
csit
feedback
arxiv
preprint
arxiv
1511.03961
2015
dehghan
seetharam
jiang
salonidis
kurose
towsley
sitaraman
complexity
optimal
routing
content
caching
heterogeneous
networks
ieee
infocom
2015
tao
chen
zhou
content-centric
sparse
multicast
beamforming
cache-enabled
cloud
ran
arxiv
preprint
arxiv
1512.06938
2015
thomas
taylor
content
providers
operators
peace
financial
times
2012
online
available
http
//goo.gl/6stcvk
openet
content
ott
partnerships
key
unlocking
new
business
models
white
paper
2014
online
available
http
//goo.gl/bvzra6
june
2016
draft
