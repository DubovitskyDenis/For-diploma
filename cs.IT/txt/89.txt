minimum
conditional
description
length
estimation
markov
random
fields
matthew
reyes∗
∗self-employed
mgreyes
umich.edu
david
neuhoff†
†eecs
dept.
university
michigan
neuhoff
umich.edu
abstract—in
paper
discuss
method
call
minimum
conditional
description
length
mcdl
estimating
parameters
subset
sites
within
markov
random
ﬁeld
assume
edges
known
entire
graph
subset
estimate
parameters
nodes
edges
well
edges
incident
node
ﬁnding
exponential
parameter
subset
yields
best
compression
conditioned
values
boundary
estimate
derived
temporally
stationary
sequence
observations
set
discuss
method
also
applied
estimate
spatially
invariant
parameter
single
conﬁguration
derive
maximum
pseudo-likelihood
mpl
estimate
introduction
markov
random
ﬁeld
mrf
also
referred
gibbs
distribution
probability
distribution
colorings
undirected
graph
nodes1
random
variable
indices
edges
represent
direct
dependencies
random
variables
one
primary
research
areas
mrfs
problem
model
selection
parameter
estimation
objective
may
either
determine
parameters
known
edges
determine
edges
graph
jointly
ﬁnd
edges
parameters
edges
markov
ﬁelds
natural
class
models
many
types
data
including
images
social
networks
images
natural
assume
set
edges
instance
connecting
nearest
neighbors
social
networks
neighbor
relations
known
two
applications
mind
paper
focuses
ﬁrst
model
selection
problem
determining
parameters
known
edges
family
mrfs
speciﬁed
vector
statistic
deﬁned
site
values
indi-
vidual
nodes
endpoints
edges
graph.2
particular
mrf
indexed
exponential
parameter
vector
scales
corresponding
components
probability
conﬁguration
given
exp
cid:104
cid:105
cid:104
cid:105
denotes
inner
product
log-partition
function
model
selection
problem
considered
paper
set
edges
known
well
statistic
determine
exponential
parameter
weights
1we
use
terms
nodes
sites
interchangeably
2properly
pairwise
mrf
generalizations
mrfs
straightforward
corresponding
components
statistic
nodes
edges
generally
estimation
performed
temporal
sequence
observations
∆=x
estimate
ˆθn
obtained
often
assumed
independent
simplify
analysis
fact
sufﬁcient
assume
stationary
assume
paper
cid:80
popular
criterion
estimating
parameter
within
family
candidate
models
maximum
likelihood
seeks
parameter
ˆθn
maximizes
probability
observed
data
parameter
vectors
indexing
probability
distributions
within
speciﬁed
class
probability
distributions
markov
ﬁelds
criterion
reduces
ﬁnding
exponential
parameter
expected
statistic
˜µ∆=µ
∆=e˜θ
mrf
induced
referred
moment
mrf
equals
empirical
moment
ˆµn
average
value
i=1
statistic
observations
tractable
graph
tree
one
clustered
tree
moderate
numbers
nodes
per
cluster
moments
exactly
efﬁciently
determined
belief
propagation
iterative
message
passing
algorithm
thus
one
compute
moments
set
candidates
choose
one
whose
moment
closely
matches
observed
empirical
moment
ˆµn
general
graph
however
intractable
thus
moment
computed
exactly
intractability
circumvented
approximating
moment
either
approximate
variant
sampling
mrf
corresponding
candidate
e.g
gibbs
sampling
selecting
whose
empirical
moment
ˆ˜µ
closely
matches
observed
data
alternative
method
making
parameter
estimation
mrfs
tractable
maximum
pseudo-likelihood
deﬁnes
different
objective
function
tractable
hence
solved
exactly
maximum
pseudo
likelihood
mpl
based
concept
coding
method
introduced
besag
assuming
translation
invariant
statistic
well
translation
invariant
parameter
site
conditional
distribution
conditioned
neighbors
sites
connected
edge
one
chooses
subset
sites
two
sites
neighbors
markov
property
sites
conditionally
independent
one
another
conditioned
sites
permitting
conditional
distribution
cid:89
j=1
cid:88
expressed
product
single-site
conditional
probabilities
thus
conditioning
\v1
one
estimate
analytically
tractable
objective
function
mpl
extends
idea
ﬁnding
parameter
ˆθm
maximizes
pseudo-
likelihood
function
xj|xv
candidate
parameters
equivalently
pseudo-log-
likelihood
function
log
log
xj|xv
j=1
assuming
translation
invariance
spatial
homogeneity
markov
property
conditional
probabilities
simplify
conditional
probabilities
given
neighbors
node
much
research
done
mpl
consistency
mpl
estimate
ˆθm
shown
interpretation
mpl
ﬁnds
parameter
ˆθm
induced
conditional
distribu-
tions
individual
nodes
best
match
empirical
conditional
distributions
individual
nodes
parameter
estimation
method
proposed
present
paper
call
minimum
conditional
description
length
mcdl
understood
generalization
maximum
pseudo-likelihood
whereas
mpl
method
es-
timates
translation
invariant
parameter
observations
¯u1
¯un
statistically
identical
subsets
within
single
observation
propose
mcdl
method
estimating
parameter
within
single
subset
sequence
observations
boundary
neighborhood
closure
assume
spatial
homogeneity
translation
invariance
within
require
temporal
stationarity
moreover
mpl
subsets
single
sites
restriction
place
subset
subgraph
induced
consisting
nodes
edges
contained
tractable
respect
minimum
description
length
mdl
principle
states
essentially
best
model
one
provides
best
compression
data
since
markov
ﬁelds
deﬁned
terms
conditional
distributions
since
conditioning
boundary
subset
renders
subﬁeld
within
subset
conditionally
independent
subﬁeld
outside
closure
subset
mcdl
natural
extension
efﬁciently
estimating
parameters
inducing
conditional
distribution
given
x∂u
subset
tractable
compute
conditional
probability
conﬁguration
boundary
given
temporal
sequence
conﬁgurations
given
conﬁguration
closure
seek
pa-
rameter
ˆθu
ˆθn
causes
conditional
distribution
given
x∂u
within
mrf
modeled
best
approximate
empirical
conditional
distribution
conditioned
corresponding
values
boundary
thus
different
candidate
parameters
compute
temporal
average
negative
log
likelihood
log
cid:88
i=1
select
minimizes
important
note
properly
parameters
nodes
edges
within
closure
conditional
distribution
xu|x∂u
given
x∂u
depends
parameters
nodes
edges
within
edges
connecting
restricted
sense
use
throughout
paper
average
negative
log-likelihood
interpreted
empirical
cross
entropy
true
conditional
distribution
induced
candidate
parameter
note
independent
would
negative
log
likelihood
method
would
produce
estimate
optimal
encoder
example
arithmetic
coding
number
bits
produced
encoding
within
bits
log
words
deriving
estimate
ˆθn
parameter
subvector
minimizes
cross-entropy
essentially
equivalent
estimating
parameter
minimizes
coding
rate
conditionally
coding
given
x∂u
conditional
coding
distribution
induced
indeed
straightforward
show
limit
number
temporal
samples
tends
inﬁnity
converges
empirical
average
cid:80
i=1
log
conditioned
xu|x∂u
xu|x∂u
||p
xu|x∂u
given
candidate
parameter
ultimately
method
would
applied
different
sub-
sets
yielding
estimates
¯u1
¯uk
con-
ditional
distributions
xu1
xuk
given
respective
boundaries
order
produce
estimate
full
parameter
vector
would
need
way
enforce
consistency
¯u1
¯uk
nodes
edges
contained
multiple
¯uj
moment
focus
estimating
single
subset
reiterate
one
way
mcdl
differs
mpl
stationarity
homogeneity
assumptions
used
obtain
statistics
estimation
setting
mpl
generally
applied
assumes
translation
invariant
exponential
parameter
regular
graph
particular
set
sites
form
lattice
estimate
global
parameter
obtained
single
observation
require
spatial
homogeneity
parameter
though
require
temporal
stationarity
estimate
parameter
single
subset
temporal
sequence
observations
cid:88
i=1
subset
words
whereas
propos-
ing
estimate
parameters
observations
given
subset
boundary
mpl
method
estimates
translation
invariant
parameter
observations
¯u1
¯un
statistically
identical
subsets
boundaries
within
single
observation
proposed
mcdl
algorithm
also
differs
mpl
allows
larger
subsets
rather
single
sites
conceptually
formulation
objective
function
digress
moment
think
mpl
context
two
differences
common
remark
literature
pseudo-likelihood
function
tractable
viewed
approximation
chain
rule
decomposition
true
likelihood
function
observed
data
however
translation
invariant
setting
mpl
analysis
rather
attempt
approximate
likelihood
function
instead
consider
mcdl
objective
function
cross
entropy
log
xi|x∂i
empirical
conditional
distributions
single
sites
single
site
conditional
distributions
induced
candidate
parameter
mathematically
objective
function
candidate
parameter
however
viewed
lens
mcdl
function
yields
parameter
achieves
minimal
conditional
description
length
site
conditioned
neighbors
without
recourse
anything
pseudo
approximate
indeed
limit
large
lattice
sites
equation
tends
x0|x∂0
||p
x0|x∂0
erasure
entropy
given
x0|x∂0
information
lost
erased
words
minimal
amount
information
needed
describe
conditioned
values
neighbors
noted
number
bits
lossless
code
clearly
nonetheless
mcdl
paradigm
mpl
estimate
interpreted
minimizing
empirical
coding
rate
xui
conditioned
values
x∂ui
rather
approximation
likelihood
function
since
markov/gibbs
ﬁelds
speciﬁed
terms
local
characteristics
i.e.
conditional
distributions
makes
perfect
sense
mpl
would
yield
consistent
estimate
moreover
casting
mpl
conditional
description
length
problem
one
generalize
considering
conditional
distributions
single
nodes
considering
conditional
dis-
tributions
larger
subsets
mrf
induced
translation
invariant
parameter
objective
function
minimized
cid:88
i=1
log
xui|x∂ui
opposed
subsets
size
using
larger
subsets
reduced
number
samples
sense
could
potentially
adverse
affect
convergence
therefore
accuracy
ˆθn
hand
subsets
become
larger
effect
conditioning
reduced
relative
inter-site
interactions
within
result
local
characteristics
within
conditioned
boundary
∂ui
closely
approximate
local
characteristics
full
distribution
words
worth
examining
tradeoffs
involved
using
larger
subsets
moreover
con-
sidering
larger
subsets
allows
greater
ﬂexibility
invariance
required
method
provide
good
estimates
example
instead
requiring
site
invariance
statistic
parameter
one
could
simply
assume
row
invariance
statistic
parameter
case
subsets
would
different
rows
lattice
consistent
ˆθn
return
mcdl
consider
task
showing
estimate
ˆθn
reasonable
course
action
would
mimic
closely
possible
proofs
consistency
mpl
estimate
difference
seems
mpl
regime
xu1
xun
independent
conditioned
respective
boundaries
whereas
case
independent
conditioned
boundaries
problems
objective
function
however
remains
seen
much
tweaking
required
extend
mpl
results
present
paradigm
rest
paper
section
provides
background
mrfs
section
iii
discusses
use
lossless
coding
section
presents
algorithm
estimating
parameter
within
subset
section
discusses
example
apply
mcdl
temporally
stationary
observations
single
subset
well
spatially
observations
multiple
subsets
single
conﬁguration
graphs
markov
random
fields
site
random
variable
assuming
values
alphabet
given
conﬁguration
function
tij
determines
contribution
pair
probability
similarly
say
mrf
based
entire
family
mrfs
based
generated
introducing
exponential
parameter
θij
node
neighbor
θij
scale
sensitivity
distribution
functions
tij
respectively
conditional
probability
conﬁguration
subset
given
values
another
subset
denoted
xu|xw
straightforward
check
xu|x∂u
xu|xv
x∂u
markov
property
conditional
distributions
random
subﬁeld
given
speciﬁc
conﬁguration
x∂u
random
subﬁeld
x∂u
denoted
xu|x∂u
xu|x∂u
respectively
likewise
xu|x∂u
xu|x∂u
respective
conditional
entropies
given
speciﬁc
conﬁguration
x∂u
random
subﬁeld
x∂u
straightforward
show
following
proposition
2.1
xu|x∂u
exp
cid:104
x∂u
cid:105
φu|x∂u
φu|x∂u
log
exp
cid:104
cid:48
x∂u
cid:105
cid:88
cid:48
log
partition
function
conditional
distribution
boundary
condition
x∂u
note
statistic
cid:48
x∂u
includes
components
least
one
argu-
ment
contained
thus
xu|x∂u
depend
˜θ∂u
iii
belief
propagation
minimum
description
general
ones
uses
belief
propagation
compute
conﬁguration
since
inner
product
cid:104
cid:105
computed
directly
used
indirectly
compute
normalizing
constant
log-partition
function
cycles
computed
complexity
linear
number
nodes
cycles
one
compute
grouping
subsets
supernodes
new
graph
acyclic
case
complexity
exponential
size
largest
supernode
graph
said
tractable
either
cycles
clustered
acyclic
graph
size
largest
supernode
moderate
example
10.
subset
said
tractable
subgraph
induced
tractable
tractable
subset
xu|x∂u
computed
given
conﬁgurations
x∂u
speciﬁcally
conditional
probability
distribution
xu|x∂u
given
conﬁguration
computed
exactly
efﬁciently
purposes
paper
sufﬁces
say
lossless
compression
optimal
encoder
involves
computation
coding
distribution
tractable
subset
conﬁguration
encoded
conditioned
x∂u
using
coding
distribution
xu|x∂u
average
number
bits
produced
xu|x∂u
¯u||xu|x∂u
xu|x∂u
xu|x∂u
||p
xu|x∂u
xu|x∂u
||p
xu|x∂u
divergence
xu|x∂u
xu|x∂u
re-
dundancy
code
clearly
true
parameter
eliminates
redundancy
achieves
minimal
con-
ditional
description
length
arithmetic
coding
proposed
optimal
encoder
details
use
encoding
mrf
given
model
selection
conditioning
discuss
mcdl
method
estimating
parameters
subset
tractable
subset
recall
exactly
compute
probabilities
since
chosen
tractable
respect
belief
prop-
agation
parameter
conditional
distribution
used
encode
codeword
length
conditioned
approximately
given
log
ˆθn
form
estimate
observations
use
compute
empirical
cross
entropy
given
candidate
parameter
seek
minimize
following
straightforward
show
proposition
4.1
cid:88
cid:88
i=1
i=1
φu|x
cid:104
ˆµn
cid:105
¯u|x
ˆµn
cid:80
ˆµn
subset
given
moment
xu|x
i=1
¯u|x
empirical
moment
conditional
well-known
φu|x
convex
components
strictly
convex
thus
afﬁnely
independent
unique
minimum
note
able
compute
chosen
tractable
¯u|x
therefore
apply
gradient
descent
algorithm
minimize
obtain
estimate
ˆθn
argmin
cid:80
mcdl
algorithm
estimating
parameter
sub-
vector
within
subset
summarized
fol-
lows
given
initially
com-
pute
empirical
moment
ˆµn
cid:80
candidate
parameter
compute
using
compute
gradient
¯u|x
using
standard
search
i=1
¯u|x
select
new
continue
process
desired
threshold
norm
i=1
attained
ˆµn
fig
true
parameter
.4.
minimizing
cid:48
indicated
red
case
plot
empirical
cross
entropy
temporally
stationary
sequence
single
subset
spatially
invariant
parameter
multiple
subsets
cid:88
i=1
cid:88
i=1
example
homogeneous
ising
model
experimented
spatially
homogeneous
ising
model
edge
parameter
θij
node
parameter
200×
200
square
grid
sites
interior
site
connected
four
nearest
neighbors
results
show
figure
consider
single
subset
middle
row
grid
boundary
consists
row
row
generated
sequence
198
conﬁgurations
computed
log
cid:48
161
evenly
spaced
cid:48
values
ranging
gran-
ularity
.00125
found
minimizing
cid:48
true
parameter
value
.4.
consider
single
conﬁguration
let
198
rows
upper
lower
boundary
row
computed
log
xui|x∂ui
cid:48
161
cid:48
values
case
minimizing
cid:48
.4025.
discussion
paper
elaborated
concept
inherent
maximum
pseudo-likelihood
namely
using
con-
ditioning
simplify
task
parameter
estimation
posed
problem
one
minimum
conditional
description
length
speciﬁc
setting
considered
differs
typical
setting
mpl
mind
temporal
rather
spatial
invariance
focused
estimation
parameters
within
single
subset
relaxing
spatial
invariance
assumption
broadens
class
graphs
accompanying
parameters
apply
method
however
requiring
temporal
stationarity
imposed
new
set
restrictions
substantively
though
feel
framing
problem
one
minimizing
conditional
description
length
natural
given
markov/gibbs
ﬁelds
speciﬁed
conditional
distributions
leads
mpl
estimate
applied
single
conﬁguration
generated
spatially
invariant
parameter
feel
mini-
mum
conditional
description
length
perspective
places
maximum
pseudo-likelihood
estimate
ﬁrmer
theoretical
footing
ˆθn
mentioned
introduction
though
method
applied
obtain
estimates
ˆθn
param-
eters
within
different
subsets
potential
inconsistency
estimates
nodes
edges
contained
within
intersection
subsets
resolving
example
alternating
direction
method
multipliers
remains
done
still
believe
value
notion
taking
large
intractable
markov
random
ﬁeld
decomposing
tractable
conditional
random
ﬁelds
good
parameter
estimates
obtained
efﬁciently
exact
inference
prediction
performed
respect
parameters
conditioned
boundaries
subsets
indeed
shown
mrf
intractable
graph
suboptimal
inference
prediction
performed
respect
whatever
parameters
available
beneﬁts
incorrectly
estimating
parameters
case
good
estimates
would
obtained
tractable
conditional
random
ﬁeld
exact
inference
could
performed
respect
parameters
may
yield
consistent
estimate
global
parameter
additionally
mcdl
method
parameter
estimation
introduced
paper
complementary
previous
work
using
cutsets
simplify
processing
particular
compression
intractable
mrfs
works
initial
lossless
compression
cutset
sites
followed
either
estimation
optimal
lossless
conditional
compression
remaining
sites
given
values
cutset
ﬁxed
cutset
used
one
algorithms
one
could
simply
estimate
parameters
tractable
conditional
subﬁelds
would
estimated
compressed
given
values
boundaries
references
besag
spatial
interaction
statistial
analysis
lattice
systems
roy
stat
soc
vol
192-235
march
1974
besag
statistical
analysis
non-lattice
data
roy
stat
soc
vol
179-195
sept.
1975
besag
efﬁciency
pseudo-likelihood
estimation
simple
gaussian
ﬁelds
biometrika
vol
616-618
1977
boyd
vandenberghe
convex
optimization
cambridge
univer-
sity
press
2004
boyd
parikh
chu
peleato
eckstein
distributed
optimization
statistical
leaning
via
alternating
direction
method
multipliers
foundations
trends
machine
learning
vol
1-122
2011
comets
consistency
class
estimators
exponential
families
markov
random
fields
lattice
annals
statistics
vol
455-468
march
1992
cover
thomas
elements
information
theory
wiley
2005
csiszar
talata
consistent
estimation
basic
neighbor-
hood
markov
random
fields
annals
statistics
vol
123-145
february
2006
geman
geman
stochastic
relaxation
gibbs
distributions
bayesian
restoration
images
ieee
trans
pami
vol
721–741
nov.
1984
geyer
thompson
constrained
monte
carlo
maximum
likelihood
dependent
data
journal
royal
statistical
society
vol
654-699
1992
geyer
convergence
monte
carlo
maximum
likelihood
calculations
journal
royal
statistical
society
vol
261-274
1994
gidas
consistency
maximum
likelihood
pseudolikelihood
estimators
gibbs
distributions
stochastic
differential
equations
applications
electronic/computer
engineering
control
theory
operations
research
fleming
lions
eds
1-17
springer
berlin
pietra
pietra
lafferty
inducing
features
random
fields
ieee
trans
pattern
analysis
machine
intelligence
vol
april
1997
m.g
reyes
d.l
neuhoff
arithmetic
compression
markov
random
fields
seoul
korea
isit
2009
m.g
reyes
d.l
neuhoff
lossless
reduced
cutset
coding
markov
random
fields
snowbird
dcc
2010
m.g
reyes
cutset
based
processing
compression
markov
random
fields
ph.d.
thesis
university
michigan
april
2011
m.g
reyes
d.l
neuhoff
cutset
width
spacing
reduced
cutset
coding
markov
random
fields
submitted
isit
2016
also
deep
blue
repository
university
michigan
rissanen
modeling
shortest
data
description
automatica
vol
465-471
september
1978
verdu
weissman
information
lost
erasures
ieee
tran
info
thy.
vol
november
2008
wainwright
jordan
graphical
models
exponential
families
variational
inference
berkeley
tech
report
649
sept.
2003
wainwright
estimating
wrong
graphical
model
beneﬁts
computation
limited
setting
journal
machine
learning
research
vol
1829-1859
september
2006
whitten
neal
cleary
arithmetic
coding
data
compression
comm
acm
vol
520-540
june
1987
