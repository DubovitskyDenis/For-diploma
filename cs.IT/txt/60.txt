achievable
rate-distortion
region
multiple
descriptions
source
coding
based
coset
codes
farhad
shirani
sandeep
pradhan∗
dept
electrical
engineering
computer
science
univ
michigan
ann
arbor
abstract
consider
problem
multiple
descriptions
source
coding
propose
new
coding
strategies
involving
unstructured
structured
coding
layers
previously
general
achiev-
able
rate-distortion
region
l-descriptions
problem
combinatorial
message
sharing
binning
cmsb
region
cmsb
scheme
utilizes
unstructured
quantizers
unstructured
bin-
ning
ﬁrst
part
paper
show
strategy
improved
upon
using
general
unstructured
quantizers
general
unstructured
binning
method
second
part
structured
coding
strategies
considered
first
structured
coding
strategies
developed
considering
speciﬁc
examples
involving
three
descriptions
show
application
structured
quantizers
results
strict
improvements
two
descriptions
furthermore
show
structured
binning
also
yields
improvements
improvements
addition
ones
derived
ﬁrst
part
paper
suggests
structured
coding
essential
coding
two
descriptions
using
ideas
developed
examples
provide
new
uniﬁed
coding
strategy
considering
several
structured
coding
layers
finally
characterize
performance
form
inner
bound
optimal
rate-distortion
region
using
computable
single-letter
information
quantities
new
region
strictly
contains
previous
known
achievable
regions
introduction
multiple-descriptions
source
coding
problem
arises
naturally
number
applications
transmission
video
audio
speech
packet
networks
fading
channels
multiple-
descriptions
source
coding
setup
describes
communications
setting
consisting
one
encoder
several
decoders
encoder
receives
discrete
memoryless
source
wishes
compress
several
descriptions
decoder
receives
speciﬁc
subset
descriptions
noiseless
links
pro-
duces
reconstruction
source
vector
respect
distortion
criterion
parameters
interest
rates
required
transmitting
description
resulting
distortions
decoders
objective
design
communications
schemes
result
optimal
asymptotic
trade-oﬀ
two
groups
parameters
problem
studied
extensively
however
optimal
asymptotically
achievable
rate-distortion
known
even
elementary
case
two
descriptions
considered
two-descriptions
setup
depicted
figure
evidently
individual
decoders
receive
one
description
perform
optimally
encoder
must
transmit
two-descriptions
according
optimal
point-to-point
ptp
source
coding
schemes
may
require
two-descriptions
similar
hand
descriptions
sim-
ilar
one
would
redundant
central
decoder
receive
two
descriptions
fact
∗this
work
supported
nsf
grant
ccf-1111061
ccf-1422284
work
presented
part
ieee
international
symposium
information
theory
isit
july
2014.
decoder
requires
two-descriptions
diﬀerent
one
another
order
yield
better
reconstruc-
tion
main
challenge
problem
strike
balance
two
situations
best
known
achievable
region
communications
setting
due
zhang
berger
zhang-
berger
strategy
encoder
ﬁrst
step
sends
common
coarsely
quantized
version
source
descriptions
next
step
encoder
sends
individual
reﬁnements
decoder
corresponding
descriptions
coding
strategy
generalized
case
two
descriptions
strategy
ﬁrst
common
coarsely
quantized
version
source
sent
decoders
next
step
several
reﬁnement
layers
transmitted
symmetric
l−descriptions
problem
coding
scheme
based
random
binning
considered
outper-
forms
vkg
scheme
involves
generation
independent
codebooks
followed
random
binning
although
problem
centralized
encoder
strategy
involving
random
binning
proved
useful
improved
upon
new
coding
scheme
based
certain
parity-check
codes
however
three
schemes
fully
exploit
common-information
among
every
subset
individual
descriptions
example
three-descriptions
problem
common-information
ﬁrst
second
descriptions
common
third
description
new
coding
scheme
called
combinatorial
message
sharing
binning
cmsb
considered
provided
uniﬁed
achievable
region
general
l-descriptions
problem
scheme
provided
grand
uniﬁcation
schemes
based
conditional
codebooks
schemes
based
random
bin-
ning
turn
results
largest
achievable
region
problem
subsumes
previous
coding
schemes
name
due
combinatorial
number
common-component
codebooks
present
noted
cmsb
scheme
based
construction
random
codes
codewords
mutually
independent
codebooks
algebraic
structure
paper
provide
new
coding
strategy
general
l-descriptions
problem
strictly
subsumes
cmsb
strategy
best
known
literature
till
coding
strategy
based
common-information
perspective
taking
cue
two-descriptions
strategy
propose
general
l-descriptions
problem
encoder
constructs
common
constituent
codebook
subset
decoders
subset
decoders
one
common
component
overall
coding
scheme
implies
number
constituent
codebooks
grows
double-exponentially
however
prove
asymptotically
exponential
number
codebooks
necessary
terms
contributing
rate-distortion
region
rest
redundant
signiﬁcantly
simpliﬁes
coding
strategy
example
case
223−1
128
possible
common
code
components
corresponding
codebooks
non-redundant
turns
one
identify
non-redundant
codebooks
associating
sperner
families
sets
result
call
new
scheme
sperner
set
coding
ssc
scheme
cmsb
scheme
utilizes
codebooks
3-descriptions
problem
prove
analytically
addition
new
codebooks
ssc
scheme
results
improved
achievable
region
words
show
analytically
cmsb
scheme
complete
additionally
propose
generalized
binning
approach
improves
upon
cmsb
scheme
enhances
ssc
scheme
characterize
asymptotic
performance
coding
scheme
using
computable
single-letter
information
quantities
forms
ﬁrst
part
paper
similar
coding
scheme
cmsb
ssc
scheme
uses
random
unstructured
codes
observed
several
multi-terminal
communications
settings
broadcast
channel
interference
channel
variations
mac
channel
dis-
tributed
source
coding
dsc
problem
application
algebraic
structured
codes
results
improvements
random
unstructured
codes
asymptotic
performance
limits
based
inherent
dualities
multi-terminal
communication
problems
corresponding
coding
schemes
observations
suggest
one
may
get
gains
performance
even
problem
figure
two-descriptions
setup
second
part
paper
show
ssc
coding
scheme
based
unstructured
codes
mentioned
complete
provide
several
speciﬁc
examples
4-description
problems
example-speciﬁc
coding
schemes
based
random
linear
codes
perform
strictly
better
ssc
coding
scheme
subsequently
supplement
ssc
scheme
new
coding
layers
algebraic
structure
restrict
attention
algebraic
structure
associated
ﬁnite
ﬁelds
present
uniﬁed
coding
scheme
works
arbitrary
sources
distortion
measures
characterize
asymptotic
performance
coding
scheme
using
computable
single-letter
information
quantities
interpret
ssc
coding
capturing
common
information
components
among
decoders
using
univariate
functions
algebraic
coding
supplement
capturing
common
information
among
decoders
using
bivariate
multivariate
functions
rest
paper
organized
follows
section
explains
notation
used
paper
section
provides
overview
ideas
developed
previous
works
provides
groundwork
next
sections
section
present
new
unstructured
coding
strategy
improves
upon
cmsb
scheme
show
two
diﬀerent
types
gains
compared
previous
scheme
ﬁrst
due
addition
several
common-component
codebook
layers
second
due
generalized
binning
method
section
identify
examples
improvements
due
structured
coding
materi-
alize
setup
section
investigate
three
diﬀerent
examples
two
examples
achievable
region
improved
via
using
linear
quantizers
example
gains
due
linear
binning
section
generalize
ideas
previous
section
provide
achievable
region
general
l-descriptions
problem
since
characterization
region
involved
complicated
provide
ﬁnal
region
several
steps
adding
new
coding
layers
step
section
concludes
paper
deﬁnitions
notation
section
introduce
notation
used
paper
restrict
ﬁnite
alphabet
random
variables
denote
random
variables
capital
letters
corresponding
alphabets
ﬁnite
sans-serif
typeface
respectively
numbers
denoted
small
letters
sets
numbers
also
denoted
sans-serif
typeface
speciﬁcally
denote
set
natural
numbers
ﬁeld
size
set
numbers
also
denoted
used
express
vector
...
collection
whose
elements
sets
called
family
sets
denoted
calligraphic
typeface
given
family
sets
m∈m
set
numbers
elements
sets
family
sets
containing
subsets
denoted
collection
whose
elements
families
sets
denoted
deﬁne
set
cid:102
cid:83
encoderdec1dec2dec12xˆx1ˆx12ˆx2
bold
typeface
collection
families
sets
.am
also
represented
random
variables
indexed
families
sets
purposes
brevity
write
um1
...
instead
wherever
notation
cause
ambiguity
unm
denotes
vector
length
random
variables
distributed
according
distribution
pum
denote
set
n-length
vectors
-typical
respect
pum
use
deﬁnition
frequency
typicality
given
paper
denote
set
random
variables
follows
um|m
two
collections
families
write
denote
unordered
collection
random
variables
um1
vm2
let
deﬁne
express
unions
intersections
complements
deﬁned
manner
family
sets
called
sperner
family
sets
none
elements
subset
another
element
words
family
sets
sperner
family
cid:64
cid:48
cid:40
cid:48
given
set
three
families
sperner
families
set
deﬁne
collection
families
sets
set
sperner
families
whose
elements
subsets
except
three
trivial
sperner
families
mentioned
cid:64
cid:48
cid:40
cid:48
general
l-descriptions
problem
deﬁne
set
cid:44
set
represents
set
descriptions
decoder
receives
subset
descriptions
let
denote
decoder
receives
descriptions
set
deﬁne
family
sets
cid:44
family
sets
corresponds
set
possible
decoders
cid:110
cid:111
explain
notation
example
consider
three-descriptions
problem
case
set
descriptions
seven
possible
decoders
set
decoders
case
cid:102
deﬁne
set
set
random
variables
um1
um2
denoted
um1
sperner
family
sperner
family
since
cid:40
furthermore
cid:60
second
part
paper
involves
application
linear
codes
cosets
following
gives
formal
deﬁnition
codes
deﬁnition
let
prime
number
linear
code
characterized
generator
matrix
gk×n
deﬁned
deﬁned
follows
cid:44
ug|u
coset
code
cid:48
shifted
version
linear
code
characterized
generator
matrix
gk×n
dither
deﬁned
cid:48
deﬁned
follows
cid:48
cid:44
b|u
cid:110
cid:111
cid:110
cid:111
consider
two
families
sets
make
frequent
use
nested
linear
codes
pair
nested
linear
codes
deﬁned
follows
deﬁnition
natural
numbers
let
gki×n
ko−ki
matrices
deﬁne
linear
codes
generated
g|∆g
respectively
called
pair
nested
linear
codes
inner
code
outer
code
co.
nested
coset
codes
deﬁned
shifted
versions
nested
linear
codes
preliminaries
3.1
problem
statement
general
l-descriptions
problem
described
section
setup
characterized
discrete
memoryless
source
probability
distribution
ﬁnite
set
distortion
functions
ˆxn
ˆxn
reconstruction
alphabet
assume
distortion
functions
bounded
distortion
n-length
sequence
ˆxn
given
average
distortion
components
ˆxi
discrete
memoryless
source
fed
encoder
encoder
upon
receiving
block
length
source
symbols
produces
diﬀerent
indices
called
descriptions
source
descriptions
sent
decoders
decoder
receives
speciﬁc
subset
descriptions
decoder
receives
description
based
descriptions
received
decoder
produces
reconstruction
source
vector
deﬁnition
multiple-descriptions
code
consist
encoder
|l|
decoders
cid:89
ˆxn
i∈n
achievable
rate-distortion
region
deﬁned
follows
deﬁnition
vector
i∈l
n∈l
said
achievable
suﬃciently
large
exists
multiple-descriptions
code
following
constraints
sat-
isﬁed
log
cid:104
cid:0
i∈n
cid:1
cid:105
exn
achievable
region
l−descriptions
problem
set
achievable
vectors
remark
although
reconstruction
alphabet
diﬀerent
source
alphabet
throughout
paper
assume
two
alphabets
ease
notation
results
hold
general
case
3.2
prior
works
section
present
brief
description
previous
known
schemes
state
corre-
sponding
inner
bounds
developed
achievable
region
one
early
strategies
coding
two
descriptions
gamal
cover
egc
strategy
similar
strategies
explained
section
egc
scheme
relies
random
unstructured
codebook
generation
following
theorem
describes
corresponding
inner
bound
achievable
region
results
egc
scheme
note
alternative
way
characterize
inner
bound
described
deﬁnition
joint
distribution
random
variables
1,2
set
recon-
struction
functions
set
rdegc
deﬁned
set
vectors
satisfying
following
bounds
x|q
x|q
x|q
1,2
x|u
theorem
egc
vector
1,2
achievable
two
descriptions
prob-
lem
exists
distribution
reconstruction
functions
1,2
rdegc
egc
scheme
two
codebooks
generated
independently
based
marginals
two
codebooks
large
enough
encoder
ﬁnd
pair
jointly
typical
codevectors
two
codebooks
codebooks
generated
jointly
based
joint
distri-
bution
x|q
1,2
x|u
would
ensure
existence
jointly
typical
codevectors
however
egc
scheme
since
codebooks
generated
independently
rate-penalty
inﬂicted
encoder
term
manifestation
rate-
penalty
towards
reducing
rate-penalty
new
coding
strategy
introduced
resulting
achievable
region
called
zhang-berger
region
region
given
following
theorem
deﬁnition
joint
distribution
random
variables
1,2
set
recon-
struction
functions
set
rdzb
deﬁned
set
vectors
satisfying
following
bounds
1,2
theorem
vector
1,2
achievable
two
descriptions
prob-
lem
exists
distribution
reconstruction
functions
1,2
rdzb
closure
union
achievable
vectors
called
rate-distortion
region
denoted
rdzb

cid:91

rdzb
rdzb
scheme
diﬀers
egc
strategy
introduction
random
variable
random
variable
called
common-component
two
descriptions
egc
scheme
order
send
cid:101
cid:101
one
pay
following
rate-penalty
cid:101
cid:101
scheme
rate-penalty
reduced
cid:101
cid:101
following
deﬁnition
provides
characterization
common-component
two
random
variables
deﬁnition
let
two
random
variables
called
common-component
exist
functions
probability
one
entropy
positive
shown
certain
two-descriptions
setup
addition
enlarges
region
call
random
variable
non-redundant
following
deﬁnition
gives
formal
description
non-redundant
random
variable
deﬁnition
given
achievable
region
l−descriptions
setup
characterized
collection
auxiliary
random
variables
auxiliary
random
variable
called
non-redundant
region
strictly
reduces
set
constant
example
provide
overview
example
rate-distortion
region
strictly
better
egc
rate-distortion
region
since
used
extensively
following
sections
consider
two-descriptions
setting
binary
symmetric
source
bss
side
decoders
intend
reconstruct
hamming
distortion
central
decoder
needs
lossless
reconstruction
source
shown
rate
distortion
vector
1,2
0.629
0.629
0.11
0.11
achievable
using
scheme
egc
scheme
typically
given
region
codebook
associated
random
variable
call
codebook
non-redundant
associated
non-redundant
random
variable
coding
scheme
codebook
corresponding
non-redundant
idea
constructing
codebook
carrying
common-component
two
random
variables
foundation
schemes
proposed
general
l−descriptions
problem
one
even
interpret
main
diﬀerence
schemes
way
common-component
diﬀerent
random
variables
exploited
explained
introduction
best
known
achievable
region
l−descriptions
problem
cms
binning
cmsb
strategy
strategy
combinatorial
number
common-component
random
variables
considered
explain
coding
scheme
three-descriptions
case
code-
book
structure
shown
figure
two
layers
codebooks
layer
maximum-distance
separable
mds
codes
layer
source
channel
erasure
codes
scec
codebook
de-
coded
decoder
cid:48
cid:48
codebooks
binned
independently
bin
numbers
whereas
bin
number
scec
let
rdcms
denote
resulting
region
achievable
mds
code
carried
description
cid:83
carried
one
description
cid:84
n∈m
using
cmsb
strategy
see
n∈m
figure
structure
cmsb
codebooks
three-descriptions
problem
improvements
using
unstructured
codes
objective
provide
new
achievable
region
l-descriptions
problem
improves
upon
region
given
cmsb
strategy
based
new
coding
scheme
involving
unstructured
structured
codes
achievable
region
corresponding
coding
scheme
presented
pedagogically
two
steps
ﬁrst
step
presented
section
provide
region
achievable
using
unstructured
codes
region
strictly
better
cmsb
region
words
improvement
upon
cmsb
region
using
unstructured
codes
second
step
presented
1,2
1,3
2,3
1,3
1,2
2,3
1,2
2,3
1,2
1,3
1,3
2,3
mdscodesscec
next
two
sections
enhanced
structured
coding
layer
improves
performance
even
words
show
codebooks
associated
structured
coding
layer
non-redundant
4.1
main
results
describe
key
ideas
case
distinct
decoders
one
associated
every
non-empty
subset
identify
set
decoders
2l\φ
new
achievable
region
provide
improves
upon
cmsb
rate-distortion
region
two
factors
ﬁrst
comes
adding
extra
codebooks
second
comes
general
binning
method
using
common-component
perspective
associate
every
non-empty
subset
decoders
auxiliary
random
variable
corresponding
codebook
identify
collection
auxiliary
variables
codebooks
2l\φ
codebook
binned
multiple
times
description
received
least
one
decoder
bin
index
codebook
associated
sent
description
although
appears
strategy
involves
generation
doubly-exponential
number
code-
books
show
codebooks
redundant
leaving
asymptotically
expo-
nential
number
non-redundant
codebooks
remaining
codebooks
generally
non-redundant
small
number
examples
consider
paper
figure
ssc
codebooks
present
three-descriptions
problem
turns
codebook
non-redundant
associated
family
sets
instead
codebooks
17.
since
indices
codebooks
associated
sperner
families
sets
call
scheme
sperner
set
coding
ssc
scheme
schematic
codebook
collection
shown
figure
start
left
top
ﬁrst
two
codebooks
identiﬁed
mds
codes
next
six
codebooks
identiﬁed
three
mds
codes
three
mds
codes
associated
decoders
get
two
descriptions
next
three
identiﬁed
source-channel
erasure
codes
scec
next
three
identiﬁed
scec
similar
codebooks
used
egc
rate
region
codebooks
considered
deriving
cmsb
rate
region
ﬁnal
set
codebooks
new
identiﬁed
three
mds
codes
associated
decoders
receive
disjoint
subsets
descriptions
following
theorem
characterizes
achievable
region
ssc
scheme
deﬁnition
joint
distribution
random
variables
set
reconstruction
functions
set
rds
deﬁned
set
vectors
satisfying
following
bounds
non-negative
real
numbers
cid:102
m∈sl
um|x
cid:88
m∈m
−rm
1,2
1,3
2,3
1,3
1,2
2,3
1,2
2,3
1,2
1,3
1,3
2,3
1,3
2,3
1,2
cid:88
m∈mn\
cid:101
cid:88
cid:102
cid:8
cid:9
umn|ul∪
cid:101
cid:88
cid:101
denotes
set
codebooks
decoded
decoders
cid:40
receive
subsets
descriptions
set
codebooks
decoded
decoder
cid:44
sl|∃n
cid:48
cid:48
received
cid:101
cid:44
cid:83
theorem
vector
i∈l
n∈l
achievable
l−descriptions
problem
exists
distribution
reconstruction
functions
i∈l
n∈l
rds
cid:40
mnp
closure
union
achievable
vectors
called
ssc
achievable
rate-distortion
region
denoted
rds

cid:91

rds
rds
order
clarify
notation
explain
random
variables
decoded
decoder
three-
descriptions
problem
know
elements
formulas
corresponds
set
random
variables
decoded
decoder
whereas
cid:101
corresponds
set
random
variables
decodable
access
strict
subsets
descriptions
received
random
variables
decoded
decoders
decoder
2,3
decoder
1,2
1,3
2,3
example
cid:40
cid:110
cid:111
decoded
decoder
.also
cid:101
2,3
cid:110
cid:111
cid:41
cid:110
cid:111
2,3
1,3
1,2
1,2
2,3
1,3
2,3
2,3
cid:110
cid:111
cid:40
cid:110
cid:111
cid:110
cid:111
cid:110
cid:111
cid:110
cid:111
cid:41
cid:110
cid:111
cid:110
cid:111
cid:110
cid:111
codebooks
cid:110
cid:111
cid:110
cid:111
codebooks
decoded
decoders
lemma
ssc
rate-distortion
region
convex
cid:3
proof
see
section
a.1
appendix
remark
every
decoder
deﬁned
reconstruction
function
random
variable
however
decoder
decodes
random
variables
following
lemma
shows
region
improve
reconstruction
function
deﬁned
function
umn
instead
lemma
region
theorem
change
reconstruction
function
decoder
deﬁned
function
umn
cid:3
proof
see
section
a.2
appendix
remark
scheme
proposed
theorem
|sl|
codebooks
know
size
number
sperner
families
minus
three
number
sperner
families
called
dedekind
numbers
large
body
work
determining
values
dedekind
numbers
diﬀerent
known
numbers
grow
exponentially
example
number
codebooks
necessary
165.
however
examples
paper
turns
many
codebooks
become
redundant
small
subset
used
scheme
proof
proceeding
detailed
description
coding
strategy
provide
brief
outline
family
sets
encoder
generates
codebook
based
marginal
pum
indepen-
uniformly
description
cid:102
description
carry
corresponding
bin
number
dently
codebooks
intuitively
codebook
common-component
among
decoders
decoded
decoders
cid:48
codebook
binned
independently
codewords
corresponding
codebooks
decoder
reconstructs
corresponding
codewords
ﬁnding
unique
set
jointly
typical
codevectors
bins
received
existence
jointly
typical
set
codewords
ensured
encoder
way
satisfaction
whereas
decoder
unique
reconstruction
warranted
codebook
generation
fix
blocklength
positive
reals
cid:102
m∈sl
erate
codebook
based
marginal
pum
size
2nrm
ith
description
cid:101
bin
every
gen-
codebook
randomly
uniformly
2nρm
bins
i.e
randomly
uniformly
assign
index
2nρm
codeword
index
called
bin-index.
encoding
upon
receiving
source
vector
encoder
ﬁnds
jointly-typical
set
codewords
unm
description
carries
bin-indices
codewords
corresponding
binning
function
decoding
received
bin-indices
descriptions
decoder
tries
reconstruct
words
decoder
ﬁnds
unique
vector
unm
n∈m
jointly
typical
sequences
corresponding
bins
vector
exist
unique
decoder
declares
error
covering
bounds
since
codebooks
generated
randomly
independently
ﬁnd
set
vectors
unm
jointly
typical
source
vector
mutual
covering
bounds
necessary
based
mutual
covering
lemma
packing
bounds
decoder
description
received
since
binning
done
independently
uniformly
ﬁnd
unique
set
jointly
typical
sequences
unm
n∈m
mutual
packing
bounds
required
mutual
packing
lemma
cid:3
remark
two
main
diﬀerences
new
scheme
previous
cmsb
scheme
first
additional
codebooks
present
example
figure
three
codebooks
right
column
present
cmsb
scheme
second
description
bins
codebooks
cid:101
show
next
sections
additional
codebooks
contribute
enlargement
achievable
region
words
prove
additional
codebooks
non-redundant
also
show
new
binning
strategy
improves
achievable
region
4.2
improvements
due
additional
codebooks
consider
general
l-descriptions
problem
section
prove
codebook
non-redundant
remark
straightforward
see
addition
codebook
cid:60
going
result
larger
achievable
region
see
consider
three
descriptions
problem
assume
add
codebook
1,2
deﬁnition
new
codebook
decoded
either
receive
description
descriptions
case
codebook
decoded
exactly
decoders
decoded
means
merging
two
codebooks
change
packing
bounds
whereas
may
relax
covering
bounds
codebook
would
redundant
reason
consider
codebooks
associated
sperner
families
remark
three
sperner
families
construct
codebooks
clear
necessary
since
decoded
decoder
furthermore
one
use
proof
provided
show
also
redundant
next
lemma
proves
random
variables
considered
theorem
non-redundant
lemma
random
variable
non-redundant
every
figure
three
descriptions
setup
showing
1,2
redundant
proof
provide
proof
case
give
outline
proof
generalized
codebooks
1,2
1,3
2,3
1,2
1,3
1,2
2,3
1,3
2,3
1,2
1,3
2,3
present
cmsb
scheme
shown
non-redundant
new
codebooks
1,2
1,3
prove
1,2
non-redundant
using
following
example
two
codebooks
non-redundant
symmetry
build
example
construct
three-descriptions
example
shown
figure
explained
previous
section
known
non-redundant
let
0.629
1,2
let
0.629
0.629
rdzb
min
let
set
probability
distributions
1,2
0.629
0.629
belongs
rdzb
given
theorem
deﬁne
joint
distribution
follows
cid:44
arginf
x∈p
dec3dec123dec12encoderxˆx
dˆx
dxdec1ˆx
let
marginal
distribution
deﬁne
random
variable
correlated
let
binary
random
variable
independent
0.5
deﬁne
denotes
logical
function
let
px|
induced
joint
conditional
distributions
respectively
example
proceed
explaining
new
example
source
bss
decoders
want
reconstruct
source
respect
hamming
distortion
central
decoder
wants
reconstruct
source
losslessly
decoder
wants
reconstruct
source
respect
distortion
function
given
log
px|
lemma
following
vector
belong
rdcms
1,2
constant
vector
belongs
rds
given
theorem
achievable
using
ssc
scheme
1,2
1,2,3
0.629
0.629
cid:48
cid:48
proof
provide
intuition
behind
proof
ﬁrst
coding
scheme
theorem
code-
books
capable
carrying
common-component
decoders
1,2
set
distortion
constraint
decoder
common
message
carried
exclusively
either
descriptions
rather
descriptions
necessary
reconstruction
common
codebook
codebook
1,2
empty
proof
cid:3
provided
section
a.3
appendix
far
shown
additional
codebooks
non-redundant
argument
cid:3
extended
case
outline
general
argument
provided
appendix
a.4
4.3
improvements
due
binning
ssc
scheme
descriptions
cid:102
carry
independent
bin
indices
codebook
diﬀerent
second
factor
contributing
gains
ssc
rate-distortion
region
binning
method
cmsb
strategy
codebook
binned
speciﬁc
subset
descriptions
based
whether
codebook
scec
mds
codebook
prove
three-descriptions
example
region
enlarges
due
binning
ssc
scheme
even
three
additional
codebooks
show
following
example
bin
indices
1,2
1,3
carried
descriptions
example
example
generated
modifying
example
illustrated
figure
source
bss
deﬁned
example
decoders
want
reconstruct
source
hamming
distortion
decoder
wants
reconstruct
source
losslessly
lemma
order
achieve
1,2
1,3
1,2,3
cid:48
must
1,2
1,3
1,2
1,3
proof
see
section
a.5
appendix
cid:3
figure
example
showing
improvements
due
binning
linear
coding
examples
providing
uniﬁed
region
uses
unstructured
structured
codes
step
sec-
tion
pedagogical
reasons
look
three
examples
l−descriptions
problems
provide
example-
speciﬁc
coding
schemes
based
linear
codes
perform
strictly
better
ssc
scheme
based
unstructured
codes
shows
ssc
region
complete
structured
coding
layer
necessary
coding
schemes
uniﬁed
presented
next
section
5.1
gains
due
linear
quantizers
create
three-descriptions
setting
reconstructions
bivariate
functions
necessary
example
consider
three-descriptions
example
figure
independent
bss
decoder
wish
reconstruct
respectively
hamming
distortion
decoders
2,3
wish
reconstruct
pair
distortion
function
dxz
interested
achieving
following
vector
1,2
1,3
2,3
first
argue
example
description
carry
bivariate
function
descriptions
decoders
operate
optimal
ptp
rate-distortion
function
corresponding
descriptions
allocate
rates
satisfy
individual
decoder
distortion
criteria
since
distortion
constraint
decoder
relates
description
carries
quantization
argument
description
carries
quantization
description
carry
sum
two
quantizations
joint
decoders
distortion
constraints
satisﬁed
since
structured
codes
eﬃcient
transmitting
bivariate
summations
random
variables
expect
using
structured
codes
would
give
gains
example
opposed
unstructured
codes
first
prove
vector
achievable
using
linear
codes
lemma
vector
achievable
dec12dec123dec13encoderxˆx
dˆx
figure
three-descriptions
example
vector
binary
source
proof
encoding
construct
sequence
random
linear
codes
rate
going
well
known
sequence
linear
codes
used
quantize
bss
hamming
distortion
deﬁne
following
ˆxn
argmincn∈cndh
ˆzn
argmincn∈cndh
since
ˆxn
ˆzn
codewords
codebook
linear
ˆxn
ˆzn
also
codeword
description
carries
index
ˆxn
description
carries
index
ˆzn
description
carries
index
ˆxn
ˆzn
decoding
decoders
receive
ˆxn
ˆzn
respectively
satisfy
distortion
constraints
decoder
reconstructs
ˆxn
ˆzn
lemma
shows
distortion
criteria
decoder
satisﬁed
lemma
setting
ˆxn
ˆzn
proof
see
section
b.1
appendix
cid:3
decoder
receives
ˆxn
ˆzn
satisﬁes
distortion
requirements
also
decoders
recover
ˆxn
ˆzn
adding
ˆxn
ˆzn
ˆxn
ˆzn
respectively
shows
vector
achievable
using
linear
codes
cid:3
next
show
ssc
scheme
achieve
vector
lemma
vector
belong
rds
i.e.
achievable
using
ssc
scheme
proof
see
section
b.2
appendix
cid:3
encoderdec1dec2dec12x
zˆxˆx
ˆzˆzdec23ˆx
ˆzdec3ˆx+ˆzdec13ˆx
5.2
gains
due
linear
binning
ssc
scheme
two
stages
codebook
generation
phase
ﬁrst
stage
unstructured
codebooks
generated
randomly
independently
second
stage
codebooks
binned
randomly
unstructured
fashion
description
previous
example
shown
ﬁrst
stage
beneﬁcial
generate
codebooks
linear
structure
however
example
need
binning
next
example
show
binning
operation
needs
carried
structured
manner
well
analogous
gains
observed
distributed
source
coding
problem
bin
structure
needs
linear
consider
four-descriptions
example
figure
figure
example
showing
gains
due
linear
binning
example
bss
independent
related
binary
symmetric
channel
bias
words
independent
decoders
wish
decode
respectively
hamming
distortion
decoders
require
lossless
reconstruction
respectively
interested
achieving
following
vector
show
vector
achievable
using
structured
codebooks
linear
binning
next
lemma
lemma
vector
achievable
proof
codebook
generation
take
arbitrary
sequence
positive
numbers
large
construct
family
nested
coset
codes
rate
outer
code
rate
inner
code
choose
good
source
code
quantizing
bss
hamming
distortion
existence
nested
coset
codes
well-known
random
coding
arguments
next
bin
space
shifted
versions
cosets
written
form
operation
bins
space
|pi|
+n
bins
bin
number
associated
arbitrary
vector
determines
exactly
quantization
noise
resulting
quantizing
vector
using
minimum
hamming
distortion
criterion
denote
bin
number
similar
binning
operation
performed
using
denote
bin
number
obtained
using
shifted
versions
let
voronoi
region
codeword
good
channel
code
bsc
choose
deﬁne
ith
bin
vector
encoderdec1dec23dec12x
zˆxxx+zdec34zdec4ˆz
encoding
encoder
quantizes
using
respectively
also
ﬁnds
bin
number
two
source
sequences
transmitted
ﬁrst
description
transmitted
second
description
transmitted
third
description
transmitted
fourth
description
decoding
since
outer
codes
good
source
codes
distortion
constraints
decoders
satisﬁed
hence
decoders
calculate
mentioned
bin
number
determines
quantization
noise
decoders
reconstruct
source
losslessly
using
bin
number
quantization
vector
decoder
receives
since
linear
codeword
thought
noise
vector
constructed
good
channel
code
bsc
decoder
recover
cid:3
subtracting
two
vectors
get
argue
voronoi
region
subset
one
true
since
although
used
linear
codes
quantization
well
binning
linearity
binning
critical
example
fact
similarly
shown
one
achieve
vector
chosen
union
random
cosets
contrast
previous
example
codebook
quantizing
codebook
required
linear
lemma
10.
vector
achievable
using
ssc
scheme
proof
see
section
b.3
appendix
cid:3
5.3
correlated
quantizations
source
noted
case
ssc
scheme
unstructured
quantizers
generated
randomly
independently
observed
two
examples
order
eﬃciently
reconstruct
bivariate
summa-
tion
beneﬁcial
use
linear
code
quantizing
source
however
two
examples
source
vector
two
components
separately
quantized
using
identical
linear
codes
analysis
coding
scheme
required
standard
ptp
covering
packing
bounds
linear
codes
general
case
evaluation
performance
identical
generally
correlated
linear
codes
quantization
requires
new
covering
packing
bounds
illustrated
following
scalar
source
example
depicted
figure
setup
constructed
based
no-excess
rate
example
described
two-descriptions
problem
two-descriptions
example
source
bss
distortion
functions
decoders
hamming
distortion
special
case
called
no-excess
rate
regime
1−h
shown
egc
region
tight
distortion
1,2
decoder
minimum
side
distortion
achievable
shown
example
source
bss
distortion
functions
decoders
hamming
distortions
distortion
function
decoder
following
general
distortion
function
2d0
three-descriptions
example
given
follows
0
figure
scalar
source
example
correlated
quantization
positive
real
numbers
interested
achieving
vectors
following
projections
1,2
1,3
2,3
2d0
objective
evaluate
optimal
trade-oﬀ
following
lemma
provides
vectors
achievable
using
linear
codes
lemma
11.
vector
achievable
using
linear
codes
long
following
constraints
satisﬁed
cid:16
cid:16
cid:17



cid:17
3


cid:16
cid:16
cid:16
cid:17
cid:17
2hb

cid:16
cid:17
cid:17
proof
consider
following
deﬁnition
deﬁnition
10.
let
ﬁeld
consider
random
variables
deﬁned
arbitrary
ﬁnite
set
deﬁned
fix
pmf
sequence
code
pairs
called
pxuv-covering
xn|∃
v|xn
encoderdec1dec2dec12xˆx
dˆx
d0ˆx
ddec23ˆx
d0dec3ˆx
d3dec13ˆx
first
derive
new
covering
packing
bounds
joint
quantization
general
source
i.e
necessarily
binary
using
two
pairs
nested
coset
codes
let
cid:48
two
pairs
nested
coset
codes
generator
matrices
shown
figure
share
inner
code
two
codebooks
generated
independently
hand
cid:48
two
codebooks
construction
generalizes
previous
constructions
figure
codebook
construction
lemma
lemma
covering
lemma
pxuv
rates
cid:48
exists
sequence
two
pairs
nested
coset
codes
cid:48
log
u|x
log
v|x
cid:48
cid:48
cid:48
log
v|x
log
βv|x
fq\
satisfying
pxuv-covering
proof
see
section
b.4
appendix
cid:3
remark
diﬀerence
new
mutual
covering
bounds
ones
independent
codebook
generation
presence
constraint
redundant
recover
mutual
covering
bounds
independent
codebook
generation
expected
cid:44
non-redundant
intuitive
explanation
additional
bound
deﬁne
αc1
βc2
coset
code
generator
matrix
cid:48
∆gt
size
codebook
ro+r
cid:48
o−ri
suppose
codevetors
jointly
typical
respect
puvx
αc1
βc2
jointly
typical
respect
pαu⊕qβv
implies
size
least
log
q−h
αu⊕qβv|x
converse
source
coding
theorem
deﬁnition
11.
let
deﬁnition
10.
sequence
code
pairs
bin
functions
2nρi
called
pxuv-packing

xn
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:48
cid:48
cid:48
cid:48
cid:44
cid:48
v|x
cid:84
cid:84
cid:48


g1c1g2gg∆g∆g0n·rin·
ro−ri
n·rin·
r0o−ri
lemma
packing
lemma
pxuv
exists
sequence
two
pairs
nested
coset
codes
cid:48
satisfy
bin
function
pxuv-packing
cid:48
log
u|v
log
v|u
cid:48
cid:48
log
proof
see
section
b.5
appendix
cid:3
proceed
explaining
achievability
scheme
deﬁne
joint
distribution
table
random
variables
2−1
1−d0
2−1
2−1
1−d0
2−1
3−2
3−2
table
joint
distribution
codebook
generation
set
cid:48
three
binning
functions
2nρi
construct
family
coset
codes
rate
also
construct
encoding
upon
receiving
source
sequence
encoder
ﬁnds
codebook
jointly
typical
respect
pair
codewords
exists
long
covering
bounds
lemma
satisﬁed
case
hand
readily
checked
cid:48
satisfy
bounds
description
carries
bin
index
using
description
carries
bin
index
using
description
carries
bin
index
using
decoding
decoder
receives
bin
index
carried
description
reconstructs
long
unique
codeword
bin
typical
respect
following
packing
bound
ensures
correct
decoding
arbitrarily
small
error
arguments
decoder
reconstructs
correctly
decoder
reconstructs
arbitrarily
small
error
since
following
packing
bound
satisﬁed
conclude
decoders
receive
two
descriptions
would
access
de-
coders
announce
decoded
codewords
reconstruction
source
recon-
struction
function
decoders
receive
two
descriptions
given
follows

ˆxi
c1i
c2i
otherwise
implies
vector
stated
lemma
achieved
strong
typicality
cid:3
following
lemma
shows
vectors
lemma
achievable
using
ssc
scheme
lemma
14.
vector
achievable
using
ssc
scheme
following
values
equality
holds
log2
log2
example
0.035
4.566
2.495
satisfy
constraints
rounded
parameters
third
decimal
place
proof
see
section
b.6
appendix
cid:3
achievable
region
using
structured
codes
section
provide
new
achievable
region
general
l−descriptions
problem
enhancing
ssc
coding
scheme
structured
coding
layer
present
region
four
stages
ﬁrst
stage
prove
ssc
region
also
achieved
using
structured
codes
particular
use
independent
nested
coset
codes
auxiliary
random
variable
exploit
pairwise
independence
codewords
show
achievability
ssc
region
subsequent
stages
add
coding
layers
facilitates
reconstruction
multi-variate
functions
auxiliary
random
variables
improvements
due
additional
layers
comes
exploiting
algebraic
structure
codebooks
second
stage
allow
reconstruction
bivariate
summation
codewords
third
stage
extend
multi-variate
summation
codewords
fourth
stage
consider
general
case
involving
reconstruction
arbitrary
number
multi-variate
summations
decoders
6.1
stage
achievability
ssc
region
using
nested
coset
codes
deﬁnition
12.
joint
distribution
random
variables
set
reconstruc-
tion
functions
set
rd1
deﬁned
set
vectors
satisfying
following
bounds
non-negative
real
numbers
cid:102
m∈sl
um|x
cid:88
umn|ul∪
cid:101
cid:88
m∈m
log
cid:88
cid:88
m∈mn\l∪
cid:101
cid:8
cid:9
log
log
theorem
vector
i∈l
n∈l
achievable
l−descriptions
problem
using
nested
coset
codes
exists
distribution
reconstruction
functions
i∈l
n∈l
rd1
proof
encoding
decoding
steps
exactly
ones
proof
theorem
diﬀerence
codebook
generation
phase
phase
every
generate
coset
code
rate
generator
matrix
dither
generated
randomly
uniformly
every
bounds
mutual
covering
bounds
independently
generated
coset
codes
bounds
ensure
encoding
carried
without
error
bounds
mutual
packing
bounds
decoder
ensure
errorless
decoding
lemma
15.
region
theorem
equal
ssc
region
proof
see
section
c.1
appendix
6.2
stage
reconstruction
summation
two
codebooks
cid:3
cid:3
ﬁrst
stage
constructed
one
codebook
subset
decoders
however
codebooks
corresponding
sperner
families
sets
shown
non-redundant
interpret
using
notion
common-information
deﬁned
gacs
körner
witsenhausen
let
denote
common
information
two
random
variables
common
information
among
random
variables
vector
length
information
common
among
every
subset
random
variables
size
least
two
common
information
given
referred
univariate
common
information
components
charac-
terized
using
univariate
functions
interpret
scheme
ﬁrst
stage
ssc
scheme
capturing
common-information
components
among
random
variables
associated
decoders
using
univariate
functions
notion
common
information
generalized
using
bivariate
functions
following
seven-dimensional
vector
seven
degrees
freedom
information
common
among
random
variables
latter
three
called
bivariate
common
information
components
characterized
using
bivariate
func-
tions
random
variables
sense
addition
structured
coding
layers
next
stages
thought
capturing
common-information
among
2l−
decoders
using
bivariate
generally
multivariate
functions
extend
notion
bivariate
common
information
random
variables
follows
characterize
bivariate
common
information
component
consider
three
subsets
deﬁne
˜an1
˜an2
˜an3
bivariate
common
information
component
among
˜ani
information
common
among
ani
example
let
characterizes
information
computed
conference
via
bivariate
function
information
common
information
concept
extended
deﬁne
multivariate
common
information
among
random
variables
return
discussion
achievable
region
problem
second
stage
aim
capture
bivariate
common
information
among
random
variables
associated
decoders
particular
reconstruct
summation
two
codebooks
arguments
cid:48
instead
one
codebook
subset
decoders
ﬁrst
stage
stage
need
construct
one
codebook
every
triple
subsets
decoders
given
triple
sets
decoders
third
set
decoders
reconstruct
bivariate
summation
random
variable
corresponding
ﬁrst
subset
random
variable
corresponding
second
subset
decoders
explained
detail
next
add
two
new
codebooks
ssc
scheme
underlying
random
variables
two
codebooks
denoted
va1
va2
cid:44
construct
two
pairs
nested
coset
codes
two
random
variables
two
nested
coset
codes
inner
code
codebook
corresponding
vai
decoded
decoder
furthermore
sum
two
codebooks
decoded
decoder
mn\
element
example
let
choose
case
ﬁrst
codebook
decoded
whenever
description
received
second
codebook
decoded
description
received
sum
decoded
whenever
description
received
corresponds
coding
schemes
presented
example
va1
va2
following
theorem
describes
achievable
region
using
scheme
deﬁnition
13.
three
distinct
families
joint
distribution
random
variables
underlying
alphabet
auxiliary
random
variables
ﬁeld
set
reconstruction
functions
set
rd2
deﬁned
set
vectors
satisfying
following
bounds
non-negative
real
numbers
cid:102
m∈sl
umve|x
cid:88
wa3
β|x
cid:88
cid:101
cid:88
cid:48
log
cid:48
log
log
cid:48
fq\
cid:88
cid:88
cid:88
cid:98
mn∪l
cid:88
m∈mn\
cid:101
mn∪l
m∈mn\
cid:101
mn∪l
cid:102
cid:102
cid:84
ai|i∈
1,3
cid:8
cid:9
cid:44
cid:44
|a3
cid:98
cid:44
cid:83
cid:48
cid:40
cid:48
cid:48
theorem
vector
i∈l
n∈l
achievable
l−descriptions
problem
exists
distribution
reconstruction
functions
i∈l
n∈l
rd2
log
wa3
cid:44
αva1
log
cid:48
cid:88
βva2
log
log
cid:44
cid:48
cid:48
m∈m
m∈m
e∈e
providing
proof
explain
bounds
new
region
mutual
covering
packing
bounds
also
present
theorem
respectively
generalization
additional
covering
bound
derived
lemma
12.
note
common
component
among
decoders
pair
ua1
va1
similarly
common
component
among
decoders
pair
ua1
wa3,1,1
observe
wa3,1,1
va1
va2
proof
given
joint
distribution
codebook
binning
rates
satisfying
bounds
theo-
rem
prove
achievability
vector
1we
used
script
denote
subscripts
random
variables
throughout
paper
however
collection
used
subscript
since
random
variable
deﬁned
using
cid:48
cid:48
codebook
generation
fix
blocklength
every
independently
generate
linear
code
inner
code
size
2nro
also
generate
two
nested
coset
codes
rate
outer
codes
rates
cid:48
deﬁne
set
codewords
size
2nr
cid:48
ith
description
bin
codebook
randomly
cid:48
uniformly
rate
2nρm
encoding
upon
receiving
source
vector
encoder
ﬁnds
jointly-typical
set
codewords
description
carries
bin-indices
corresponding
codewords
encoder
declares
error
jointly
typical
set
codewords
available
decoding
received
bin-indices
descriptions
decoder
tries
ﬁnd
set
jointly
typical
codewords
set
codewords
unique
decoder
declares
error
cid:44
order
encoder
ﬁnd
set
jointly
typical
codewords
mutual
covering
bounds
hold
generalization
result
lemma
omit
proof
brevity
bounds
mutual
packing
bounds
decoder
cid:3
remark
considered
general
case
chosen
arbitrarily
turns
certain
choices
would
give
non-redundant
codebooks
thus
provide
improvements
ssc
scheme
one
show
codebooks
redundant
cid:48
cid:48
example
take
6.3
stage
reconstruction
summation
arbitrary
number
codebooks
decoder
take
families
distinct
random
variable
cid:80
section
reconstruct
multi-variate
summation
arbitrary
number
random
variables
one
decoder
summation
respect
ﬁnite
ﬁeld
following
steps
previous
section
add
new
codebooks
original
ssc
scheme
let
cid:44
underlying
random
variables
codebooks
denoted
vak
random
variable
vak
decoded
i∈m
vak
decoded
decoder
am+1
am+1
element
following
theorem
describes
achievable
region
deﬁnition
14.
distinct
families
joint
distribution
random
variables
vak
underlying
alphabet
auxiliary
random
variables
ﬁeld
set
reconstruction
functions
set
rd3
deﬁned
set
vectors
satisfying
following
bounds
non-negative
real
numbers
cid:102
m∈sl
umve|x
cid:88
umwf|x
cid:88
cid:101
log
log
cid:88
log
cid:48
cid:88
log
cid:48
cid:88
cid:88
cid:98
mn∪l
cid:88
m∈mn\
cid:101
mn∪l
m∈mn\
cid:101
mn∪l
cid:102
cid:84
ai|i∈
m+1
cid:8
cid:9
am+1
cid:48
log
cid:88
cid:102
cid:48
log
m∈m
m∈m
e∈e
cid:88
cid:80
cid:98
cid:83
k|αk
cid:44
cid:48
j⊂j
cid:48
cid:48
ak|ak
am+1
|am+1
am+1
|αm
cid:48
cid:40
cid:48
log
wam+1
cid:48
cid:80
i∈m
αivak
am+1
k∈j
cid:48
theorem
vector
i∈l
n∈l
achievable
l−descriptions
problem
exists
distribution
reconstruction
functions
i∈l
n∈l
rd3
cid:80
cid:44
cid:84
toward
proving
theorem
need
following
deﬁnition
deﬁnition
15.
set
coset
codes
cnak
j⊂m
size
intersection
caj
called
ensemble
nested
coset
codes
parameter
k∈j
cak
equal
2nrj
parameter
j⊂m
long
cid:80
straightforward
show
one
always
generate
ensemble
nested
coset
codes
cak
cid:48
j⊂j
cid:48
cid:48
enough
choose
rows
generator
matrices
cak
nri
common
rows
similar
case
figure
proof
provide
outline
proof
codebook
generation
codebooks
similar
previous
scheme
random
variables
vak
construct
ensemble
nested
coset
codes
cak
parameter
j⊂m
encoder
chooses
set
codewords
codebooks
jointly
typical
source
sequence
following
generalized
covering
lemma
shows
satisﬁed
set
codewords
exists
deﬁnition
16.
let
ﬁeld
deﬁne
cid:44
cid:8
cid:9
consider
random
variables
deﬁned
arbitrary
ﬁnite
set
deﬁned
fix
pmf
sequence
m-tuples
codebooks
called
pxvm-covering
vm|xn
∈mc
xn|∃vnm
rates
satisfying
lemma
covering
lemma
x×fm
exists
sequence
ensemble
nested
coset
codes
cnm
parameter
j⊂m
vm-covering
log
log
vj|x
cid:88
wk|x
cid:88
cid:88
cid:44
cid:80
αm∈k
cid:48
j⊂j
cid:48
wαm
cid:48
cid:44
j∈m
cid:44
cid:80
j∈j
k|αk
cid:44
source
sequence
linear
combination
cid:44
cid:80
proof
proof
lemma
follows
steps
lemma
12.
provide
intuition
behind
proof
given
set
codewords
codebooks
jointly
typical
j∈m
codeword
jointly
typical
random
variables
ptp
perspective
rate
codebook
must
satisfy
rate
calculated
counting
number
rows
generator
matrix
cid:3
nro
packing
bounds
encoder
written
way
previous
section
given
deﬁned
set
possible
linear
combinations
vak
cid:3
6.4
stage
reconstruction
arbitrary
number
summations
arbitrary
lengths
decoder
fix
prime
number
random
variable
cid:80
section
completeness
provide
coding
scheme
reconstruct
multi-variate
summa-
tions
random
variables
arbitrary
number
decoders
summations
arbitrary
lengths
course
due
large
number
random
variables
coding
scheme
becomes
extremely
complicated
let
number
summations
summation
let
length
sum-
mation
denoted
deﬁne
sets
cid:44
cid:44
following
steps
previous
sections
add
new
codebooks
summation
underlying
random
variables
codebooks
denoted
vak
random
variable
vak
decoded
j∈mi
vak
decoded
decoder
ami+1
summation
carried
ﬁnite
ﬁeld
fqi
following
theorem
describes
achievable
region
deﬁnition
17.
joint
distribution
random
variables
vak
underlying
alphabet
auxiliary
random
variables
ﬁeld
set
reconstruction
functions
set
rdlinear
deﬁned
set
vectors
satisfying
fol-
lowing
bounds
non-negative
real
numbers
cid:102
m∈sl
cid:101
ami+1
ve|x
cid:88
wf|x
cid:88
log
log
m∈m
e∈e
cid:88
log
cid:88
log
cid:88
cid:88
m∈mn\
cid:101
mn∪l
cid:102
cid:84
s|i∈
ms+1
s∈s
log
m∈m
log
cid:98
mn∪l
cid:88
m∈mn\
cid:101
mn∪l
cid:88
cid:8
cid:9
cid:83
i∈s
i|k
cid:83
αji
k|αk
cid:44
cid:80
ami+1
αmi
|ami+1
cid:98
cid:83
cid:80
cid:80
k∈j
cid:48
j⊂j
cid:48
cid:48
i|k
cid:48
cid:40
cid:48
log
i∈s
ami+1
αmi
fqi
ami+1
αmi
j=1
ivak
wam+1
αmi
theorem
vector
i∈l
n∈l
achievable
l−descriptions
problem
exists
distribution
reconstruction
functions
i∈l
n∈l
rdlinear
cid:88
cid:102
cid:48
proof
straightforward
generalization
previous
step
since
proof
similar
omitted
cid:3
remark
similar
theorem
one
identify
non-redundant
codebooks
scheme
one
show
large
number
possible
codebooks
become
redundant
case
well
conclusion
provided
several
improvements
previous
coding
strategies
problem
first
showed
cmsb
strategy
enhanced
using
additional
unstructured
quantizers
new
unstructured
binning
approach
demonstrated
gains
using
examples
involving
binary
sources
three
de-
scriptions
provided
resulting
region
l-descriptions
problem
arbitrary
sources
distortion
functions
additionally
proved
new
codebooks
scheme
non-redundant
l-descriptions
problem
second
part
paper
introduced
structure
quantizer
construction
well
binning
functions
showed
several
examples
improvements
derived
ﬁrst
part
extended
structured
quantizers
binning
functions
utilized
region
ﬁrst
part
paper
improved
upon
introducing
additional
linear
coding
layers
lastly
combined
ideas
two
parts
provide
new
strictly
improved
achievable
region
l-descriptions
problem
appendices
proofs
section
a.1
proof
lemma
proof
let
i∈l
n∈l
rds
cid:48
i∈l
n∈l
rds
cid:48
assume
cid:48
cid:44
deﬁne
new
distribution
follows
let
cid:48
deﬁned
also
let
without
loss
generality
˜um
cid:40
λpu
cid:48
straightforward
check
i∈l
n∈l
cid:48
cid:48
i∈l
n∈l
rds
cid:3
a.2
proof
lemma
proof
provide
outline
proof
fix
cid:48
consider
new
scheme
reconstruction
function
decoder
cid:48
deﬁned
cid:48
cid:81
m∈mm
cid:48
rest
reconstruction
functions
xand
reconstruction
functions
cid:48
deﬁned
theorem
let
vector
i∈l
n∈l
achievable
new
scheme
using
dis-
tribution
pusl
reconstruction
functions
cid:48
provide
new
probability
distribution
shows
region
given
theorem
cid:48
sn\
cid:48
contains
i∈l
n∈l
construct
probability
distribution
deﬁne
cid:48
cid:48
cid:48
cid:48
cid:48
umm
cid:48
reconstruction
functions
deﬁne
cid:48
cid:48
cid:48
cid:48
cid:48
cid:48
umm
cid:48
straightforward
check
parameters
region
theorem
contains
i∈l
n∈l
intuitively
since
reconstruction
functions
distortion
achieved
schemes
rates
ﬁrst
scheme
wherever
cid:48
decoded
random
variables
umm
cid:48
also
decoded
adding
function
random
variables
cid:48
require
cid:3
additional
rate
a.3
proof
lemma
proof
let
1,2
1,2
ˆx1
ˆx2
ˆxi
reconstructions
decoder
two
user
problem
example
straightforward
check
vector
achievable
theorem
next
assuming
codebook
1,2
empty
consider
remaining
codebooks
ssc
scheme
show
vector
achievable
step
step
argue
non-trivial
codebooks
1,2
due
structure
problem
number
codebooks
functionally
equivalent
meaning
decoded
exactly
decoders
merge
codebooks
without
loss
example
description
received
decoders
hence
merge
1,2
without
loss
1,3
1,3
2,3
1,2,3
decoded
decoder
redundant
results
merged
since
decoder
present
equivalent
eliminated
1,2
1,3
2,3
1,2
1,3
1,2
2,3
merged
1,2
finally
2,3
merged
also
1,2
merged
1,2,3
eliminated
left
four
codebooks
1,2
step
step
show
set
would
loss
terms
function
codebooks
decodable
using
description
since
decoder
prove
following
lemma
lemma
17.
ptp
setup
assume
decoder
optimal
ptp
receives
variables
reconstruction
function
following
markov
chain
holds
ptp
optimality
codebooks
carry
precise
markov
chain
cid:0
cid:1
proof
used
fact
function
used
ptp
optimality
code
random
variables
extra
rate
required
also
lemma
cid:0
cid:1
cid:3
since
decoded
decoder
replace
decoders
de-
hence
conclude
set
without
loss
terms
distor-
tion
step
assume
random
variables
cid:48
vector
achievable
ssc
scheme
markov
chain
description
used
reconstruction
decoders
set
distortions
constraint
decoders
satisﬁed
constructed
scheme
send
descriptions
lower
rate
setting
without
loss
terms
distortion
three
decoders
contradicts
optimality
random
variables
chosen
two
user
scheme
a.4
proof
lemma
proved
vector
achievable
constraint
lifted
scheme
achieve
vector
codebook
non-redundant
general
l-descriptions
prob-
lem
provide
outline
non-redundancy
proof
let
ani
elements
construct
example
non-redundant
ﬁrst
consider
set
set
three
decoders
ani
i+1
i+1
ani+1
i+1
ani
i+1
ani+1
i+1
two
user
setup
example
common
component
two
descriptions
straightforward
show
common
components
must
decoders
otherwise
since
codebooks
inde-
pendent
would
rate-loss
explained
previous
section
ensure
common
com-
ponent
decoded
descriptions
ia2
ani
ia1
i+1a2
ani+1
i+1
received
subset
descriptions
received
done
adding
decoders
ani
i+1
i+1
ani+1
i+1
would
ptp
optimality
receiving
reﬁned
version
i.e
would
receive
would
receive
reﬁnement
cid:3
way
codebook
carry
without
rate-loss
a.5
proof
lemma
proof
let
1,2
1,3
,2+ρ
1,2
1,3
description
carries
decoder
rate
descriptions
send
decoders
sending
reﬁnement
1,2
1,3
words
1,2
1,3
1,2
ˆx1
1,2
ˆx2
similar
proof
lemma
one
check
vector
achievable
using
ssc
scheme
next
assume
1,2
1,3
1,2
1,3
1,2
1,3
previous
section
begin
eliminating
redundant
codebooks
communications
setting
step
step
argue
codebooks
1,3
1,2
1,2
1,3
non-trivial
due
structure
communications
setting
many
codebooks
functionally
merged
together
codebooks
2,3
decoded
four
decoders
merged
1,3
2,3
merged
1,3
since
decoder
present
argument
1,2
1,3
2,3
concatenated
1,2
1,3
also
1,2
2,3
1,2
merged
1,2
1,3
combined
1,2
2,3
lastly
since
decoders
present
merged
1,2
1,3
respectively
four
codebooks
1,3
1,2
1,2
1,3
remain
step
arguments
step
lemma
set
step
assumption
codebook
1,2
1,3
carried
ﬁrst
description
however
code-
book
decoded
decoder
since
decoder
ptp
optimality
1,2
1,3
sent
ﬁrst
description
either
i.e
1,2
1,3
1,2
1,3
eliminated.
step
fourier-motzkin
elimination
covering
packing
bounds
remaining
three
code-
books
give
following
inequality
1,2
1,3
1,3
1,2
deﬁnition
bound
strictly
larger
case
replaced
i.e
1,2
1,3
concludes
proof
cid:3
proofs
section
b.1
proof
lemma
proof
ˆxn
ˆzn
ˆxn
ˆzn
ˆxn
ˆzn
ˆxn
ˆzn
note
ˆxn
quantization
noise
quantizing
ˆzn
quantization
noise
quantizing
since
source
vectors
independent
noise
vectors
also
independent
summation
converges
arguments
similar
ones
given
cid:3
b.2
proof
lemma
proof
assume
exists
probability
distribution
usl
vector
achievable
using
ssc
scheme
arrive
contradiction
since
decoders
present
setup
need
consider
ssc
codebooks
present
proof
involved
proofs
previous
section
step
step
show
description
carry
bin
indices
codewords
codebook
cid:60
descriptions
carry
indices
used
reconstruction
decoders
respectively
true
since
two
decoders
receiving
information
optimal
ptp
rate-distortion
note
mean
corresponding
codebooks
empty
conclude
bin
indices
codewords
sent
descriptions
example
lemma
18.
cid:60
proof
optimality
decoder
following
equality
consider
following
covering
bound
random
variables
−rm
m∈m
also
following
packing
bound
decoder
cid:88
cid:88
cid:88
m∈m
adding
get
m∈m
cid:80
m∈sl
comparing
equality
completes
proof
cid:84
cid:3
step
step
show
common
codebooks
decoded
decoders
since
decoder
receives
descriptions
optimal
ptp
perspective
random
variables
decoded
decoder
must
independent
decoded
decoder
next
lemma
lemma
19.
consider
setup
figure
let
1,2
+r2
rdd
1,2
1,2
rdd
shannon
optimal
ptp
function
distortion
function
point
distri-
bution
1,2
achieves
vector
following
conditions
must
hold
cid:121
addition
rdd
1,2
proof
consider
following
packing
bounds
dec
,1−r
dec
,2−r
dec
1,2
1,2
1,2
1,2
,2−r
1,2
also
mutual
covering
bound
1,2
1,2
1,2
add
inequalities
43-45
subtract
get
1,2
using
condition
rdd12
1,2
conclude
one
may
deduce
cid:121
furthermore
get
1,2
1,2
x|u
right-hand
side
second
equality
sum-rate
two-descriptions
problem
using
conditions
rddi
1,2
x|u
1,2
x|u
gives
desired
markov
chain
cid:3
assuming
original
scheme
achieves
vector
theorem
give
new
scheme
also
achieves
vector
propose
encoder
operates
decoder
decodes
needs
shown
vector
first
consider
resulting
rates
covering
bounds
changed
packing
bounds
decoders
decoder
since
variables
decoded
decoders
let
subsets
need
show
following
packing
bound
satisﬁed
ρm,1
ρm,2
m∈m
following
two
packing
bounds
decoders
cid:88
cid:88
cid:88
m∈m
˜m1
m∈m
˜m1
ρm,1
ρm,2
get
proves
packing
bounds
also
note
arguments
lemma
independent
hence
adding
lemma
1,2
lemma
shows
new
scheme
achieves
distortions
previous
one
lemma
20.
let
random
variables
arbitrary
distortion
function
optimal
reconstruction
using
function
proof
know
optimal
reconstruction
function
given
given
arg
min
ˆx∈
arg
min
ˆx∈
function
arguments
codebook
eliminated
1,2
cid:101
1,2
also
new
scheme
1,2
1,3
2,3
1,3
2,3
functionally
similar
since
arguments
step
1,2
1,3
2,3
used
reconstruction
decoder
eliminate
1,2
1,3
2,3
summary
thus
far
eliminated
codebooks
step
following
lemma
lemma
21.
optimality
rate
distortion
decoders
cid:3
2,3
1,3
2,3
1,3
proof
first
argue
2,3
true
contradicts
optimality
decoder
2,3
decoded
decoder
bin
index
carried
description
bin
index
non-
zero
one
could
reduce
setting
bin
index
equal
without
increasing
distortion
decoder
contradicts
optimality
decoder
arguments
1,3
assume
2,3
cid:44
show
contradicts
optimality
decoder
2,3
decodable
using
description
since
decodable
decoder
hence
set
2,3
i.e
send
bin
index
description
decoder
still
decode
u23,1
using
description
distortion
decoder
cid:3
rate
reduced
contradicts
optimality
arguments
13,2
step
proceed
showing
1,3
2,3
far
shown
none
descriptions
carry
bin
indices
codebooks.consider
following
packing
bounds
decoders
2,3
2,3
2,3
2,3
1,3
2,3
1,3
2,3
2,3
1,3
2,3
1,3
2,3
2,3
1,3
2,3
1,3
2,3
1,3
1,3
2,3
1,3
2,3
1,3
1,3
add
inequalities
subtract
mutual
covering
bound
get
2,3
2,3
1,3
2,3
1,3
2,3
1,3
1,3
2,3
1,3
2,3
1,3
2,3
2,3
1,3
2,3
1,3
1,3
2,3
1,3
2,3
1,3
1,3
2,3
1,3
2,3
2,3
1,3
z|u
1,3
2,3
1,3
2,3
1,3
1,3
2,3
1,3
2,3
imposes
markov
chain
1,3
1,3
2,3
1,3
2,3
hence
arguments
step
eliminate
1,3
also
arguments
2,3
eliminated
step
step
eliminate
lemma
22.
following
equality
holds
proof
assume
claim
contradicts
optimality
decoder
since
readily
decoded
bin
number
carried
description
setting
would
decease
rate
without
cid:3
increasing
distortion
rest
proof
follows
argument
consider
following
packing
bounds
decoders
mutual
covering
bound
2,3
2,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
adding
packing
bounds
subtracting
mutual
covering
bound
get
2,3
1,3
2,3
1,3
2,3
1,3
2,3
1,3
2,3
2,3
1,3
2,3
1,3
2,3
2,3
particularly
arguments
step
far
shown
1,3
2,3
1,3
2,3
non-trivial
optimality
decoders
following
equalities
2,3
2,3
1,3
1,3
2,3
hence
deﬁne
following
1,3
1,3
2,3
z|u
2,3
reconstruction
decoder
reconstruction
decoder
1,3
reconstruction
decoder
cid:44
2,3
cid:44
cid:44
1,3
2,3
1,3
1,3
2,3
δ∗δ
n1,3
1,3
z|u
2,3
n1,3
z|u
2,3
z|z
n1,3
z|z
n1,3
n1,3
n1,3
δ∗δ
z|u
2,3
z|z
n1,3
δ∗δ
2,3
δ∗δ
2,3
inequalities
must
equality
particular
δ∗δ
δ∗δ
n1,3
δ∗δ
n1,3
n1,3
n1,3
n1,3
n1,3
n1,3
note
conclude
independent
n1,3
independent
deﬁne
cid:48
cid:44
δ∗δ
1,3
cid:48
1,3
cid:48
0|n
1,3
1,3
cid:48
cid:48
1,3
cid:48
0|n
1,3
cid:48
1,3
n1,3
δ∗δ
cid:48
1,3
cid:48
1,3
holds
since
n1,3
cid:48
1,3
n1,3
δ∗δ
cid:48
1,3
independent
replaced
1,3
cid:48
deﬁne
cid:44
cid:48
1,3
cid:48
2δ−1
hence
using
cid:48
2δ−1
get
cid:48
equality
also
note
cid:48
available
decoder
cid:48
otherwise
contradiction
optimality
1,3
1,3
calculations
cid:48
1,3
note
cid:48
1,3
1,3
equal
cid:48
arguments
since
δ∗δ
1,3
2,3
n2,3
cid:44
1,3
cid:44
2,3
1,3
2,3
1,3
2,3
cid:121
cid:121
1,3
cid:121
2,3
1,3
2,3
δ∗δ
2,3
argue
1,3
2,3
1,3
2,3
taken
eliminated
without
loss
prove
assume
scheme
1,3
2,3
1,3
2,3
construct
new
random
variables
1,3
˜u3
eliminate
rest
codebooks
independence
relations
packing
bounds
would
stay
since
merged
codebooks
covering
bounds
would
loosen
straightforward
see
reconstructions
decoder
still
left
four
codebooks
note
since
decoder
decoding
must
deduced
packing
bound
decoder
equal
argument
gives
also
optimality
joint
decoders
lemma
cid:121
cid:44
note
+r3
optimality
decoders
z|u
replacing
get
markov
chain
arguments
derive
markov
chain
using
lemma
previous
two
markov
chains
get
take
markov
chain
along
cid:121
get
also
optimality
reconstruction
decoders
x|u
cid:121
conclude
applying
lemma
get
cid:121
lemma
23.
let
also
assume
given
non-constant
functions
probability
proof
lemma
generalization
one
need
show
a|b
a|b
cid:48
cid:48
cid:48
cid:48
note
since
functions
exist
straightforward
show
ﬁnite
sequence
pairs
cid:48
cid:48
property
either
ci+1
di+1
cid:44
ﬁrst
markov
chain
di+1
a|b
a|b
ci+1
di+1
also
ci+1
second
markov
chain
gives
result
a|b
constant
sequence
particularly
a|b
a|b
cid:48
cid:48
cid:3
let
reconstruction
decoder
cid:88
cid:88
cid:88
least
one
cid:80
let
reconstruction
using
argument
ﬁnd
reconstruction
using
ptp
perspective
contradiction
cid:3
b.3
proof
lemma
proof
provide
outline
proof
arguments
similar
ones
previous
proofs
step
codebook
decoded
decoders
redundant
implies
codebooks
non-redundant
codebooks
2,3
3,4
2,3
3,4
2,3
2,3
1,2
2,3
1,2
1,2
2,3
3,4
1,2
2,3
1,2
3,4
2,3
3,4
1,2
2,3
3,4
step
step
prove
non-trivial
codebook
decoded
decoder
possible
codebooks
decoded
decoder
2,3
3,4
2,3
3,4
2,3
optimality
decoder
2,3
redundant
reason
2,3
otherwise
set
zero
without
loss
distortion
decoder
contradicts
optimality
also
random
variable
description
carries
must
used
reconstructing
decoder
decoder
optimality
means
2,3
codebook
decoded
decoder
sent
either
description
similar
arguments
codebook
redundant
arguments
provided
deduce
redundancy
3,4
2,3
2,3
3,4
2,3
implies
decoded
decoder
decoder
step
proceed
eliminating
1,2
3,4
1,2
2,3
3,4
using
ptp
optimality
decoder
1,2
1,2
2,3
1,2
3,4
1,2
2,3
3,4
1,2
1,2
2,3
1,2
3,4
1,2
2,3
3,4
follows
usual
ptp
source
coding
results
comparing
lhs
rhs
conclude
markov
chain
1,2
1,2
2,3
1,2
3,4
1,2
2,3
3,4
particular
inter-
ested
1,2
3,4
1,2
2,3
3,4
arguments
using
optimality
decoder
get
1,2
3,4
1,2
2,3
3,4
two
markov
chains
along
lemma
prove
1,2
3,4
1,2
2,3
3,4
cid:121
two
variables
used
reconstructing
source
corresponding
codebooks
eliminated
step
remaining
codebooks
1,2
3,4
1,2
2,3
2,3
3,4
opti-
mality
decoders
must
1,2
1,2
2,3
3,4
2,3
3,4
also
1,2
1,2
2,3
3,4
2,3
3,4
lemma
get
1,2
1,2
2,3
3,4
2,3
3,4
lemma
24.
random
variables
three
short
markov
chains
equivalent
long
markov
chain
proof
need
show
rest
implications
long
markov
chain
either
direct
results
three
short
markov
chains
follow
symmetry
arbitrary
cid:88
c|b
d|a
cid:88
c|b
d|b
d|b
c∈c
d|b
c∈c
get
inner
bound
decoder
min
minimum
taken
v|x
long
markov
chain
satisﬁed
produce
lossless
reconstruction
resembles
distributed
source
coding
problem
cid:3
vector
achieved
using
random
codes
cid:3
b.4
proof
lemma
proof
proof
use
bold
letters
denote
vectors
matrices
fix
integers
cid:48
choose
elements
matrices
∆gl×n
cid:48
cid:48
gk×n
vectors
cid:48
randomly
uniformly
codebooks
deﬁned
follows
cid:48
m∆g
b|a
cid:48
cid:48
cid:48
cid:48
cid:48
cid:48
jointly
typical
respect
pxuv
typical
sequence
respect
deﬁne
function
counts
number
cid:88
codewords
cid:48
cid:88
cid:88
cid:88
v|x
m∆g
cid:48
cid:48
cid:48
v∈co
u∈c
cid:48
cid:48
b∈fk
∈an
v|x
goal
ﬁnd
bounds
cid:48
denote
corresponding
codeword
m∆g
similarly
following
lemma
proves
several
cid:48
cid:48
deﬁne
cid:48
cid:48
cid:48
cid:48
cid:48
results
pairwise
independence
codewords
lemma
25.
following
hold
cid:48
cid:48
distributed
uniformly
uniform
cid:44
independent
cid:44
cid:48
cid:48
independent
cid:48
cid:48
cid:48
chosen
independently
uniformly
dent
cid:48
cid:48
indepen-
proof
follows
fact
cid:48
independent
uniform
cid:3
intend
use
chebyshev
inequality
obtain
4var
ql+l
cid:48
2−n
v|x
−maxi
cid:44
v|x
v+iu
cid:48
lemma
26.
var
q2n
following
bound
var
ql+l
cid:48
2−n
v|x
cid:48
ql+l
cid:48
ql+k
proof
calculate
expected
value
ql+l
cid:48
2−n
u|x
ql+l
cid:48
q2k
2−n
v|x
qlqk
2−n
u|x
cid:48
2−n
v|x
cid:88
cid:88
cid:88
cid:88
cid:88
cid:88
cid:88
|an
v|x
cid:88
cid:88
cid:88
m∈fl
cid:48
∈fl
cid:48
cid:88
cid:88
v|x
∈an
x∈a
x∈an
cid:48
cid:44
cid:44
∈an
v|x
cid:48
cid:48
also
cid:48
cid:48
q2n
ql+l
cid:48
q2k
q2n
v|x
cid:48
cid:48
cid:48
cid:48
using
lemma
cid:44
cid:48
cid:48
q2n
cid:48
cid:48
cid:48
point
consider
several
diﬀerent
cases
values
cid:48
cid:48
cid:48
cid:48
1.1
1.2
cid:44
1.3
cid:44
1.4
cid:44
cid:44
cid:80
q2n
q3n
q3n
α∈fq
q3n
α∈fq
q4n
cid:80
cid:44
cid:48
cid:48
q3n
2.1
2.2
cid:44
2.3
cid:44
2.4
cid:44
cid:44
cases
cid:48
cid:44
cid:48
cid:44
cid:48
cid:44
cid:48
similarly
considered
derivations
q3n
q4n
q4n
2|m
cid:48
cid:48
cid:34
cid:88
omitted
brevity
considering
cases
1.1−4
cid:88
cid:88
cid:88
cid:88
cid:48
b=˜b
cid:44
a=˜a
b=˜b
cid:88
cid:88
cid:88
cid:88
cid:88
v|x
∈an
q3n
q2n
cid:88
cid:88
α∈fq\
cid:88
cid:88
cid:88
a=˜a
cid:88
cid:88
cid:44
q3n
cid:88
v−˜v=α
u−˜u
b−˜b=α
a−˜a
cid:44
α∈fq\0
cid:35
cid:44
q4n
q3n
α∈fq−
cid:44
b−˜b
cid:44
a−˜a
cid:44
α∈fq\0
v−˜v
cid:44
u−˜u
consequently
2|m
cid:48
cid:48
cid:48
ql+l
cid:48
q2k
q2n
v|x
ql+l
cid:48
q3k
q3n
v|x
+maxα
cid:44
v|x
v+αu
ql+l
cid:48
q3k
q3n
v|x
v|x
ql+l
cid:48
q4k
q4n
22n
v|x
ql+l
cid:48
q3k
q3n
v|x
u|x
used
lemma
get
fourth
term
considering
cases
cid:3
non-redundant
bounds
ones
mentioned
lemma
following
bounds
need
satisﬁed
log
v|x
cid:48
log
min
u|x
v|z
log
v|x
max
cid:48
cid:48
cid:44
v|x
log
u|x
log
v|x
cid:48
min
cid:48
observe
v|x
v+αu|x
v+αu|x
v|x
αu|x
cid:3
b.5
proof
lemma
proof
proof
follows
arguments
lemma
12.
provide
outline
proof
deﬁne
probability
error
follows
c2|∃
cid:48
cid:48
deﬁne
new
conditional
probability
error
triple
clearly
pe|x
goes
goes
also
deﬁne
pe|x
vpx
cid:88
pe|x
cid:48
cid:88
cid:88
cid:88
cid:48
cid:88
cid:88
cid:88
cid:88
v|x
|an
cid:88
cid:88
cid:88
cid:88
ql+l
cid:48
q2k
q2n
v|x
cid:48
cid:48
m∈fl
cid:48
∈fl
cid:48
cid:88
cid:88
v|x
∈an
q2n
x∈a
x∈an
cid:48
cid:44
cid:44
cid:88
cid:48
cid:48
v|x
b1∈
1,2nρ1
b2∈
1,2nρ2
cid:48
cid:48
cid:48
cid:48
note
binning
done
independently
uniformly
2−2
ρ1+ρ2
rest
summations
ones
present
proof
lemma
12.
case
case
investigation
summation
new
bond
comes
case
cid:48
cid:48
cid:44
cid:44
cid:88
cid:88
q−3n2−n
ρ1+ρ2
cid:88
cid:88
cid:44
cid:88
v|x
u−˜u=i
v−˜v
a−˜a=i
b−˜b
ql+l
cid:48
q3n
q3k2nh
v|x
2nh
v|u+iv
2−n
ρ1+ρ2
dividing
last
term
goes
following
satisﬁed
2nh
v|u+iv
2−n
ρ1+ρ2
log
v|u
however
shown
next
lemma
new
bound
redundant
lemma
27.
inequality
lemma
redundant
proof
assume
distribution
violated
show
either
also
violated
conversely
long
satisﬁed
also
satisﬁed
assume
cid:48
log
v|u
log
adding
two
bounds
get
cid:48
log
v|u
log
log
iv|x
contradicts
b.6
proof
lemma
cid:3
cid:3
proof
proof
follows
arguments
previous
two
examples
first
assume
exists
joint
distribution
pux
ssc
scheme
achieves
vector
arrive
contradiction
eliminating
codebooks
first
note
deﬁnition
direct
calculation
shows
means
decoder
ptp
optimality
also
deﬁnition
distortion
function
decoder
optimal
step
optimality
decoder
lemma
codebook
common
decoders
eliminated
step
optimality
decoder
description
carry
bin
number
codebook
decoded
decoder
also
description
carry
bin
numbers
codebooks
decoded
optimality
decoder
codebooks
1,3
2,3
1,3
2,3
sent
description
redundant
step
codebook
2,3
binned
description
description
bin
codebook
since
decoded
decoder
decoder
ptp
optimality
note
2,3
decoded
using
description
bin
information
codebook
carried
description
used
decoder
since
decoder
ptp
optimality
must
2,3
codebook
sent
description
arguments
previous
proofs
help
reconstruction
decoder
redundant
arguments
1,3
redundant
step
step
show
reﬁnement
codebook
decoded
decoder
would
eliminate
1,2
1,2
1,2
1,3
1,2
2,3
1,2
1,3
2,3
precisely
show
reconstruction
decoder
function
reconstructions
decoders
means
sending
reﬁnement
codebook
decoder
help
reconstruction
codebook
redundant
prove
claim
consider
two
user
example
depicted
figure
distortions
hamming
distortions
interested
achieving
rate
distortion
vector
1,2
given
let
1,2
distribution
random
variables
two
user
ssc
achiev-
ing
vector
deﬁne
ˆx1
ˆx2
ˆx12
reconstructions
corresponding
codebooks
lemma
28.
two
choices
joint
distribution
ˆx1
ˆx2
ˆx12
furthermore
choices
ˆx12
function
ˆx1
ˆx2
proof
step
optimality
decoder
1,2
redundant
also
independent
lemma
19.
note
ˆx1
function
ˆx2
function
ˆx1
cid:121
ˆx2
proceed
characterizing
ˆx12
note
decoder
ptp
optimality
well-known
result
quantizing
bss
hamming
distortion
rate
reconstruction
uniquely
given
ˆx12
cid:121
ˆx1
ˆx2
ˆx12
available
decoder
optimality
decoder
must
ˆx1
ˆx2
ˆx1,2
ˆx12
inequality
must
equality
means
ˆx1
ˆx2
x|x12
words
markov
chain
ˆx1
ˆx2
ˆx12
must
hold
using
three
facts
ˆx12
x⊕2n0
ˆx1
cid:121
ˆx2
ˆx1
ˆx2
ˆx12
characterize
possible
distributions
ˆx12
ˆx1
ˆx2
let
ˆx1
ˆx2
ˆx1
cid:121
ˆx2
ˆx1
ˆx2
ﬁxed
assume
distribution
ˆx12
ˆx1
ˆx2
given
shown
table
ˆx1
ˆx2
ˆx12
sum
p000
p100
p001
p101
p010
p110
p011
p111
a1a2
sum
independent
linear
constraints
table
p000
p001
p010
p100
p000
p011
p110
p010
p000
p001
p010
p000
p001
p010
p111
a1a2
p000
p001
p010
a1a2
p101
p001
using
markov
chain
ˆx1
ˆx2
ˆx12
ˆx1
ˆx2
ˆx12
px|
ˆx12p
ˆx1
ˆx2
ˆx12
ˆx1
ˆx2
follows
minimize
resulting
distortion
decoders
choosing
p000
p001
p010
optimally
let
ˆx1
ˆx2
optimal
joint
distribution
show
two
choices
ˆx1
ˆx2
cid:80
ˆx1
ˆx2
ˆx1
cid:44
ˆx2
cid:44
ˆx1
ˆx2
ˆx1
ˆx2
ˆx1
ˆx2
ˆx1
ˆx2
ˆx1
ˆx2
ˆx1
ˆx2
p001
p001
p010
p010
2d0
p000
a1a2
2d0
2d0
2d0
p000
2d0
p001
2d0
p010
4d0
p000
p001
p010
p000
p000
p001
p010
ˆx1
ˆx2
p000
p000
d0p000
p000
p001
p001
d0p001
p001
p010
p010
d0p010
p010
p000
p001
p010
a1a2
p000
p001
p010
p000
p001
p010
a1a2
p000
p001
p010
table
optimization
problem
p000
p001
p010
respect
constraints
p000
p001
p010
p000
p001
p010
a1a2
also
note
ﬁxed
problem
becomes
linear
optimization
problem
otherwise
con-
straints
linear
optimize
p000
p001
p010
value
case
simplex
algorithm
provides
straightforward
solution
investigate
solution
several
diﬀerent
cases
case
negative
coeﬃcient
takes
maximum
possible
value
ﬁrst.since
would
ﬁrst
maximize
value
p000
since
constraint
p000
p001
p010
note
simplex
algorithm
variable
smallest
2d0
algorithm
along
case
000
a1a2
sets
001
010
ˆx1
ˆx2
2d0
2d0
2d0
4d0
2d0
optimize
optimal
value
achieved
increasing
decreases
distortion
ˆx1
ˆx2
2d0
1−a1
optimizing
value
get
also
replacing
values
ˆx12
ˆx1
ˆx2
get
shows
ˆx12
function
ˆx1
ˆx2
case
1−a1
1−a2
values
give
ˆx1
ˆx2
ˆx1
ˆx2
ˆx12
2−1
3−2
2−1
table
case
simplex
method
yields
following
set
optimal
distributions
001
000
since
coeﬃcients
auxiliary
variable
play
role
distortion
010
equal
distortion
formula
get
001
a1a2
010
011
100
101
010
111
ˆx1
ˆx2
2d0
a1a2
note
since
optimal
values
term
a1a2
decreasing
distortion
increasing
1−a1
since
1−a1
replacing
max
ˆx1
ˆx2
solving
get
case
distortion
similar
last
case
since
tun
probabilities
last
case
distortion
decreasing
previous
case
a1a2
2a1
yields
ˆx1
ˆx2
2a1
would
solution
optimizing
given
range
case
a1a2
arguments
optimal
solution
000
001
010
100
101
111
010
011
ˆx12
ˆx1
ˆx2
second
choice
optimal
joint
distribution
note
ˆx12
ˆx1
ˆx2
ˆx12
3−2
2−1
2−1
table
function
ˆx1
ˆx2
cid:3
step
left
let
reconstruction
decoder
lemma
29.
following
markov
chains
hold
cid:121
proof
holds
lemma
19.
optimality
decoder
step
proves
next
prove
x|x1
cid:88
cid:88
x|x1
x|x1
x2|u
x|x1
used
markov
chain
used
follows
symmetry
proved
using
optimality
decoder
argument
given
proof
proceed
proof
consider
following
packing
bounds
decoder
r1,3
r2,3
r1,3
r2,3
following
covering
bounds
r1,3
r2,3
r1,3
r2,3
adding
bounds
simplifying
get
resembles
two
user
sum-rate
bound
ﬁrst
user
sending
descriptions
sec-
ond
user
transmits
description
optimality
decoder
optimality
decoder
yields
proves
u1|u
x|u
u1|u
x|u
u1|u
x|u
follows
lemma
given
follows
shown
using
lemma
conclude
follows
symmetry
lastly
prove
x|u
x1|u
x|u
x1|u
x1|u
x1|u
follows
form
holds
follows
lemma
30.
lemma
30.
random
variables
proof
d|b
b|c
d|c
b|c
a|bc
d|c
a|bc
d|bc
cid:3
cid:3
next
argue
set
equal
would
change
distortion
rate
increase
first
consider
decoder
optimal
reconstruction
function
given
argmaxx
px|u
x|u1,3
u23
argmaxx
px|u
x|u1,3
u23
argmaxx
px|u
x|u1,3
u23
argmaxx
px|u
x|u1,3
u23
used
fact
function
use
distortion
change
decoder
also
reconstruction
decoder
setting
change
reconstruction
decoder
decoder
showed
step
x12
function
function
setting
change
distortion
decoder
either
rest
decoders
receive
rate
note
reconstructed
decoders
reconstructing
replacing
require
sending
extra
information
set
without
loss
distortion
potential
gain
rate
argument
combined
markov
chains
sets
also
using
markov
chains
set
lemma
31.
following
constraints
hold
pxx1x2
ﬁxed
equal
previous
step
pxx3
ﬁxed
equal
optimizing
distribution
decoder
proof
proved
step
follows
ptp
optimality
decoder
follows
cid:3
follows
follows
follows
proceed
bounding
cardinality
using
lemma
joint
distribution
random
variables
given
follows
x|x1
x3|u
x|x1
x|x1
x3x
x|x1
|x3
x3x
cid:80
also
note
following
equality
cid:88
cid:88
|x3
|x1
|x2
xx1
denote
pxx1x2
θ|x1
u1,3
γ|x2
u2,3
|x3
γ|0
px3
+pu
|x3
γ|1
px3
p000
p001
p010
p011
|x3
γ|0
px3
+pu
|x3
γ|1
px3
p100
p101
p110
p111
using
values
given
table
solve
system
equations
|x3
γ|0
|x3
γ|1
hence
distribution
completely
determined
lemma
32.
assume
exists
1,3
x1x3
1−hb
proof
proof
follows
shannon
rate
distortion
function
ptp
source
coding
cid:3
based
previous
lemma
enough
show
every
x1x3
1−hb
case
contradiction
need
maximize
x1x3
function
use
following
lemma
lemma
let
ﬁnite
set
arbitrary
set
let
set
pmfs
x|u
collection
pmfs
every
let
real-valued
continuous
functions
every
deﬁned
exists
random
variable
cid:48
cid:48
cardinality
cid:48
collection
conditional
pmfs
cid:48
every
cid:48
cid:48
every
cid:90
px|u
x|u
px|u
cid:48
x|u
cid:48
cid:48
cid:88
cid:48
figure
plot
maximum
value
want
use
lemma
bound
cardinality
u1,3
take
x|u
px1|u
1|u13
x|u
x|u
u1,3
note
ﬁxing
expectation
ﬁxes
joint
distribution
ﬁxing
expectation
ﬁxes
term
want
minimize
minimizing
x1x3
exists
cid:48
1,3
cardinality
joint
distribution
x1x3
enough
search
cardinality
arguments
hold
bounding
cardinality
u2,3
size
random
vari-
ables
computer-assisted
calculation
shows
1.42
1.58
shown
figure
10.
contradiction
ssc
cid:3
achieve
vector
1.3711.3751.380.81.38511.39i1+i20.60.81.395p
u13=0|x1=1
1.40.6p
u13=0|x1=0
0.41.4050.40.20.200
proofs
section
c.1
proof
lemma
proof
index
inequalities
ssc
every
inequality
linear
coding
region
lcr
exists
unique
inequality
ssc
left
hand
side
index
inequality
index
used
rcr
let
bound
resulting
applying
fme
ssc
assume
bound
results
adding
inequalities
indexed
straightforward
show
adding
inequalities
indices
lcr
gives
bound
reason
construction
left-hand
sides
would
right-hand
side
due
fme
terms
involving
would
eliminated
deﬁne
cid:48
cid:3
log
eliminating
equivalent
eliminating
cid:48
cid:48
cid:48
acknowledgment
authors
would
like
thank
prof.
kenneth
rose
santa
barbara
mohsen
heidari
khoozani
univ
michigan
helpful
discussions
references
goyal
multiple
description
coding
compression
meets
network
signal
pro-
cessing
magazine
ieee
vol.18
no.5
pp.74-93
sep
2001
wang
reibman
lin
multiple
description
coding
video
delivery
proceedings
ieee
vol.93
no.1
pp.57-70
jan.
2005
ozarow
source-coding
problem
two
channels
three
receivers
bell
systems
tech
journal
:1909-1921
dec
1980
ahlswede
rate-distortion
region
multiple
descriptions
without
excess
rate
ieee
trans
inf
theory
:721
726
nov
1985
gamal
cover
achievable
rates
multiple
descriptions
ieee
trans
inf
theory
vol
it-28
851-857
1982
zhang
berger
new
results
binary
multiple-descriptions
ieee
trans
inf
theory
vol.33
no.4
pp.502,521
jul
1987
venkataramani
kramer
goyal
multiple
description
coding
many
channels
ieee
trans
inf
theory
vol
2106-2114
2003
tian
chen
new
coding
schemes
symmetric
-description
problem
ieee
trans
inf
theory
vol.56
no.10
pp.5344,5365
oct.
2010
pradhan
puri
ramchandran
n-channel
symmetric
multiple
descriptions-part
source-channel
erasure
codes
ieee
trans
inf
theory
vol
47-61
2004
akyol
viswanatha
rose
combinatorial
message
sharing
random
bin-
ning
multiple
description
coding
ieee
international
symp
inf
theory
ieee
pp.1371,1375
1-6
july
2012
viswanatha
akyol
rose
combinatorial
message
sharing
reﬁned
multiple-
descriptions
achievable
region
ieee
international
symp
inf
theory
ieee
1312-
1316.
2011
viswanatha
akyol
rose
combinatorial
message
sharing
new
achiev-
able
region
multiple
descriptions
ieee
trans
information
theory
769-792
feb.
2016
anderson
combinatorics
ﬁnite
sets
clarendon
press
oxford
university
press
new
york
1987
csiszár
korner
information
theory
coding
theorems
discrete
memoryless
systems
academic
press
inc.
ltd.
1981
körner
marton
encode
modulo-two
sum
binary
sources
ieee
trans
inf
theory
vol
219-221
1979
padakandla
s.s.
pradhan
achievable
rate
region
three
user
discrete
broad-
cast
channel
based
coset
codes
ieee
international
symp
inf
theory
ieee
pp.1277,1281
7-12
july
2013
padakandla
a.g.
sahebi
s.s.
pradhan
new
achievable
rate
region
3-user
discrete
memoryless
interference
channel
ieee
international
symp
inf
theory
july
2012
also
appear
ieee
trans
information
theory
2016
nazer
gastpar
computation
gaussian
multiple-access
channels
ieee
international
symp
inf
theory
ieee
pp.2391,2395
24-29
june
2007
philosof
zamir
loss
single-letter
characterization
dirty
multiple
access
channel
ieee
trans
inf
theory
vol.55
no.6
pp.2442,2454
june
2009
krithivasan
s.s.
pradhan
distributed
source
coding
using
abelian
group
codes
new
achievable
rate-distortion
region
ieee
trans
inf
theory
vol.57
no.3
pp.1495,1519
march
2011
gamal
kim
network
information
theory
cambridge
university
press
2011
a.b
wagner
b.g
kelly
altu˘g
distributed
rate-distortion
common
compo-
nents
ieee
trans
inf
theory
vol.57
no.7
pp.4035-4057
july
2011
shirani
s.s.
pradhan
achievable
rate-distortion
region
multiple
descriptions
problem
2014
ieee
international
symp
inf
theory
isit
pp.576-580
june
2014-
july
2014
kleitman
markowsky
dedekind
problem
number
isotone
boolean
func-
tions
transactions
american
mathematical
society
213
373-390
1975
wang
chen
zhao
cuﬀ
permuter
role
reﬁnement
layer
multiple
description
coding
scalable
coding
ieee
trans
inf
theory
vol.57
no.3
pp.1443-1456
march
2011
pradhan
chou
ramchandran
duality
source
coding
channel
coding
extension
side
information
case
ieee
trans
inf
theory
vol.49
no.5
pp.1181-1203
may
2003
gallager
information
theory
reliable
communication.
new
york
wiley
1968
chaharsooghi
sahebi
pradhan
distributed
source
coding
absence
common
components
ieee
international
symp
inf
theory
ieee
pp.1362-1366
july
2013
vinodh
lalitha
prakash
kumar
pradhan
achievable
rates
sources
group
alphabet
distributed
source
coding
setting
communication
control
computing
allerton
2010
48th
annual
allerton
conference
pp.479-486
sept.
2010-oct.
2010
gacs
körner
common
information
far
less
mutual
information
problems
control
information
theory
vol
119-162
1972
witsenhausen
sequences
pairs
dependent
random
variables
siam
journal
applied
mathematics
vol
100-113
january
1975
