cooperative
hierarchical
caching
cloud
radio
access
networks
c-rans
tuyen
tran
student
member
ieee
abolfazl
hajisami
student
member
ieee
dario
pompili
senior
member
ieee
abstract—over
last
years
cloud
radio
access
net-
work
c-ran
proposed
transformative
architecture
cellular
networks
brings
ﬂexibility
agility
cloud
computing
wireless
communications
time
content
caching
wireless
networks
become
essential
solution
lower
content-access
latency
backhaul
trafﬁc
loading
leading
user
quality
experience
qoe
improvement
network
cost
reduction
article
novel
cooperative
hierarchical
caching
chc
framework
c-ran
introduced
contents
jointly
cached
baseband
unit
bbu
radio
remote
heads
rrhs
unlike
traditional
approaches
cache
bbu
cloud
cache
presents
new
layer
cache
hierarchy
bridging
latency/capacity
gap
traditional
edge-based
core-based
caching
schemes
trace-driven
simulations
reveal
chc
yields
improvement
cache
hit
ratio
decrease
average
content-access
latency
reduction
backhaul
trafﬁc
load
compared
edge-only
caching
scheme
total
cache
capacity
closing
article
discuss
key
challenges
promising
opportunities
deploying
content
caching
c-ran
order
make
enabler
technology
ultra-dense
systems
index
terms—cloud
radio
access
networks
hierarchical
caching
cooperative
caching
content-centric
networks
introduction
last
years
proliferation
personal
mobile
devices
smartphones
tablets
along
plethora
over-the-top
ott
multimedia
content
providers
e.g.
youtube
netﬂix
amazon
resulted
exponential
growth
capacity
demand
mobile
wireless
systems
moreover
future
video
encoding
playback
advances
e.g.
resolution
high
quality
encoding
multi-angle
increase
capacity
requirements
demand
wireless
networks
shifted
traditional
connection-centric
communications
phone
calls
text
messages
multimedia
content-centric
communications
video
streaming
content
sharing
several
solutions
proposed
improve
network
capacity
deployment
ultra-dense
small
cells
massive
mimo
approaches
fundamentally
constrained
limited
spectrum
resources
control
signaling
overhead
therefore
order
support
foreseen
massive
trafﬁc
networks
affordable
way
improving
network
capacity
alone
sufﬁcient
accompanied
innovations
higher
layers
e.g.
network
architecture
backhaul
transportation
applications
recently
cloud
radio
access
network
c-ran
introduced
clean-slate
redesign
cellular
network
ar-
internet
rrh
backhaul
cpri
epc
bbu
rrh
rrh
fig
c-ran
architecture
distributed
rrhs
connected
common
bbu
via
cpri
links
chitecture
addresses
capacity
coverage
issues
reducing
operational
costs
improving
network
ﬂex-
ibility
using
virtualization
technologies
software-
deﬁned
networking
sdn
network
function
virtualiza-
tion
nfv
c-ran
shows
also
great
potential
support-
ing
autonomic
network
management
self-optimization
self-
adaptation
self
conﬁguration
c-ran
computa-
tional
functionalities
decoupled
distributed
base
stations
bss
consolidated
centralized
processing
center
typical
c-ran
shown
fig
constituted
light-weight
distributed
radio
remote
heads
rrhs
deployed
cell
sites
central
baseband
unit
bbu
pool
hosted
cloud
datacenter
iii
high-bandwidth
low-latency
fronthaul
links
connecting
rrhs
bbu
pool
centralized
nature
c-ran
along
virtual-
ization
technology
enables
dynamic
resource
allocation
mo-
bility
management
cooperative
communications
cloud
infrastructure
bbu
pool
strong
comput-
ing
resources
storage
capacity
provides
central
port
trafﬁc
ofﬂoading
content
management
handle
growing
internet
trafﬁc
mobile
users
directly
translates
capital
expenditure
capex
operational
expenditure
opex
reduction
well
user
quality
experience
qoe
improvement
time
today
mobile
networks
caching
computing
resources
already
ubiquitous
bss
user
devices
fundamental
question
effectively
utilize
existing
resources
order
address
need
massive
content
distribution
one
promising
approach
enable
content
caching
within
wireless
ieee
network
feature
topic
ultra-dense
heterogeneous
small
cell
deployment
beyond
july
2017
operators
networks
popular
contents
cached
bss
edge
ran
upon
receiving
content
request
user
provide
content
cached
rather
downloading
original
server
beneﬁts
content
caching
cellular
network
explored
recently
particular
works
propose
alleviate
backhaul
usage
via
proactive
caching
small
cell
bss
whereby
ﬁles
proactively
cached
off-peak
hours
based
ﬁle
popularity
correlations
among
user
ﬁle
patterns
author
also
consider
collabo-
rative
caching
introduce
online
algorithm
require
prior
knowledge
content
popularities
minimize
total
cost
paid
content
providers
recently
work
proposes
cooperative
ran
caching
framework
coordinated
multi-point
joint
transmission
single
cell
transmission
based
local
altruistic
game
model
aimed
minimizing
content
transmission
time
mobile
users
huang
study
content
caching
user
scheduling
scheme
heterogeneous
networks
propose
algorithm
maximize
number
successfully
scheduled
users
limited
radio
resources
context
c-ran
works
investigate
content
caching
beamforming
design
minimize
transmission
power
backhaul
cost
however
consider
caching
level
collaboration
among
caches
implementing
caching
edge
network
offers
signiﬁcant
backhaul
trafﬁc
reduction
however
afore-
mentioned
edge-only
caching
schemes
face
two
important
drawbacks
high
cache
miss
ratio
due
limited
cache
size
bss
compared
large
number
content
ﬁles
lack
consideration
user
mobility
one
cell
compensate
relative
small
cache
size
bss
authors
consider
caches
ran
edge
evolved
packet
core
epc
possible
implement
relatively
large
cache
size
epc
improve
cache
hit
ratio
fetching
content
epc
bss
still
undertakes
considerable
delay
due
involvement
multiple
intermediate
network
components
article
leverage
c-ran
architecture
propose
cooperative
hierarchical
caching
chc
scheme
particular
scheme
allocates
relatively
larger
caches
bbu
pool
cloud
cache
supplementary
smaller
caches
distributed
rrhs
edge
cache
keeping
total
cache
size
network
ﬁxed
deployment
cloud
cache
edge
caches
complementary
managed
centrally
controller
bbu
pool
hierarchical
caching
paradigm
studied
context
content
delivery
networks
cdns
settings
constraints
much
different
caching
system
cellular
wireless
networks
firstly
limited
spectrum
resources
coupled
dynamic
wireless
channels
user
mobility
highly
affect
strategy
cache
placement
content
delivery
wireless
networks
secondly
storage
capacity
ran
caches
much
smaller
caches
cdn
making
cache
placement
critically
important
simulation
results
shown
proposed
chc
caching
algorithm
signiﬁcantly
outperforms
counterpart
algorithm
proposed
cdn
remainder
article
organized
follows
sect
envision
new
c-ran
architecture
support
ultra-dense
networks
sect
iii
introduce
pro-
posed
novel
caching
strategy
c-ran
present
illustrative
results
sect
discuss
key
challenges
open-
research
directions
call
investigation
finally
draw
conclusions
sect
new
c-ran
architecture
support
ultra-dense
networks
envision
essential
evolutions
c-ran
sup-
port
key
features
ultra-dense
cellular
networks
i.g.
ultra-high
radio
speed
ultra-low
latency
massive
connectivity
content
distribution
new
fronthaul
interface
c-ran
rrhs
connected
bbu
pool
via
fronthaul
links
using
common
public
radio
interface
cpri
widely
adopted
industry
open
base
station
architecture
initiative
obsai
realize
high-speed
cpri
links
common
solution
use
direct
ﬁber
connections
limited
expensive
example
td-lte
system
mhz
bandwidth
antennas
rrh
cpri
data
rate
bbu
pool
rrh
td-lte
carrier
transmission
high
2.45
gbps1
considering
network
two
bands
three
rrhs
3-sector
cell
site
required
fronthaul
capacity
14.7
gbps
suppose
rrh
uses
one
ﬁber
link
cell
site
would
require
six
ﬁber
links
number
could
even
higher
widely
used
fdd-lte
system
downlink
uplink
use
mhz
bandwidth
high
requirements
fronthaul
ﬁber
links
makes
costly
difﬁcult
achieve
operators
due
limited
ﬁber
resources
addition
usually
takes
long
time
install
ﬁber
locations
possible
install
ﬁber
massive
mimo
deployed
fronthaul
capacity
bbu
rrh
needs
dramatically
in-
creased
moreover
new
radio
access
technologies
rats
introduced
bandwidth
extend
beyond
100
400
mhz
eventually
requiring
tens
hundreds
gbps
cpri
capacity
per
rrh
current
ran
fronthaul
architecture
maximum
transmission
capacity
per
fronthaul
link
gbps
longer
able
handle
humongous
capacity
requirement
network
overcome
issue
various
solutions
proposed
including
new
compression
techniques
new
trans-
port
modes
fronthaul
transmission
wavelength-
division
multiplexing
wdm
microwave
transmission
flexible
functional
splitting
alternative
fron-
thaul
solutions
help
reducing
ﬁber
consumption
multi-fold
reduction
requires
architectural
solution
transforma-
tive
solution
redeﬁne
functionalities
bbu
pool
rrh
differently
current
deﬁnition
phy
mac
implemented
bbu
pool
change
interface
bbu
rrh
circuit
fronthaul
cpri
packet
fronthaul
ethernet
make
1refer
common
public
radio
interface
cpri
speciﬁcation
v6.0
ericsson
2013
ieee
network
feature
topic
ultra-dense
heterogeneous
small
cell
deployment
beyond
july
2017
cran
cran
new
functional
splitting
options
bbu
pdcp
rlc
mac
phy
pdcp
pdcp
pdcp
rlc
rlc
mac
rlc
pdu
pdcp
pdu
rrh
data
mac
pdu
rlc
mac
mac
phy
phy
phy
fronthaul
capacity
requirement
delay
requirement
fig
functional
split
bbu
rrh
c-rans
shifting
functionalities
rrh
decreases
capacity
requirement
increases
delay
requirement
fronthaul
links
changes
many
functional
split
options
proposed
offering
different
trade-offs
reduced
fronthaul
capacity
delay
requirement
figure
illustrates
func-
tional
split
bbu
pool
rrh
compares
c-ran
new
options
c-ran
distributed
core
era
radio
capacity
become
large
gbps
per
sector
ultra-large
content
trafﬁc–e.g.
uhd
video
streaming
augmented
reality
virtual
reality
–will
travel
across
faster
radio
net-
work
mobile
communication
trafﬁc
travel
via
packet
core
network
i.e.
packet
gateway
pgw
cur-
rent
architecture
countries
sites
pgws
across
nations
current
architecture
kept
massive
backhaul
bbu
pools
located
across
country
packet
core
centralized
sites
becomes
inevitable
substantial
backhaul
investment
made
well
instance
assuming
10,000
cell
sites
nationwide
sectors
half
cell
sites
peak-trafﬁc
time
backhaul
capacity
required
least
300
tbps
gbps/sector
sector
5,000
sites
obviously
core
centralized
sites
ultra
high
processing
capacity
well
foregoing
circumstances
highly
desirable
solutions
involve
distribution
core
nodes
close
cell
sites
case
content
servers
caching
servers
placed
rack
right
next
distributed
core
signiﬁcantly
helps
reducing
backhaul
trafﬁc
mobile
devices
download
content
directly
in-network
content
servers
without
pass
backhaul
core
scenario
core
data
plane
bbu
applications
run
virtualized
servers
local
c-ran
sites
iii
cooperative
hierarchical
caching
c-ran
section
investigate
problem
cache
place-
ment
c-ran
aiming
minimizing
average
content
access
delay
users
time
reducing
backhaul
trafﬁc
load
consider
c-ran
consists
rrhs
distributed
corresponding
cells
set
active
users
collection
ﬁles
available
downloads
...
assumed
popularities
ranking
ﬁles
...
known
priori
predicting
content
popularity
challenging
task
terms
accuracy
scalability
recent
advances
machine
learning
data
mining
techniques
made
signiﬁcant
progress
achieving
goal
techniques
could
involve
analyzing
data
popular
web
sites
news-
papers
social
networks
order
determine—around
speciﬁc
rrh—what
kind
content
people
like
search
consumer
proﬁle
people
envision
rrh
integrates
front
radio
frequency
also
certain
capabilities
enable
caching
content
storage
look
similar
idea
evolved
rrh
proposed
fog-based
ran
consider
rrh
equipped
cache
capacity
assume
bbu
cloud
larger
cache
capacity
given
storage
capacity
cache
limited
imperative
design
effective
caching
strategy
decides
store
cache
optimize
qoe
users
current
cellular
network
enodebs
inter-
connected
via
interface
designed
ex-
changing
control
information
user
data
buffer
handover
interface
available
limited
data
transfer
exploited
inter-cache
data
transfer
hence
enodebs
share
cache
contents
directly
contrast
rrhs
c-ran
connected
common
bbu
via
high-bandwidth
low-latency
cpri
links
user
data
transportation
allows
rrh
retrieve
cache
contents
neighboring
rrhs
via
u-turn
rrh-bbu-rrh
using
fronthaul
links
note
retrieving
cache
data
neighboring
rrhs
latency-
cost-effective
fetching
content
original
remote
server
via
backhaul
network
article
proposed
chc
strategy
fully
exploit
extra
degrees
cooperation
brought
c-ran
pool
resources
increase
cache
hit
ratio
reducing
outbound
requests
higher-level
network
elements
proposed
caching
strategy
proposed
system
consider
central
cache
manager
ccm
imple-
mented
bbu
cloud
monitor
requests
generated
users
within
local
c-ran
responsible
make
cache
placement
decision
addition
leveraging
powerful
processing
capability
bbu
cloud
implement
sophisticated
learning
prediction
algorithms
estimate
content
popularity
information
actual
content
ﬁles
physically
stored
separated
caches
global
indexing
table
maintained
ccm
facilitate
content
lookup
cache
management
request
ﬁle
user
cell
ﬁrstly
ccm
ccm
determines
ﬁle
already
cached
rrh
inform
rrh
send
ﬁle
directly
user
without
incurring
fronthaul
trafﬁc
overhead
otherwise
ccm
search
cloud
cache
neighboring
ieee
network
feature
topic
ultra-dense
heterogeneous
small
cell
deployment
beyond
july
2017
delay
cost
user
cell
expressed
¯du
i=1
x0
irdr
k=1
k6=r
irdrk
xr+1
request
ﬁle
user
retrieved
cache
otherwise
...
xr+1
indicates
whether
request
retrieved
cdn
optimal
cache
placement
algorithm
obtained
solving
optimization
problem
minimizes
total
¯du
subject
average
delay
users
network
pu=1
set
cache
capacity
constraints
general
cache
placement
problem
np-complete
impractical
implement
due
high-complexity
solution
equivalently
recast
cache-placement
problem
problem
maximizing
system
utility
function—the
expected
delay
cost
saving—and
show
problem
belongs
class
maximizing
monotone
submodular
set
function
ma-
troid
constraint
proposed
greedy
chc
strategy
comprises
two
phases
namely
proactive
cache
distribution
pcd
phase
reactive
cache
replacement
rcr
phase
firstly
pcd
phase
involves
building
cache
placement
solution
starting
empty
caches
incrementally
adding
ﬁles
caches
iteration
adds
new
ﬁle
highest
marginal
value
cache
placement
set
caches
full
since
objective
function
submodular
marginal
value
new
ﬁle
decreases
cache
placement
set
grows
bigger
furthermore
due
monotonicity
objective
function
pcd
algorithm
guaranteed
achieve
objective
function
least
optimal
value
phase
done
off-peak
trafﬁc
hours
e.g.
night
time
utilize
unused
backhaul
bandwidth
secondly
rcr
phase
occurs
course
day
make
cache-
replacement
decision
particular
following
cache
miss
new
ﬁle
downloaded
remote
content
server
local
ran
delivered
requesting
user
rcr
algorithm
decide
replace
new
ﬁle
existing
ﬁles
cache
replacement
could
improve
value
objective
function
performance
evaluation
carry
trace-driven
sim-
ulations
evaluate
performance
aforementioned
chc
strategy
terms
cache
hit
ratio
average
latency
backhaul
trafﬁc
load
use
youtube
request
trace
data
collected
campus
university
massachusetts
amherst
day
03/12/20082
video
popularities
extracted
trace
used
input
greedy
chc
algorithm
based
video
request
data
simulated
c-ran
system
cell
one
rrh
mobile
users
uniformly
distributed
cells
e2e
latency
video
delivery
cdn
rrh
bbu
cloud
rrh
assigned
100
respectively
assume
backhaul
fronthaul
link
capacity
well
radio
resources
access
network
sufﬁciently
provisioned
handle
generated
trafﬁc
requests
allocate
cache
capacity
2refer
http
//traces.cs.umass.edu/index.php/network/network
fig
abstraction
cooperative
hierarchical
caching
system
c-ran
edge
caches
ccm
locate
requested
ﬁle
cache
direct
request
original
content
server
remote
cdn
incurring
trafﬁc
backhaul
links
fig
illustrate
abstraction
chc
system
c-ran
example
request
user
cell
user
moved
cell
cell
retrieved
rrh
cache
request
user
cell
retrieved
cloud
cache
following
introduce
cost
model
characterize
cache
management
strategy
costs
associated
access
delay
bandwidth
consumption
often
pro-
portional
interchangeable
focus
cost
model
content
access
delay
considered
directly
translated
user
qoe
let
denote
delay
cost
transferring
ﬁle
bbu
pool
rrh
assume
cost
retrieving
ﬁle
rrh
uplink
bbu
let
denote
delay
cost
incurred
user
cell
downloads
ﬁle
original
server
cdn
furthermore
assume
cost
transferring
ﬁle
cache
rrh
rrh
drk
practice
usually
many-fold
higher
drk
noted
cost
transferring
ﬁles
rrhs
users
always
incur
matter
whether
caching
used
depend
cache
placement
therefore
without
loss
generality
consider
associated
cost
user
downloading
ﬁle
directly
local
cache
serving
rrh
zero
considering
cache
placement
design
hence
average
ieee
network
feature
topic
ultra-dense
heterogeneous
small
cell
deployment
beyond
july
2017
bbu
cloud
four
times
larger
cache
capacity
rrh
i.e.
4mr
keeping
total
cache
capacity
network
considered
scenarios
backhaul
trafﬁc
volume
calculated
amount
trafﬁc
downloading
cdn
due
cache
misses
trace-driven
simulation
parameters
summarized
table
trace-driven
simulation
parameters
table
description
number
cells
number
users
user
distribution
number
videos
video
size
number
request
bbu-rrh
latency
cdn-rrh
latency
value
777
uniform
414
122
280
100
impact
caching
architecture
compare
perfor-
mance
four
caching
architectures
edge
popular
ﬁles
cached
rrhs
requested
ﬁle
mobile
user
found
home
rrh
cache
ﬁle
download
immediately
cache
otherwise
fetched
cdn
edge+cloud
non-coop
hierarchical
caching
strategy
contents
cached
bbu
rrhs
however
cooperation
among
rrhs
caches
ﬁle
request
resulting
cache
miss
rrh
searched
bbu
cloud
cache
ﬁnally
goes
cdn
edge+cloud
coop
chc
proposed
cooperative
hierarchical
caching
strategy
cloud
contents
cached
bbu
cloud
figs
a-c
see
total
cache
capacity
allocating
caches
bbu
cloud
rrhs
provides
signiﬁcant
performance
improvement
compared
al-
locating
caches
rrh
example
performance
gains
chc
scheme
edge
scheme
total
cache
size
0.4
approximately
improvement
cache
hit
ratio
decrease
average
e2e
latency
reduction
backhaul
trafﬁc
load
addition
performance
improved
cooperating
rrh
caches
characterized
gains
chc
scheme
non-coop
scheme
cache
hit
performance
backhaul
usage
chc
scheme
cloud
scheme
almost
however
chc
achieves
signiﬁcantly
lower
average
access
delay
impact
cache
replacement
policy
evaluate
impact
different
caching
policies
c-ran
compare
proposed
chc
strategy
three
baselines
mpc-ex
popular
caching
scheme
cache
indepen-
dently
stores
popular
ﬁles
ﬁles
stored
edge
caches
excluded
cloud
cache
femtox
extension
femtocaching
scheme
c-ran
iii
lru
least
recently
used
cache
replacement
algorithm
figs
a-c
see
chc
scheme
signiﬁcantly
outperforms
baselines
terms
cache
hit
ratio
improvement
well
average
latency
backhaul
trafﬁc
loading
reduction
open
research
directions
section
discuss
key
challenges
open-
research
issues
need
addressed
order
fully
exploit
beneﬁts
content
caching
c-ran
on-device
caching
mobile
devices
hosting
multi
gigabytes
main
storage
idea
buffering
multiple
videos
devices
becoming
relevant
ﬁrst
interesting
problem
predictive
part
i.e.
work
system
know
user
might
want
watch
prediction
involves
interrogating
user
preference
content-recommendation
engines
personalized
video
content
pre-position
mobile
devices
mechanism
may
work
personalized
catch-up
service
falling
video
demand
broadcast
channel
hand
on-device
caches
underlying
device-to-device
d2d
communications
become
popular
imperative
exploit
possible
opportunistic
coordination
among
caches
particular
ccm
bbu
pool
explore
social
relationships
ties
among
users
identify
inﬂuential
users
using
social
graph
given
user
requests
ﬁle
ccm
determines
whether
one
inﬂuential
users
requested
ﬁle
direct
inﬂuential
user
transfer
ﬁle
requesting
user
via
d2d
approach
beneﬁts
network
requesting
users
quite
challenging
e.g.
design
effective
incentive
model
attract
users
caches
form
coalition
open
research
problem
collaboration
ott
network
operator
improve
revenue
per
subscriber
ott
content
providers
want
expand
subscriber
base
provide
high-quality
video
service
turn
increases
video
trafﬁc
prompting
content
provider
pay
cdn
services
positioning
caching
servers
c-ran
network
operators
deliver
high-
quality
video
contents
users
utilizing
idle
bandwidth
fronthaul
links
without
increasing
load
backbone
network
securing
new
revenue
model
caching
fee
without
additional
investment
networks
time
ott
providers
provide
high
quality
service
lower
cost
using
3rd
party
cdn
caching
server
operator
networks
helps
expand
subscriber
base
enhance
customer
qoe
new
business
model
play
key
role
achieve
win-win
game
ott
providers
network
operator
share
caching
resources
cross-layer
design
leverage
extra
degrees
co-
operation
c-ran
many
advanced
cooperation
techniques
involving
user
scheduling
rrh
clustering
beamforming
design
proposed
optimize
spectral
and/or
energy
efﬁciency
cache
storage
deployed
rrhs
bring
new
optimization
dimension
ex-
isting
approaches
example
user
requesting
ﬁle
might
scheduled
connect
rrh
requested
ﬁle
cache
instead
connecting
closest
rrh
ieee
network
feature
topic
ultra-dense
heterogeneous
small
cell
deployment
beyond
july
2017
0.5
0.4
0.3
0.2
0.1
edge
edge+cloud
non-coop
edge+cloud
coop
chc
cloud
0.2
0.3
0.4
total
cache
size
edge
edge+cloud
non-coop
edge+cloud
coop
chc
cloud
0.2
0.3
0.4
total
cache
size
2.5
1.5
0.5
edge
edge+cloud
non-coop
edge+cloud
coop
chc
cloud
0.2
0.3
0.4
total
cache
size
fig
performance
different
caching
strategies
c-ran
evaluated
different
metrics
terms
different
total
cache
sizes
cache
hit
ratio
average
latency
backhaul
trafﬁc
load
0.5
0.4
0.3
0.2
0.1
100
chc
mpc-ex
femtox
lfu
0.1
0.2
0.3
0.4
total
cache
size
chc
mpc-ex
femtox
lfu
0.1
0.2
0.3
0.4
total
cache
size
2.4
2.2
1.8
1.6
1.4
1.2
chc
mpc-ex
femtox
lfu
0.1
0.2
0.3
0.4
total
cache
size
fig
performance
cooperative
hierarchical
caching
chc
different
cache
replacement
algorithms
cache
hit
ratio
average
latency
backhaul
trafﬁc
load
would
interesting
design
holistic
cooperation
strategy
c-ran
taking
account
channel
opportunities
cache
availability
conclusions
introduced
novel
cooperative
hierarchical
caching
chc
framework
context
cloud
access
radio
networks
c-ran
contents
jointly
cached
baseband
unit
bbu
pool
radio
remote
heads
rrhs
cloud
cache
bbu
pool
envisioned
new
layer
cache
hierarchy
coordinates
edge
caches
rrhs
trace-driven
simulations
show
chc
signiﬁcantly
outperforms
traditional
edge-only
caching
scheme
rendering
improvement
cache
hit
ratio
decrease
content-access
latency
reduction
backhaul
trafﬁc
load
also
highlighted
related
challenges
opportunities
deploying
content
caching
c-ran
acknowledgment
work
supported
national
science
foundation
nsf
grant
cns-1319945
references
cisco
cisco
visual
networking
index
forecast
methodology
2011–2016
cisco
white
paper
2012
pompili
hajisami
tran
elastic
resource
utilization
framework
high
capacity
energy
efﬁciency
cloud
ran
ieee
commun
mag.
vol
26–32
2016
tran
pompili
dynamic
radio
cooperation
user-
centric
cloud-ran
computing
resource
sharing
ieee
trans
wireless
commun.
2017
appear
bastug
bennis
debbah
living
edge
role
proactive
caching
wireless
networks
ieee
commun
mag.
vol
82–89
2014
ahlehagh
dey
video-aware
scheduling
caching
radio
access
network
ieee/acm
trans
netw.
vol
1444–
1462
2014
golrezaei
shanmugam
dimakis
molisch
caire
femtocaching
wireless
video
content
delivery
distributed
caching
helpers
proc
ieee
infocom
1107–1115
2012
gharaibeh
khreishah
ayyash
provably
efﬁcient
online
collaborative
caching
algorithm
multicell-coordinated
systems
ieee
trans
mobile
comput.
vol
1–14
2015
yang
huang
ansari
wang
cooperative
ran
caching
based
local
altruistic
game
single
joint
transmissions
ieee
commun
letters
2016
huang
ansari
content
caching
user
scheduling
heterogeneous
wireless
networks
proc
ieee
globecom
1–6
2016
tao
chen
zhou
content-centric
sparse
multicast
beamforming
cache-enabled
cloud
ran
ieee
trans
wireless
commun.
vol
6118–6131
2016
mosleh
liu
hou
coordinated
data
assignment
novel
scheme
big
data
cached
cloud-ran
proc
ieee
globecom
dec.
2016.
ieee
network
feature
topic
ultra-dense
heterogeneous
small
cell
deployment
beyond
july
2017
wang
chen
taleb
ksentini
leung
cache
air
exploiting
content
caching
delivery
techniques
systems
ieee
commun
mag.
vol
131–139
2014
borst
gupt
walid
distributed
caching
algorithms
content
distribution
networks
proc
ieee
infocom
1–9
2010
peng
yan
zhang
wang
fog-computing-based
radio
access
networks
issues
challenges
ieee
network
vol
46–53
2016
nemhauser
wolsey
fisher
analysis
approximations
maximizing
submodular
set
functions
mathe-
matical
programming
vol
265–294
1978
jelenkovi´c
radovanovi´c
least-recently-used
caching
dependent
requests
theoretical
computer
science
vol
326
293–327
2004.
biography
tuyen
tran
working
towards
phd
degree
electrical
computer
engineering
ece
rutgers
guidance
dr.
pompili
received
msc
degree
ece
akron
usa
2013
beng
degree
honors
program
electronics
telecommunications
hanoi
technology
vietnam
2011.
research
interests
applications
optimization
machine
learning
wireless
networking
systems
abolfazl
hajisami
started
phd
program
ece
rutgers
2012.
currently
pursuing
research
ﬁelds
c-ran
cellular
networking
mobility
management
guidance
dr.
pompili
previously
received
sharif
technology
shahid
beheshti
tehran
iran
2010
2008
respectively
research
interests
wireless
communications
c-ran
statistical
signal
processing
image
processing
dario
pompili
assoc
prof.
dept
ece
rutgers
directs
cyber-physical
systems
laboratory
cps
lab
received
phd
ece
georgia
institute
technology
2007.
previously
received
laurea
com-
bined
doctorate
degrees
telecommunications
systems
engineering
rome
sapienza
italy
2001
2004
respectively
recipient
nsf
career
onr
young
investigator
program
darpa
young
faculty
awards
senior
member
ieee
communications
society
acm
