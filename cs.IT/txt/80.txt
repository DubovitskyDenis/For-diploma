coding
fork
network
framework
kolmogorov
complexity∗
andrei
romashchenko
october
2018
abstract
many
statements
classic
information
theory
theory
shan-
non
entropy
natural
counterparts
algorithmic
information
theory
framework
kolmogorov
complexity
paper
discuss
one
simple
instance
parallelism
shannon
kol-
mogorov
theories
prove
setting
kolmogorov
complexity
algorithmic
version
wolf
characterization
admissible
rates
fork
network
introduction
slepian–wolf
coding
scheme
many
remarkable
similarities
probabilistic
algorithmic
infor-
mation
theories
studied
since
seminal
paper
kolmogorov
present
article
discuss
one
particular
example
parallelism
shannon
kolmogorov
frameworks
information
theory
study
cod-
ing
schemes
simple
multi-source
networks
so-called
fork
networks
show
wolf
theorem
classic
information
theory
naturally
translated
framework
kolmogorov
complexity
first
remind
classic
slepian–wolf
theorem
algorithmic
counterpart
special
case
theorem
non
symmetric
version
shows
auxiliary
source
used
eﬃcient
compression
source
theorem
let
sequence
i.i.d
pairs
random
variables
jointly
distributed
ﬁnite
range
every
exist
mappings
prob
lim
n→∞
α|β
∗this
article
mostly
translation
paper
romashchenko
complexity
version
network
coding
problem
information
processes
electronic
journal
2005
20–28
russian
theorem
clear
intuitive
meaning
sender
encodes
randomly
chosen
values
economic
way
encoding
function
denoted
receiver
reconstruct
values
given
additional
information
values
correlated
decoding
function
denoted
error
probability
must
bounded
aim
minimize
length
transmitted
message
shannon
coding
theorem
claims
achieve
error
probability
even
used
decoding
slepian
wolf
show
given
reduce
length
message
αn|β1
makes
theorem
notrivial
values
available
receiver
sender
i.e.
argument
framework
kolmogorov
complexity
counterpart
theorem
proven
muchnik
see
theorem
strings
exists
string
cid:48
cid:48
log
a|a
cid:48
log
cid:48
a|b
see
also
similar
result
theorem
3.11
analogous
technique
used
theorem
string
cid:48
plays
role
code
allows
easily
reconstruct
given
moreover
code
cid:48
easily
computed
usual
theory
kolmogorov
complexity
words
easily
computed
mean
corresponding
conditional
kolmogorov
complexity
bounded
log
loosely
speaking
theorem
claims
among
almost
shortest
programs
translate
one
whose
complexity
conditional
negligibly
small
theorem
optimal
sense
ratio
α|β
made
less
similarly
theorem
conditions
cid:48
a|b
log
proofs
theorem
theorem
consist
constructing
suitable
hash
functions
given
ﬁrst
source
information
compute
ﬁngerprint
hash
value
recover
initial
value
given
ﬁngerprint
an-
auxiliary
source
information
however
technical
implementations
idea
proofs
theorem
theorem
pretty
diﬀerent
fork
networks
theorem
generalized
larger
class
communication
networks
let
deﬁne
admissible
rates
fork
networks
fig
fork
network
sources
deﬁnition
let
k-dimensional
random
variable
distributed
ﬁnite
set
denote
sequence
i.i.d
k-dimensional
random
variables
let
distributed
tuple
reals
called
ε-admissible
fork
network
sources
every
large
enough
exist
functions
...
+lk
prob
¯α1
¯αk
¯α1
¯αk
¯αj
denotes
n-tuple
deﬁnition
corresponds
information
transmission
network
shown
fig
given
correlated
sources
information
distribution
speciﬁed
varables
sources
encoded
independently
block
codes
deﬁnition
speciﬁes
lengths
encoded
messages
senders
spend
average
bits
per
letter
source
receiver
recovers
values
sources
decoding
function
probability
error
must
less
set
ε-admissible
rates
characterized
terms
entropies
involving
random
variables
notation
let
tuple
jointly
distributed
random
variables
follows
denote
tuple
random
variables
α¬w
tuple
random
variables
cid:54
example
denotes
α¬w
denotes
suppose
constant
random
variable
zero
entropy
particular
αw|α¬w
formulate
wolf
theorem
characterizes
set
admissible
rates
fork
networks
theorem
j.k.
wolf
see
also
every
k-tuple
jointly
distributed
random
variables
every
necessary
condition
every
ε-admissible
tuple
reals
holds
cid:88
αw|α¬w
suﬃcient
condition
set
holds
j∈w
cid:88
j∈w
αw|α¬w
tuple
reals
ε-admissible
fork
network
example
theorem
implies
pair
ε-admissible
network
sources
similarly
conditions
α1|α2
α2|α1
α1|α2
α2|α1
enough
guarantee
pair
ε-admissible
special
case
theorem
general
statement
slepian–wolf
theorem
remaining
condition
|α2
get
statement
theorem
special
case
follows
prove
counterpart
theorem
kolmogorov
com-
plexity
technically
give
criterion
following
property
tuple
binary
strings
counterpart
admissibility
property
deﬁnition
adapted
kolmogorov
theory
tuple
strings
tuple
integers
exist
strings
cid:48
cid:48
cid:48
|a1|
|ak|
cid:48
cid:48
ak|a
cid:48
j|aj
log
log
theorem
main
result
necessary
condition
integer
exists
constant
strings
total
length
|a1|
|ak|
integers
property
holds
every
non
empty
set
cid:88
aw|a¬w
log
j∈w
cid:88
j∈w
suﬃcient
condition
integer
exists
constant
strings
integers
property
holds
every
nonempty
set
aw|a¬w
log
notation
theorem
use
notation
stands
tuple
strings
similarly
a¬w
stands
tuple
strings
cid:54
empty
denote
empty
word
particular
aw|a¬w
example
theorem
gives
necessary
suﬃcient
conditions
a1|a2
log
a2|a1
log
log
theorem
proven
present
paper
prove
theorem
integer
standard
proof
theorem
see
translated
language
kolmogorov
complexity
crucial
point
proof
employs
principle
time
sharing
apply
framework
kolmogorov
complexity
prove
theorem
using
following
version
muchnik
theorem
somewhat
stronger
theorem
theorem
every
integer
exists
number
following
property
let
binary
strings
|x1|
+|xk|
number
less
|x0|
exists
string
|y|
y|x0
log
y|xj
min
x0|xj
log
every
informally
theorem
claims
extract
logarithmic
advice
string
ﬁngerprint
length
looks
maximally
random
given
strings
condition
remark
since
y|x0
log
every
y|xj
x0|xj
log
remark
x0|xj
completely
reconstructed
given
logarithmic
advice
i.e.
x0|y
log
indeed
case
y|xj
x0|xj
log
x0|y
y|xj
y|xj
log
x0|xj
y|xj
log
log
remark
theorem
implies
theorem
indeed
let
apply
theorem
a|b
obtain
string
|y|
y|a
log
y|b
a|b
log
conditions
imply
a|y
log
thus
may
let
cid:48
cid:3
proof
theorem
sake
brevity
use
following
asymptotic
notation
cid:11
log
cid:11
log
cid:11
log
proof
necessity
condition
let
set
indices
condition
theorem
strings
logarithmic
complexity
conditional
tuple
cid:104
cid:48
follows
aw|a
cid:48
a¬w
hence
complexity
tuple
cid:48
less
conditional
complexity
aw|a¬w
hand
kolmogorov
greater
done
complexity
cid:48
formally
argument
presented
chain
inequalities
a¬w
cid:48
cid:105
cid:48
aw|a¬w
cid:48
cid:48
cid:48
aw|a
cid:48
cid:80
aw|a
cid:48
j∈w
proof
suﬃciency
condition
prove
theorem
induction
make
inductive
step
work
need
reformulate
theorem
make
somewhat
stronger
inductive
claim
every
integer
exists
number
following
property
let
binary
strings
integers
denote
|a1|
|ak|
|b|
assume
every
aw|a¬w
log
cid:48
nonempty
holds
cid:80
j∈w
follows
exist
binary
strings
cid:48
cid:48
cid:48
ak|a
cid:48
cid:48
j|aj
log
log
diﬀerence
claim
new
parameter
inductive
claim
follows
immediately
theorem
let
perform
inductive
step
fix
binary
strings
ak+1
theorem
follows
exists
string
cid:48
k+1
k+1|
rk+1
cid:48
cid:48
k+1|ak+1
log
every
nonempty
cid:48
k+1|aw
min
ak+1|aw
rk+1
log
value
depends
going
use
inductive
hypothesis
tuple
strings
cid:48
cid:104
cid:48
k+1
cid:105
tuple
integers
end
verify
in-
ductive
claim
applicable
strings
i.e.
need
prove
following
lemma
lemma
exists
cid:48
complement
holds
every
non-empty
cid:48
cid:88
j∈v
|a¬v
cid:48
cid:48
log
proof
consider
separately
two
cases
case
assume
rk+1
ak+1|a¬v
remark
know
ak+1|a
cid:48
k+1
a¬v
hence
|a¬v
cid:48
k+1
|a¬v
ak+1
cid:88
j∈v
last
inequality
part
condition
inductive
claim
case
assume
rk+1
ak+1|a¬v
given
rk+1
ak+1
|a¬v
using
kolmogorov–levin
theorem
reformulate
inequality
cid:88
j∈v
condition
rk+1
cid:80
j∈v
***
cid:48
k+1|a¬v
ak+1|a
cid:48
k+1
a¬v
|ak+1
a¬v
get
cid:48
k+1|a¬v
rk+1
***
rewrites
cid:88
j∈v
rk+1
implies
rk+1
ak+1|a
cid:48
k+1
a¬v
|ak+1
a¬v
cid:88
j∈v
|ak+1
a¬v
lemma
apply
inductive
hypothesis
obtain
cid:48
done
cid:3
strings
cid:48
cid:48
j|aj
cid:48
cid:48
ak|a
cid:48
cid:48
cid:48
log
cid:48
k+1
cid:48
cid:48
log
remains
show
ak+1|a
cid:48
cid:48
cid:48
k+1
log
cid:48
prove
ak+1|a1
cid:48
asymptotic
notation
may
depend
end
enough
k+1
sake
brevity
use
ak+1|a1
cid:48
k+1
ak+1
cid:48
ak+1|a1
cid:48
ak+1|a1
min
ak+1|a1
rk+1
k+1|a1
cid:48
k+1|a1
k+1|a1
cid:3
conclusion
seems
natural
ask
whether
version
theorem
holds
resource
bounded
versions
kolmgorov
complexity
e.g.
programs
running
poly-
nomial
time
polynomial
space
recently
zimand
proved
variant
thereom
encoding
procedures
cid:48
encj
performed
probabilistic
polynomial
time
algorithms
see
seems
un-
likely
optimal
lengths
codewords
cid:48
polynomial
time
encoding
cid:55
could
combined
also
polynomial
time
decoding
cid:48
acknowledgments
author
grateful
marius
zimand
pointed
error
ﬁrst
version
paper
cid:48
references
kolmogorov
a.n.
three
approaches
quantitative
deﬁnition
infor-
mation
problems
information
transmission
1–7
1965
slepian
wolf
j.k.
noiseless
coding
correlated
information
sources
ieee
transactions
information
theory
471–480
1973
wolf
j.k.
data
reduction
multiple
correlated
sources
proc
fifth
colloquium
microwave
communication
budapest
287–295
1974
bennett
c.h.
g´acs
vit´anyi
zurek
information
dis-
tance
ieee
transactions
information
theory
1998,1407–1423
fortnow
laplante
nearly
optimal
language
compression
using
extrac-
tors
proc
stacs
1998
84–93
muchnik
an.a.
semenov
a.l
multi-conditional
descriptions
codes
kolmogorov
complexity
electronic
collocuium
computational
com-
plexity
eccc
2000
buhrman
fortnow
laplante
resource-bounded
kolmogorov
com-
plexity
revisited
siam
journal
computing
887–905
2001
muchnik
a.a.
conditional
complexity
codes
theoretical
computer
science
271
97–109
2002
izmailova
a.a.
information
transmission
fork
network
bounded
channel
capacities
master
thesis
moscow
state
university
2004.
russian
измайлова
а.а.
передача
сообщений
вилочной
сети
ограниченными
пропускными
способностями
каналов
дипломная
работа
москва
мгу
ломоносова
2004
csiszar
k¨orner
information
theory
coding
theorems
discrete
memoryless
systems
cambridge
university
press
2011
zimand
kolmogorov
complexity
version
slepian-wolf
coding
arxiv:1511.03602
2015
