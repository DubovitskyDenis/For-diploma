source-channel
separation
theorem
application
source
broadcast
problem
kia
khezeli
jun
chen
abstract—a
converse
method
developed
source
broadcast
problem
speciﬁcally
shown
separation
architecture
optimal
variant
source
broadcast
prob-
lem
associated
source-channel
separation
theorem
leveraged
via
reduction
argument
establish
necessary
condition
original
problem
uniﬁes
several
existing
results
literature
somewhat
surprisingly
method
albeit
based
source-channel
separation
theorem
used
prove
optimality
non-separation
based
schemes
determine
performance
limits
certain
scenarios
separation
architecture
suboptimal
index
terms—bandwidth
mismatch
broadcast
channel
capac-
ity
region
joint
source-channel
coding
separation
theorem
side
information
introduction
source
broadcast
problem
source
sent
broadcast
channel
suitable
encoding
decoding
reconstructions
receivers
satisfy
prescribed
constraints
special
case
sending
gaussian
source
gaussian
broadcast
channel
received
particular
attention
special
case
known
source-channel
sepa-
ration
general
suboptimal
hybrid
digital-analog
coding
schemes
outperform
pure
digital/analog
schemes
extension
hybrid
coding
architecture
non-gaussian
setting
found
contrast
progress
converse
side
still
some-
limited
best
knowledge
ﬁrst
non-
trivial
result
direction
obtained
reznic
scalar
version
aforementioned
gaussian
case
converse
argument
involves
auxiliary
random
variable
generated
source
via
additive
gaussian
noise
channel
auxiliary
random
variable
constructed
exactly
manner
one
ozarow
celebrated
work
gaussian
multiple
description
problem
however
resemblance
certain
sense
rather
superﬁcial
indeed
technical
level
auxiliary
random
variable
introduced
ozarow
elucidated
plays
role
exploiting
implicit
conditional
inde-
pendence
structure
whereas
role
auxiliary
random
work
supported
part
early
researcher
award
province
ontario
part
natural
science
engineering
re-
search
council
nserc
canada
discovery
grant
paper
presented
part
2014
ieee
international
symposium
information
theory
khezeli
department
electrical
computer
engi-
neering
mcmaster
university
hamilton
l8s
4k1
canada
school
electrical
computer
engineering
cornell
university
ithaca
14853
usa
email
kk839
cornell.edu
chen
department
electrical
computer
engi-
neering
mcmaster
university
hamilton
l8s
4k1
canada
email
junchen
ece.mcmaster.ca
variable
apparently
different
still
largely
elusive
recent
years
seen
several
new
converse
results
source
broadcast
problem
results
based
arguments
similar
original
one
reznic
al.
especially
terms
way
auxiliary
random
variables
constructed
exploited
worth
noting
arguments
handle
restricted
class
auxiliary
random
variables
essentially
generated
source
via
certain
additive
noise
channels
restriction
typically
leads
certain
constraints
set
sources
channels
distortion
measures
analyzed
present
paper
certain
extent
outcome
effort
seeking
conceptual
understanding
converse
argument
reznic
general
role
asso-
ciated
auxiliary
random
variable
particular
shall
show
one
establish
source-channel
separation
theorem
variant
source
broadcast
problem
leverage
derive
necessary
condition
original
problem
necessary
condition
specialized
case
sending
scalar
gaussian
source
gaussian
broadcast
channel
recovers
corresponding
result
reznic
moreover
way
converse
argument
ﬁnds
simple
interpretation
associated
auxiliary
random
variable
acquires
operational
meaning
pointed
approach
auxiliary
random
variable
generated
source
arbitrary
manner
therefore
restriction
imposed
existing
arguments
fact
unnecessary
hand
problem
identifying
optimal
auxiliary
random
variable
naturally
arises
due
additional
freedom
seen
analytical
solutions
problem
found
special
cases
interestingly
solutions
indicate
speciﬁc
choices
auxiliary
random
variables
actually
optimal
respective
contexts
work
also
partly
motivated
problem
sending
bivariate
gaussian
source
gaussian
broadcast
channel
ﬁrst
studied
bross
problem
known
achievable
distortion
region
certain
hybrid
digital-analog
coding
scheme
matches
outer
bound
whereas
separate
source-channel
coding
general
suboptimal
alternative
proof
outer
bound
recently
obtained
song
new
proof
bears
similarity
aforementioned
converse
argument
reznic
clarify
connection
giving
uniﬁed
proof
vector
gaussian
case
implies
among
things
outer
bound
deduced
general
necessary
condi-
tion
source
broadcast
problem
found
present
paper
therefore
converse
method
albeit
based
transmitter
py1
y2|x
receiver
receiver
ˆsm
ˆsm
fig
system
source-channel
separation
theorem
used
prove
optimality
non-separation
based
schemes
determine
performance
limits
certain
scenarios
separation
architecture
suboptimal
rest
paper
organized
follows
present
problem
setup
section
relevant
capacity
results
broadcast
channels
receiver
side
information
section
iii
establish
source-channel
separation
theorem
variant
source
broadcast
problem
section
shown
section
separation
theorem
used
conjunction
simple
reduction
argument
derive
necessary
condition
original
source
broadcast
problem
moreover
necessary
condition
evaluated
special
case
binary
uniform
source
hamming
distortion
measure
quadratic
gaussian
case
treated
section
conclude
paper
section
vii
throughout
paper
binary
entropy
function
inverse
denoted
respectively
deﬁne
logarithm
function
assumed
base
unless
speciﬁed
otherwise
problem
setup
source
broadcast
system
system
consists
following
components
see
fig
i.i.d
source
t=1
marginal
distribution
alphabet
discrete
memoryless
broadcast
channel
py1
y2|x
input
alphabet
output
alphabets
transmitter
equipped
encoding
func-
tion
maps
block
source
samples
length
channel
input
block
length
number
channel
uses
per
source
sample
i.e.
referred
bandwidth
expansion
ratio
two
receivers
receiver
equipped
de-
maps
gener-
coding
function
channel
output
block
ated
source
reconstruction
block
ˆsm
ˆsi
ˆsi
ˆsm
unless
stated
otherwise
assume
ˆs1
ˆs2
ﬁnite
sets
let
ps×
ˆsi
denote
set
joint
distributions
ˆsi
marginal
distribution
ﬁxed
deﬁnition
let
non-negative
number
non-empty
compact
subset
ps×
ˆsi
say
achievable
system
every
exist
encoding
function
decoding
functions
ˆsm
min
qi∈qi
xt=1
cid:13
cid:13
cid:13
cid:13
cid:13
ˆsi
cid:13
cid:13
cid:13
cid:13
cid:13
k·k
1-norm
set
achievable
system
denoted
remark
easy
verify
xt=1
ˆsi
ps×
ˆsi
consider
following
conventional
deﬁnition
ˆsi
two
distor-
deﬁnition
let
tion
measures
non-negative
numbers
say
achievable
system
distortion
measures
every
exist
en-
coding
function
decoding
functions
ˆsm
xt=1
ˆsi
following
result
shows
deﬁnition
general
deﬁnition
proposition
distortion
measures
ˆsi
ps×
ˆsi
ˆsi
achievable
system
proof
let
random
variable
independent
uniformly
distributed
ˆsm
easy
verify
written
equivalently
ˆsm
min
qi∈qi
cid:13
cid:13
cid:13
ˆsi
cid:13
cid:13
cid:13
written
equivalently
ˆsi
˜sm
˜sm
transmitter
py1
y2|x
˜sm
receiver
receiver
ˆsm
ˆsm
fig
system
note
ˆsi
ˆsi
ˆsi
ˆsi
ˆsi
ˆsi
xs∈s
ˆsi∈
ˆsi
xs∈s
ˆsi∈
ˆsi
xs∈s
ˆsi∈
ˆsi
|ps
ˆsi
ˆsi
ˆsi
|wi
ˆsi
kps
ˆsi
qik
max
s∈s
ˆsi∈
ˆsi
ˆsi
therefore
ˆsi
min
qi∈qi
kps
ˆsi
qik
max
s∈s
ˆsi∈
ˆsi
ˆsi
part
follows
immediately
proceed
prove
part
assume
achievable
system
distortion
measures
every
according
deﬁnition
ﬁnd
encoding
function
decoding
functions
satisfying
ˆsi
shall
denote
simply
since
distribution
denote
ˆs1
ˆs2
respectively
stress
dependence
note
contained
compact
set
every
therefore
one
ﬁnd
sequence
converging
zero
ˆsm
lim
k→∞
ˆs1
ˆs2
ˆs1
ˆs2
completes
proof
part
ˆsi
source-channel
separation
known
incur
performance
loss
system
general
however
turns
following
variant
system
see
fig
separate
source-
channel
coding
fact
optimal
system
system
system
except
two
differences
source
i.i.d
vector
process
˜s1
˜s2
t=1
ﬁnite
alphabet
marginal
distribution
˜s1
˜s2
˜s1
˜s2
available
receiver
used
together
construct
ˆsm
˜sm
˜s1
˜s2
let
˜s1×
˜s2×
ˆs1
denote
set
joint
distributions
˜s1
˜s2
ˆs1
marginal
distribution
˜s1
˜s2
denote
set
ﬁxed
˜s1
˜s2
joint
distributions
˜s2
ˆs2
marginal
distribution
˜s2
ﬁxed
˜s2
moreover
let
˜s2×
ˆs2
˜s2
deﬁnition
let
non-negative
number
˜q1
˜q2
non-empty
compact
subset
˜s1×
˜s2×
ˆs1
say
non-empty
compact
subset
˜s2×
ˆs2
˜q1
˜q2
achievable
system
every
exist
encoding
function
˜sm
well
decoding
functions
˜sm
˜sm
˜s1
˜s2
˜s2
ˆsm
ˆsm
min
˜q1∈
˜q1
min
˜q2∈
˜q2
xt=1
xt=1
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
˜s1
˜s2
ˆs1
˜q1
cid:13
cid:13
cid:13
cid:13
cid:13
˜s2
ˆs2
˜q2
cid:13
cid:13
cid:13
cid:13
cid:13
set
achievable
˜q1
˜q2
system
denoted
remark
ease
subsequent
applications
allow
non-deterministic
functions
long
markov
chains
˜sm
ˆsm
˜sm
preserved
clear
relaxation
affect
˜sm
ˆsm
˜sm
˜sm
discuss
source-channel
separation
system
need
specify
source
coding
component
channel
coding
component
seen
source
coding
part
conventional
lossy
source
coding
scheme
channel
coding
part
involved
described
next
section
transmitter
py1
y2|x
fig
broadcast
channel
two
private
messages
transmitter
py1
y2|x
receiver
receiver
receiver
receiver
ˆm1
ˆm2
ˆm1
ˆm2
fig
broadcast
channel
receiver
side
information
iii
broadcast
channels
receiver
side
information
deﬁnitions
let
py1
y2|x
discrete
memoryless
broadcast
channel
input
alphabet
output
alphabets
length-n
coding
scheme
see
fig
py1
y2|x
consists
two
private
messages
uniformly
distributed
encoding
function
maps
channel
input
block
two
decoding
functions
maps
channel
output
block
receiver
i.e.
ˆmi
deﬁnition
rate
pair
said
achievable
broadcast
channel
py1
y2|x
exists
sequence
encoding
functions
log
|mi|
decoding
functions
lim
n→∞
ˆm1
ˆm2
private-message
capacity
region
py1
y2|x
closure
set
achievable
broadcast
channel
py1
y2|x
computable
characterization
py1
y2|x
still
largely
unknown
interestingly
problem
becomes
signiﬁcantly
simpler
message
available
receiver
message
available
receiver
fact
setting
relevant
present
work
speciﬁcally
consider
scenario
two
private
messages
need
sent
broadcast
channel
py1
y2|x
receiver
receiver
respectively
available
receiver
case
length-n
coding
scheme
see
fig
consists
two
private
messages
uniformly
distributed
encoding
function
maps
channel
input
block
two
decoding
functions
maps
ˆm2
ˆm1
maps
deﬁnition
rate
pair
said
achievable
broadcast
channel
py1
y2|x
message
available
receiver
exists
sequence
encoding
functions
log
|mi|
well
decoding
functions
lim
n→∞
ˆm1
ˆm2
capacity
region
py1
y2|x
closure
set
achievable
capacity
region
py1
y2|x
broadcast
channel
py1
y2|x
message
available
receiver
deﬁned
analogous
manner
capacity
results
known
theorem
py1
y2|x
given
set
satisfying
y1|v
py1
y2|x
moreover
sufﬁces
assume
|v|
|+1
symmetry
py1
y2|x
given
set
satisfying
proposition
py1|x
essentially
capable
py2|x
py1
y2|x
given
set
satisfying
y2|v
py1
y2|x
proof
compute
py1
y2|x
deﬁned
sufﬁces
consider
sufﬁciently
class
note
py1
y2|x
sufﬁces
assume
|v|
input
sufﬁcient
class
distributions
alphabet
class
distributions
broadcast
channel
py1
y2|x
exists
˜v1
˜v2
˜y1
˜y2|
said
deﬁnition
pv1
pv1
xpy1
y2|x
˜v1
˜v2
˜y1
˜y2
˜y1
˜y2|
py1
y2|x
that1
˜v1
˜y1
˜v2
˜y2
y2|v1
˜v1
˜y1
˜y2|
˜v1
y1|v2
˜y1|
˜v2
˜v2
˜y2
broadcast
channel
py1
y2|x
say
py1|x
essen-
tially
less
noisy
py2|x
exists
sufﬁcient
class
distributions
py1
y2|x
deﬁnition
simply
say
py1|x
less
noisy
py2|x
chosen
set
distributions
similarly
say
py1|x
essentially
capable
py2|x
exists
sufﬁcient
class
distributions
y1|v
y2|v
xpy1
y2|x
deﬁnition
simply
say
py1|x
capable
py2|x
chosen
set
distributions
known
less
noisy
capable
implies
essentially
less
noisy
essentially
capable
less
noisy
implies
capable
converses
true
general
proposition
py1|x
essentially
less
noisy
py2|x
py1
y2|x
py1
y2|x
proof
compute
py1
y2|x
deﬁned
sufﬁces
consider
sufﬁcient
class
easy
see
y1|v
y1|v
py1
y2|x
due
fact
py1|x
essentially
less
noisy
py2|x
therefore
redundant
restricted
note
rate
region
deﬁned
py1
y2|x
exactly
py1
y2|x
theorem
completes
proof
proposition
1setting
one
readily
verify
˜v1
˜y1
˜y1
similarly
one
obtain
˜y2
setting
y2|v
y1|v
xpy1
y2|x
due
fact
py1|x
essentially
capable
py2|x
therefore
given
right-hand
side
inequality
attains
maximum
value
clearly
given
right-hand
side
inequality
also
attains
maximum
value
consequence
py1
y2|x
expressed
set
satisfying
py1
y2|x
removing
redundant
constraint
completes
proof
proposition
examples
consider
broadcast
channel
py1
y2|x
pyi|x
binary
symmetric
channel
crossover
probability
channel
denoted
bs-bc
without
loss
generality
shall
assume
well
known
given
set
satisfying
next
consider
broadcast
channel
py1
y2|x
pyi|x
binary
erasure
channel
erasure
probability
channel
denoted
be-bc
without
loss
generality
shall
assume
well
known
be-bc
given
set
satisfying
following
results
simple
consequences
proposi-
tion
proposition
proposition
bs-bc
bs-bc
bs-bc
bs-bc
proposition
be-bc
be-bc
be-bc
be-bc
proposition
bsc
bec
following
ex-
plicit
characterization
bsc
bec
bsc
bec
consider
broadcast
channel
py1
y2|x
py1|x
binary
symmetric
channel
crossover
probability
py2|x
binary
erasure
channel
erasure
probability
channel
denoted
bsc
bec
without
loss
generality
shall
assume
one
obtain
following
explicit
characterization
bsc
bec
theorem
bsc
bec
given
set
satisfying
1−p
bsc
bec
given
set
satisfying
unique
number
satisfying
bsc
bec
given
set
satisfying
proposition
bsc
bec
following
ex-
plicit
characterization
bsc
bec
bsc
bec
bsc
bec
proof
according
theorem
bec
capable
bsc
therefore
one
readily
prove
part
invoking
proposition
well
fact
simultaneously
maximized
part
follows
proposition
fact
bsc
essentially
less
noisy
bec
theorem
bsc
bec
given
set
satisfying
unique
number
satisfying
log
cid:16
cid:17
log
cid:16
cid:17
bsc
bec
proof
part
follows
proposition
fact
bec
less
noisy
bsc
1−p
theorem
part
trivial
part
one
readily
show
bsc
bec
given
set
satisfying
following
proof
claim
claim
light
lemma
following
optimization
problem
max
unique
maximizer
completes
proof
proposition
remark
might
tempting
conjecture
proposition
continues
hold
essentially
less
noisy
replaced
essentially
capable
however
conjecture
turns
false
indeed
bsc
bec
known
theorem
bec
capable
less
noisy
bsc
yet
part
proposition
indicates
case
bsc
bec
strictly
larger
bsc
bec
see
fig
analo-
gously
proposition
true
general
essentially
capable
replaced
essentially
less
noisy
example
according
theorem
bsc
essentially
less
noisy
bec
part
proposition
shows
case
bsc
bec
strictly
larger
see
fig
0.13
0.0749
0.0259
0.0066
0.1
0.0265
bsc
bec
bsc
bec
optimality
source-channel
separation
system
position
state
following
source-
channel
separation
theorem
shows
separation-
based
scheme
consists
lossy
source
coding
broad-
cast
channel
coding
see
fig
associated
description
optimal
system
result
viewed
extension
lemma
degraded
broadcast
channels
general
broadcast
channels
theorem
˜q1
˜q2
˜q2
˜κc1
py1
y2|x
˜s1|
˜s2
˜q1
˜s2
0.0617
0.1041
0.1187
˜s1|
˜s2
˜q1
min
˜s1
˜s2
ˆs1
˜s1
ˆs1|
˜s2
˜q1
˜s2
ˆs2
fig
0.87
bsc
bec
vs.
bec
bsc
0.3
˜s2
˜q2
min
˜s2
ˆs2
˜q2
bsc
bec
˜c2
bsc
bec
proof
proof
part
hinges
separation-
based
scheme
shall
give
sketch
since
argument
involves
standard
techniques
let
ˆs1
jointly
˜q1
distributed
˜s1
˜s2
˜s1
˜s2
ˆs1
˜q1
let
ˆs2
jointly
distributed
˜s1
ˆs1|
˜s2
˜s1|
˜s2
˜q2
˜s2
˜s2
ˆs2
functional
representation
lemma
626
see
also
lemma
ﬁnd
random
variable
cardinality
|w|
˜s2|
ˆs1|
following
properties
˜q2
˜s2
ˆs2
˜s2
0.0243
0.0978
0.1187
fig
bsc
bec
vs.
˜c2
bsc
bec
0.3
0.9
finally
consider
case
py1
y2|x
scalar
gaus-
sian
broadcast
channel
power
constraint
noise
variances
channel
denoted
g-bc
well
known
g-bc
given
set
satisfying
log
cid:16
cid:17
log
cid:16
cid:17
one
readily
prove
following
result
adapting
proposition
proposition
channel
model
proposition
g-bc
g-bc
g-bc
g-bc
cid:17
log
cid:16
log
cid:16
cid:17
independent
˜s2
ˆs1
˜s2
deterministic
function
˜s2
ˆs1
˜s1
˜s2
ˆs1
form
markov
chain
easy
see
˜s1
ˆs1|
˜s2
˜s1
˜s2
˜s1
˜s2
˜sm
˜sm
2mr2
m1=1
ˆsm
let
˜s1
ˆs1|
˜s2
˜s2
ˆs2
independently
generate
2mr1
codewords
2mr1
according
t=1
independently
generate
2mr2
codewords
ˆsm
2mr2
according
t=1
ˆs2
codebooks
2mr1
m2=1
re-
vealed
transmitter
receivers
shown
given
˜sm
high
probability
one
ﬁnd
index
˜sm
jointly
typical
respect
˜s1
˜s2
large
enough
see
deﬁnition
typical
sequences
related
properties
similarly
given
˜sm
high
probability
one
ﬁnd
index
˜sm
jointly
typical
one
respect
˜s2
ˆs2
choose
smallest
index
among
exists
set
length-n
coding
scheme
used
send
messages
broadcast
channel
py1
y2|x
receiver
receiver
respectively
given
˜sm
receiver
recover
use
produce
estimate
ˆm1
receiver
together
produce
estimate
ˆm2
assume
use
length-n
coding
scheme
good
sense
ˆmi
high
probability
note
existence
ˆsm
good
length-n
coding
scheme
guaranteed
deﬁnition
large
enough
receiver
constructs
ˆsm
ˆs1
˜s2
ˆm1
ˆsm
ˆm2
easy
show
˜sm
ˆm1
t-th
entry
sets
ˆsm
jointly
typical
respect
˜s1
˜s2
ˆs1
˜sm
high
probability
completes
proof
part
ˆm1
receiver
high
probability
jointly
typical
respect
˜s2
ˆs2
ˆsm
˜sm
ˆsm
˜sm
˜sm
proceed
prove
part
consider
arbitrary
tuple
˜q1
˜q2
given
according
deﬁnition
ﬁnd
encoding
function
˜sm
well
decoding
functions
ˆsm
satisﬁed
let
random
variable
inde-
pendent
˜sm
uniformly
distributed
deﬁne
t−1
easy
verify
form
markov
chain
note
ˆsm
t+1
˜sm
˜sm
˜sm
ˆsm
˜sm
˜sm
˜sm
˜sm
˜sm
t−1
t−1
xt=1
xt=1
xt=1
˜sm
ˆsm
˜sm
ˆsm
˜sm
˜sm
xt=1
xt=1
xt=1
˜sm
t+1
t−1
t+1
˜sm
moreover
˜sm
˜sm
˜sm
ˆsm
˜sm
˜sm
t−1
˜sm
˜sm
t+1
t−1
˜sm
˜sm
t+1
ˆsm
˜sm
˜sm
xt=1
xt=1
xt=1
t+1
t−1
˜sm
t+1
˜sm
xt=1
xt=1
xt=1
xt=1
t−1
t+1
˜sm
t+1
t−1
˜sm
t+1
˜sm
t−1
t+1
˜sm
t−1
t+1
˜sm
t+1
˜sm
t−1
t+1
˜sm
t−1
t+1
˜sm
y1|v
follows
csisz´ar
sum
identity
let
random
variable
independent
˜sm
uniformly
distributed
deﬁne
˜si
˜si
ˆsi
note
ˆsm
˜sm
ˆsm
˜s1
˜s2
xt=1
˜s1
˜s2
ˆs1
ˆs2
moreover
˜st−1
˜sm
˜st−1
˜st−1
˜s1
ˆsm
˜s1
ˆsm
˜s1
ˆs1
˜s2
xt=1
xt=1
xt=1
˜s1
ˆs1
˜s2
˜s1
ˆs1
˜s2
˜s1
ˆs1
˜s2
˜s1
˜s2
˜sn
t+1|
˜s2
˜sm
ˆsm
˜st−1
˜st−1
˜s2
ˆsm
˜s2
ˆsm
˜s2
ˆs2
xt=1
xt=1
xt=1
˜s2
ˆs2
˜s2
ˆs2
˜s2
ˆs2
˜s2
follows
˜s1
˜s2
˜s2
py1
y2|x
since
˜s1
˜s2
contained
compact
set
min
˜q1∈
˜q1
min
˜q2∈
˜q2
˜s1
˜s2
˜q1k
˜s2
˜q2k
theorem
exists
ˆs1
ˆs2
ˆsi
ˆs1
ˆs2
κci
py1
y2|x
ˆsm
proof
symmetry
sufﬁces
prove
augment
probability
space
introducing
remote
source
˜s1
˜s2
t=1
˜s1
˜s2
independent
identically
distributed
ﬁnite
alphabet
˜s1×
˜s2×s
consider
arbitrary
tuple
given
according
deﬁnition
ﬁnd
encoding
function
decoding
functions
satisfying
let
random
variable
independent
˜sm
uniformly
distributed
deﬁne
˜si
˜si
ˆsi
clear
distribution
˜s1
˜s2
identical
˜s1
˜s2
every
˜s1
˜s2
form
markov
chain
moreover
xt=1
˜s1
˜s2
ˆs1
ˆs2
˜s1
˜s2
ˆsm
ˆsm
˜sm
since
minqi∈qi
qik
every
one
ﬁnd
sequence
converging
zero
every
one
ﬁnd
sequence
converging
zero
lim
k→∞
˜s1
˜s2
˜s1
˜s2
ˆs1
ˆs2
lim
k→∞
˜s1
˜s2
˜s1
˜s2
ˆs1
ˆs2
˜s1
˜s2
ˆs1
ˆs2
clear
˜s1
˜s2
ˆs1
˜q1
˜s2
ˆs2
˜q2
˜s1
ˆs1|
˜s2
˜s1|
˜s2
˜q2
˜s2
ˆs2
˜s2
˜q1
proof
completed
via
simple
limiting
argu-
ment
necessary
condition
source
broadcast
problem
necessary
condition
shall
show
source-channel
separation
theorem
system
i.e.
theorem
leveraged
establish
necessary
condition
system
via
simple
reduction
denote
set
argument
let
ˆs1
ˆs2
satisfying
ˆs1|u
ˆs2
ˆs1
ˆs2
ˆs1
ˆs2
pu|sps
ˆs1
ˆs2
denote
set
similarly
satisfying
let
ˆs1
ˆs2|u
˜s1
˜s2
ˆs1
ˆs2
implies
˜s1
˜s2
ˆs1
follows
theorem
ˆsi
˜s2
ˆs2
note
therefore
˜s1
ˆs1|
˜s2
˜s2
ˆs2
κc1
py1
y2|x
choose
˜s1
˜s2|s
arbitrarily
since
one
ˆs1
ˆs2
˜s1
ˆs1|
˜s2
ˆs1|
˜s2
loss
generality
setting
˜s1
denoting
˜s2
completes
proof
theorem
remark
since
py1
y2|x
py1
y2|x
convex
sets
follows
holds
κci
py1
y2|x
one
contains
extreme
points
ˆs1
ˆs2
show
via
standard
application
support
lemma
631
contrast
cardinality
bound
|u|
sufﬁces
|s|
preserving
ˆs1
ˆs2
|u|
|s|
purpose
realizing
extreme
points
binary
uniform
source
hamming
distortion
measure
subsection
set
ˆs1
ˆs2
hamming
distortion
measure
i.e.
cid:26
otherwise
problem
trivial2
shall
focus
non-degenerate
case
therefore
ˆs1
ˆs2
pu|sps
ˆs1
ˆs2
2in
fact
reduces
point-to-point
problem
assume
pyi|x
max
correspondingly
proposition
ˆs1
ˆs2
ˆsi
ˆs1
ˆs2
ˆs1
ˆs2
bs-bc
bs-bc
ˆs1
ˆs2|u
ˆs1|u
ˆs2|u
max
u∈u
ˆs1|u
ˆs2|u
max
bs-bc
see
section
iii-c
deﬁnition
given
set
satisfying
deﬁne
monotonically
increasing
function
note
bs-bc
given
set
satisfying
moreover
ˆs1
ˆs2
ˆs1
ˆs2
bs-bc
bs-bc
ˆs1
ˆs2|s
bs-bc
proof
let
ˆs1
ˆs2
pu|sps
ˆs1
ˆs2
pu|s
bsc
min
ˆs1|u
ˆs1|s
ˆs1
≤d1
min
ˆs1|s
ˆs1
≤d1
min
ˆs1|s
ˆs1
≤d1
min
ˆs1
ˆs1
ˆs1
ˆs1
follows
since
follows
lemma
due
fact
monotonically
decreasing
function
similarly
shown
d2−d1
1−2d1
lemma
follows
convexity
max
max
therefore
must
ˆs1
ˆs2
together
proves
bs-bc
remark
proof
proposition
indicates
binary
uniform
source
hamming
distortion
measure
loss
optimality
far
theorem
con-
cerned
restricting
pu|s
binary
symmetric
channel
provides
certain
justiﬁcation
choice
auxiliary
random
variable
note
rate
pairs
py1|x
py2|x
contained
py1
y2|x
py1
y2|x
easy
see
bs-bc
κc1
py1
y2|x
implies
pyi|x
implies
bs-bc
κc2
py1
y2|x
observation
together
proposition
shows
binary
uniform
source
hamming
distortion
measure
theorem
equivalent
following
explicit
result
theorem
min
ˆs2|s
ˆs2
≤d2
ˆs2
bs-bc
κc1
py1
y2|x
combining
proves
easy
see
ˆs1
ˆs2
contained
ˆs1
ˆs2
note
ˆsi
ˆsi
one
readily
prove
invoking
fact
ˆs1
ˆs2
convex
set
since
obviously
true
remains
proved
ˆs1
ˆs2|s
bs-bc
symmetry
bs-bc
κc2
py1
y2|x
deﬁne
min
bs-bc
κc1
py1
y2|x
min
bs-bc
κc2
py1
y2|x
obvious
maxn
py1|x
py2|x
i.e.
necessary
condition
stated
theorem
least
strong
one
implied
source-channel
separation
theorem
point-to-point
communication
systems
shall
show
cases
possible
determine
whether
equal
strictly
greater
without
explicit
characterization
py1
y2|x
recall
bs-bc
given
set
satisfying
veriﬁed
that3
cid:17
2d2
log
cid:16
1−d2
2d1
log
cid:16
1−d1
cid:17
2d2
2d1
dr2
dr1
cid:12
cid:12
cid:12
cid:12
α=0
dr1
cid:12
cid:12
cid:12
cid:12
dr2
view
fact
dr2
function
dr1
monotonically
decreasing
clear
bs-bc
py1|x
py2|x
one
following
conditions
satisﬁed
1−2d2
py1|x
1−2d1
py1|x
py2|x
cid:17
1−2d1
log
cid:16
1−d1
cid:17
1−2d2
log
cid:16
1−d2
py2|x
py1|x
py2|x
observation
together
well
fact
py1
y2|x
py1|x
py2|x
yields
following
result
1−hb
py1|x
proposition
1−2d1
1−2d2
1−2d1
log
cid:16
1−d1
cid:17
1−2d2
log
cid:16
1−d2
cid:17
1−hb
py2|x
py1
py2
symmetry
py1
py2
1−hb
py2|x
1−hb
py1|x
simple
py2
py1
1−2d2
1−2d1
1−2d2
log
cid:16
1−d2
cid:17
cid:17
1−2d1
log
cid:16
1−d1
sufﬁcient
condition
py2
py1
remark




py1|x
py2|x
maxpx
min
capacity
compound
channel
py1|x
py2|x
proposition
indicates
sufﬁcient
condition
also
necessary
py1|x
py2|x
py1|x
py1|x
py2|x
py2|x
special
case
shown
py1|x
py2|x
hand
special
case
proposition
gives
maxn
py1|x
py2|x
since
py1|x
py2|x
min
py1|x
py2|x
necessary
condition
stated
theorem
sufﬁcient
general
every
py1|x
set
smaller
strictly
max
py1
y2|x
note
py1|x
py2|x
monotonically
decreasing
concave
deﬁne
lim
r1↓0
py2|x
py1|x
lim
r1↑c
py1|x
py1|x
similarly
set
max
py1
y2|x
every
py2|x
deﬁne
lim
r2↓0
py1|x
py2|x
lim
r2↑c
py2
py2|x
consider
case
clear
must
κ⋆c
py1|x
2d2
2d1
py1|x
similarly
must
κ⋆c
py2|x
cid:17
2d2
log
cid:16
1−d2
2d1
log
cid:16
1−d1
cid:17
moreover
since
py1|x
follows
satisﬁed
simultaneously
following
result
simple
consequence
observation
proposition
max
py1|x
py2|x
3we
set
1−2d2
log
cid:16
1−d2
cid:17
1−2d1
log
cid:16
1−d1
cid:17
cid:17
2d2
log
cid:16
1−d2
cid:17
2d1
log
cid:16
1−d1
2d2
2d1
py1|x
symmetry
cid:17
2d1
log
cid:16
1−d1
2d2
log
cid:16
1−d2
cid:17
2d1
2d2
py2|x
channel
integer
said
circularly
symmetric
deﬁnition
see
also
deﬁnition
exists
bijective
function
y|0
denotes
k-times
self-composition
identity
function
note
binary
symmetric
channel
circularly
symmetric
given
bs-bc
first
consider
case
py1
y2|x
bs-bc
without
loss
generality
shall
assume
theorem
proposition
theorem
proposition
bs-bc
bs-bc
hand
necessary
condition
implied
source-channel
separation
theorem
point-to-point
commu-
nication
systems
special
case
reduce
cid:26
achievable
uncoded
scheme
view
proposition
well
binary
erasure
channel
also
circularly
symmetric
associated
given
proposition
py1|x
py2|x
circularly
symmetric
min
bs-bc
py1
y2|x
proof
symmetry
sufﬁces
consider
case
let
csc
py1
y2|x
denote
superposition
coding
inner
satisfying
bound
py1
y2|x
i.e.
set
y1|v
xpy1
y2|x
light
lemma
uniform
distribution
forms
sufﬁcient
class
distributions
broadcast
channel
py1
y2|x
py1|x
py2|x
circularly
symmetric
consequence
one
readily
show
csc
py1
y2|x
py1
y2|x
py1|x
note
bs-bc
κc1
py1
y2|x
must
py1|x
implies
together
fact
dr2
bs-bc
py1|x
therefore
dr1
bs-bc
κc1
py1
y2|x
bs-bc
κcsc
py1
y2|x
since
csc
py1
y2|x
py1
y2|x
py1
y2|x
proof
complete
proceed
consider
several
concrete
examples
cid:17
2p2
log
cid:16
1−p2
cid:17
2p1
log
cid:16
1−p1
2p2
2p1
py1|x
hence
follows
proposition
cid:17
2d2
log
cid:16
1−d2
2d1
log
cid:16
1−d1
cid:17
2p2
2d2
2d1
2p1
cid:17
2p2
log
cid:16
1−p2
2p1
log
cid:16
1−p1
cid:17
example
satisﬁed
0.035
0.095
0.15
0.2
be-bc
next
consider
case
py1
y2|x
be-bc
without
loss
generality
shall
assume
proposition
proposition
min
bs-bc
be-bc
expressions
be-bc
found
respectively
clear
exists
bs-bc
κ⋆β
implies
equality
must
hold
moreover
equalities
must
hold
consequence
therefore
max
one
readily
recover
theorem
invoking
theorem
light
lemma
optimization
problem
maximum
value
attained
2d2
log
cid:16
1−d2
cid:17
cid:17
2d1
log
cid:16
1−d1
2d2
2d1
gives
necessary
sufﬁcient
condition
hold
condition
obtained
propo-
sition
proposition
bsc
bec
finally
consider
py1
y2|x
bsc
bec
proposition
case
min
bs-bc
bsc
bec
note
maxn
case
bsc
bec
see
section
iii-c
fact
dr2
dr1
one
readily
verify
view
expression
bs-bc
bsc
bec
bs-bc
be-bc
consequence
max
2d2
log
cid:16
1−d2
cid:17
cid:17
2d1
log
cid:16
1−d1
case
shall
show
2d2
2d1
combining
observation
fact
bs-bc
bsc
bec
d1≥d2⇒
bs-bc
proves
proceed
show
that5
view
sufﬁces
show
note
hold
moreover
implies
therefore
argument
similar
used
ﬁnish
proof
quadratic
gaussian
case
let
t=1
system
i.i.d
vector
gaussian
process
zero-mean
gaussian
random
vector
positive
deﬁnite
covariance
matrix
following
deﬁnition
quadratic
gaussian
counterpart
deﬁnition
deﬁnition
let
non-negative
number
non-empty
compact
set
ℓ×ℓ
positive
semi-deﬁnite
matrices
say
achievable
system
every
exist
encoding
function
rℓ×m
decoding
functions
rℓ×m
min
di∈di
xt=1
cid:13
cid:13
cid:13
cid:13
cid:13
ˆsi
ˆsi
cid:13
cid:13
cid:13
cid:13
cid:13
set
achievable
system
denoted
remark
clear
¯d1
¯d2
bs-bc
bsc
bec
bs-bc
bsc
bec
¯di
di∈di
cid:22
cid:22
bsc
bec
given
set4
satisfying
furthermore
determine
whether
¯d1
¯d2
loss
generality
setting
ˆsm
sm|y
xt=1
ˆsi
ˆsi
cid:22
moreover
easy
see
true
therefore
sufﬁces
consider
property
bsc
bec
bsc
bec
¯di
cid:22
cid:22
henceforth
shall
implicitly
assume
satisﬁed
4it
follows
lemma
bsc
bec
convex
set
5this
result
implied
proposition
˜st
proceed
introduce
corresponding
system
quadratic
gaussian
setting
establish
associated
source-channel
separation
theorem
let
˜st
zero-mean
gaussian
random
vector
positive
deﬁnite
covariance
matrix
˜si
˜ℓi
random
vector
covariance
matrix
denoted
˜si
t=1
i.i.d
copies
˜s1
˜s2
deﬁne
let
˜s1
˜s2
˜st
deﬁnition
let
non-negative
number
˜d1
non-
empty
compact
subset
˜d1
cid:22
˜d1
cid:22
˜d2
non-empty
compact
subset
˜d2
cid:22
˜d2
cid:22
˜s2
say
˜d1
˜d2
achievable
system
every
˜ℓ2×m
exist
encoding
function
˜ℓ2×m
well
decoding
functions
˜ℓ2×m
˜ℓ1×m
˜st
˜ℓ×m
min
˜d1∈
˜d1
min
˜d2∈
˜d2
cid:13
cid:13
cid:13
cid:13
cid:13
xt=1
cid:13
cid:13
cid:13
cid:13
cid:13
xt=1
ˆs1
ˆs1
˜d1
cid:13
cid:13
cid:13
cid:13
cid:13
˜s2
ˆs2
˜s2
ˆs2
˜d2
cid:13
cid:13
cid:13
cid:13
cid:13
set
achievable
˜d1
˜d2
system
denoted
˜γg
remark
allow
non-deterministic
functions
long
markov
chains
˜sm
ˆsm
˜sm
˜sm
˜sm
preserved
ˆsm
˜sm
note
cid:18
˜s1
˜s2
˜s1
˜s1
˜st
˜s2
˜s1
˜s1
˜s2
˜s2
cid:19
˜s2
˜st
moreover
˜s1
˜s2
write
˜d1
cid:18
˜d1,1
˜d2,1
˜d1,2
˜d2,2
cid:19
˜d1
˜d1
˜di
˜ℓi
˜ℓi
matrix
following
source-channel
separation
theorem
simple
translation
theorem
quadratic
gaussian
setting
proof
omitted
theorem
˜d1
˜d2
˜γg
˜s1|
˜s2
˜d1
˜s2
˜d2
˜κc1
py1
y2|x
σ−1
˜s2
˜s1
˜s1
˜s2
˜d1,1
˜d2,1|
˜s2
˜s1
˜s1|
˜s2
˜s2
˜d1
min
˜d1∈
˜d1
˜d2
min
˜d2∈
˜d2
log
cid:16
log
cid:16
˜s2
˜d2|
cid:17
solution6
˜d2,2
˜d1,2
remark
veriﬁed
˜s1|
˜s2
˜d1
min
ˆs1|
˜s−
ˆs1
˜s−
ˆs1
˜d1
˜s2
˜d2
min
˜s2−
ˆs2
˜s2−
ˆs2
˜d2
ˆs2|
˜s2
˜s2
ˆs2
6if
˜d2,2
invertible
˜d1,2
˜d−1
2,2
highlights
similarity
theorem
the-
orem
quadratic
gaussian
setting
source-channel
separation
theorem
system
leveraged
derive
necessary
condition
system
let
denote
convex
closure
set
satisfying
log
cid:16
|σs||d1
|d1||σs
cid:17
log
cid:16
|σs
σz|
|d2
σz|
cid:17
let
denote
convex
closure
set
satisfying
log
cid:16
|σs
σz|
|d1
cid:17
log
cid:16
|σs||d2
σz|
|d2||σs
σz|
cid:17
setting
−1σs
write
equivalently
convex
hull
set
log
cid:16
|σu
σ−1
log
cid:16
|σu
σ−1
cid:17
cid:17
|d1|
|σs|
satisfying
cid:22
cid:22
similarly
written
equivalently
convex
hull
set
|σu
σ−1
log
cid:16
log
cid:16
|σu
σ−1
|σs|
cid:17
cid:17
|d2|
satisfying
cid:22
cid:22
let
zero-mean
gaussian
random
vector
positive
deﬁnite
covariance
matrix
recall
deﬁnition
section
following
ˆs1
ˆs2
result
provides
connection
ˆs1
ˆs2
proposition
ˆsi
ˆsi
cid:17
ˆs1
ˆs2
ˆsi
ˆsi
independent
zero-mean
moreover
gaussian
random
vectors
covariance
matrices
respectively
cid:22
cid:22
cid:22
˜s1
ˆs1|
˜s2
ˆs1
ˆs2
ˆs1
ˆs2
log
cid:16
|σs|
|d2|
cid:17
log
cid:16
|σs|
|d1|
cid:17
proof
symmetry
sufﬁces
prove
given
satisfying
cid:22
cid:22
ﬁnd
jointly
distributed
independent
zero-mean
gaussian
random
vectors
covariance
matrices
respectively
note
ˆs1
ˆs2
jointly
distributed
subject
constraints
ˆsi
ˆsi
ˆs1
ˆs2
form
markov
chain
cid:17
ˆs1|u
|d1|
ˆs2
|σs|
cid:17
log
cid:16
|σu
σ−1
log
cid:16
|σu
σ−1
equalities
hold
ˆsi
ˆsi
independent
zero-mean
gaussian
random
vectors
co-
variance
matrices
−di
respectively
desired
result
follows
convexity
ˆs1
ˆs2
prove
sufﬁces
consider
non-degenerate
case
cid:22
general
case
cid:22
cid:22
cid:22
proved
via
simple
limiting
argument
let
zero-mean
gaussian
random
vector
independent
covariance
matrix
σoi
d−1
clear
σ−1
ˆs1|u
o1|u
ˆs2
λr1
ˆs1|u
ˆs2
max
∈r1
ˆs1
ˆs2
max
max
o1|u
max
cid:22
cid:22
max
cid:22
cid:22
log
cid:16
|σs
σo1
|σo1
cid:17
|σs
σo2
|σs
σo2
cid:17
cid:17
|d1|
log
cid:16
log
cid:16
|σu
σ−1
log
cid:16
|σs|
cid:17
|σu
σ−1
max
∈r1
λr1
due
conditional
version
corollary
together
convexity
ˆs1
ˆs2
proves
veriﬁed
ˆs2|u
ˆs2
log
cid:16
|σs|
|d2|
cid:17
ˆs1
ˆs2|u
ˆs1
ˆs1|u
ˆs1
log
cid:16
|σs|
|d1|
cid:17
follows
immediately
theorem
exist
κci
py1
y2|x
proof
symmetry
sufﬁces
prove
t=1
i.i.d
vector
gaussian
process
inde-
let
pendent
t=1
zero-
mean
gaussian
random
vector
positive
deﬁnite
covariance
matrix
deﬁne
˜s1
˜s2
consider
arbitrary
tuple
given
according
deﬁnition
exist
encoding
function
rℓ×m
decoding
functions
rℓ×m
satisfying7
xt=1
min
di∈di
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
therefore
one
ﬁnd
sequence
converging
zero
lim
k→∞
xt=1
note
lim
k→∞
lim
k→∞
lim
k→∞
xt=1
xt=1
xt=1
˜s1
˜s1
˜s1
˜s2
˜s2
˜s1
lim
k→∞
xt=1
˜s2
˜s2
xt=1
lim
k→∞
˜d2
˜s2
˜s2
consequence
must
˜d1
˜d2
˜γg
˜d1
cid:18
cid:19
follows
theorem
cid:16
log
cid:16
|σs
−1σs|
|d1
−1d1|
cid:17
κc1
py1
y2|x
log
cid:16
|σs
|d2
cid:17
cid:17
7we
denoted
ˆsi
stress
dependence
one
choose
positive
deﬁnite
covariance
matrix
arbitrarily
moreover
veriﬁed
|σs
−1σs|
|d1
−1d1|
σ−1
σ−1
|d−1
|σ−1
|σs||d1
|d1||σs
completes
proof
theorem
note
coincides
capacity
region
vector
gaussian
broadcast
channel
covariance
power
constraint
noise
covariances
d−1
σ−1
cid:22
reason
shall
denote
alternatively
g-bc
even
well-deﬁned
one
obtain
following
reﬁned
necessary
condition
case
py1
y2|x
scalar
gaussian
broadcast
channel
theorem
py1
y2|x
g-bc
exist
cid:22
g-bc
g-bc
proof
according
remark
deﬁnition
loss
generality
setting
ˆsm
consequence
must
cid:22
py2|x
degraded
respect
py1|x
one
readily
adapt
proof
theorem
current
setting
show
exist
cid:22
sm|y
κci
g-bc
follows
proposition
g-bc
g-bc
g-bc
given
set
satisfying
log
cid:16
cid:17
log
cid:16
cid:17
note
κc1
g-bc
implies
log
cid:16
|σs|
|di|
cid:17
log
cid:16
cid:17
moreover
view
proposition
therefore
log
cid:16
|σs|
|d2|
cid:17
log
cid:16
|σs|
|d1|
cid:17
existence
ˆs1
ˆs2
ˆsi
ˆsi
ˆs1
ˆs2
κci
g-bc
fact
loss
generality
assuming
ˆsi
ˆsi
independent
zero-mean
gaussian
random
vectors
covariance
matrices
respectively
note
restricted
form
equivalently
s|s
deﬁnition
zero-mean
gaussian
ˆs1
ˆs2
random
vector
independent
therefore
removing
restriction
lead
stronger
necessary
condition
provides
certain
justiﬁcation
choice
auxiliary
random
variable
essential
loss
generality
henceforth
focus
non-degenerate
case
deﬁne
min
g-bc
g-bc
clear
exists
log
cid:16
|σs||d1
|d1||σs
cid:17
log
cid:16
|σs
|d2
cid:17
log
cid:16
log
cid:16
cid:17
rewritten
cid:17
cid:16
|σs||d1
σz|
|d1||σs
σz|
cid:17
cid:16
|d2
|σs
cid:17
hence
cid:16
|d2
σz|
|σs
σz|
cid:17
cid:16
|σs||d1
σz|
|d1||σs
σz|
cid:17
i.e.
cid:16
|σs||d1
|d1||d2
cid:17
cid:16
|σs
|d2
cid:17
moreover
must
exist
sequence
positive
deﬁnite
matrices
log
cid:16
|σs||d1
cid:17
|d1||σs
log
cid:16
|σs
cid:17
cid:17
log
cid:16
log
cid:16
cid:17
|d2
cid:17
lim
k→∞
lim
k→∞
κc1
g-bc
κc2
g-bc
cid:22
cid:22
cid:22
completes
proof
theorem
case
cid:22
cid:22
cid:22
one
show
leveraging
proposition
equivalent
implies
lim
k→∞
cid:16
|σs||d1
cid:17
|d1||d2
cid:16
|σs
cid:17
|d2
cid:18
σz1
σz2
cid:19
combining
gives
sup
cid:16
|σs||d1
σz|
|d1||d2
σz|
cid:17
cid:16
|σs
|d2
cid:17
therefore
theorem
inf
sup
cid:16
|σs||d1
σz|
|d1||d2
σz|
cid:17
cid:16
|σs
|d2
cid:17
inﬁmum
subject
constraints
cid:22
case
cid:22
cid:22
satisfying
cid:22
cid:22
simplify
sup
cid:16
|σs||θ1
σz|
|θ1||θ2
σz|
cid:17
cid:16
|σs
|θ2
cid:17
one
readily
recover
theorem
setting
partition
form
zero-mean
gaussian
random
vector
positive
deﬁnite
covariance
matrix
σsi
t=1
reconstructed
require
receiver
subject
positive
deﬁnite
covariance
distortion
constraint
corresponds
case
cid:22
cid:22
cid:22
partitioned
form
cid:18
di,1
di,2
cid:19
therefore
lower
bound
also
applicable
restricting
special
block
diagonal
form8
cid:18
σz2
cid:19
one
deduce
inf
inf
sup
σz2
sup
σz2
lim
λ→∞
cid:16
|σs||d1
σz|
|d1||d2
σz|
cid:17
cid:16
|σs
|d2
σz|
cid:17
cid:16
|σs||d1,2
σz2
|d1||d2,2
σz2
cid:17
cid:16
|σs2
σz2
|d2,2
σz2
cid:17
inﬁmum
subject
constraints
cid:22
potentially
weakened
lower
bound
specialized
case
least
tight
theorem
note
8here
identity
matrix
positive
deﬁnite
matrix
partitioned
form
|σs||d1,2
σz2
|d1||d2,2
σz2|
|σs
σz||d1,2
σz2|
|d1
σz||d2,2
σz2|
|σs
|d1,1
σz1||d2,2
σz2|
|σs
|λ1
σz1||λ2
σz2
|σs2
σz2
|d2,2
σz2
|σs2
σz2
|λ2
σz2
substituting
gives
sup
|σs
|λ1
σz1
||λ2
σz2|
cid:17
cid:16
cid:16
|σs2
σz2
|λ2
σz2
cid:17
partitioned
form
setting
recovers
corollary
equivalent
form
lower
bound
ﬁrst
obtained
bross
via
different
approach
special
case
worth
mentioning
source-channel
separation
known
suboptimal
general
problem
somewhat
surprisingly
lower
bound
derived
aid
source-channel
separation
theorem
i.e.
theorem
turns
tight
theorem
achievable
class
hybrid
digital-analog
coding
schemes9
section
iv.b
therefore
application
source-channel
separation
theorems
restricted
relatively
limited
scenarios
separation
architecture
optimal
also
used
prove
optimality
non-separation
based
schemes
determine
performance
limits
certain
scenarios
separation
architecture
suboptimal
vii
conclusion
established
source-channel
separation
theorem
leveraged
derive
general
necessary
condition
source
broadcast
problem
intriguing
note
certain
cases
see
e.g.
theorem
theorem
necessary
condition
takes
form
comparison
two
capacity
regions
means
coincidence
fact
suggests
new
direction
explored
establish
stronger
converse
results
source
broadcast
problem
acknowledgment
authors
would
like
thank
prof.
chandra
nair
valuable
help
9the
hybrid
scheme
viewed
extremal
case
class
schemes
khezeli
chen
outer
bounds
admissible
source
region
broadcast
channels
correlated
sources
ieee
trans
inf
theory
vol
4616–4629
sep.
2015
references
goblick
jr.
theoretical
limitations
transmission
data
analog
sources
ieee
trans
inf
theory
vol
it-11
558–567
oct.
1965
mittal
phamdo
hybrid
digital-analog
hda
joint
source-
channel
codes
broadcasting
robust
communications
ieee
trans
inf
theory
vol
1082–1102
may
2002
reznic
feder
zamir
distortion
bounds
broadcasting
bandwidth
expansion
ieee
trans
inf
theory
vol
3778–3788
aug.
2006
narayanan
caire
wilson
duality
broadcasting
bandwidth
expansion
bandwidth
compression
proc
ieee
int
symp
inform
theory
isit
nice
france
jun
2007
1161–1165
prabhakaran
puri
ramchandran
hybrid
digital-analog
codes
source-channel
broadcast
gaussian
sources
gaussian
channels
ieee
trans
inf
theory
vol
4573–4588
jul
2011
minero
lim
y.-h.
kim
uniﬁed
approach
hybrid
coding
ieee
trans
inf
theory
vol
1509–1523
apr
2015
ozarow
source
coding
problem
two
channels
three
receivers
bell
syst
tech
vol
1909–1921
dec.
1980
wang
viswanath
vector
gaussian
multiple
description
individual
central
receivers
ieee
trans
inf
theory
vol
2133–2153
jun
2007
wang
viswanath
vector
gaussian
multiple
description
two
levels
receivers
ieee
trans
inf
theory
vol
401–410
jan.
2009
chen
rate
region
gaussian
multiple
description
coding
individual
central
distortion
constraints
ieee
trans
inf
theory
vol
3991–4005
sep.
2009
song
shao
chen
sum
rate
multiple
description
coding
symmetric
distortion
constraints
ieee
trans
inf
theory
submitted
publication
tian
diggavi
shamai
approximate
characterizations
gaussian
source
broadcast
distortion
region
ieee
trans
inf
theory
vol
124–136
jan.
2011
tan
khisti
soljanin
distortion
bounds
broadcasting
binary
source
binary
erasure
channels
proc
13th
canadian
workshop
information
theory
toronto
canada
jun
2013
49–54
tian
chen
diggavi
shamai
shitz
optimality
approximate
optimality
source-channel
separation
networks
ieee
trans
inf
theory
vol
904–918
feb.
2014
bross
lapidoth
tinguely
broadcasting
correlated
gaus-
sians
ieee
trans
inf
theory
vol
3057–3068
jul
2010
tian
diggavi
shamai
shitz
achievable
distortion
region
sending
bivariate
gaussian
source
gaussian
broadcast
channel
ieee
trans
inf
theory
vol
6419–6427
oct.
2011
gao
tuncel
separate
source-channel
coding
transmitting
correlated
gaussian
sources
degraded
broadcast
channels
ieee
trans
inf
theory
vol
3619–3634
jun
2013
song
chen
tian
broadcasting
correlated
vector
gaus-
sians
ieee
trans
inf
theory
vol
2465–2477
may
2015
kramer
shamai
shitz
capacity
classes
broadcast
channels
receiver
side
information
proc
ieee
inf
theory
workshop
lake
tahoe
sep.
2007
313–318
nair
capacity
regions
two
new
classes
two-receiver
broadcast
channels
ieee
trans
inf
theory
vol
4207–4214
sep.
2010
gamal
y.-h.
kim
network
information
theory
cambridge
u.k.
cambridge
univ
press
2011
wang
chen
zhao
cuff
permuter
role
reﬁnement
layer
multiple
description
coding
scalable
coding
ieee
trans
inf
theory
vol
1443-1456
mar
2011
wyner
ziv
theorem
entropy
certain
binary
sequences
applications
part
ieee
trans
inf
theory
vol
it-19
769–772
nov.
1973
wang
kulkarni
poor
finite-dimensional
bounds
binary
ldpc
codes
belief
propagation
decoders
ieee
trans
inf
theory
vol
56–81
jan.
2007
liu
viswanath
extremal
inequality
motivated
multi-
terminal
information-theoretic
problems
ieee
trans
inf
theory
vol
1839–1851
may
2007
