ima
journal
applied
mathematics
2013
1−28
preprint
doi
10.1093/imamat/
new
mode
reduction
strategy
generalized
kuramoto-sivashinsky
equation
schmuck1,2
pradas1
pavliotis2
kalliadasis1
department
chemical
engineering
imperial
college
london
sw7
2az
department
mathematics
imperial
college
london
sw7
2az
consider
generalized
kuramoto-sivashinsky
gks
equation
model
prototype
wide
va-
riety
physical
systems
ﬂame-front
propagation
general
front
propagation
reaction-
diffusion
systems
interface
motion
viscous
ﬁlm
ﬂows
aim
develop
systematic
rigorous
low-dimensional
representation
gks
equation
purpose
approximate
renormalization
group
equation
qualitatively
characterized
rigorous
error
bounds
formulation
allows
new
stochastic
mode
reduction
guaranteeing
optimality
sense
maximal
information
entropy
herewith
noise
systematically
added
reduced
gks
equation
gives
rigorous
analytical
explanation
origin
new
results
would
allow
reliably
perform
low-dimensional
numerical
computations
account-
ing
neglected
degrees
freedom
systematic
way
moreover
presented
reduction
strategy
might
also
useful
applications
classical
mode
reduction
approaches
fail
com-
plicated
implemented
keywords
generalized
kuramoto-sivashinsky
equation
renormalization
group
method
stochastic
mode
reduction
introduction
consider
abstract
evolution
equations
form
+au
x,0
1..1
denotes
general
linear
operator
represents
nonlinear
term
burgers
type
i.e.
uux
well
known
equations
class
include
e.g
viscous
burgers
equation
korteweg-de
vries
equation
benney-lin
equation
start
performing
formal
renor-
malization
group
approach
general
form
1..1
subsequently
focus
rigorous
low-dimensional
reduction
generalized
kuramoto-sivashinsky
gks
equation
tu+l
uux+k
uxx
uxxx
uxxxx
x,0
1..2
periodic
domain
−ap
arbitrary
period
solu-
tion
1..2
represents
example
ﬂuctuations
around
ﬁxed
mean
height
one-dimensional
surface
substrate
point
time
e.g
thin
ﬁlm
ﬂowing
vertical
wall
e.g
also
take
∈hq
periodic
initial
condition
i.e.
x+l
cid:13
institute
mathematics
applications
2005
rights
reserved
gks
equation
type
1..1
uux
+d¶
+n¶
cid:0
cid:1
1..3
rigorous
dimensional
reduction
gks
equation
special
interest
hamilto-
nian
system
intrinsic
invariant
measure
makes
direct
application
stochastic
mode
reduction
strategies
difﬁcult
see
instance
noteworthy
gks
equation
retains
fundamental
elements
nonlinear
process
involves
wave
evolution
simplest
possible
nonlinearity
uux
instability
energy
production
uxx
stability
energy
dissipation
uxxxx
dispersion
uxxx
notice
nonlinearity
arises
effectively
nonlinear
correction
phase
speed
nonlinear
kinematic
effect
captures
larger
waves
move
faster
smaller
ones
context
thin-ﬁlm
ﬂows
terms
uux
uxx
uxxx
uxxxx
due
interfacial
kinematics
associated
mean
ﬂow
inertia
viscosity
surface
tension
respectively
corresponding
parameters
pos-
itive
measuring
relative
importance
effects
strength
nonlinearity
particular
associated
scaling
velocity
hence
time
addition
rpa
udx
measure
volume
liquid
conservation
property
systems
whose
spatial
average
drift
simpliﬁed
form
1..2
obtained
appropriately
rescaling
equivalent
setting
keeping
notation
dimensionless
quantities
many
nonlinear
time-dependent
problems
science
engineering
equations
form
1..1
complex
fully
resolved
inﬂuence
neglected
degrees
freedom
clear
priori
problem
exists
independently
spatial
dimensions
1..1
hence
gks
equation
also
reliable
resolution
high
dimensional
problems
well-known
issue
computational
science
one
numerically
deal
ﬁnite
number
degrees
freedom
hence
strong
need
ﬁnite
dimensional/
dimensionally
reduced
formulations
turn
would
allow
studies
long
time
behavior
physical
systems
modeling
ocean-
atmosphere
mainly
generates
weather
one
important
example
one
characteristic
timescale
several
years
ocean
contrast
couple
days
governing
atmospheric
structures
cyclones
consequence
characteristic
feature
many
physical
systems
presence
fast
slow
degrees
freedom
relevant
information
system
long
time
behavior
often
primarily
contained
slow
modes
hamiltonian
systems
mode
reduced
mathematical
formulation
generally
obtained
mori-zwanzig
optimal
prediction
techniques
described
later
focus
nonlinear
equations
showing
hamiltonian-like
structure
exempliﬁed
equation
1..2
provide
systematic
e.g
via
method
maximum
entropy
principle
rigorous
e.g
via
error
estimates
framework
reliable
derivation
low-dimensional
/slow-
mode
representations
equations
first
recall
general
often
hoc
approximation
decomposing
problem
interest
+we
reads
fast
slow
modes
equation
1..1
purely
formal
splitting
i.e.
standard
notation
applied
literature
1..4
small
parameter
mediates
timescale
separation
mode
reduction
strategies
adiabatic
elimination
invariant
manifolds
optimal
prediction
tools
eliminate
fast
modes
derive
appropriate
equations
slow
modes
remark
especially
systems
spatio-temporal
chaos
like
gks
equation
reduction
needs
carefully
performed
order
lose
relevant
dynamical
characteristics
full
system
also
study
emphasizes
importance
careful
ﬁnite
dimensional
approx-
imations
computational
schemes
exploiting
structure
galerkin
methods
strategy
deﬁning
invariant
manifold
almost
classical
example
existence
inertial
manifold
equation
obtained
1..2
shown
inertial
manifold
ﬁnite-dimensional
exponentially
attracting
positively
invariant
lipschitz
manifold
principle
idea
determine
map
rewrite
equation
1..1
low-dimensional
form
tv+pb
v+f
v+f
+apv
1..5
i−p
projections
onto
orthogonal
subspaces
v⊕w
strategy
determine
general
galerkin
spaces
example
suggested
equation
approach
performed
also
understood
formal
feasible
procedure
derive
asymptotic
invariant
manifold
see
1..8
1..9
analytical
results
characterization
global
attracting
set
kuramoto-sivashinsky
equation
so-called
background
ﬂow
method
via
capillary
burgers
equation
latter
also
forms
best
known
bound
context
analyticity
solutions
studied
open
questions
answers
classical
separation
1..4
splitting
1..4
approximation
valid
sense
question
often
answered
literature
outset
separation
1..4
assumed
see
instance
studies
heuristically
motivate
timescale
mediation
separation
slow
fast
scales
form
1..4
present
work
aims
provide
rigorous
foundation
theorem
3..1
following
estimate
1..6
suppose
satisfy
gevrey
regularity
characterized
parameter
improve
1..6
following
way
6ce
+exp
cid:16
1/4
cid:17
ku−v
ku−v
6ce
+exp
cid:18
1/4exp
cid:18
1/4
cid:19
cid:19
cid:19
1..7
pointed
estimates
also
account
reduction
slow
degrees
freedom
error
account
fast
degrees
freedom
equation
slow
modes
purpose
apply
abstract
approach
extended
general
multiscale
problems
see
method
ﬁrst
introduced
quantum
ﬁeld
theory
tool
perform
scale
transformations
method
became
popular
wilson
work
kondo
problem
formally
provide
separation
1..4
means
ﬁrst
obtain
approximation
form
+avv
+pnb
=−e
1..8
perturbation
force
originating
renormalization
method
solution
equations
+avv
+pnb
+qnb1
1..9
pnu
i−pn
qnu
projections
onto
normalized
slow
fast
manifolds
respectively
since
analytically
solve
end
equation
slow
variable
estimates
1..6
1..7
make
reduction
1..8
rigorous
moreover
equation
1..9
interpreted
map
onto
asymptotic
invariant
manifold
also
pointed
stage
approximation
1..8
alone
satisfactory
since
fast
variable
contained
inﬁnite
dimension
hence
entirely
resolved
numerically
give
answer
problem
last
question
iii
principle
maximum
entropy
moreover
question
particular
relevance
since
fast
modes
prevent
existence
canonical
invariant
measure
measure
makes
classical
reduction
methods
mori-
zwanzig
optimal
prediction
feasible
require
choice
less
physically
founded
non-invariant
measure
see
also
question
iii
different
methodology
proposed
iii
kind
information
need
carry
inﬁnite
dimensional
fast
degrees
freedom
ﬁnite
dimensional
slow
ones
end
derive
stochastic
evolution
equation
resolved
slow
variable
properly
including
necessary
information
unre-
solved
fast
variable
maximum
information
entropy
principle
introduced
principle
require
statistical
data
deﬁne
fourier
modes
turns
asymptotic
behavior
time
weighted
variance
fast
modes
sufﬁcient
necessity
strong
assumption
relies
fact
gks
equation
inﬁnite-dimensional
invariant
measure
account
spatial
randomness
via
entropy
principle
theorem
4..1
conclude
fourier
modes
fast
variable
1..9
gaussian
distributed
zero
mean
hence
rigorously
obtain
noisy
gks
equation
applying
random
variable
deterministic
equation
slow
variable
1..8
herewith
analysis
explains
rig-
orously
add
random
force
gks
equation
furthermore
derivation
shows
induced
noise
accounts
unresolved
degrees
freedom
hence
becomes
less
important
increasing
number
grid
points
computations
approach
proposed
provides
alternative
mori-zwanzig
formalism
advantageously
makes
use
hamiltonian
extended
hamiltonian
structure
mori-zwanzig
techniques
related
optimal
prediction
methods
generally
rely
canonical
prob-
ability
distribution
invariant
measure
exists
naturally
hamiltonian
systems
principle
one
also
apply
techniques
systems
lack
invariant
measure
however
methodology
becomes
much
involved
situations
clear
choose
required
non-
invariant
measure
unlike
systems
canonical
invariant
measure
canonical
probability
density
hamiltonian
z−1exp
inverse
temperature
normalization
constant
referred
partition
function
mori-zwanzig
formalism
based
projection
operator
projects
functions
onto
subspace
depends
resolved
degrees
freedom
respect
canonical
density
projection
operator
deﬁned
conditional
expectation
cid:2
cid:12
cid:12
cid:3
1..10
∈l2
resolved
unresolved
variable
projection
dyson
formula
evolution
operators
provide
equation
resolved
modes
moreover
1..10
conditional
expectation
given
hence
best
least
square
approximation
function
therefore
projection
guarantees
optimality
key
idea
optimal
prediction
method
however
neither
hamiltonian
structure
invariant
measure
exists
gks
equation
therefore
obvious
derive
standard
optimality
statements
relying
conditional
probability
argument
contrast
conditional
probability
approach
achieve
optimality
sense
maximum
information
entropy
however
remark
one
also
deﬁne
projections
1..10
purpose
present
article
threefold
reliably
perform
stochastic
mode
reduction
full
gks
equation
contrast
truncated
problem
studied
principal
idea
based
abstract
approach
emphasized
earlier
derive
error
estimates
theorem
3..1
reduction
hence
provide
rigorous
support
heuristic
motivation
noisy
low
dimen-
sional
approximation
deducted
standard
method
physics
rigorously
support
stinis
assumption
gaussian
distributed
fourier
modes
end
derive
probability
distribution
theorem
4..1
fast
modes
principle
maximum
information
entropy
ﬁndings
form
bases
new
stochastic
mode
reduction
strategy
able
reduce
fast
variable
equation
slow
variable
information
fast
modes
enters
random
variable
via
force
term
slow
mode
equations
aware
previous
work
utilizes
method
context
stochastic
mode
reduction
introduce
basic
notation
well-known
results
section
1.2..
formal
derivation
equation
gks
equation
follows
section
2..
section
obtain
error
estimates
rigorously
verify
approximation
derived
section
2..
section
reduce
fast
modes
mode
reduction
strategy
based
maximum
information
entropy
principle
finally
section
close
conclusions
perspectives
1.1.
gks
equation
equation
paradigmatic
model
study
low-dimensional
spatio-temporal
chaos
weak/dissipative
turbulence
deﬁned
manneville
type
turbulence
often
characterized
formation
clearly
identiﬁable
localized
coherent
structures
appears
randomly
disturbed
system
e.g
case
rayleigh-b´enard
convection
equation
ﬁrst
proposed
model
pattern
formation
reaction-diffusion
systems
kuramoto
derivation
based
generalized
time-dependent
ginzburg-landau
equation
sivashinsky
derived
equation
asymptotic
approximation
diffusional-thermal
ﬂame
model
equation
also
describes
small-amplitude
waves
surface
thin
ﬁlm
ﬂowing
planar
inclined
wall
e.g
addition
dispersive
term
uxxx
equation
becomes
gks
equation
like
equation
reported
wide
variety
systems
plasma
waves
dispersion
due
ﬁnite
ion
banana
width
thin
ﬁlm
ﬂowing
planar
wall
near-critical
conditions
e.g
studies
developed
coherent-structure
theory
interaction
solitary-pulse
solutions
gks
equation
theory
shown
agreement
experiments
using
thin
ﬁlm
coating
vertical
ﬁber
another
hydrodynamic
system
gks
equation
applicable
well-posedness
1..1
established
example
class
generalized
burgers
equations
consist
quadratic
nonlinearity
arbitrary
linear
parabolic
part
article
veriﬁes
solvability
gks
equation
bounded
domains
studies
limit
towards
korteweg-
vries
equation
context
long-time
large-space
considerations
recent
analytical
attempts
verify
equipartition
principle
power
spectrum
periodic
solutions
deriv-
ing
bounds
space
average
|u|
certain
derivatives
see
spectral
characterization
reminiscent
white
noise
interesting
work
applies
optimal
prediction
equation
stinis
since
approach
requires
non-invariant
measure
author
constructs
gibbs
measure
required
initial
distribution
inference
empirical
data
obtained
computational
approach
allows
deﬁne
conditional
expectation
providing
optimality
orthogonal
projection
unresolved
modes
resolved
ones
however
approach
already
assumes
gaussian
distribution
outset
strategy
one
also
needs
work
truncated
equation
sufﬁcient
numerical
data
required
advance
reliable
construction
initial
distribution
1.2.
notation
functions
u∈hs
represented
fourier
series
cid:229
k∈z
ukexp
cid:18
cid:19
u−k
denotes
usual
periodic
sobolev
space
ﬁnite
norm
cid:229
fk2
k∈z
1+|k|2
cid:12
cid:12
cid:12
cid:12
subspace
˙hs
spanned
set
˙hs
cid:26
u∈hs
cid:12
cid:12
cid:12
cid:12
zpa
udx
cid:27
furthermore
square
root
latter
quantity
norm
equivalent
usual
one
denote
denoted
given
integer
deﬁne
projections
pnu
qnu
i−pn
nei
cid:12
cid:12
pnu
cid:229
ukexp
cid:18
ukexp
cid:18
cid:19
cid:19
|k|6n
qnu
cid:229
|k|
let
mention
gks
equation
preserves
mass
already
noted
section
i.e.
udx
zpa
zero-th
fourier
mode
remark
orthogonal
projection
respect
means
zpa
pnu−u
∈hs
1..17
1..11
1..12
1..13
1..14
1..15
1..16
projection
enjoys
following
well-known
property
i.e.
holds
ku−pnukhs
6cns−kkukhk
u∈hk
1..18
next
introduce
gevrey
spaces
say
function
gevrey
space
cid:229
fk2
k∈z
cid:16
1+|k|2
cid:17
exp
cid:18
q1+|k|2
cid:19
fk|2
1..19
denote
fourier
coefﬁcients
note
moreover
readily
proved
see
u∈gs
following
inequality
holds
ku−pnukhs
ns−kexp
kukgs
1..20
formal
derivation
reduced
gks
equation
noted
section
adapt
approaches
gks
equation
2.1.
projections
fast
slow
equations
apply
projections
deﬁned
1..15
equation
1..1
obtain
following
coupled
system
tv+pnb
v+w
+avv
tw+qnb
v+w
+aww
pna
apn
qna
aqn
deﬁne
large
enough
see
error
estimates
i.e
theorem
3..1
set
˜av
˜aw
˙hs
˙hs
˙hs\hs
2..1
2..2
cid:1
|k|
eigenvalues
cid:19
−id
cid:18
eigenvectors
˜av
functions
exp
cid:0
=−n
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
correspondingly
eigenvectors
˜aw
functions
exp
cid:0
cid:1
|k|
eigenvalues
cid:19
−id
cid:18
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
remark
2..1
method
formally
applied
operators
˜av
˜aw
independent
technical
step
scaling
linear
operator
subsequent
treatment
part
abstract
approach
introduced
context
ﬂuid
dynamics
2..3
rewrite
2..1
tv+
˜avv+pnb
v+w
˜aww+qnb
v+w
tw+
convenience
additionally
deﬁne
cid:18
cid:19
cid:18
˜aw
cid:19
cid:18
˜av
cid:19
cid:18
−pnb
v+w
−qnb
v+w
cid:19
hence
rewrite
2..4
following
compact
way
tu+
lu+a
2..4
2..5
2..6
subsequent
analysis
introduce
fast
time
scale
deﬁne
set
variables
2..4
becomes
˜v+e
˜av
˜v+e
pnb
˜v+
˜w+
˜aw
˜w+e
qnb
˜v+
2..6
˜u+l
˜u+e
2.2.
perturbation
expansion
equation
2..7
2..8
formally
apply
method
additionally
omit
dependence
simplicity
also
assume
either
proportional
denotes
largest
fourier
mode
galerkin
approximation
make
ansatz
naive
perturbation
expansion
˜u0
˜u1+e
˜u2
...
2..9
2..8
substituting
2..9
2..8
formally
obtain
following
sequence
prob-
lems
˜u0
˜u0
˜u1
˜u1
˜u0
˜u0
formally
solution
2..10
initial
condition
˜u0
equation
2..11
equivalently
written
˜u0
exp
−ls
˜v0
˜w0
exp
cid:0
˜aws
cid:1
2..10
2..11
2..12
solve
equation
2..10
variation
constants
formula
˜u1
exp
−ls
exp
exp
−ls
exp
−ls
2..13
˜u1
since
interested
approximations
˜u1
irrelevant
taken
zero
see
note
exp
−ls
decompose
rest
integrand
2..13
exp
exp
−ls
˜fnr
2..14
represents
part
independent
left
hand
side
2..14
˜fnr
rest
using
standard
terminology
refer
resonant
˜fnr
non-resonant
term
using
2..11
2..13
2..14
2..9
provides
following
duhamel
form
formal
perturbation
expansion
˜ue
exp
−ls
cid:18
sfr
˜fnr
cid:19
2..15
key
idea
remove
secular
term
sfr
grows
time
end
deﬁne
renormalized
function
solution
equation
slow
variable
t/e
correspondingly
satisﬁes
2..16
2..17
let
derive
explicit
form
equation
problem
expressions
identity
+w0
get
exp
exp
−ls
exp
cid:18
−pnb
+exp
−ls
−qnb
+exp
−ls
cid:19
next
identify
resonant
terms
i.e.
fourier
series
expansion
cid:229
k∈z
exp
cid:18
cid:19
exp
cid:18
exp
cid:18
k∈z
j∈z
cid:19
cid:229
cid:19
cid:229
cid:19
exp
cid:18
k+l=
cid:18
cid:19
l∈z
2..18
2..19
2..20
cid:229
cid:229
consequence
end
expressions
2..21
w0l
w0l
k+l=
|k|
|l|
w0k
k+l=
|k|6n
|l|
cid:19
exp
−sr
following
set
characterizes
resonant
indices
qnb
exp
−ls
exp
cid:18
qnb
exp
−ls
exp
−ls
cid:18
exp
−sr
cid:19
cid:229
cid:18
v0k
cid:19
exp
cid:18
cid:19
exp
−sr
resonant
terms
ﬁrst
sum
terms
holds
note
one
also
needs
look
skew-symmetric
bilinear
form
qnb
exp
−ls
leads
resonance
cid:17
cid:19
since
cid:17
cid:18
cid:12
cid:12
cid:12
−id
cid:16
cid:12
cid:12
−id
cid:0
condition
means
cid:16
cid:12
cid:12
cid:12
cid:12
cid:1
|l|
cid:9
cid:8
cid:12
cid:12
2,3,4
needs
hold
time
assuming
condition
holds
holds
characterizes
resonant
terms
second
sum
2..21
i.e.
cid:0
cid:1
condition
cid:0
cid:1
cid:12
cid:12
cid:12
immediately
obtain
additional
requirement
cid:12
cid:12
cid:12
|k|
|l|
cid:9
cid:8
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
|k|
|l|
cid:9
since
|k|
|l|
rigorous
detailed
proof
refer
appendix
immediately
recognize
2..23
also
justiﬁes
assumption
case
respect
set
resonant
indices
deﬁned
cid:8
cid:12
cid:12
cid:17
cid:16
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
2..22
2..23
considerations
determine
resonant
part
cid:20
−pnb
˜avv0
−qnb1
cid:21
given
fourier
series
expansions
corresponding
index
set
i.e.
qnb1
2il
cid:18
v00
cid:19
equation
2..14
consideration
give
non-resonant
term
˜fnr
−pnb
cid:16
+e−
˜aws
cid:17
+pnb
˜avv0
−qn
˜b1
−qn
˜b2
2..24
2..25
2..26
cid:229
cid:229
cid:229
cid:229
˜b1
˜b2
deﬁned
fourier
series
expansions
˜b1
k+l=
|l|6=|
|k|6n
|l|
cid:18
cid:18
v0k
cid:19
w0l
cid:18
w0l
cid:19
v0k
cid:19
˜b2
|k/a
|n+|l/a
|n6=|
j/a
forn=2,3,4
k+l=
|k|
|l|
cid:18
w0k
cid:19
w0le
2..24
equation
problem
fast
time
scale
˜av
pnb
cid:0
cid:1
qnb1
rescaling
denoting
pnu
qnu
+avv
+pnb
+qnb1
2..27
2..28
2..29
remark
2..2
considerations
resonant
non-resonant
terms
easily
ex-
tended
situations
replace
linear
spatial
differential
operator
pseudodifferential
operators
symbol
form
c|x
2..30
3/2
requirement
2..30
guarantees
well-posedness
gener-
alized
burgers
equations
one
needs
adapt
sets
resonant
indices
see
2..22
2..23
note
-equation
equation
2..29
simply
galerkin
approximation
gks
equation
1..1
|→¥
special
structure
renormalization
equation
2..29
unresolved
fast
variable
al-
lows
give
explicit
expression
solution
rewriting
2..29
twj
+2il
const
due
conservation
mass
1..16
immediately
obtain
solution
ei2l
2..32
solution
2..29
becomes
cid:229
v0t
=wj
x+2l
v0t
2..31
2..32
2..33
equation
2..33
shows
restriction
deﬁnition
mass
context
stochastic
mode
reduction
situation
different
see
section
4..
cid:229
cid:229
cid:229
cid:229
2.3.
construction
approximate/renormalized
solutions
order
deﬁne
renormalized
solutions
ﬁrst
determine
non-resonant
term
˜fnr
given
2..26
fact
interested
let
pfnr
2il
qfnr
=−2il
fnr
˜fnr
e−r
s−1
j|6n
+il
j|6n
k+l=
|k|6n
|l|
k+l=
|k|
|l|
k+l=
|k|6n
|l|
|l|6=|
−il
|k/a
|n+|l/a
|n6=|
j/a
forn=2,3,4
k+l=
|k|
|l|
s−1
able
deﬁne
approximate
solution
suggested
theory
obtain
respect
fast
slow
variables
e−l
fnr
t/e
pnu
qnu
pfnr
t/e
e−qn
qfnr
t/e
note
initial
data
deﬁned
pfnr
v0+e
pfnr
qfnr
renormalized
gks
equation
approximation
error
inserting
2..36
1..1
obtain
following
perturbed
gks
equation
deﬁned
1..3
given
+au
=−e
cid:16
e−l
e−l
fnr
t/e
cid:17
cid:16
e−l
fnr
t/e
e−l
cid:17
cid:16
e−l
fnr
t/e
e−l
fnr
t/e
cid:17
−apfnr
t/e
−e−l
fnr
t/e
2..34
2..35
2..36
2..37
2..38
3..1
3..2
cid:229
cid:229
cid:229
cid:229
cid:229
cid:229
cid:229
cid:229
next
study
estimates
approximate
solutions
equation
3..1
ﬁrst
step
need
investigate
non-resonant
part
fnr
approximate
solutions
lemma
3..1
let
let
initial
condition
satisfy
g∈hq
assume
solution
equation
2..29
satisﬁes
large
enough
exist
two
uniform
constants
depends
initial
conditions
depends
independent
following
estimates
true
kpnfnr
t/e
6c2e−c1n4t
e−qn
atqnfnr
t/e
cid:13
cid:13
6c2e−c1n4t
cid:13
cid:13
3..3
remark
3..1
initial
conditions
note
regularity
assumed
lemma
3..1
results
slightly
higher
since
g∈h
would
enough
regularity
assumption
enters
via
argument
based
gronwall
inequality
proof
represent
generic
constants
independent
ﬁrst
derive
estimate
3..3
expression
2..35
immediately
obtain
kpnfnr
t/e
6c2e−c1n4t
cid:209
wkh
+kw
cid:209
vkh
+kw
cid:209
wkh
3..4
used
fact
following
bound
e−r
t/e
−id
cid:12
cid:12
−id
cid:0
cid:1
last
inequality
follows
due
|l|
second
estimate
3..3
obtained
way
using
inequalities
1−e−x
xe−x
refer
interested
reader
deeper
consideration
cid:3
1/n4
cid:12
cid:12
cid:12
cid:12
6c2e−c1n4t
cid:12
cid:12
3..5
bounds
lemma
3..1
allow
control
spirit
lemma
3..2
initial
conditions
g∈hq
exist
two
constants
independent
following
estimate
holds
true
kre
kl2
6c2e−c1n4t
3..6
proof
proof
follows
way
proof
lemma
3..1.
need
take
account
expression
apply
lemma
3..1
cid:3
subsequently
write
k·k
-norm
-scalar
product
respec-
tively
lemma
3..3
initial
conditions
lemma
3..2
1/n4
solutions
equation
3..1
satisfy
exists
∈l¥
proof
give
elements
proof
case
refer
stronger
regularity
e.g
existence
results
found
formally
test
equation
3..1
using
periodicity
i.e.
∈l¥
used
inequality
cid:209
deﬁning
cid:13
cid:13
6kd
3,1
cid:1
kre
cid:0
cid:13
cid:13
3..7
holds
periodic
case
see
kre
multiply
3..7
exp
cid:0
exp
cid:1
exp
+exp
since
cid:18
exp
cid:19
=−b
exp
+exp
rewrite
3..9
cid:18
exp
cid:19
exp
subsequent
integration
together
lemma
3..2
gives
6cexp
exp
−c/e
+c/e
exp
3..8
3..9
3..10
3..11
3..12
aribtrary
choose
exp
/cc¥
constant
chosen
+c/e
exp
6c¥
cexp
3..13
cid:3
reduced
equation
resolved
slow
modes
alone
follows
immediately
using
2..37
2..29
i.e.
pfnr
t/e
+avv
+pnb
=−e
3..14
induced
force
term
deﬁned
e−l
pfnr
t/e
cid:17
pnb
cid:16
e−l
cid:17
+pnb
cid:16
e−l
pfnr
t/e
e−l
+pnb
cid:16
e−l
pfnr
t/e
e−l
pfnr
t/e
cid:17
−avpfnr
t/e
−e−l
pfnr
t/e
3..15
lemma
3..4
solutions
3..14
satisfy
pnue
proof
proof
similar
proof
lemma
3..3
∈l¥
solution
equation
2..29
lemma
3..2
exists
∩l2
cid:3
arguments
lemma
3..2
lead
following
lemma
3..5
png∈hq
exist
two
constants
indepen-
dent
following
estimate
holds
true
kge
kl2
6c2e−c1n4t
3..16
following
theorem
gives
qualitative
information
approach
quantifying
error
3..14
1..1
theorem
3..1
let
g∈h4
differ-
ence
reduced
solution
exact
solution
gks
equation
1..1
satisﬁes
following
error
estimate
suppose
∈l¥
suppose
improve
3..17
following
way
6ce
+exp
cid:16
1/4
cid:17
3..17
6ce
+exp
cid:18
1/4exp
cid:18
1/4
cid:19
cid:19
cid:19
3..18
remark
3..1
exponential
growth
time
surprising
see
example
estimate
3..12
proof
lemma
3..3.
estimate
motivates
deﬁnition
new
variable
exp
tadmor
veriﬁes
global
existence
decayed
variable
con-
servative
form
equation
assumption
direct
consequence
priori
estimates
derived
analogous
steps
proof
lemma
3..3
imposing
initial
conditions
proof
error
ku−ve
0∈h2
∈l¥
kl2
bounded
using
triangle
inequality
ku−v
kl2
6ku−u
kl2
+ku
kl2
3..19
∈l¥
ﬁrst
term
right-hand
side
3..19
represents
approximation
error
method
error
second
term
accounts
truncation
error
error
notational
brevity
introduce
error
variables
step
error
equation
error
variable
u−u
reads
xu+u
+n¶
+d¶
cid:2
first
test
3..21
i.e.
cid:0
cid:0
use
test
function
cid:0
cid:3
cid:1
cid:0
cid:1
cid:0
cid:1
cid:0
cid:1
cid:0
cid:1
cid:1
cid:0
cid:1
cid:1
cid:0
cid:1
3..20
3..21
3..22
3..23
next
add
3..22
3..23
apply
sobolev
embedding
theorem
standard
inequalities
end
deﬁning
rgk2
+k¶
rgk2i+
−3a
cid:13
cid:13
dthke
6crg
kukh1
xukh1
cid:13
cid:13
kh1
cid:13
cid:13
kh1
cid:13
cid:13
rgk2
˜crg
2crg
multiply
3..24
exp
cid:0
˜crgds
cid:1
˜crgds
cid:19
rgk
exp
cid:18
exp
cid:18
˜crgds
cid:19
˜crg
rgk
3..24
3..25
3..26
applying
corresponding
identity
based
product
rule
3..10
proof
lemma
3..3
simplify
3..26
cid:18
exp
cid:18
˜crgds
cid:19
rgk
cid:19
reduces
assumptions
theorem
3..1
integration
exp
cid:18
˜crgds
cid:19
6cke
order
get
bound
controlled
right-hand
side
3..28
take
account
deﬁnition
initial
data
2..38
i.e.
2kpfnr
6ce
3..29
3..27
3..28
since
g∈h2
hence
pfnr
∈h1
norm
bounded
independently
hence
conclude
6ce
3..30
−ve
−pnue
3..31
3..32
holds
uniformly
time
step
error
derive
estimate
error
variable
satisﬁes
equation
3..1
3..14
error
+n¶
+d¶
cid:2
cid:3
rewritten
∈h2
+n¶
+d¶
cid:0
cid:2
+pn
choosing
pnre
−ge
cid:1
cid:3
pnre
−ge
deﬁne
allows
estimate
3..32
following
way
trk
trk
cid:13
cid:13
cid:13
cid:13
kpnre
k+kge
−vvx
trk
3..33
trk
3..34
let
ﬁrst
control
term
means
−pnu
pnu
−pnu
kh1
+kpnu
kh1
+pnu
pnu
|+|
pnu
x−v
|+1/4|
pnu
trk2
kh1ke
trk+cke
+ve
kl¥
second
term
−pnu
i.e.
pnue
3..35
used
embedding
immediately
becomes
deﬁne
exp
−ct/e
cke
trk
kh1
kpnu
exp
−ct/e
cid:1
mulitply
3..33
exp
cid:0
exp
trk
exp
kh1
kh2
1/4
trk
exp
3..36
3..37
3..38
using
corresponding
identity
3..10
lemma
3..3
rewrite
3..38
cid:19
exp
trk
becomes
integration
respect
time
cid:18
exp
exp
trk
6cz
1/4
cid:16
1/4
exp
−ct/e
cid:17
exp
1−exp
+c/e
1−exp
+c/e
3..39
3..40
remaining
part
want
improve
3..40
help
gevrey
spaces
end
remark
factor
1/4
3..37
relies
interpolation
estimate
1..18
assume
solutions
improve
1..18
1..20
consequence
able
rewrite
inequality
3..40
trk
6cz
1/4
cid:16
1/4exp
cid:18
1/4
cid:19
exp
−ct/e
t−t
cid:17
exp
+c/e
exp
3..41
cid:3
stochastic
mode
reduction
section
renormalized
equations
2..29
2..31
sections
2.1
allow
rigorous
stochastic
mode
reduction
similar
spirit
mori-zwanzig
one
systems
satis-
fying
extended
generalized
hamiltonian
structure
without
canonical
invariant
measure
mori-zwanzig
formalism
assign
stochastic
process
unresolved
modes
done
applying
jaynes
maximum
entropy
principle
see
seems
reasonable
approach
problem
since
canonically
induced
probability
density
hence
maxi-
mizing
information
entropy
probability
density
fourier
modes
equivalent
maximizing
multiplicity
fourier
modes
multiplicity
means
number
different
ways
certain
state
system
achieved
states
system
highest
multiplicity
realized
nature
largest
number
ways
hence
probability
density
functions
maximum
entropy
optimal
statistical
descriptions
also
noted
system
equilibrium
probably
found
state
high-
est
multiplicity
since
ﬂuctuations
state
usually
small
measure
probability
distribution
may
also
obtained
experiments
statistical
data
probability
distribu-
tion
constructed
conditional
expectation
obtained
previously
computed
samples
used
priori
assumed
gaussian
distribution
finally
emphasize
maximum
entropy
principle
also
applied
problems
one
lacks
deterministic
data
consequence
enough
experimental
data
degrees
freedom
common
approach
model
uncertainty
use
white
noise
maximum
entropy
method
turns
attractive
alternative
allows
systematically
add
noise
gks
equation
equation
3..14
obtained
evolutionary
method
however
since
apply
entropy
maximization
principle
approximate
equation
already
neglect
information
beginning
hence
account
asymptotic
time
characterization
fast
modes
example
see
assumption
assumption
might
improved
adapted
appropriately
applications
subsequently
denotes
usual
probability
space
sample
space
-algebra
probability
measure
4.1.
problem
induced
probability
density
maximizing
information
entropy
considerations
beginning
section
assign
probability
distribution
unre-
solved
degrees
freedom
based
following
assumptions
probability
measure
density
ing
order
term
asymptotically
time
cid:20
cid:21
cid:16
cid:17
4..1
denotes
realization
j-th
fourier
mode
lead-
2..37
i.e.
e−qnt/e
assume
holds
=−r
e−2r
4..2
i.e.
4..2
holds
call
dissipation
rate
denotes
expectation
respect
probability
density
i.e.
probability
maximum
information
entropy
=−z
log
cid:18
cid:19
4..3
4..4
denotes
probability
density
j-th
fourier
mode
unresolved
variable
according
invariant
measure
deﬁned
background
information
intrinsically
given
physical
origin
remark
4..1
idea
deriving
probability
distributions
multiscale
evolution
problems
maximizing
information
entropy
seems
back
energy
argument
assumes
fast
modes
reached
already
stationary
state
provide
enough
infor-
mation
lagrange
multiplier
associated
energy
constraint
impose
assumption
instead
note
take
slightly
information
account
using
instead
decay
fast
mechanical
system
governed
hamiltonian
canonically
induces
invariant
measure
density
distribution
function
equation
4..2
accounts
fact
invariant
measure
fast
modes
simplicity
also
neglect
possible
randomness
time
reason
assumption
4..2
e−b
information
theory
entropy
related
4..4
originally
introduced
shannon
measure
maximum
information
content
message
assumptions
account
lack
free
energy
hamiltonian
thermodynamic
equilibrium
invariant
measure
achieved
via
gradient
ﬂow
respect
wasserstein
distance
fact
noted
minimizing
free
energy
respect
constant
internal
energy
equivalent
maximizing
entropy
theorem
4..1
assumptions
follows
unresolved
modes
|k|
obtained
equation
2..31
normally
distributed
zero
mean
i.e.
variance
langrange
multiplier
remark
4..2
instead
one
make
following
assumption
large
enough
times
holds
cid:20
cid:21
4..5
4..6
4..7
immediately
leads
result
fast
modes
satisfy
wk∼
variance
deﬁned
power
spectral
density
case
complete
uncertainty
see
also
section
5..
keep
considerations
simple
account
spatial
random
process
keep
time
deterministic
theorem
4..1
assumption
proof
maximize
4..4
assumptions
apply
following
constraints
4..6
consequence
assumption
hence
maximizing
entropy
subject
constraints
4..6
leads
log
lagrange
multipliers
associated
constraints
4..6
order
give
4..6
precise
meaning
write
explicit
form
equation
belonging
fourier
coefﬁcient
fast
mode
variable
qnu
solving
2..29
brieﬂy
show
constraint
4..6
means
=−z
cid:16
cid:17
cid:18
2il
v0−
cid:19
4..8
recall
const
due
conservation
mass
since
4..7
hold
arbitrary
variations
obtain
following
expression
probability
density
function
e−l
4..9
straint
4..6
i.e.
called
partition
function
determined
normalization
con-
e−l
since
constraint
4..6
quadratic
nature
represent
=−l
cid:16
cid:17
cid:16
2−m
cid:17
2il
v0−r
identities
4..11
4..12
probability
density
function
4..9
written
k√2p
c−1
|k|
normal
distribution
given
k√2p
characterized
following
moments
wdw
4..10
4..11
4..12
4..13
4..14
4..15
ﬁrst
property
4..15
together
normalization
condition
4..6
allow
deﬁne
partition
function
c−1
k√2p
4..16
|k|
remark
4..3
measure
cid:213
probability
density
function
priori
information
usually
nontrivial
task
basic
considerations
symmetries
required
ﬁnd
measure
|k|
cwk
probability
density
function
admits
simple
form
product
gaussian
distribu-
tions
i.e.
4..17
|k|
second
third
property
4..15
constraint
4..6
i.e.
4..8
obtain
|k|
conclude
4..18
lagrange
parameter
cid:0
cid:8
cid:9
cid:1
4..18
4..19
e2r
important
information
contained
formula
4..19
4..12
assert
fourier
mode
standard
deviation
k2s
need
determine
lagrange
paramter
via
4..19
4..18
property
obtain
mean
satisﬁes
|k|
cid:3
hence
approach
maximizing
generalized
information
entropy
allows
systematically
determine
probability
distribution
function
fourier
modes
unresolved
degrees
freedom
stochastic
partial
differential
equation
resolved
degrees
freedom
obtained
computing
probability
distribution
inverse
fourier
transform
sum
normally
distributed
unresolved
fourier
modes
assuming
probability
distribution
derived
long
time
regime
also
holds
unresolved
modes
initial
conditions
emphasize
approach
suggests
multiplicative
noise
compensation
unre-
solved
modes
unlike
commonly
obtained
additive
noise
mori-zwanzig
mode
reduction
moreover
estimate
3..6
correspondingly
derived
additionally
accounting
galerkin
error
shows
inﬂuence
stochastic
force
decreases
decreasing
direct
approach
replacement
white
noise
result
lemma
3..5
also
enables
direct
approach
model
unresolved
degrees
freedom
completely
unknown
kind
complete
uncertainty
generally
described
white
noise
common
widely
zero
mean
variance
equal
power
spectral
density
accepted
model
uncertainty
white
noise
hence
replace
equation
3..14
exp
−ct/e
5..1
∈l2
gaussian
random
variable
motivated
i.e.
zero
mean
suitable
variance
immediately
clear
compatible
replacement
since
5..1
satisﬁes
bound
corresponding
one
lemma
3..5.
one
follow
stinis
approach
example
order
determine
maximum
likelihood
method
discussion
conclusions
formally
developed
new
stochastic
mode
reduction
strategy
rigorous
basis
obtaining
appropriate
error
estimates
analysis
summarized
three
key
steps
follows
method
technique
turns
formal
feasible
method
decom-
pose
gks
equation
slow
fast
variables
respectively
equation
slow
modes
represents
galerkin
approximation
gks
equation
plus
additional
perturbed
force
term
also
depends
inﬁnite
dimensional
renormalized
fast
modes
important
property
technique
easily
extended
higher
space
dimensions
see
respect
method
existence
theory
equation
higher
space
dimensions
also
remark
dispersion
term
i.e
uxxx
affect
mode
reduction
analysis
error
bounds
rigorously
characterize
formal
method
qualitative
error
esti-
mates
theorem
3..1
estimates
allow
additional
direct
mode
reduction
strategy
much
simpler
straightforward
systematic
basic
idea
replace
per-
turbed
force
term
directly
white
noise
physical
motivation
simpliﬁed
reduction
fact
white
noise
well-accepted
random
model
complete
uncertainty
maximum
entropy
principle
due
lack
hamiltonian
structure
invariant
measure
apply
jaynes
maximum
entropy
principle
deﬁne
renormalized
fast
modes
random
variable
random
variable
together
renormalized
approximation
slow
variable
provides
systematic
explanation
appearance
noisy
low
dimensional
gks
equation
contrast
optimal
prediction
obtain
optimality
sense
maximum
entropy
three
main
features
new
low
dimensional
gks
equations
reliable
efﬁcient
numerics
low
dimensional
formulation
developed
allow
reliable
since
information
unresolved
degrees
freedom
included
efﬁcient
since
low
dimensional
numerical
approximations
fact
systematically
account
unresolved
degrees
freedom
steps
especially
importance
since
choice
slow
fast
variables
depends
physical
problem
often
clear
instance
considering
gks
large
domains
possible
introduce
scale
accounts
unstable
modes
hence
study
three
different
scales
unstable
modes
slow
stable
modes
fast
stable
modes
main
question
account
unstable
fast
stable
modes
equation
resolved
slow
modes
moreover
error
estimates
step
provide
qualitative
measure
choose
dimension
slow
variable
also
main
advantage
mode
reduction
considerations
pure
convergence
analyses
galerkin
approximations
e.g
numerical
schemes
one
completely
neglects
unresolved
degrees
freedom
hence
straightforward
discretization
strategies
might
lose
model
relevant
information
neglected
degrees
freedom
major
motivation
include
rigorous
mode
reduction
strategies
important
part
development
computational
schemes
remark
major
reason
addition
noise
deterministic
partial
differential
equations
shows
good
results
currently
topic
increasing
interest
also
important
emphasize
one
key
points
presented
methodoly
compuationally
efﬁcient
precisely
add
noise
posteriori
solving
reduced
model
something
computationally
simpler
solving
full
system
every
time
step
hamiltonian
structure
invariant
measure
many
classical
mode
reduction
strategies
rely
either
hamiltonian
structure
invariant
measure
based
three
steps
new
asymptotic
reduction
strategy
circumvents
dependences
example
classical
optimal
prediction
methods
fail
deﬁciencies
stochastic
renormalization
provides
optimality
sense
maximum
information
entropy
hence
proves
promising
alternative
iii
role
noise
gain
rigorous
understanding
origin
noise
way
appears
gks
equation
especially
interest
due
numerical
evidence
provided
together
heuristic
motivation
instance
clearly
open
questions
future
perspectives
example
motivated
comparative
study
initiated
stinis
would
interest
numerically
analyze
compare
available
mode
reduction
strategies
adiabatic
elimination
invariant
manifolds
optimal
prediction
new
approach
developed
since
statistically
based
optimal
prediction
performed
truncated
equation
provides
convenient
setup
comparison
new
generally
applicable
method
suggested
another
question
apply
method
derivation
low-dimensional
ap-
proximation
gks
equation
investigated
three
scales
i.e.
slow
unstable
modes
slow
stable
modes
fast
stable
modes
explore
possibility
obtaining
low-dimensional
approxima-
tions
equations
noise
present
outset
e.g
method
based
natural
splitting
linear
nonlinear
terms
variation
constants
formula
recent
studies
e.g
holden
make
use
splitting
via
suitable
numerical
scheme
equations
burgers
nonlinearity
hence
reliability
efﬁciency
renormalized
low
dimensional
gks
equation
motivate
application
numerical
splitting
strategies
new
reduced
equations
derived
finally
emphasize
efﬁcient
low
dimensional
approximations
great
interest
numerical
scrutiny
long
time
asymptotes
shall
examine
related
issues
future
studies
acknowledgements
thank
dirk
bl¨omker
augsburg
drawing
attention
reference
acknowledge
ﬁnancial
support
epsrc
grant
ep/h034587
eu-fp7
itn
multiﬂow
erc
advanced
grant
247031.
references
akrivis
papageorgiou
y.-s.
smyrlis
analyticity
certain
dissipative-
dispersive
systems
lond
math
soc.
:52–60
2013
biswas
swanson
existence
generalized
gevrey
regularity
solutions
kuramoto-sivashinsky
equation
differential
equations
240
:145
163
2007
bl¨omker
gugg
maier-paape
stochastic
navier–stokes
equation
renormalization
group
theory
physica
137:137–152
2002
b.m
boghosian
c.c
chow
hwa
hydrodynamics
kuramoto-sivashinsky
equation
two
dimensions
phys
rev
lett.
:5262–5265
1999
l.-y
chen
goldenfeld
oono
renormalization
group
singular
perturbations
mul-
tiple
scales
boundary
layers
reductive
perturbation
theory
phys
rev
:376–394
1996
chorin
kast
kupferman
optimal
prediction
underresolved
dynamics
natl
acad
sci
usa
:4094–8
1998
chow
hwa
defect-mediated
stability
effective
hydrodynamic
theory
spatiotem-
poral
chaos
physica
3-4
:494–512
1995
cohen
krommes
tang
rosenbluth
nonlinear
saturation
dissipative
trapped-ion
mode
mode
coupling
nucl
fusion
16:971–992
1976
collet
j.-p.
eckmann
epstein
stubbe
analyticity
kuramoto-sivashinsky
equation
physica
:321
326
1993
collet
j.-p.
eckmann
epstein
stubbe
global
attracting
set
kuramoto-
sivashinsky
equation
commun
math
phys.
152
:203–214
1993
duprat
giorgioutti-dauphin´e
tseluiko
saprykin
kalliadasis
liquid
ﬁlm
coating
ﬁber
model
system
formation
bound
states
active
dispersive-dissipative
nonlinear
media
phys
rev
lett.
103:234501
2009
foias
jolly
kevrekidis
titi
computation
inertial
manifolds
phys
lett
131
7,8
:433–436
1988
foias
nicolaenko
sell
temam
inertial
manifolds
kuramoto–
sivashinsky
equation
estimate
lowest
dimension
math
pure
appl.
67:197–226
1988
giacomelli
otto
new
bounds
kuramoto-sivashinsky
equation
commun
pur
appl
math.
:297–318
2005
goodman
stability
kuramoto-sivashinsky
related
systems
commun
pure
appl
maths
:293–306
1994
holden
karlsen
risebro
tao
operator
splitting
kdv
equation
math
comput.
274
:821–846
2011
holden
lubich
risebro
operator
splitting
partial
differential
equations
burgers
nonlinearity
arxiv:1102.4218
pages
1–12
2011
homsy
model
equations
wavy
viscous
ﬁlm
ﬂow
lect
appl
math.
15:191–194
1974
jackson
theory
approximations
ams
colloquium
publications
1930
jaynes
information
theory
statistical
mechanics
phys
rev.
106:620–630
1957
jaynes
information
theory
statistical
mechanics
phys
rev.
108:171–190
1957
jordan
kinderlehrer
otto
variational
formulation
fokker-planck
equation
siam
math
anal.
1998
kalisch
raynaud
rate
convergence
collocation
projection
kdv
equation
esaim
math
model
numer
anal.
:95–110
2007
kalliadasis
ruyer-quil
scheid
velarde
falling
liquid
films
springer
series
applied
mathematical
sciences
london
2012
kuramoto
tsuzuki
persistent
propagation
concentration
waves
dissipative
media
far
thermal
equilibrium
prog
theor
phys.
:356–369
1976
larkin
korteweg-de
vries
kuramoto-sivashinsky
equations
bounded
domains
math
anal
appl.
297
:169–185
2004
lorenz
predictability
problem
partly
solved
ecmwf
seminar
predictability
1995
pages
1–18
reading
united
kingdom
1996
maday
quarteroni
error
analysis
spectral
approximation
korteweg-de
vries
equation
esaim
math
model
numer
anal.
:499–529
1988
manneville
dissipative
structures
weak
turbulence
academic
press
new
york
1990
marion
temam
nonlinear
galerkin
methods
siam
numer
anal.
:1139–1157
1989
moise
temam
renormalization
group
method
application
navier-stokes
equation
discret.contin
dyn
:191–210
2000
moise
ziane
renormalization
group
method
applications
partial
differential
equa-
tions
dyn
differ
equ.
:275–321
2001
mori
transport
collective
motion
brownian
motion
prog
theor
phys.
:423–455
1965
otto
optimal
bounds
kuramoto-sivashinsky
equation
funct
anal.
257
:2188–
2245
2009
pradas
kalliadasis
nguyen
p.-k.
bontozoglou
bound-state
formation
interfacial
turbulence
direct
numerical
simulations
theory
fluid
mech.
716
2013
pradas
g.a
pavliotis
kalliadasis
d.t
papageorgiou
tseluiko
additive
noise
effects
active
nonlinear
spatially
extended
systems
eur
appl
math.
page
563591
2012
pradas
tseluiko
kalliadasis
rigorous
coherent-structure
theory
falling
liquid
ﬁlms
viscous
dispersion
effects
bound-state
formation
self-organization
phys
fluids
23:044104
2011
pradas
tseluiko
kalliadasis
d.t
pagageorgiou
g.a
pavliotis
noise
induced
state
transitions
intermittency
universality
noisy
kuramoto-sivashinsky
equation
phys
rev
lett.
106:060602
2011
rosenkrantz
editor
jaynes
e.t
papers
probability
statistics
statistical
physics
kluwer
academic
publisher
1989
saprykin
demekhin
kalliadasis
self-organization
two-dimensional
waves
active
dispersive-dissipative
nonlinear
medium
phys
rev
lett.
94:224101
2005
schmuck
pradas
kalliadasis
pavliotis
new
stochastic
mode
reduction
strategy
dissipative
systems
phys
rev
lett.
110:244101
2013
shannon
mathematical
theory
communication
reprint
bell
system
technical
journal
:379–423
623–656
1948
shraiman
order
disorder
phase
turbulence
phys
rev
lett.
:325–328
1986
sivashinsky
self-turbulization
laminar
ﬂame
acta
astronaut.
5-6
:569–591
1979
stinis
stochastic
optimal
prediction
kuramoto-sivashinsky
equation
multiscale
model
simul.
:613–638
2004
stinis
comparative
study
two
stochastic
mode
reduction
methods
physica
213
:197–
213
2006
tadmor
well-posedness
kuramoto-sivashinsky
equation
siam
math
anal.
:884
1986
tseluiko
kalliadasis
weak
interaction
solitary
pulses
active
dispersive-dissipative
nonlinear
media
ima
appl
math.
pages
1–26
2012.
doi:10.1093/imamat/hxs064
tseluiko
saprykin
duprat
giorgiutti-dauphin´e
kalliadasis
pulse
dynamics
low-reynolds-number
interfacial
hydrodynamics
experiments
theory
physica
239
20-
:2000–2010
2010
tseluiko
saprykin
kalliadasis
interaction
solitary
pulses
active
dispersive-
dissipative
media
proc
est
acad
sci.
pages
139–144
2010
van
kampen
elimination
fast
variables
phys
rep.
124:69–160
1985
wilson
renormalizaton
group
critical
phenomena
kondo
problem
rev
mod
phys.
:773–840
1975
zwanzig
memory
effects
irreversible
thermodynamics
phys
rev.
124
:983–992
1961
zwanzig
nonlinear
generalized
langevin
equations
stat
phys.
:215–220
1973.
prove
following
appendix
lemma
empty
set
proof
let
ﬁrst
recall
deﬁnition
second
resonance
indices
satisfying
a.1
belong
remind
convention
according
2..3
a.1
cid:19
cid:18
cid:19
−id
cid:18
cid:18
cid:19
taking
imaginary
parts
a.1
one
obtains
cid:19
cid:18
cid:19
cid:18
cid:19
cid:18
a.2
a.3
taking
real
parts
one
gets
cid:19
cid:18
cid:18
cid:19
cid:18
cid:19
cid:18
cid:19
=−n
cid:18
cid:19
cid:19
cid:18
a.4
follows
transform
a.4
expression
convinces
indices
satisfy
a.4
end
make
use
fact
k+l
reads
taking
square
side
k+l
+l2
+2kl
multiplying
a.4
gives
−k2−l2
+l4
applying
a.5
right-hand
side
obtain
−k2−l2
+l4
=−k2−l2−2kl
cid:16
+l2
+2kl
cid:17
hence
becomes
r−3kl
+l2
set
positive
proportional
equation
a.8
satisﬁed
integers
cid:3
remark
a.1
note
without
either
assuming
proportional
obtain
two
explicit
solutions
via
a.8
depressed
cubic
equation
i.e.
cid:18
−64∓q642
+3922r/27
cid:19
1/3
392r
cid:16
−64∓p642+3922r/27
cid:17
1/3
expression
also
deﬁnes
herewith
leaves
check
whether
given
solutions
integers
whether
satisfy
|k+l|
|k|
|l|
a.5
a.6
a.7
a.8
