analysis
algorithms
partial
algorithms
andrew
macfie
abstract
present
alternative
methodology
analysis
algorithms
based
concept
expected
discounted
reward
methodology
naturally
handles
algorithms
always
terminate
theoretically
used
partial
algorithms
undecidable
problems
found
artiﬁcial
general
intelligence
agi
automated
theorem
proving
mention
approach
self-improving
agi
enabled
methodology
introduction
shortcomings
traditional
analysis
algorithms
currently
running
time
analysis
algorithms
takes
following
form
given
two
algorithms
solve
problem
ﬁnd
ef-
ﬁcient
asymptotically
comparing
running
time
sequences
4,15
could
using
worst-case
average-case
running
times
even
smoothed
analysis
refer
general
method
traditional
analysis
algo-
rithms
model
traditional
analysis
algorithms
perfect
authors
noted
1,9
comparing
sequence
tails
avoids
arbitrariness
particular
range
input
lengths
leads
say
n100
superior
false
practical
purposes
cid:0
exp
−1010
cid:1
issue
traditional
analysis
illustrated
situation
say
function
algorithm
computes
takes
steps
input
steps
input
length
algorithm
worst-case
running
time
average-case
running
time
slightly
greater
2−n
terrible
however
inputs
generated
according
uniform
distribution
probability
taking
steps
2−n
quickly
negligible
see
considered
excellent
algorithm
traditional
analysis
tell
unless
add
high
probability
issue
arises
simply
halt
case
worst-case
average-case
running
times
inﬁnite
indeed
esoteric
phenomenon
problem
turing
degree
algorithm
halts
every
input
develop
partial
solutions
work
subset
inputs
problems
include
string
compression
kolmogorov
complexity
halting
problem
program
analysis
algebraic
simpliﬁcation
program
optimization
automated
theorem
proving
solomonoﬀ
induc-
tion
central
artiﬁcial
general
intelligence
e.g
case
automated
theorem
proving
buss
describing
main
open
problems
proof
theory
states
computerized
proof
search
...
widely
used
almost
mathematical
theory
known
eﬀectiveness
optimality
present-day
algorithms.
deﬁnition
algorithm
partial
algorithm
a.k.a
computational
method
given
problem
inputs
either
outputs
correct
value
terminate
deﬁnition
refer
partial
algorithms
problems
turing
degree
algorithms
analyze
algorithms
perhaps
better
analyze
normal
terminat-
ing
algorithms
need
new
approach
based
worst-case
average-case
running
time
sequences
sect
present
new
method
analyzing
algorithms
called
expected-reward
analysis
avoids
issues
mentioned
sect
mention
method
used
self-improving
systems
give
directions
work
sect
notation
given
possibly
partial
algorithm
input
denote
number
steps
taken
takes
value
halt
expected-reward
analysis
algorithms
2.1
deﬁnition
let
possibly
partial
algorithm
inputs
say
score
xω∈ω
probability
measure
discount
function
reward
a.k.a
utility
value
associated
obtaining
solution
expression
may
interpreted
expected
discounted
reward
receives
run
random
input
practice
comparing
scores
among
algorithms
call
expected-reward
analysis
higher
score
indicates
eﬃcient
algorithm
functions
arbitrary
free
set
context
particular
application
e.g
graphical
user
interface
software
often
desire
near-instant
responses
utility
rapidly
dropping
time
assuming
immediately
see
partial
simplicity
paper
assume
exponential
discount
function
i.e
exp
discount
rate
choice
also
arbitrary
remark
two
special
cases
inputs
given
length
weighted
equally
determined
probability
mass
function
z0+
case
common
discrete
probability
distribution
may
used
appropriate
measure
also
determined
probability
mass
function
z0+
weight
equal-length
inputs
according
solomonoﬀ
uni-
versal
distribution
particularly
good
general
model
although
computationally
diﬃcult
expected-reward
analysis
non-asymptotic
sense
inputs
po-
tentially
matter
thus
expected-reward
analysis
used
terminat-
ing
algorithms
expect
give
diﬀerent
results
traditional
analysis
general
since
particular
inputs
make
diﬀerence
may
ad-
vantageous
hardcode
initial
cases
algorithm
practice
certainly
exists
e.g
humans
may
store
multiplication
table
well
knowing
general
integer
multiplication
algorithm
computational
complexity
theory
often
works
classes
problems
whose
deﬁnitions
equivalent
reasonable
models
computation
however
even
varying
constant
factor
could
arbitrarily
change
score
simply
price
concreteness
outside
complexity
theory
traditional
analysis
algorithms
generally
selects
particular
model
computation
gives
precise
results
necessarily
apply
models
unlike
traditional
analysis
experimental
data
relevant
score
values
statistical
sense
able
generate
inputs
according
either
arti-
ﬁcially
sampling
inputs
found
practice
quantity
amenable
statistical
estimation
suggests
form
experimental
analysis
algorithms
focuses
single
real
number
rather
plotting
estimated
run-
ning
time
every
input
length
necessary
absence
asymptotics
experimental
analysis
may
conclusively
rank
two
competing
algorithms
anyway
expected-reward
paradigm
already
appears
analysis
artiﬁcial
agents
rather
algorithms
see
sect
however
even
applica-
tions
working
classical
domain
algorithms
brings
beneﬁts
2.2
theory
practice
traditional
analysis
algorithms
established
literature
going
back
decades
provides
set
techniques
performing
traditional
analysis
algo-
rithms
developed
various
problems
signiﬁcantly
develop
math-
ematical
theory
expected-reward
analysis
make
brief
initial
remarks
way
introductory
example
consider
expected-reward
analysis
ap-
plied
well-known
sorting
algorithms
let
set
permutations
1..n
let
uniform
random
element
denote
algorithms
mergesort
quicksort
deﬁned
set
exp
exp
number
comparison
operations
used
algorithm
sort
input
proposition
exp
cid:16
n⌈lg
2⌈lg
cid:17
e−λ
n+1
qk−1qn−k
xk=1
proof
makes
number
comparisons
inputs
length
n⌈lg
2⌈lg
immediate
called
let
pivot
element
let
subarrays
constructed
recursive
calls
elements
less
elements
greater
exp
−λcq
xk=1
e−λ
n+1
exp
exp
xk=1
seen
given
independent
thus
exp
−λcq
e−λ
n+1
e−λ
n+1
xk=1
xk=1
exp
−λcq
exp
−λcq
exp
−λcq
πk−1
exp
−λcq
πn−k
examining
best-case
performance
turns
expected-reward
comparison
easy
parameters
however
may
analyze
ab-
solute
scores
facilitate
comparisons
arbitrary
sorting
algo-
rithms
performing
expected-reward
analysis
individual
algorithm
main
desideratum
way
quickly
compute
score
value
within
given
precision
possible
parameter
value
proposition
gives
way
computing
scores
measures
give
equal
length
inputs
equal
weight
although
immediately
suggest
eﬃcient
way
cases
bounds
scores
also
potentially
useful
may
faster
compute
next
proposition
give
bounds
simpler
exact
expressions
proposition
e−2λ
n−1
log
e−λ
n−1
log
log
e−2γλ
n+1
e−2λn
log
euler
constant
proof
sedgewick
flajolet
give
alternative
expression
running
time
mergesort
n−1
⌊lg
xk=1
statement
follows
log
log
⌊lg
log
log
log
prove
upper
bound
e−2λn
log
induction
relation
clearly
holds
show
proved
assumption
holds
proposition
gives
e−λ
e−λ
xk=1
xk=1
qk−1qn
e−2λ
k−1
e−2λ
log
log
assumption
e−3λn
e−3λn
+λ
xk=1
cid:18
log
xk=1
cid:19
log
log
jensen
inequality
since
log
e−3λn
cid:18
log
log
cid:19
e−2λn
log
thus
proved
lower
bound
use
probabilistic
form
jensen
inequal-
ity
exp
−λcq
exp
−λe
noting
average-case
analysis
quicksort
yields
hn+1
harmonic
sequence
bound
hn+1
log
holds
sharper
bounds
exist
exp
cid:18
−2λ
cid:18
log
e−2
γ−1
n+1
−2λ
n+1
cid:19
cid:19
ﬁnish
applying
stirling
inequality
n+1
≥p2π
n+1
results
may
get
sense
tasks
involved
expected-
reward
analysis
typical
algorithms
note
exponential
discount
function
independence
subproblems
quicksort
required
obtaining
recursive
formula
whereas
traditional
average-case
analysis
linearity
expectation
suﬃces
end
section
mentioning
open
question
relevant
theory
expected-reward
analysis
question
computational
problem
parameters
supa
attained
supa
attained
situation
similar
blum
speedup
theorem
comparing
supa
among
problems
would
expected-
reward
analog
computational
complexity
theory
sensitivity
parameters
model
computation
useful
self-improving
generality
problems
allows
view
design
analysis
algo-
rithms
task
may
given
algorithm
bringing
recursive
self-improvement
present
one
possible
concrete
example
notion
discuss
connections
computational
problems
turing
degree
turing-equivalent
with-
loss
generality
section
assume
algorithms
automated
theorem
provers
speciﬁcally
formal
logic
system
say
zfc
assuming
consistent
take
set
inputs
zfc
sentences
possible
outputs
provable
provable
let
predicate
holds
algorithm
correct
provable
inputs
terminate
otherwise
pseudocode
write
instruction
run
input
contains
score
function
deﬁnitions
implicitly
included
give
auxiliary
procedure
search
takes
input
algorithm
rational
number
uses
obtain
algorithm
satisﬁes
score
greater
possible
symbols
bold
within
string
literal
get
replaced
value
corresponding
variable
assume
algorithms
encoded
strings
binary
preﬁx
code
empty
string
loop
procedure
search
parallel
one
returns
provable
u0v
u1v
returned
provable
returned
provable
returned
provable
return
remark
mechanism
search
purely
syntactic
rely
consistency
completeness
zfc
provability
thereof
would
case
strengthened
require
true
one
returns
provable
would
never
provably
hold
zfc
following
procedure
improve
takes
initial
algorithm
uses
dovetailed
calls
search
output
sequence
algorithms
tend
toward
optimality
best
pool
score
procedure
improve
nth
term
stern-brocot
enumeration
score
initialstate
initial
state
search
best
add
best
initialstate
pool
improvementf
ound
false
state
pool
run
search
one
step
starting
state
state
newstate
new
current
state
search
state
terminating
state
pool
mutate
state
newstate
continue
improvementf
ound
true
best
output
search
score
remove
ˆstate
pool
ˆstate
pool
score
print
best
improvementf
ound
state
pool
initialstate
initial
state
search
best
add
best
initialstate
pool
procedure
improve
following
basic
property
proposition
let
sequence
algorithms
printed
improve
holds
algorithm
provable
lim
n→∞
ﬁnite
limit
replaced
last
term
proof
value
appears
value
score
line
search
best
run
one
step
greater
equal
value
either
terminates
since
exists
score
set
interrupted
eventually
score
search
best
terminates
suﬃces
note
score
attains
value
outputs
satisfy
least
one
output
procedure
improve
also
makes
attempt
use
recently
printed
algorithms
calls
search
however
true
general
zn+1
checking
particular
output
actually
improvement
zn−1
requires
extra
work
artiﬁcial
general
intelligence
agi
desirable
intelligent
sys-
tems
ability
make
autonomous
improvements
agi
system
aixi
approximation
already
uses
algorithm
compute
universal
distribution
give
system
ability
improve
time
devoting
computational
resources
run-
ning
improve
yields
general
agent
whose
environment
prediction
ability
tends
toward
optimality
future
work
would
like
able
practically
use
expected-reward
analysis
vari-
ous
parameter
values
probability
measures
discount
functions
ter-
minating
non-terminating
algorithms
particularly
would
like
know
whether
algorithms
may
practically
analyzed
may
possible
develop
general
mathematical
tools
techniques
enhance
practicality
methods
exist
traditional
analysis
broad
open-ended
research
goal
acknowledgements
author
wishes
thank
zhicheng
gao
nima
hoda
patrick
lavictoire
saran
neti
anonymous
referees
helpful
com-
ments
references
aaronson
philosophers
care
computational
complexity
computability
gödel
turing
church
beyond
2012
burnim
jalbert
stergiou
sen
looper
lightweight
detection
inﬁnite
loops
runtime
international
conference
automated
software
engineering
2009
2000.
http
//www.ihes.fr/~carbone/papers/proofsurveyfeferman2000.html
1999
accessed
2015-10-04
buss
theory
proof
year
eve
cormen
t.h.
leiserson
c.e.
rivest
r.l.
stein
introduction
algorithms
mit
press
cambridge
third
edn
2009
van
emde
boas
handbook
theoretical
computer
science
vol
1–66
mit
press
cambridge
usa
1990
flajolet
sedgewick
analytic
combinatorics
cambridge
university
press
cambridge
2009
frederick
loewenstein
donoghue
time
discounting
time
pref-
erence
critical
review
journal
economic
literature
351–401
2002
goertzel
toward
formal
characterization
real-world
general
intelligence
proceedings
3rd
conference
artiﬁcial
general
intelligence
agi
19–24
2010
gurevich
feasible
functions
london
mathematical
society
newsletter
206
6–7
1993
10.
hutter
universal
artiﬁcial
intelligence
sequential
decisions
based
algo-
rithmic
probability
springer
berlin
2005
11.
julian
gamma
exploring
euler
constant
princeton
university
press
2003
12.
knuth
d.e
art
computer
programming
vol
addison-wesley
reading
1997
13.
vitányi
introduction
kolmogorov
complexity
applica-
tions
springer
science
business
media
2013
14.
schmidhuber
gödel
machines
fully
self-referential
optimal
universal
self-
improvers
artiﬁcial
general
intelligence
199–226
springer
2007
15.
sedgewick
flajolet
introduction
analysis
algorithms
addison-
wesley
2013
16.
spielman
d.a.
teng
s.h
smoothed
analysis
attempt
explain
behavior
algorithms
practice
communications
acm
76–84
2009
17.
trott
mathematica
guidebook
symbolics
springer
science
business
media
2007
