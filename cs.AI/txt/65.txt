detection
cooperative
interactions
logistic
regression
models
easton
member
ieee
xiaoning
qian
member
ieee
tie
liu
senior
member
ieee
shuguang
cui
fellow
ieee
abstract—an
important
problem
ﬁeld
bioinformatics
identify
interactive
effects
among
proﬁled
variables
outcome
prediction
paper
logistic
regression
model
pairwise
interactions
among
set
binary
covariates
considered
modeling
structure
interactions
graph
goal
recover
interaction
graph
independently
identically
distributed
i.i.d
samples
covariates
outcome
viewed
feature
selection
problem
simple
quantity
called
inﬂuence
proposed
measure
marginal
effects
interaction
terms
outcome
case
underlying
interaction
graph
known
acyclic
shown
simple
algorithm
based
maximum-weight
span-
ning
tree
respect
plug-in
estimates
inﬂuences
strong
theoretical
performance
guarantees
also
outperform
generic
feature
selection
algorithms
recovering
interaction
graph
i.i.d
samples
covariates
outcome
results
also
extended
model
includes
individual
effects
pairwise
interactions
via
help
auxiliary
covariate
introduction
consider
regression
problem
independent
covari-
ates
binary
outcome
variable
covariates
assumed
uniformly
distributed
conditional
probabilities
outcome
given
covariates
assumed
logistic
+1|xv
cid:16
−1|xv
cid:16
xixj
cid:17
xixj
cid:17
real
constants
ex/
sigmoid
function
straightforward
verify
+1|xv
+pr
−1|xv
two
distinct
say
covariates
interact
let
simple
graph
vertex
set
edge
set
work
qian
liu
cui
supported
part
grant
nsfc-61328102/61629101
dod
grant
hdtra1-13-1-0029
nsf
grants
cns-1265227
eccs-1305979
cns-1343155
ccf-
1447235
eccs-1508051
ast-1547436
ios-1547557
qian
liu
department
electrical
computer
engineering
texas
university
college
station
77843
usa
e-mails
xulimc
gmail.com
xqian
tamu.edu
tieliu
tamu.edu
cui
department
electrical
computer
engineering
university
california
davis
95616
usa
e-mail
sgcui
ucdavis.edu
captures
pairwise
interactions
covariates
determining
odds
outcome
interest
goal
recover
graph
independently
identically
distributed
i.i.d
samples
main
motivation
considering
pairwise
interaction
problem
computational
biology
covariate
represents
expression
biomarker
gene
environmental
factor
variable
represents
phenotypic
outcome
respect
speciﬁc
phenotype
computational
biology
many
complex
diseases
cancer
diabetes
conjectured
complicated
underlying
disease
mechanisms
multiple
candidate
risk
factors
either
genetic
environmental
interactions
known
play
critical
roles
triggering
determining
development
large
family
diseases
identifying
interactive
effects
among
proﬁled
variables
helps
accurate
identiﬁcation
critical
risk
factors
outcome
prediction
also
helps
reveal
functional
interactions
un-
derstand
aberrant
system
changes
speciﬁcally
related
outcome
effective
systems
intervention
model
course
simpliﬁed
one
real-world
situations
studied
since
captures
essential
features
problem
shall
see
shortly
relatively
simple
note
let
xixj
consider
instead
covariates
problem
recovering
graph
viewed
feature
selection
problem
statistics
machine
learning
basic
approach
feature
selection
ﬁrst
use
shannon
mutual
information
measure
marginal
effects
covariates
outcome
select
features
based
ranking
mutual
information
advanced
approaches
immensely
popular
mrmr
method
make
incremental
selections
taking
account
relevance
outcome
redundancy
among
selected
features
however
even
though
shannon
mutual
information
provides
compact
model-free
measure
correlation
covariates
outcome
well
accepted
statistics
computational
biology
communities
complex
function
underlying
joint
distribution
hence
difﬁcult
analyze
estimate
limited
data
samples
result
applied
speciﬁc
regression
models
performance
generic
feature
selection
algorithms
usually
difﬁcult
characterize
motivated
recent
progress
learning
ising
models
arbitrary
graphs
paper
propose
quantity
called
inﬂuence
measure
marginal
effects
outcome
compared
shannon
mutual
information
inﬂuence
simple
function
low-order
joint
probabilities
outcome
hence
much
easier
analyze
estimate
underlying
graph
known
acyclic
show
simple
algorithm
based
maximum-weight
spanning
tree
respect
plug-in
estimate
inﬂuences
fol-
lowed
simple
thresholding
operations
strong
theoretical
performance
guarantees
also
outperform
generic
feature
selection
algorithms
recovering
i.i.d
samples
rest
paper
organized
follows
section
show
acyclic
identiﬁed
inﬂuences
outcome
building
results
section
section
iii
show
acyclic
recovered
probability
least
i.i.d
samples
cid:16
log
d2/ǫ
cid:17
section
extend
results
sections
model
involving
individual
effects
cooperative
interactions
section
use
computer
simulations
demonstrate
proposed
algorithm
outperform
generic
feature
selection
algorithms
finally
section
conclude
paper
remarks
notation
random
variables
written
serif
font
sets
written
capital
letters
identification
cooperative
interactions
low-order
joint
probabilities
main
result
section
show
acyclic
identiﬁed
low-order
joint
probabilities
towards
goal
let
weight
assignment
given
cid:12
cid:12
cid:0
+1|xi
cid:1
cid:0
−1|xi
cid:1
cid:12
cid:12
cid:12
cid:12
2pr
cid:0
+1|xi
cid:1
cid:12
cid:12
cid:12
cid:12
8pr
cid:0
cid:1
cid:12
cid:12
follows
fact
cid:0
+1|xi
cid:1
cid:0
−1|xi
cid:1
due
fact
1/4
following
proposition
helps
clarify
meaning
weight
assignment
deﬁned
proposition
inﬂuence
assume
acyclic
cid:12
cid:12
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
cid:12
cid:12
proof
see
section
a-a
useful
indication
whether
intuition
partially
justiﬁed
following
proposition
proposition
direct
inﬂuence
assume
acyclic
proof
see
section
a-b
say
product
xixj
direct
inﬂuence
outcome
proposition
guarantees
direct
inﬂuences
strictly
positive
acyclic
following
proposition
provides
partial
converse
proposition
proposition
zero
inﬂuence
assume
acyclic
two
distinct
disconnected
unique
path
even
length
proof
see
section
a-c.
theorem
union
stars
assume
connected
component
star
two
distinct
proof
follows
immediately
propositions
fact
connected
component
star
implies
acyclic
two
distinct
must
either
disconnected
belong
two
different
connected
components
connected
unique
path
length
two
belong
connected
component
following
example
however
shows
converse
proposition
true
general
consider
1,2
2,3
3,4
note
graph
acyclic
unique
path
length
three
straightforward
calculate
1,4
even
though
say
product
xixj
indirect
inﬂuence
outcome
due
possible
existence
indirect
inﬂuences
unlike
unions
stars
general
acyclic
recovered
via
edge-by-
edge
identiﬁcations
following
proposition
however
shows
indirect
inﬂuences
locally
dominated
direct
inﬂuences
proposition
indirect
inﬂuence
assume
acyclic
let
cid:8
im+1
cid:9
path
length
im+1
is+1
proof
note
even
propositions
im+1
is+1
therefore
need
consider
cases
odd
proof
found
appendix
a-d.
let
disconnected
weight
assignment
said
strict
separation
exists
real
constant
consequence
strict
separation
local
dominance
summarized
following
proposition
indicates
whether
product
xixj
inﬂuence
event
hence
proposition
assume
acyclic
let
weight
assignment
satisfying
strict
separa-
tion
exists
real
constant
local
dominance
im+1
is+1
path
cid:8
im+1
cid:9
length
maximum-weight
spanning
tree
respect
weight
assignment
proof
see
section
a-e.
following
theorem
main
result
section
theorem
acyclic
graphs
assume
acyclic
let
maximum-weight
spanning
tree
respect
weight
assignment
deﬁned
two
distinct
proof
note
propositions
proposition
im+1
is+1
path
cid:8
im+1
cid:9
length
theorem
thus
follows
directly
proposition
iii
detection
cooperative
interactions
finite
data
samples
let
i.i.d
samples
recover
graph
shall
assign
weight
based
empirical
joint
probability
xt=1
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
indicator
function
converging
probability
limit
following
simple
proposition
follows
directly
well-known
hoeffding
inequality
provides
bound
rate
weight
assignment
converges
uniformly
proposition
cid:12
cid:12
cid:12
cid:17
2e−nη2/32
cid:0
cid:1
cid:12
cid:12
cid:12
cid:12
ﬁnish
proof
applying
hoeffding
inequality
following
propositions
generalizations
propositions
respectively
play
key
role
adapting
results
theorem
weight
assignment
proposition
assume
acyclic
let
proof
note
cid:16
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
xt=1
proof
see
section
a-b
proposition
assume
acyclic
im+1
is+1
path
cid:8
im+1
cid:9
length
deﬁned
proof
see
section
a-d.
error
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
given
propositions
clear
estimation
uniformly
bounded
γ/2
acyclic
recovered
similar
theorem
assume
acyclic
let
maximum-weight
spanning
tree
respect
weight
assignment
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
two
distinct
γ/2
proof
proposition
assumption
implies
γ/2
proposition
im+1
is+1
path
cid:8
im+1
cid:9
length
assumption
implies
im+1
is+1
path
cid:8
im+1
cid:9
length
theorem
thus
follows
directly
proposition
γ/2
establish
following
algorithm
detect
based
theorem
compute
according
algorithm
input
output
compute
according
find
maximum-weight
spanning
tree
ˆg′
vertex
set
respect
weight
assignment
return
γ/2o
sample
complexity
algorithm
summarized
following
theorem
theorem
assume
acyclic
|βi
fix
let
positive
integer
128
log
64πd
log
probability
least
algorithm
success-
fully
detect
graph
i.i.d
samples
cid:16
cid:17
cid:18
∈en
cid:12
cid:12
ˆwi
cid:12
cid:12
cid:19
proof
proposition
theorem
nγ2
128
completes
proof
theorem
extension
models
individual
effects
cooperative
interactions
section
extend
results
sections
iii
models
include
individual
effects
cooperative
interactions
speciﬁcally
shall
assume
conditional
probability
outcome
given
covariates
given
xixj
cid:17
xixj
cid:17
βixi
βixi
+1|xv
cid:16
xi∈v
−1|xv
cid:16
xi∈v
real
constants
say
covariate
individual
effect
say
covariates
interact
let
i,0
structure
model
including
individual
effects
cooperative
interactions
fully
captured
simple
graph
goal
recover
graph
i.i.d
samples
toward
goal
shall
introduce
additional
covariate
assume
uniformly
independent
use
deﬁne
auxiliary
model
conditional
probabilities
outcome
given
covariates
given
cid:16
+1|x
cid:17
cid:16
cid:17
cid:16
cid:16
−1|x
xixj
cid:17
xixj
cid:17
results
section
underlying
graph
known
acyclic
recovered
weight
assignment
cid:12
cid:12
2pr
cid:0
+1|xi
cid:1
cid:12
cid:12
note
trivially
+1|xi
+1|xi
i,0
|2pr
+1|xi
hand
may
write
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
proceed
note
2d−2pr
cid:0
+1|xi
cid:1
+1|xv
cid:16
xk∈v
cid:16
xk∈v
βkxk
βkxk
xkxl
cid:17
xkxl
cid:17
+1|xv
2d−2pr
cid:0
+1|xi
cid:1
follows
simple
change
variable
−xv
thus
follows
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
hence
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
cid:0
+1|xi
cid:1
giving
cid:0
+1|xi
cid:1
cid:12
cid:12
cid:12
cid:12
cid:0
+1|xi
cid:1
combining
conclude
weight
assignment
hence
acyclic
fully
recovered
low-order
joint
probabilities
results
section
iii
extended
similarly
details
omitted
simulation
results
simulations
randomly
generate
5,000
logistic
regression
models
including
independent
binary
co-
variates
model
generate
randomly
choose
individual
effects
interaction
pairs
resulting
acyclic
graph
underlying
structure
model
parame-
ters
individual
effect
interaction
pair
randomly
assigned
uniform
distribution
fig
compare
detection
rate
algorithm
different
parameter
ranges
0.3
0.5
0.5
sample
sizes
300
600
900
1,200
1,500
respectively
emphasize
logistic
regression
model
correctly
detected
features
including
individual
effects
interaction
pairs
correctly
detected
clearly
detection
fig
detection
rates
algorithm
different
parameter
ranges
fig
comparison
detection
rates
among
mrmr
forward
selection
ranking
l1-regularized
logistic
regression
algorithm
rate
increases
lower
upper
bounds
parameter
range
increase
algorithm
achieve
high
detection
rate
least
reasonably
large
number
training
samples
around
1200
also
fig
plot
ﬁtted
curves
detection
rate
respect
increasing
sample
size
based
functional
form
log
detection
rate
derived
section
iii
clear
curves
well
empirical
results
thus
validating
order-tightness
lower
bound
next
shall
compare
performance
algorithm
algorithm
three
generic
feature
selection
algorithms
mrmr
forward
selection
mutual
information
rank-
ing
problem-speciﬁc
l1-regularized
logistic
re-
gression
algorithm
mrmr
forward
se-
lection
ranking
l1-regularized
logistic
regression
algorithms
shall
view
single
variables
interaction
terms
xixj
separate
feature
assume
number
features
selected
known
estimation
mutual
information
mrmr
forward
selection
ranking
algorithms
based
l1-regularized
logistic
regression
algorithm
tune
regularization
parameter
till
desired
number
nonzero
coefﬁcients
obtained
fig
compare
detection
rate
algorithm
mrmr
forward
selection
ranking
l1-
regularized
logistic
regression
algorithms
0.3
0.5
ﬁnite
number
data
samples
see
algorithm
achieves
signiﬁcantly
higher
detection
rate
mrmr
forward
selection
ranking
algorithms
especially
sample
size
relatively
small
due
facts
algorithm
exploits
fact
underlying
interaction
graph
acyclic
two
algorithms
proposed
inﬂuence
measure
much
easier
estimate
performances
mrmr
forward
selection
ranking
algorithms
nearly
identical
since
feature
candidates
pairwise
indepen-
dent
hand
performances
algorithm
l1-regularized
logistic
regression
algorithm
appear
comparable
somewhat
surprising
l1-regularized
logistic
regression
algorithm
performs
well
typical
problem
instances
ﬁnite
sample
sizes
intuitively
related
fact
acyclic
graphs
sparse
graphs
however
analyzing
sample
complexity
l1-
regularized
logistic
regression
algorithm
appears
challenging
completeness
fig
fig
also
compare
miss
detection/false
positive
rate
prediction
accuracy
algorithm
mrmr
forward
selection
ranking
l1-regularized
logistic
regression
algorithms
note
since
number
features
selected
ﬁxed
case
miss
detection
false
positive
rates
identical
prediction
accuracy
calculated
follows
logistic
regression
model
generate
ﬁrst
obtain
model
structure
via
one
algorithms
consideration
followed
standard
logistic
regression
parameter
estimation
logistic
regression
model
reconstructed
randomly
generate
200
testing
samples
estimate
accuracy
outcome
prediction
see
relative
performance
among
algorithms
similar
case
detection
rate
concluding
remarks
important
problem
bioinformatics
identify
inter-
active
effects
among
proﬁled
variables
outcome
prediction
paper
simple
logistic
regression
model
pairwise
interactions
among
binary
covariates
considered
mod-
eling
structure
interactions
graph
goal
recover
i.i.d
samples
covariates
outcome
viewed
feature
selection
problem
simple
quantity
called
inﬂuence
proposed
measure
l1-regularized
logistic
regression
algorithm
theoretical
standpoint
also
extend
results
challenging
case
interaction
graph
might
cyclic
references
moore
ubiquitous
nature
epistasis
determining
susceptibility
common
human
diseases
hum
hered.
vol
1–3
73–82
nov.
2003
chung
lee
elston
park
odds
ratio
based
multifactor-dimensionality
reduction
method
detecting
gene-gene
interactions
bioinformatics
vol
71–76
jan.
2007
anastassiou
computational
analysis
synergy
among
mul-
tiple
interacting
genes
mol
syst
biol.
vol
1–8
feb.
2007
eddy
sung
geman
price
relative
expression
analysis
molecular
cancer
diagnosis
prognosis
tech
cancer
res
treat.
vol
149–159
apr
2010
hoon
watkinson
anastassiou
biomarker
discovery
using
statistically
signiﬁcant
gene
sets
comput
biol.
vol
1–10
oct.
2011
adl
qian
vehik
krischer
feature
ranking
based
synergy
networks
identify
prognostic
markers
dpt-1
eurasip
bioinform
syst
biol.
vol
2013
1–9
sept.
2013
sakhanenko
galas
biological
data
analysis
information
theory
problem
multivariable
dependence
measures
shadows
algorithm
comput
biol.
vol
1005-
1024
nov.
2015
saeys
inza
larranaga
review
feature
selection
tech-
niques
bioinformatics
bioinformatics
vol
2507–
2517
oct.
2007
cover
thomas
elements
information
theory
2nd
ed.
hoboken
john
wiley
sons
july
2006
peng
long
ding
feature
selection
based
mutual
information
criteria
max-dependency
max-relevance
min-
redundancy
ieee
trans
pattern
anal
mach
intell.
vol
1226–1238
aug.
2005
bresler
efﬁciently
learning
ising
models
arbitrary
graphs
proc
47th
annu
acm
symp
theory
comput.
771–782
june
2015
hoeffding
probability
inequalities
sums
bounded
random
variables
amer
stat
assoc.
vol
301
13–30
mar
1963
s.-i
lee
lee
abbeel
efﬁcient
l1-regularized
logistic
regression
proc
nat
conf
artif
intel.
vol
401–408
july
2006
park
hastie
l1-regularization
path
algorithm
generalized
linear
models
roy
stat
soc
vol
659–
677
sept.
2007
antos
kontoyiannis
convergence
properties
functional
estimates
discrete
distributions
random
struct
algor.
vol
163–193
nov.
2001
paninski
estimation
entropy
mutual
information
neural
comput.
vol
1191–1253
june
2003
berggren
borwein
borwein
source
book
3rd
ed.
new
york
springer
june
2004.
appendix
proof
propositions
proof
proposition
begin
following
lemma
lemma
acyclic
proof
lemma
found
appendix
b-a
lemma
fig
comparison
false
positive
rates
detecting
nonzero
model
parameters
among
mrmr
forward
selection
ranking
l1-regularized
logistic
regression
algorithm
fig
selection
ranking
l1-regularized
logistic
regression
algorithm
comparison
prediction
accuracy
among
mrmr
forward
marginal
effects
interaction
terms
outcome
case
known
acyclic
shown
simple
algorithm
based
maximum-weight
spanning
tree
respect
plug-in
estimates
inﬂuences
strong
theoretical
performance
guarantees
also
outperform
generic
feature
selection
algorithms
recovering
graph
i.i.d
samples
covariates
outcome
sample
complexity
analysis
detecting
interaction
graph
provided
results
extended
model
includes
individual
effects
pairwise
interactions
future
work
would
like
understand
behavior
hence
+1|xi
−1|xi
due
fact
1/4
substituting
completes
proof
proposition
proof
propositions
fix
let
cid:16
∈i\
cid:16
∈i\
following
lemma
proof
provided
appendix
b-b
xkxl
cid:17
xkxl
cid:17
lemma
assume
acyclic
one-on-one
thus
d−2
hence
+1|xi
−1|xi
d−2
d−2
assume
without
loss
generality
other-
wise
may
simply
replace
rest
proof
remains
monotonicity
sigmoid
function
d−2
thus
follows
lemma
d−2
d−2
d−2
xzt
∈∆1
+1|xi
−1|xi
d−2
prove
proposition
note
sigmoid
function
strictly
monotone
increasing
thus
thus
follows
lemma
d−2
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
completes
proof
proposition
prove
proposition
let
tree
covers
slight
abuse
notation
let
cid:16
cid:16
cid:16
∈i\
cid:16
∈i\
cid:17
cid:17
cid:17
cid:17
follows
fact
note
union
two
trees
different
trees
mapping
=nzt
d−2
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
µ
|x|≤3µhσ
cid:16
cid:17
cid:16
cid:17
min
cid:16
cid:17
cid:16
cid:17
min
β≤λ
follows
|∆1|
2d−2
last
inequality
follows
following
lemma
whose
proof
found
appendix
b-c.
lemma
let
i.i.d
random
variables
uniformly
distributed
real
constants
xi=1
cid:16
cid:12
cid:12
cid:12
aixi
cid:12
cid:12
cid:12
cid:17
max
|ai|
proof
proposition
fix
assume
either
discon-
nected
length
unique
path
even
assumption
acyclic
must
exist
vertex
bipartition
note
thus
2d−2pr
+1|xi
xkxl
cid:17
+1|xv
cid:16
xk∈v1
xl∈v2
cid:16
xk∈v1
xl∈v2
−1|xv
xkxl
cid:17
2d−2pr
−1|xi
follows
change
variable
−xl
+1|xi
−1|xi
implies
completes
proof
proposition
together
proof
propositions
mentioned
need
consider
odd
notational
convenience
let
assume
without
loss
generality
compare
m+1
s+1
note
fact
+1|x1
xm+1
−1|x1
xm+1
m+1
max
cid:8
2pr
+1|x1
xm+1
max
cid:8
2pr
+1|x1
xm+1
2pr
−1|x1
xm+1
cid:9
2pr
−1|x1
xm+1
cid:9
shall
compare
+1|xs
xs+1
+1|x1
xm+1
−1|x1
xm+1
separately
case
following
lemma
proof
provided
appendix
b-d.
lemma
+1|x1
d−2
+1|x1
xm+1
xm+1
1,2
furthermore
odd
+1|x1
−1|x1
xm+1
d−2
xm+1
1,2
show
1,2
m+1
shall
consider
cases
1,2
1,2
separately
1,2
1,2
lemma
1,2
|2pr
+1|x1
2pr
+1|x1
max
cid:8
2pr
+1|x1
xm+1
2pr
−1|x1
xm+1
cid:9
m+1
1,2
1,2
lemma
1,2
|2pr
+1|x1
2pr
+1|x1
max
cid:8
2pr
+1|x1
xm+1
2pr
−1|x1
xm+1
cid:9
m+1
show
1,2
m+1
let
tree
covers
note
1,2
1,2
cid:16
1,2
2,3
z2,3
x2xm+1/
yr=3
r+1
cid:17
union
three
trees
m+1
different
trees
mapping
1,2
2,3
xm+1
one-on-one
thus
1,2
xm+1
1,2
2,3
d−3
1,2
cid:16
1,2
2,3
2,3
yr=3
r+1
cid:17
follows
+1|x1
d−2
+1|x1
xm+1
1,2
cid:16
r+1
cid:17
yr=3
1,2
2,3
d−3
1,2
2,3
2,3
also
completely
analogous
argument
+1|x1
d−2
−1|x1
xm+1
1,2
cid:16
r+1
cid:17
1,2
2,3
d−3
1,2
2,3
2,3
yr=3
assume
without
loss
generality
1,2
other-
wise
may
simply
replace
1,2
1,2
rest
proof
remains
monotonicity
sigmoid
function
1,2
1,2
1,2
d−2
thus
+1|x1
d−2
+1|x1
xm+1
1,2
2,3
∈∆2
1,2
cid:16
yr=3
1,2
2,3
2,3
r+1
cid:17
=nzt
d−3
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
µ
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
1,2
2,3
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
r+1
cid:17
1,2
2,3
1,2
2,3
hence
1,2
2,3
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
2,3
cid:16
yr=3
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
2,3
cid:12
cid:12
cid:12
1,2
cid:16
1,2
2,3
2,3
r+1
cid:17
yr=3
|x|≤3µhσ
cid:16
1,2
cid:17
cid:16
1,2
cid:17
min
cid:16
1,2
cid:17
cid:16
1,2
cid:17
min
β≤λ
follows
lemma
+1|x1
+1|x1
xm+1
|∆2|
2d−2
√2πd
+1|x1
−1|x1
xm+1
therefore
1,2
m+1
case
proof
case
completely
analogous
previous
case
hence
omitted
case
fix
following
lemma
proof
provided
appendix
b-d.
lemma
2d−2
cid:2
+1|xs
xs+1
xs+1
xm+1
+1|x1
xm+1
cid:3
s+1
s+1
xs+1
xm+1
odd
2d−2
cid:2
+1|xs
xs+1
−1|x1
xm+1
cid:3
s+1
s+1
xs+1
xm+1
xs+1
xm+1
show
s+1
m+1
shall
consider
cases
s+1
s+1
separately
s+1
s+1
lemma
s+1
2pr
+1|xs
xs+1
max
cid:8
2pr
+1|x1
xm+1
2pr
−1|x1
xm+1
cid:9
s+1
s+1
lemma
m+1
s+1
2pr
+1|xs
xs+1
m+1
max
cid:8
2pr
+1|x1
xm+1
2pr
−1|x1
xm+1
cid:9
show
s+1
m+1
let
s+1
s+1
cid:16
1,2
s+1
m+1
tree
covers
note
s−1
1,2
x1xs/
r+1
yr=2
m−1
yr=s+1
m+1
xs+1xm+1/
r+1
cid:17
g′−
s+1
m+1
union
four
trees
different
trees
mapping
1,2
s+1
m+1
xs+1
xm+1
one-on-
one
thus
xs+1
xm+1
s+1
1,2
s+1
m+1
d−4
s+1
cid:16
1,2
s+1
m+1
1,2
s−1
yr=2
r+1
m−1
yr=s+1
m+1
r+1
cid:17
follows
+1|xs
xs+1
d−2
+1|x1
xm+1
1,2
s+1
m+1
d−4h
s−1
1,2
yr=2
s+1
cid:16
1,2
s+1
m+1
r+1
m+1
s+1
cid:16
1,2
s+1
m+1
1,2
r+1
m+1
s−1
yr=2
m−1
yr=s+1
m−1
yr=s+1
r+1
cid:17
r+1
cid:17
+1|xs
xs+1
d−2
−1|x1
xm+1
1,2
s+1
m+1
d−4h
s+1
cid:16
1,2
s+1
m+1
s−1
m−1
1,2
r+1
m+1
yr=2
yr=s+1
r+1
cid:17
s−1
m−1
yr=2
s+1
cid:16
1,2
s+1
m+1
1,2
r+1
m+1
yr=s+1
r+1
cid:17
assume
without
loss
generality
s+1
oth-
erwise
may
simply
replace
s+1
s+1
rest
proof
remains
monotonicity
sigmoid
function
s+1
s+1
s+1
d−2
thus
+1|xs
xs+1
+1|x1
xm+1
1,2
s+1
m+1
∈∆3h
d−2
s+1
cid:16
1,2
s+1
m+1
r+1
m+1
s+1
cid:16
1,2
s+1
m+1
1,2
r+1
m+1
yr=2
1,2
s−1
s−1
m−1
yr=s+1
m−1
yr=s+1
yr=2
r+1
cid:17
r+1
cid:17
s−1
m−1
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
1,2
yr=2
1,2
s+1
m+1
µ
r+1
m+1
cid:16
1,2
s+1
m+1
=nzt
1,2
s+1
m+1
d−4
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
r+1
cid:17
yr=s+1
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
1,2
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
m+1
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
1,2
s+1
m+1
1,2
s+1
m+1
hence
s+1
cid:16
1,2
s+1
m+1
r+1
m+1
1,2
s−1
yr=2
m−1
yr=s+1
r+1
cid:17
|x|≤3µhσ
cid:16
s+1
cid:17
cid:16
s+1
cid:17
min
cid:16
s+1
cid:17
cid:16
s+1
cid:17
β≤λhσ
cid:16
cid:17
cid:16
cid:17
min
similarly
s+1
cid:16
1,2
s+1
m+1
s−1
1,2
yr=2
r+1
m+1
follows
lemma
m−1
yr=s+1
r+1
cid:17
+1|xs
xs+1
+1|x1
xm+1
|∆3|
2d−3
√2πd
also
completely
analogous
argument
+1|xs
xs+1
−1|x1
xm+1
therefore
s+1
m+1
proof
proposition
let
ﬁrst
show
assume
contrary
exists
let
cid:8
km+1
cid:9
path
km+1
path
must
exist
since
spanning
tree
assumption
let
set
vertices
connected
since
km+1
must
exist
ks+1
ks+1
connected
unique
path
ks+1
must
include
otherwise
would
ks+1
assumption
ks+1
disconnected
uks
ks+1
assumption
uks
ks+1
either
case
ks+1
new
spanning
tree
larger
total
weight
violating
assumption
maximum-weight
spanning
tree
therefore
must
furthermore
assumption
thus
show
need
show
|i|
argued
follows
let
number
connected
components
must
include
least
edges
cross
two
different
connected
components
assumption
weights
edges
must
less
equal
thus
follows
immediately
|t|
|i|
completes
proof
proposition
appendix
proof
lemmas
proof
lemma
assumption
acyclic
must
exist
vertex
bipartition
assume
without
loss
generality
2d−1pr
+1|xi
+1|xv
xkxl
cid:17
cid:16
xk∈v1
xl∈v2
xkxl
cid:17
cid:16
xk∈v1
xl∈v2
−1|xv
xxv
xi=+1
xxv
xi=+1
xxv
xi=+1
xxv
xi=+1
2d−1pr
−1|xi
hence
due
+1|xi
−1|xi
fact
cid:16
|xi
cid:17
d−1
change
variable
−xl
since
+1|xi
−1|xi
immediately
implies
+1|xi
1/2
thus
d−1
follows
follows
fact
1/2
+1|xi
proof
lemma
let
connected
components
assumption
acyclic
therefore
must
tree
note
connected
must
belong
two
different
trees
assume
without
loss
generality
vertex
bipartition
assume
let
without
loss
generality
construction
follows
s=1
2d−2pr
+1|xi
s=1
note
+1|xv
2d−2pr
−1|xi
−1|xv
cid:16
xk∈v
xl∈v
cid:16
xk∈v
xl∈v
xkxl
cid:17
xkxl
cid:17
follows
change
variable
−xl
combining
completes
proof
proof
lemma
first
note
left-hand
side
independent
signs
real
constants
right-hand
side
monotone
decreasing
thus
may
assume
without
loss
generality
···
let
pr
−a1
xj=1
xj=i+1
a1
following
claim
claim
monotone
decreasing
pr
2−i
proof
fix
xj=1
−a1
xj=i+1
pr
−
xj=1
xj=1
a1
zj
zj
a1
...
xj=i+1
⌊i/2⌋
2−i
pr
xk=0
2−i
pr
xk=0
⌊i/2⌋
2−i
...
ai+1
xj=i+1
pr
pr
−a1
−a1
pi+1
xj=1
xj=1
i+1
a1
ai+1
xj=i+1
zj
pr
−
xj=1
zj
a1
xj=1
a1
a1
xj=i+1
xj=i+2
ai+1
ai+1
⌊i/2⌋
follows
assumption
ai+1
may
thus
conclude
monotone
decreasing
cid:0
cid:1
cid:0
k−1
cid:1
claim
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
pr
xj=1
pr
xj=1
−1
a1
⌊q/2⌋
follows
well-known
wallis
product
completes
proof
lemma
proof
lemmas
let
connected
components
assumption
acyclic
therefore
connected
component
must
tree
vertices
different
tree
assume
without
loss
generality
apparently
let
odd
even
sets
vertices
whose
graphical
distances
odd
even
respectively
prove
lemma
deﬁne
1,2
m+1
xm+1
xm+1
+1|xv
xkxl
cid:17
cid:16
xm+1
write
xm+1
−1|xv
cid:16
xkxl
cid:17
2d−2pr
+1|x1
1,2
m+1
2d−2pr
+1|x1
xm+1
1,2
m+1
2d−2pr
−1|x1
xm+1
1,2
m+1
1,2
m+1
1,2
m+1
1,2
m+1
1,2
m+1
xm+1
1,2
xj=i+1
a1
1,2
m+1
xm+1
1,2
1,2
m+1
1,2
m+1
xm+1
xkxl
cid:17
cid:16
cid:16
1,2
xm+1
∈i\
1,2
xkxl
cid:17
xm+1
1,2
follows
change
variable
−xk
∈sm+1
r=2
substituting
completes
proof
odd
1,2
m+1
xm+1
xm+1
xkxl
cid:17
cid:16
cid:16
1,2
∈i\
1,2
xkxl
cid:17
1,2
xm+1
1,2
m+1
xm+1
xm+1
cid:16
cid:16
1,2
xkxl
cid:17
∈i\
1,2
xkxl
cid:17
xm+1
1,2
follows
change
variable
−xk
odd
even
follows
change
variable
−xk
odd
even
substituting
completes
proof
prove
lemma
let
ﬁrst
write
2d−2pr
+1|xs
xs+1
s+1
m+1
s+1
m+1
s+1
m+1
s+1
m+1
2d−2pr
+1|x1
xm+1
s+1
m+1
s+1
m+1
s+1
m+1
s+1
m+1
2d−2pr
−1|x1
xm+1
s+1
m+1
s+1
m+1
s+1
m+1
s+1
m+1
s+1
m+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
s+1
s+1
s+1
s+1
xkxl
cid:17
cid:16
cid:16
s+1
xs+1
xm+1
∈i\
s+1
xkxl
cid:17
s+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
xkxl
cid:17
cid:16
cid:16
s+1
xs+1
xm+1
∈i\
s+1
xkxl
cid:17
s+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
cid:16
xkxl
cid:17
xs+1
xm+1
cid:16
s+1
∈i\
s+1
xkxl
cid:17
s+1
xs+1
xm+1
follows
change
variable
−xk
sm+1
r=s+1
follows
change
variable
−xk
r=1
follows
change
variable
−xk
sm+1
r=1
substituting
completes
proof
prove
assume
odd
even
xs+1
xm+1
cid:16
xkxl
cid:17
cid:16
s+1
∈i\
s+1
xs+1
xm+1
xs+1
xm+1
xkxl
cid:17
s+1
s+1
m+1
xs+1
xm+1
cid:16
xkxl
cid:17
cid:16
s+1
∈i\
s+1
xs+1
xm+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
cid:16
cid:16
s+1
cid:16
cid:16
s+1
xkxl
cid:17
∈i\
s+1
xkxl
cid:17
∈i\
s+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
xs+1
xm+1
xkxl
cid:17
s+1
xkxl
cid:17
s+1
xkxl
cid:17
s+1
follows
change
variable
−xk
odd
even
follows
change
variable
−xk
odd
even
follows
change
variable
−xk
odd
even
follows
change
variable
−xk
odd
even
substituting
completes
proof
even
odd
s+1
m+1
xs+1
xm+1
cid:16
xkxl
cid:17
cid:16
s+1
∈i\
s+1
xs+1
xm+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
cid:16
cid:16
s+1
xkxl
cid:17
∈i\
s+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
xs+1
xm+1
xkxl
cid:17
s+1
xkxl
cid:17
s+1
xkxl
cid:17
s+1
xs+1
xm+1
cid:16
cid:16
s+1
xkxl
cid:17
∈i\
s+1
xs+1
xm+1
s+1
m+1
xs+1
xm+1
cid:16
xkxl
cid:17
cid:16
s+1
∈i\
s+1
xs+1
xm+1
xs+1
xm+1
xkxl
cid:17
s+1
even
follows
change
variable
−xk
odd
even
s−1
s+2
s+4
follows
change
variable
−xk
odd
m+1
m+2
follows
change
variable
−xk
odd
even
follows
change
variable
−xk
odd
even
s+1
s+3
m+1
m+2
substituting
completes
proof
odd
