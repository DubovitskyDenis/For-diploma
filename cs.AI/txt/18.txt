web
semantics
science
services
agents
world
wide
web
journal
web
semantics
learning
semantics
structured
data
sources
mohsen
taheriyan∗
craig
knoblock
pedro
szekely
jos´e
luis
ambite
university
southern
california
information
sciences
institute
4676
admiralty
way
marina
del
rey
90292
usa
abstract
information
sources
relational
databases
spreadsheets
xml
json
web
apis
contain
tremendous
amount
structured
data
leveraged
build
augment
knowledge
graphs
however
rarely
provide
semantic
model
describe
contents
semantic
models
data
sources
represent
implicit
meaning
data
specifying
concepts
relationships
within
data
models
key
ingredients
automatically
publish
data
knowledge
graphs
manually
modeling
semantics
data
sources
requires
signiﬁcant
eﬀort
expertise
although
desirable
building
models
automatically
challenging
problem
related
work
focuses
semantic
annotation
data
ﬁelds
source
attributes
however
constructing
semantic
model
explicitly
describes
relationships
attributes
addition
semantic
types
critical
present
novel
approach
exploits
knowledge
domain
ontology
semantic
models
previously
modeled
sources
automatically
learn
rich
semantic
model
new
source
model
represents
semantics
new
source
terms
concepts
relationships
deﬁned
domain
ontology
given
sample
data
new
source
leverage
knowledge
domain
ontology
known
semantic
models
construct
weighted
graph
represents
space
plausible
semantic
models
new
source
compute
top
candidate
semantic
models
suggest
user
ranked
list
semantic
models
new
source
approach
takes
account
user
corrections
learn
accurate
semantic
models
future
data
sources
evaluation
shows
method
generates
expressive
semantic
models
data
sources
services
minimal
user
input
precise
models
make
possible
automatically
integrate
data
across
sources
provide
rich
support
source
discovery
service
composition
also
make
possible
automatically
publish
semantic
data
knowledge
graphs
keywords
knowledge
graph
ontology
semantic
model
source
modeling
semantic
labeling
semantic
web
linked
data
introduction
knowledge
graphs
recently
emerged
rich
ﬂexible
representation
domain
knowledge
nodes
graph
represent
entities
edges
show
relationships
entities
large
com-
panies
google
microsoft
employ
knowl-
edge
graphs
complement
traditional
search
∗corresponding
author
email
addresses
mohsen
isi.edu
mohsen
taheriyan
knoblock
isi.edu
craig
knoblock
pszekely
isi.edu
pedro
szekely
ambite
isi.edu
jos´e
luis
ambite
http
//dx.doi.org/10.1016/j.websem.2015.12.003
cid:13
2016.
licensed
creative
commons
cc-by-nc-nd
4.0
http
//creativecommons.org/licenses/by-nc-nd/4.0
methods
enhance
search
results
semantic-
search
information
linked
open
data
lod
on-
going
eﬀort
semantic
web
community
build
massive
public
knowledge
graph
goal
extend
web
publishing
various
open
datasets
rdf
web
linking
data
items
use-
ful
information
diﬀerent
data
sources
linked
data
starting
certain
point
graph
person
machine
explore
graph
ﬁnd
related
data
focus
work
ﬁrst
step
pub-
lishing
linked
data
automatically
publishing
datasets
rdf
using
common
domain
ontology
large
amount
data
lod
comes
struc-
taheriyan
web
semantics
science
services
agents
world
wide
web
tured
sources
relational
databases
spread-
sheets
publishing
sources
lod
involves
con-
structing
source
descriptions
represent
intended
meaning
data
specifying
mappings
sources
domain
ontology
domain
on-
tology
formal
model
represents
concepts
within
domain
properties
interrelation-
ships
concepts
context
meant
source
description
schema
mapping
source
ontology
represent
mapping
semantic
network
ontology
classes
nodes
ontology
properties
links
nodes
network
also
called
semantic
model
describes
source
terms
concepts
relationships
de-
ﬁned
domain
ontology
figure
depicts
se-
mantic
model
sample
data
source
including
infor-
mation
paintings
model
explicitly
rep-
resents
meaning
data
mapping
source
dbpedia1
foaf2
ontologies
knowing
semantic
model
enables
publish
data
ta-
ble
lod
knowledge
graph
figure
semantic
model
sample
data
source
containing
information
paintings
one
step
building
semantic
model
data
source
semantic
labeling
determining
semantic
types
data
ﬁelds
source
attributes
source
attribute
labeled
class
and/or
data
property
domain
ontology
exam-
ple
figure
semantic
types
ﬁrst
second
third
columns
title
artwork
name
per-
son
label
museum
respectively
however
sim-
ply
annotating
attributes
suﬃcient
unless
relationships
columns
explicitly
speci-
ﬁed
precise
model
data
1http
//dbpedia.org/ontology
2http
//xmlns.com/foaf/spec
example
person
could
owner
painter
sculptor
artwork
context
given
source
painter
correctly
interprets
relationship
artwork
person
correct
semantic
model
museum
connected
artwork
link
museum
models
may
connect
museum
person
instead
artwork
instance
person
could
president
owner
founder
museum
museum
could
employer
workplace
person
build
semantic
model
fully
recovers
semantics
data
need
second
step
determines
rela-
tionships
source
attributes
terms
properties
ontology
manually
constructing
semantic
models
requires
sig-
niﬁcant
eﬀort
expertise
although
desirable
gener-
ating
models
automatically
challenging
prob-
lem
semantic
web
research
much
work
mapping
data
sources
ontologies
2–13
focus
semantic
labeling
limited
au-
tomatically
inferring
relationships
goal
construct
semantic
models
include
se-
mantic
types
source
attributes
also
describe
relationships
paper
present
novel
approach
ex-
ploits
knowledge
domain
ontology
known
semantic
models
sources
domain
automatically
learn
rich
semantic
model
new
source
work
inspired
idea
diﬀer-
ent
sources
domain
often
provide
similar
overlapping
data
similar
semantic
models
given
sample
data
new
source
use
la-
beling
technique
annotate
source
attribute
set
candidate
semantic
types
ontol-
ogy
next
build
weighted
directed
graph
known
semantic
models
learned
semantic
types
domain
ontology
graph
models
space
plausible
semantic
models
ﬁnd
promising
mappings
source
attributes
nodes
graph
mapping
gener-
ate
candidate
model
computing
minimal
tree
connects
mapped
nodes
finally
score
candidate
models
prefer
ones
formed
coherent
frequent
patterns
work
builds
top
previous
work
learning
semantic
models
sources
cen-
tral
data
structure
approach
learn
semantic
model
new
source
graph
built
top
known
semantic
models
previous
work
add
new
component
graph
known
semantic
model
two
semantic
models
similar
diﬀer
one
link
example
still
two
diﬀerent
components
dbpedia
titlerdfs
labelmortimer
smithabraham
lincolnwinter
landscapecharles
demuthmathew
bradyzinniasdbpedia
museumdbpedia
artworkfoaf
namedbpedia
persondbpedia
paintertitlenamenational
portrait
gallerydetroit
institute
artdallas
museum
artlocationdbpedia
museum
taheriyan
web
semantics
science
services
agents
world
wide
web
graph
graph
grows
number
known
seman-
tic
models
grows
makes
computing
seman-
tic
models
ineﬃcient
large
set
known
semantic
models
paper
extend
previ-
ous
work
make
scale
large
number
seman-
tic
models
present
new
algorithm
constructs
much
compact
graph
merging
overlapping
segments
known
semantic
models
new
tech-
nique
signiﬁcantly
reduces
size
graph
terms
number
nodes
links
consequently
con-
siderably
decreases
number
possible
mappings
source
attributes
nodes
graph
also
makes
computing
minimal
tree
connects
nodes
candidate
mappings
graph
eﬃcient
new
method
build
graph
changes
algorithms
compute
rank
candidate
se-
mantic
models
main
contribution
paper
scalable
ap-
proach
exploits
structure
domain
ontol-
ogy
known
semantic
models
build
semantic
models
new
sources
evaluated
approach
set
museum
data
sources
modeled
using
two
well-
known
data
models
cultural
heritage
domain
eu-
ropeana
data
model
edm
cidoc
con-
ceptual
reference
model
cidoc-crm
data
model
standardizes
map
data
elements
domain
set
domain
ontologies
evaluation
shows
approach
automatically
generates
high-
quality
semantic
models
would
required
sig-
niﬁcant
user
eﬀort
create
manually
also
shows
semantic
models
learned
using
domain
on-
tology
known
models
approximately
accurate
models
learned
domain
ontology
background
knowledge
gen-
erated
semantic
models
key
ingredients
auto-
mate
tasks
source
discovery
information
inte-
gration
service
composition
also
for-
malized
using
mapping
languages
r2rml
used
converting
data
sources
rdf
publishing
linked
open
data
lod
cloud
knowledge
graph
implemented
approach
karma
data
modeling
integration
framework.3
users
import
data
variety
sources
including
rela-
tional
databases
spreadsheet
xml
ﬁles
json
ﬁles
karma
also
import
domain
ontolo-
gies
want
use
modeling
data
system
automatically
suggests
semantic
model
loaded
source
karma
provides
easy
use
graphical
3http
//karma.isi.edu
user
interface
let
users
interactively
reﬁne
learned
semantic
models
needed
semantic
model
created
new
source
users
publish
data
rdf
clicking
single
button
szekely
used
karma
model
data
smithsonian
amer-
ican
art
museum4
publish
linked
open
data
cloud
karma
also
able
build
semantic
models
web
services
exploits
created
semantic
models
build
apis
directly
communi-
cate
semantic
level
22–24
motivating
example
explain
problem
learning
semantic
models
giving
concrete
example
used
through-
paper
illustrate
diﬀerent
steps
ap-
proach
example
goal
model
set
museum
data
sources
using
edm5
aac6
skos7
dublin
core
metadata
terms8
frbr9
foaf
ore10
elementsgr211
ontologies
use
created
semantic
models
publish
data
rdf
sup-
pose
three
data
sources
ﬁrst
source
table
containing
information
artworks
dallas
museum
art12
figure
formally
write
signature
source
dma
title
creationdate
name
type
dma
name
source
title
creationdate
name
type
names
source
attributes
columns
second
source
npg
csv
ﬁle
including
data
portraits
national
portrait
gallery13
figure
third
data
source
dia
data
artworks
detroit
institute
art14
figure
figure
shows
correct
semantic
model
sources
dma
npg
dia
created
experts
museum
domain
semantic
model
source
called
directed
graph
containing
two
types
nodes
class
nodes
ovals
correspond
classes
ontology
data
nodes
rectangles
correspond
source
attributes
labeled
attribute
names
links
graph
associated
ontology
proper-
ties
particular
link
karma
uri
class
node
4http
//americanart.si.edu
5http
//www.europeana.eu/schemas/edm
6http
//www.americanartcollaborative.org/ontology
7http
//www.w3.org/2008/05/skos
8http
//purl.org/dc/terms
9http
//vocab.org/frbr/core.html
10http
//www.openarchives.org/ore/terms
11http
//rdvocab.info/elementsgr2
12http
//www.dma.org
13http
//www.nationalportraitgallery.org
14http
//www.dia.org
taheriyan
web
semantics
science
services
agents
world
wide
web
dma
title
creationdate
name
type
npg
name
artist
year
image
dia
title
credit
classiﬁcation
name
imageurl
figure
sample
data
three
museum
sources
dallas
museum
art
national
portrait
gallery
detroit
institute
art
represents
ontology
class
data
node
represents
source
attribute
denotes
at-
tribute
values
uris
class
instances
instance
figure
values
column
image
source
npg
uris
instances
class
edm
webresource
discussed
earlier
automatically
building
se-
mantic
models
diﬃcult
machine
learning
meth-
ods
help
assigning
semantic
types
at-
tributes
looking
attributes
values
however
methods
error
prone
similar
data
val-
ues
diﬀerent
semantic
types
example
data
values
attribute
creationdate
source
dma
hard
say
whether
creation
date
aac
culturalheritageobject
birth-
date
aac
person
extracting
relationships
be-
tween
attributes
complicated
problem
might
multiple
paths
connecting
two
classes
ontology
know
one
captures
intended
meaning
data
instance
several
paths
domain
ontology
connecting
aac
culturalheritageobject
aac
person
context
source
dma
link
dcterms
creator
represents
correct
meaning
source
another
example
attributes
artist
name
source
npg
labeled
name
person
nevertheless
decide
whether
two
attributes
diﬀerent
names
one
person
belong
two
distinct
indi-
viduals
general
ontology
deﬁnes
large
space
possible
semantic
models
without
additional
con-
text
know
one
describes
source
precisely
dma
semantic
model
source
dma
npg
semantic
model
source
npg
dia
semantic
model
source
dia
figure
semantic
models
example
data
sources
created
experts
museum
domain
class
nodes
ovals
links
correspond
classes
properties
ontology
preﬁxed
ontology
namespace
particular
link
karma
uri
simply
means
values
attribute
image
source
npg
uris
instances
class
edm
webresource
aac
culturalheritageobjectcreationdate
dcterms
createdaac
person
dcterms
creatorskos
concept
dcterms
hastypetitle
dcterms
titlename
foaf
nametype
skos
preflabelaac
culturalheritageobjectaac
person
dcterms
creatoraac
person
aac
sitteryear
dcterms
createdartistnameedm
europeanaaggregation
edm
aggregatedchoedm
webresource
edm
hasviewimage
karma
uri
foaf
name
foaf
nameaac
culturalheritageobjectcredit
dcterms
provenanceaac
person
dcterms
creatorskos
concept
dcterms
hastypetitle
dcterms
titlename
foaf
nameclassiﬁcation
skos
preflabelimageurledm
europeanaaggregation
edm
aggregatedchoedm
webresource
edm
hasview
karma
uri
taheriyan
web
semantics
science
services
agents
world
wide
web
assume
correct
semantic
models
sources
dma
npg
given
leverage
known
semantic
models
build
semantic
model
new
source
dia
next
section
present
scalable
automated
approach
exploits
known
semantic
models
dma
npg
limit
search
space
learn
semantic
model
dia
new
source
dia
learning
semantic
models
formally
state
problem
learning
se-
mantic
models
data
sources
let
do-
main
ontology15
···
set
known
semantic
models
corresponding
data
sources
···
given
sample
data
new
source
···
called
target
source
···
source
attributes
goal
automatically
compute
semantic
model
captures
intended
meaning
source
example
dma
npg
known
semantic
models
source
dia
new
source
want
automatically
learn
semantic
model
main
idea
data
sources
do-
main
usually
provide
overlapping
data
therefore
leverage
attribute
relationships
known
semantic
models
hypothesize
attribute
relationships
new
sources
one
metrics
helping
infer
relation-
ships
attributes
new
source
pop-
ularity
links
semantic
types
set
known
models
nevertheless
simply
using
link
pop-
ularity
connect
set
nodes
would
lead
myopic
decisions
select
links
appear
frequently
models
without
taking
account
nodes
connected
nodes
given
models
suppose
set
known
semantic
models
one
models
contains
link
painter
art-
work
person
link
museum
artwork
museum
similar
example
figure
models
contain
type
artwork
include
link
founder
museum
person
given
new
source
contains
types
artwork
museum
person
using
link
popularity
yields
incorrect
model
approach
takes
account
coherence
patterns
addition
popularity
complicated
approach
learn
semantic
model
new
source
four
steps
using
sample
data
15o
set
ontologies
new
source
learn
semantic
types
source
at-
tributes
construct
graph
known
semantic
models
augmented
nodes
links
corresponding
learned
semantic
types
ontology
paths
con-
necting
nodes
graph
compute
candidate
mappings
source
attributes
nodes
graph
finally
build
candidate
semantic
models
candidate
mappings
rank
generated
mod-
els
3.1.
learning
semantic
types
source
attributes
ﬁrst
step
model
semantics
new
source
recognize
semantic
types
data
call
step
semantic
labeling
involves
anno-
tating
source
columns
classes
properties
ontology
objective
step
as-
sign
semantic
types
source
attributes
formally
deﬁne
semantic
type
either
ontology
class
cid:104
class
uri
cid:105
pair
consisting
domain
class
one
data
properties
cid:104
class
uri
property
uri
cid:105
use
class
semantic
type
attributes
whose
values
uris
instances
class
attributes
con-
taining
automatically-generated
database
keys
also
modeled
instances
class
use
do-
main/data
property
pair
semantic
type
attributes
containing
literal
values
example
semantic
types
attributes
imageurl
classiﬁcation
source
dia
respectively
cid:104
edm
webresource
cid:105
cid:104
skos
concept
skos
preflabel
cid:105
syntactic
information
data
sources
attribute
names
attribute
types
string
int
date
...
may
give
system
hints
discover
seman-
tic
types
often
suﬃcient
e.g.
name
ﬁrst
ﬁeld
source
dia
title
know
whether
title
book
song
artwork
moreover
many
cases
attribute
names
used
abbreviated
forms
e.g.
dob
rather
birthdate
employ
technique
proposed
krishna-
murthy
learn
semantic
types
source
at-
tributes
approach
focuses
learning
seman-
tic
types
data
rather
attribute
names
learns
semantic
labeling
function
set
sources
manually
labeled
presented
new
source
learned
semantic
labeling
function
automatically
assign
semantic
types
attribute
new
source
training
data
consists
set
semantic
types
semantic
type
set
data
values
attribute
names
associated
given
new
set
data
values
new
source
goal
predict
top
candidate
semantic
types
along
conﬁdence
scores
using
training
data
taheriyan
web
semantics
science
services
agents
world
wide
web
table
top
two
learned
semantic
types
at-
tributes
source
dia
attribute
title
credit
classiﬁcation
name
imageurl
candidate
semantic
types
cid:104
aac
culturalheritageobject
dcterms
title
cid:105
0.49
cid:104
aac
culturalheritageobject
rdfs
label
cid:105
0.28
cid:104
aac
culturalheritageobject
dcterms
provenance
cid:105
0.83
cid:104
aac
person
elementsgr2
note
cid:105
0.06
cid:104
skos
concept
skos
preflabel
cid:105
0.58
cid:104
skos
concept
rdfs
label
cid:105
0.41
cid:104
aac
person
foaf
name
cid:105
0.65
cid:104
foaf
person
foaf
name
cid:105
0.32
cid:104
foaf
document
cid:105
0.47
cid:104
edm
webresource
cid:105
0.40
data
values
associated
source
attribute
textual
data
labeling
algorithm
uses
co-
sine
similarity
tf/idf
vectors
labeled
documents
input
document
predict
candi-
date
semantic
types
set
data
values
associated
textual
semantic
type
training
data
treated
document
input
document
consists
data
values
associated
attributes
numeric
data
algorithm
uses
statistical
hypothesis
testing
analyze
distribution
numeric
val-
ues
intuition
distribution
values
semantic
type
diﬀerent
example
distri-
bution
temperatures
likely
diﬀerent
distribution
weights
training
data
consists
set
numeric
semantic
types
semantic
type
sample
numeric
data
values
predic-
tion
time
given
new
set
numeric
data
values
query
sample
algorithm
performs
statistical
hypothesis
tests
query
sample
sample
training
data
apply
labeling
method
generates
set
candidate
semantic
types
source
attribute
conﬁdence
value
algorithm
se-
lects
top
semantic
types
attribute
input
next
step
process
thus
output
labeling
step
···
tp11
···
tp1k
jth
semantic
type
learned
attribute
associated
conﬁdence
value
decimal
value
table
lists
candidate
semantic
types
source
dia
considering
k=2
semantic
labeling
method
prefers
cid:104
foaf
document
cid:105
semantic
type
tpi
see
table
···
tpm1
···
tpmk
algorithm
construct
graph
input
known
semantic
models
sm1
···
smn
attributes
···
semantic
types
tp11
···
tpm1
ontology
···
tp1k
···
tpmk
output
graph
addknownmodels
addsemantictypes
addontologypaths
return
attribute
imageurl
according
cor-
rect
model
figure
cid:104
edm
webresource
cid:105
cor-
rect
semantic
type
show
later
ap-
proach
recovers
correct
semantic
type
consider-
ing
coherence
structure
computing
semantic
models
3.2.
building
graph
known
semantic
models
semantic
types
domain
ontology
far
tagged
attributes
dia
set
candidate
semantic
types
build
complete
semantic
model
still
need
determine
relation-
ships
attributes
leverage
knowl-
edge
known
semantic
models
discover
popular
coherent
patterns
connecting
candidate
semantic
types
central
component
method
directed
weighted
graph
built
top
known
semantic
models
expanded
using
semantic
types
domain
ontology
similar
semantic
model
contains
class
nodes
data
nodes
links
links
correspond
properties
weights
links
algorithm
shows
steps
build
graph
algorithm
three
parts
adding
known
semantic
models
dma
npg
algorithm
adding
semantic
types
learned
target
source
algorithm
expanding
graph
using
domain
ontology
algorithm
adding
known
semantic
models
suppose
want
add
graph
graph
empty
simply
add
nodes
links
otherwise
merge
nodes
links
adding
nodes
links
exist
adding
new
node
link
tag
unique
identiﬁer
e.g.
name
source
indicating
node/link
exist
node
link
already
exists
graph
add
identiﬁer
tags
taheriyan
web
semantics
science
services
agents
world
wide
web
figure
graph
adding
known
semantic
models
dma
npg
nodes
links
added
step
shown
black
color
figure
order
easily
refer
nodes
ﬁgure
text
assign
unique
name
node
name
node
written
small
font
left
side
node
example
node
label
edm
europeanaaggregartion
named
orange
green
tags
labels
black
links
identiﬁers
indicating
seman-
tic
model
supporting
links
instance
link
dcterms
creator
aac
culturalheritageobject
aac
person
tagged
dma
npg
be-
cause
exists
dma
npg
read-
ability
put
tags
nodes
figure
although
merging
semantic
model
looks
straightforward
diﬃculties
semantic
model
graph
include
multiple
class
nodes
label
suppose
already
includes
two
class
nodes
labeled
person
connected
link
isfriendof
want
add
semantic
model
including
link
worksfor
person
or-
ganization
assuming
class
node
label
organization
add
new
class
node
question
put
link
works-
one
option
duplicate
link
adding
link
pair
assign
diﬀerent
tags
added
links
approach
slows
process
building
graph
yield
graph
large
number
links
algorithm
compute
candidate
semantic
models
would
ineﬃcient
therefore
adopt
diﬀerent
strategy
one
node
graph
matching
node
semantic
model
select
one
tags
heuristic
creates
compact
graph
makes
whole
algorithm
faster
much
impact
results
algorithm
illustrates
details
method
add
semantic
model
line
let
hashmap
keeping
mappings
nodes
nodes
key
entry
node
value
node
lines
3-13
class
node
search
graph
see
includes
class
node
label
node
exists
graph
simply
add
new
node
graph
possible
contains
multiple
class
nodes
label
instance
model
including
link
isfriendof
one
person
another
per-
son
case
make
sure
also
least
number
class
nodes
la-
bel
example
one
person
add
another
class
node
label
person
added
required
class
nodes
graph
map
class
nodes
model
class
nodes
graph
multiple
class
nodes
label
select
one
tagged
larger
num-
ber
known
semantic
models
add
entry
key
mapped
node
cid:48
value
lines
14-23
link
data
node
search
graph
see
match
pattern
ﬁrst
use
ﬁnd
node
cid:48
node
mapped
cid:48
outgoing
link
label
equal
aac
culturalheritageobjectcreationdate
dcterms
createdtitle
dcterms
titleskos
concept
dcterms
hastypeaac
person
dcterms
creatoraac
person
aac
sittername
foaf
nametype
skos
preflabelimageedm
europeanaaggregation
edm
aggregatedchoedm
webresource
edm
hasview
karma
uriname
foaf
namen1n3n2n4n5n6n7n8n9n10n11n12npgnpgnpgnpgnpgnpgnpgnpgdmadmadmadmadmadma
taheriyan
web
semantics
science
services
agents
world
wide
web
algorithm
add
known
semantic
models
function
addknownmodels
hashmap
cid:104
node
node
cid:105
cid:46
keys
nodes
smi
cid:46
values
matched
nodes
class
node
smi
smi
label
number
class
nodes
smi
label
number
class
nodes
label
add
class
nodes
label
matched
nodes
class
nodes
label
unmapped
nodes
matched
nodes
values
cid:48
node
largest
tag
set
unmapped
nodes
add
cid:104
cid:48
cid:105
end
link
class
node
data
node
smi
label
cid:48
cid:48
outgoing
link
label
else
cid:48
target
link
label
add
new
data
node
cid:48
end
add
cid:104
cid:48
cid:105
end
link
smi
cid:48
cid:48
cid:48
cid:48
cid:48
cid:48
tagse
cid:48
tagse
cid:48
smi
weight
cid:48
|tagse
cid:48
add
link
cid:48
cid:48
cid:48
cid:48
tagse
cid:48
smi
weight
cid:48
else
end
end
end
end
function
label
add
new
data
node
cid:48
add
mapped
data
node
cid:48
lines
24-37
link
ﬁnd
nodes
mapped
say
cid:48
cid:48
includes
link
label
label
cid:48
cid:48
add
tags
associated
link
otherwise
add
new
link
graph
tag
adding
semantic
types
known
semantic
models
added
add
semantic
types
learned
attributes
target
source
men-
tioned
two
kinds
semantic
types
cid:104
class
uri
cid:105
attributes
whose
data
values
uris
cid:104
class
uri
property
uri
cid:105
attributes
lit-
eral
data
learned
semantic
type
search
graph
see
whether
includes
match
algorithm
add
semantic
types
function
addsemantictypes
attributes
tpi1
···
tpik
cid:104
class
uri
cid:105
class
uri
karma
uri
class
uri
property
uri
tpi
else
cid:104
class
uri
property
uri
cid:105
end
node
label
add
new
node
label
end
vmatch
class
nodes
label
|e|
vmatch
outgoing
link
labeled
add
data
node
label
add
link
label
weight
end
end
end
end
end
function
cid:104
class
uri
cid:105
say
match
class
node
label
class
uri
data
node
link
label
karma
uri
example
figure
karma
uri
match
semantic
type
cid:104
edm
webresource
cid:105
cid:104
class
uri
property
uri
cid:105
say
match
class
node
labeled
class
uri
data
node
link
labeled
property
uri
figure
n10
skos
preflabel
match
seman-
tic
type
cid:104
skos
concept
skos
preflabel
cid:105
say
cid:104
class
uri
cid:105
cid:104
class
uri
property
uri
cid:105
partial
match
ﬁnd
full
match
class
node
whose
label
matches
class
uri
instance
semantic
type
cid:104
skos
concept
rdfs
label
cid:105
partial
match
contains
class
node
labeled
skos
concept
class
node
outgoing
link
label
rdfs
label
algorithm
shows
function
adds
learned
semantic
types
graph
semantic
type
learned
labeling
step
add
necessary
nodes
links
create
match
complete
existing
partial
matches
consider
semantic
types
learned
source
dia
table
figure
illustrates
graph
adding
semantic
types
nodes
links
added
step
depicted
blue
color
cid:104
aac
culturalheritageobject
dcterms
title
cid:105
taheriyan
web
semantics
science
services
agents
world
wide
web
figure
graph
adding
nodes
links
corresponding
semantic
types
shown
blue
need
change
graph
already
contained
one
match
dcterms
title
seman-
tic
type
cid:104
skos
concept
rdfs
label
cid:105
one
partial
match
thus
add
one
data
node
n18
label
equal
name
corresponding
attribute
one
link
rdfs
label
n18
order
complete
existing
partial
match
semantic
type
cid:104
foaf
document
cid:105
neither
match
partial
match
add
class
node
n15
data
node
n17
link
karma
uri
n15
n17
create
match
adding
paths
ontology
use
do-
main
ontology
ﬁnd
paths
relate
cur-
rent
class
nodes
algorithm
goal
connect
class
nodes
using
direct
paths
paths
inferred
subclass
hierarchy
ﬁnal
graph
shown
figure
con-
nect
two
class
nodes
graph
ob-
ject
property
subclassof
relationship
connects
corresponding
classes
ontology
in-
stance
figure
link
ore
aggregates
link
added
object
prop-
erty
ore
aggregates
deﬁned
ore
aggregation
domain
ore
aggregatedresource
range
edm
europeanaaggregation
subclass
class
ore
aggregation
aac
culturalheritageobject
subclass
edm
providedcho
turn
sub-
class
class
ore
aggregatedresource
another
example
reason
connected
n15
property
foaf
page
deﬁned
owl
thing
foaf
document
foaf
ontology
thus
link
label
foaf
page
would
exist
class
node
algorithm
add
ontology
paths
function
addontologypaths
pair
class
nodes
ontology
class
uri
ontology
class
uri
direct
inferred
properties
including
rdfs
subclassof
|e|
property
uri
property
link
label
add
link
label
weight
end
end
end
end
function
n15
since
classes
subclasses
class
owl
thing
depending
size
ontology
many
nodes
links
may
added
graph
step
make
ﬁgure
readable
added
nodes
links
illustrated
figure
ones
red
color
cases
consists
disconnected
compo-
nents
add
class
node
label
owl
thing
graph
connect
class
nodes
parent
root
node
using
rdfs
subclassof
link
converts
original
graph
graph
one
connected
component
links
graph
weighted
assigning
weights
links
graph
important
algorithm
divide
links
two
categories
ﬁrst
category
includes
links
associated
known
semantic
models
black
links
figure
group
consists
links
added
aac
culturalheritageobjectfoaf
personcreationdate
dcterms
createdtitle
dcterms
titleskos
concept
dcterms
hastypeaac
person
dcterms
creatoraac
person
aac
sittercredit
dcterms
provenancename
foaf
namecredit
elementsgr2
notetype
skos
preflabelclassiﬁcation
rdfs
labelimageedm
europeanaaggregation
edm
aggregatedchoedm
webresource
edm
hasviewfoaf
document
karma
urititle
rdfs
labelname
foaf
namecredit
elementsgr2
notename
foaf
nameimageurl
karma
urin1n3n2n4n5n6n7n8n9n10n11n12n13n14n15n17n16n18n19n20n21npgnpgnpgnpgnpgdmadmadmadmanpgdmanpgdmanpg
taheriyan
web
semantics
science
services
agents
world
wide
web
figure
ﬁnal
graph
adding
paths
domain
ontologies
legibility
possible
paths
class
nodes
shown
drawn
red
color
learned
semantic
types
ontology
blue
red
links
tagged
identiﬁer
basis
weighting
function
assign
much
lower
weight
links
former
group
compared
links
latter
group
default
weigh
link
ﬁrst
group
default
weight
link
second
group
cid:28
intuition
behind
decision
produce
coherent
models
next
step
generat-
ing
minimum-cost
semantic
models
section
3.4
goal
give
priority
models
containing
larger
segments
known
patterns
one
reason-
able
value
|e|
|e|
number
links
formula
ensures
even
long
pat-
tern
known
semantic
model
cost
less
single
link
exist
known
semantic
model
one
factor
consider
weighting
links
coming
known
semantic
models
black
links
popularity
links
i.e.
number
known
semantic
models
supporting
link
assign
black
link
number
known
semantic
models
number
identi-
ﬁers
link
tagged
suppose
use
example
since
graph
figure
total
links
∗|e|=
26.
figure
link
edm
hasview
weighted
0.66
supported
npg
n=2
x=1
weight
link
dcterms
creator
0.33
since
dma
npg
contain
link
link
two
tags
assign
links
associated
known
models
blue
red
links
tag
small
adjustment
links
coming
ontology
red
links
prior-
itize
direct
properties
inherited
properties
as-
signing
slightly
higher
weight
inherited
ones
rationale
behind
decision
comes
observation
direct
properties
spe-
ciﬁc
likely
used
semantic
mod-
els
inherited
properties
general
instance
red
link
aac
sitter
weighted
deﬁnition
on-
tology
aac
aac
culturalheritageobject
domain
aac
person
range
hand
weight
link
ore
aggregates
26.01
as-
sume
0.01
since
domain
ore
aggregates
ontology
ore
class
ore
aggregation
superclass
edm
europeanaaggregation
range
class
ore
aggregatedresource
superclass
aac
culturalheritageobject
3.3.
mapping
source
attributes
graph
use
graph
built
previous
step
infer
relationships
source
attributes
first
ﬁnd
mappings
source
attributes
subset
nodes
graph
use
mappings
generate
rank
candidate
semantic
models
section
describe
mapping
process
sec-
tion
3.4
talk
computing
candidate
semantic
models
map
attributes
source
nodes
figure
search
ﬁnd
nodes
matching
semantic
types
associated
at-
aac
culturalheritageobjectfoaf
person
dcterms
creatorcreationdate
dcterms
createdtitle
dcterms
titleskos
concept
dcterms
hastypeaac
person
dcterms
creatoraac
person
aac
sitter
aac
sitter
dcterms
creatorcredit
dcterms
provenancename
foaf
namecredit
elementsgr2
notetype
skos
preflabelclassiﬁcation
rdfs
labelimageedm
europeanaaggregation
ore
aggregates
edm
aggregatedchoedm
webresource
edm
hasviewfoaf
document
foaf
page
karma
uri
edm
isshownattitle
rdfs
labelname
foaf
namecredit
elementsgr2
notename
foaf
nameimageurl
karma
uriore
aggregation
rdfs
subclassof
ore
aggregatesn22npgnpgnpgnpgnpgdmadmadmadmanpgdmanpgdmanpgn1n3n2n4n5n6n7n8n9n10n11n12n13n14n15n17n16n18n19n20n21
taheriyan
web
semantics
science
services
agents
world
wide
web
tributes
example
attribute
classiﬁcation
dia
maps
n10
n18
corresponding
semantic
types
cid:104
skos
concept
skos
preflabel
cid:105
cid:104
skos
concept
rdfs
label
cid:105
respectively
since
attribute
annotated
seman-
tic
types
also
semantic
type
may
one
match
e.g.
cid:104
aac
person
foaf
name
cid:105
maps
n11
n12
one
mapping
might
exist
source
attributes
nodes
generating
mappings
feasible
cases
data
source
many
attributes
learned
semantic
types
many
matches
graph
problem
becomes
worse
gener-
ate
one
candidate
semantic
type
at-
tribute
suppose
modeling
source
con-
sisting
attributes
generated
semantic
types
attribute
matches
semantic
type
mappings
source
attributes
nodes
present
heuristic
search
algorithm
explores
space
possible
mappings
map
seman-
tic
types
nodes
graph
expands
promising
mappings
algorithm
scores
mappings
processing
attribute
removes
low
score
ones
scoring
function
takes
ac-
count
conﬁdence
values
semantic
types
coherence
nodes
mappings
size
mappings
inputs
algorithm
learned
semantic
types
tp11
···
tpm1
···
tpmk
attributes
source
···
graph
output
set
candi-
date
mappings
source
attributes
subset
nodes
key
idea
instead
gener-
ating
mappings
feasible
score
partial
mappings
processing
attribute
prune
mappings
lower
scores
words
soon
ﬁnd
matches
semantic
types
attribute
rank
partial
mappings
keep
better
ones
way
number
candidate
map-
pings
never
exceeds
ﬁxed
size
branching
factor
mapping
attribute
···
tp1k
algorithm
shows
mapping
process
heart
algorithm
scoring
function
use
rank
partial
mappings
line
algorithm
compute
three
functions
mapping
conﬁdence
coherence
sizereduction
calculate
ﬁnal
score
score
combin-
ing
values
three
functions
explain
functions
using
example
suppose
maxi-
mum
number
mappings
expand
step
branching
factor
mapping
sec-
ond
attribute
source
dia
credit
algorithm
generate
candidate
mappings
input
attributes
···
tp11
···
tpm1
branching
actor
max
number
mappings
expand
num
candidates
number
candidate
mappings
···
tpmk
···
tp1k
output
set
candidate
mappings
attributes
else
tpi1
matches
mappings
mappings
mappings
candidates
attributes
···
tpik
tpi
matches
matching
mappings
end
candidates
top
num
candidates
items
mappings
end
mappings
matches
cid:48
mappings
mappings
cid:48
compute
score
mappings
sort
items
mappings
descending
based
score
keep
top
branching
factor
mappings
remove
others
end
|mappings|
branching
factor
end
remove
mappings
end
end
end
return
candidates
mappings
title
credit
n13
title
credit
n19
title
credit
n20
title
credit
n14
n13
title
credit
n14
n19
title
credit
n14
n20
two
matches
attribute
title
semantic
type
cid:104
aac
culturalheritageobject
dcterms
title
cid:105
n14
semantic
type
cid:104
aac
culturalheritageobject
rdfs
label
cid:105
three
matches
cid:104
aac
culturalheritageobject
dcterms
provenance
cid:105
n19
n20
semantic
type
cid:104
aac
person
elementsgr2
note
cid:105
yields
diﬀerent
mappings
since
branching
factor
eliminate
four
mappings
describe
algorithm
ranks
mappings
semantic
n13
attribute
credit
type
conﬁdence
deﬁne
conﬁdence
arithmetic
mean
conﬁdence
values
associated
mapping
example
consisting
matches
taheriyan
web
semantics
science
services
agents
world
wide
web
semantic
types
cid:104
aac
culturalheritageobject
dcterms
title
cid:105
0.49
cid:104
aac
culturalheritageobject
dcterms
provenance
cid:105
0.83.
thus
conﬁdence
0.66.
coherence
function
measures
largest
num-
ber
nodes
mapping
belong
known
semantic
model
like
links
nodes
also
tagged
model
identiﬁers
although
shown
figure
calculate
coherence
maximum
number
nodes
mapping
least
one
common
tag
in-
stance
coherence
0.66
two
nodes
three
nodes
dma
coherence
1.0
nodes
semantic
model
dma
goal
deﬁning
coherence
give
priority
models
containing
larger
segments
known
pat-
terns
size
reduction
deﬁne
size
mapping
size
number
nodes
mapping
since
prefer
concise
models
seek
mappings
mapping
attributes
fewer
nodes
smallest
possible
size
mapping
attributes
map
class
node
e.g.
largest
attributes
map
diﬀerent
class
nodes
e.g.
thus
possible
size
reduction
mapping
deﬁne
sizereduction
size
much
size
mapping
reduced
com-
pared
possible
size
reduction
example
sizereduction
0.5
sizereduction
score
score
ﬁnal
combina-
tion
values
conﬁdence
coherence
sizereduction
range
assign
weight
values
compute
ﬁnal
score
weighted
sum
score
conﬁdence
coherence
sizereduction
weights
decimal
values
range
summing
proper
values
weights
tuned
experiments
evaluation
section
obtained
better
results
three
functions
contributed
equally
ﬁnal
score
score
calculated
arithmetic
mean
conﬁdence
coherence
sizereduction
1/3
example
use
arithmetic
mean
com-
pute
ﬁnal
score
scores
mappings
score
0.60
mentioned
follows
score
0.42
score
0.42
score
0.46
score
0.39
score
0.39.
therefore
removed
mappings
line
algorithm
continues
next
it-
eration
mapping
next
attribute
source
dia
classiﬁcation
graph
end
maximum
branching
factor
mappings
include
attributes
sort
mappings
based
score
consider
top
num
candidates
mappings
candidates
algo-
rithm
line
3.4.
generating
ranking
semantic
models
generated
candidate
mappings
source
attributes
nodes
graph
compute
rank
candidate
semantic
models
compute
se-
mantic
model
mapping
ﬁnd
minimum-
cost
tree
connects
nodes
cost
tree
sum
weights
links
problem
known
steiner
tree
problem
given
edge-weighted
graph
subset
vertices
called
steiner
nodes
goal
ﬁnd
minimum-weight
tree
spans
steiner
nodes
general
steiner
tree
problem
np-complete
however
several
approximation
algorithms
26–29
used
gain
polynomial
runtime
complexity
inputs
algorithm
graph
nodes
steiner
nodes
output
tree
consider
candidate
semantic
model
source
example
source
dia
map-
ping
title
credit
classiﬁcation
name
imageurl
n13
n10
n11
resulting
steiner
tree
exactly
shown
fig-
ure
correct
semantic
model
source
dia
algorithm
compute
minimal
tree
prefers
links
appear
known
semantic
mod-
els
links
tags
much
lower
weight
links
additionally
since
weight
link
tags
inverse
relation
number
tags
number
known
semantic
mod-
els
containing
link
semantic
model
obtained
computing
minimal
tree
contain
links
popular
known
semantic
models
selecting
popular
links
always
yield
correct
semantic
model
suppose
three
known
semantic
models
connects
aac
culturalheritageobject
one
two
instances
aac
person
using
links
dc-
terms
creator
aac
sitter
similar
npg
two
semantic
models
contain
class
node
aac
culturalheritageobject
two
class
nodes
aac
person
connected
using
link
foaf
knows
figure
shows
small
part
graph
constructed
using
known
models
black
labels
links
represent
weights
links
instance
link
dcterms
creator
weight
taheriyan
web
semantics
science
services
agents
world
wide
web
inal
banks
algorithm
developed
problem
keyword-based
search
relational
databases
makes
speciﬁc
assumptions
topol-
ogy
graph
applying
directly
problem
eliminates
trees
results
in-
stance
two
nodes
connected
using
two
links
diﬀerent
weights
considers
one
lower
weight
never
generates
tree
including
link
higher
weight
customized
original
algorithm
support
general
cases
figure
small
part
example
graph
constructed
using
three
known
models
equal
0.75
supported
0.75
attributes
assume
new
source
annotated
three
aac
culturalheritageobject
aac
person
aac
person
computing
minimal
tree
mapping
result
tree
consists
link
foaf
knows
either
dcterms
creator
aac
sitter
nonetheless
correct
semantic
model
source
includes
aac
culturalheritageobject
addition
two
aac
person
likely
source
describ-
ing
relations
cultural
heritage
objects
people
relations
people
solve
problem
taking
account
co-
herence
patterns
instead
minimal
steiner
tree
compute
top-k
steiner
trees
rank
ﬁrst
based
coherence
links
cost
example
shown
figure
top-3
results
assuming
steiner
nodes
t1=
aac
sitter
foaf
knows
t2=
dcterms
creator
foaf
knows
t3=
dcterms
creator
aac
sitter
cost
=cost
=1.25
cost
=1.5
computed
top-k
trees
sort
according
coherence
coherence
means
percent-
age
links
steiner
tree
supported
semantic
model
computed
similar
coherence
nodes
diﬀerence
use
tags
links
instead
tags
nodes
example
coherence
0.5
links
belong
known
se-
mantic
model
coherence
1.0
since
links
tagged
therefore
ranked
higher
although
higher
cost
use
customized
version
banks
algo-
rithms
compute
top-k
steiner
trees
orig-
banks
algorithm
creates
one
iterator
nodes
corresponding
semantic
types
iterators
follow
incoming
links
reach
common
ancestor
algorithm
uses
iterator
dis-
tance
starting
point
decide
link
followed
next
weights
inverse
re-
lation
popularity
algorithm
prefers
frequent
links
make
algorithm
converge
coherent
models
ﬁrst
use
heuristic
prefers
links
parts
pattern
known
seman-
tic
model
even
higher
weights
suppose
e3−→v3
sm1
known
models
used
build
graph
weight
link
higher
assume
semantic
labels
algorithm
creates
two
iterators
one
starting
one
iterator
starts
reaches
following
incoming
link
e3−→v3
point
analyzes
incoming
links
although
lower
weight
ﬁrst
chooses
traverse
next
part
known
model
sm2
includes
previously
traversed
link
e1−→v2
sm2
e2−→v2
example
source
dia
important
note
considering
coherence
patterns
scoring
mappings
also
ranking
ﬁnal
semantic
models
enables
approach
compute
correct
semantic
model
many
cases
top
semantic
types
correct
ones
map-
ping
title
credit
classiﬁcation
name
imageurl
n13
n10
n11
maps
attribute
imageurl
using
type
cid:104
edm
webresource
cid:105
scored
higher
mapping
cid:48
title
credit
classiﬁcation
name
imageurl
n13
n10
n11
n15
n17
maps
type
cid:104
foaf
document
cid:105
mapping
lower
con-
ﬁdence
value
cid:48
scored
higher
coherence
value
higher
model
computed
mapping
also
ranked
higher
model
computed
cid:48
includes
links
known
patterns
thus
resulting
lower
cost
tree
imageurl
n15
n17
using
aac
culturalheritageobjectaac
person
dcterms
creatoraac
person
aac
sitter
foaf
knows0.750.5n1n3n2s1s1s2s30.75
taheriyan
web
semantics
science
services
agents
world
wide
web
evaluation
table
evaluation
datasets
dsedm
dscrm
evaluated
approach
two
datasets
in-
cluding
set
data
sources
set
domain
on-
tologies
used
model
sources
datasets
set
data
sources
museum
sources
csv
xml
json
format
con-
taining
data
diﬀerent
art
museums
how-
ever
include
diﬀerent
domain
ontologies
goal
learn
semantic
models
data
sources
respect
two
well-known
data
models
museum
domain
europeana
data
model
edm
,16
cidoc
conceptual
reference
model
cidoc-crm
.17
data
models
use
diﬀerent
domain
ontologies
repre-
sent
knowledge
museum
domain
ﬁrst
dataset
dsedm
contains
edm
aac
skos
dublin
core
metadata
terms
frbr
foaf
ore
elementsgr2
ontologies
second
dataset
dscrm
includes
cidoc-crm
skos
ontologies
reason
used
two
data
mod-
els
evaluate
approach
performs
re-
spect
diﬀerent
representations
knowledge
do-
main
applied
approach
datasets
ﬁnd
candidate
semantic
models
source
compared
best
suggested
models
ﬁrst
ranked
models
models
created
manually
domain
ex-
perts
table
shows
details
evaluation
datasets
datasets
including
sources
domain
ontologies
gold
standard
models
available
github.18
source
code
approach
inte-
grated
karma
available
open
source.19
addi-
tion
time-consuming
error-prone
requires
thorough
understanding
domain
ontologies
karma
provides
user
friendly
graphical
interface
enabling
users
interactively
build
semantic
mod-
els
yet
building
models
karma
without
au-
tomation
requires
signiﬁcant
user
eﬀort
automatic
approach
learns
accurate
semantic
models
transformed
gold
standard
models
user
actions
manually
constructing
semantic
models
dataset
applied
method
learn
se-
mantic
model
target
source
assuming
semantic
models
sources
known
investigate
number
known
models
in-
ﬂuences
results
used
variable
number
known
16http
//pro.europeana.eu/page/edm-documentation
17http
//www.cidoc-crm.org
18https
//github.com/taheriyan/
jws-knowledge-graphs-2015
19https
//github.com/usc-isi-i2/web-karma
data
source
classes
domain
ontologies
properties
domain
ontologies
nodes
gold-standard
models
data
nodes
gold-standard
models
class
nodes
gold-standard
models
links
gold-standard
models
dsedm
119
351
473
331
142
444
dscrm
147
409
812
418
394
785
models
input
suppose
set
known
se-
mantic
models
including
models
running
experi-
ment
means
use
knowledge
domain
ontology
running
m28
means
semantic
models
sources
known
m28
leave-one-out
cross
validation
example
ran
code
times
using
m0=
m1=
m2=
···
m28=
···
s29
learning
semantic
types
source
use
data
sources
whose
semantic
models
known
training
data
precisely
running
labeling
algorithm
source
setting
training
data
data
sources
sk|k
test
data
data
target
source
using
means
training
data
thus
labeling
function
able
suggest
semantic
type
source
at-
tributes
evaluate
labeling
algorithm
use
mean
reciprocal
rank
mrr
useful
consider
top
semantic
types
mrr
helps
an-
alyze
ranking
predictions
made
seman-
tic
labeling
approach
using
single
measure
rather
analyze
top-1
top-k
prediction
accuracies
separately
cumbersome
task
learning
semantic
types
source
attributes
mrr
computed
cid:88
mrr
ranki
i=1
ranki
rank
correct
semantic
type
top
predictions
made
attribute
obvi-
ous
consider
top
semantic
type
pre-
dictions
value
mrr
equal
accuracy
example
table
mrr
1/5
1/1
1/1
1/1
1/1
1/2
0.9
correct
semantic
type
at-
tribute
imageurl
ranked
second
compute
accuracy
learned
semantic
models
comparing
gold
standard
mod-
taheriyan
web
semantics
science
services
agents
world
wide
web
table
overlap
pairs
semantic
models
datasets
dsedm
dscrm
minimum
overlap
maximum
overlap
median
overlap
average
overlap
dsedm
0.04
0.45
0.43
dscrm
0.03
0.46
0.46
figure
two
semantic
models
equivalent
els
terms
precision
recall
assuming
correct
semantic
model
source
se-
mantic
model
learned
approach
cid:48
deﬁne
precision
recall
precision
recall
|rel
rel
cid:48
|rel
cid:48
|rel
rel
cid:48
|rel
edm
webresource
rel
set
triples
link
node
node
semantic
model
example
semantic
model
figure
rel
edm
europeanaaggregation
aac
culturalheritageobject
edm
aggregatedcho
edm
europeanaaggregation
edm
aac
person
hasview
aac
culturalheritageobject
dcterms
creator
···
nodes
unique
labels
nodes
cid:48
also
unique
labels
rel
rel
cid:48
ensures
cid:48
equivalent
however
semantic
models
one
instance
ontology
class
nodes
la-
bel
case
rel
rel
cid:48
guarantee
cid:48
example
two
semantic
models
exem-
pliﬁed
figure
set
triples
although
convey
semantics
figure
creator
artwork
knows
another
person
semantic
model
figure
states
creator
artwork
known
another
person
many
sources
datasets
models
include
two
instances
ontology
class
accurate
evaluation
number
nodes
use
numbered
labels
measuring
precision
recall
assume
model
figure
correct
semantic
model
one
model
learned
approach
cid:48
change
labels
nodes
aac
person1
aac
person2
aac
culturalheritageobject1
aac
person1
aac
person2
change
rel
aac
culturalheritageobject1
aac
person1
foaf
dcterms
creator
knows
try
permutations
num-
bering
learned
model
cid:48
report
precision
recall
one
generates
best
f1-
measure.20
instance
number
nodes
cid:48
aac
person1
aac
person2
aac
person1
dcterms
creator
aac
person2
aac
person1
foaf
knows
yields
precision=recall=0.5
label
aac
person2
aac
person1
rel
cid:48
aac
culturalheritageobject1
aac
person2
aac
person1
foaf
knows
still
preci-
aac
person2
sion=recall=0.5
rel
cid:48
aac
culturalheritageobject1
dcterms
creator
one
factors
inﬂuencing
results
method
overlap
known
semantic
models
semantic
model
target
source
see
much
two
semantic
models
overlap
deﬁne
overlap
metric
jaccard
similarity
relationships
overlap
|rel
rel
cid:48
|rel
rel
cid:48
table
reports
minimum
maximum
median
average
overlap
semantic
models
dataset
overall
higher
overlap
known
semantic
models
semantic
model
target
source
accurate
models
learned
mapping
algorithm
algorithm
used
cut-oﬀ
branching
factor=50
consid-
ered
generated
mappings
candidate
map-
pings
num
candidates=50
justify
choice
section
4.2
analyzing
impact
branch-
ing
factor
accuracy
results
run-
ning
time
algorithm
score
mapping
20f1-measure=2
precision
recall
precision
recall
aac
culturalheritageobjectaac
person
dcterms
creatoraac
person
foaf
knowsaac
culturalheritageobjectaac
person
dcterms
creatoraac
person
foaf
knows
n1n3n2n1n3n2
taheriyan
web
semantics
science
services
agents
world
wide
web
assigned
equal
weights
functions
conﬁdence
coherence
sizereduction
tried
diﬀerent
combinations
weights
although
algorithm
generated
precise
models
sources
weight
systems
average
results
better
functions
contributed
equally
ﬁnal
score
found
candidate
map-
pings
generated
top
steiner
trees
k=10
top-k
steiner
tree
algorithm
finally
ranked
candidate
semantic
models
500
compared
best
one
correct
model
source
ran
two
experiments
diﬀerent
scenarios
explained
next
4.1.
scenario
ﬁrst
scenario
assumed
source
at-
tribute
annotated
correct
semantic
type
goal
see
well
approach
learns
at-
tribute
relationships
using
correct
semantic
types
figure
illustrates
average
precision
recall
learned
semantic
models
cid:48
···
cid:48
s29
0..28
dataset
since
correct
semantic
types
given
excluded
cor-
responding
triples
computing
precision
recall
compared
links
class
nodes
gold
standard
models
links
be-
tween
class
nodes
learned
models
call
links
internal
links
links
established
class
nodes
semantic
models
total
number
links
dataset
dsedm
444
331
links
corresponds
source
attributes
331
data
nodes
thus
dsedm
113
internal
links
444-331=113
following
rationale
dscrm
367
internal
links
results
show
precision
recall
in-
crease
signiﬁcantly
even
known
semantic
models
interesting
observation
known
semantic
model
background
knowledge
domain
ontology
baseline
precision
recall
close
low
accuracy
comes
fact
multiple
links
be-
tween
pair
class
nodes
graph
with-
additional
information
resolve
ambi-
guity
although
assign
lower
weights
direct
prop-
erties
prioritize
inherited
ones
help
much
many
class
nodes
correct
models
object
property
on-
tology
explicitly
deﬁned
corresponding
classes
domain
range
fact
proper-
ties
used
correct
models
either
inherited
properties
deﬁned
without
domain
or/and
range
ontology
dsedm
dscrm
figure
average
precision
recall
learned
semantic
models
attributes
labeled
correct
semantic
types
evaluate
running
time
approach
measured
running
time
algorithm
starting
building
graph
ranking
results
single
machine
mac
operating
system
2.3
ghz
intel
core
cpu
figure
shows
av-
erage
time
seconds
learning
semantic
mod-
els
reason
ﬂuctuations
timing
diagram
dscrm
figure
10b
related
topology
graph
built
top
known
models
also
details
implementation
one
expects
see
linear
increase
time
number
known
semantic
models
grows
sometimes
adding
new
semantic
model
changes
structure
graph
way
steiner
tree
algorithm
ﬁnds
candidate
trees
faster
believe
overall
time
process
reduced
using
parallel
programming
optimizations
implementation
exam-
ple
graph
built
incrementally
new
known
model
added
need
create
graph
scratch
need
merge
new
known
model
existing
graph
update
links
taheriyan
web
semantics
science
services
agents
world
wide
web
dsedm
dsedm
dscrm
dscrm
figure
average
semantic
model
learning
time
attributes
labeled
correct
semantic
types
figure
mrr
value
learned
semantic
types
top
learned
semantic
types
considered
k=1
top
four
suggested
types
considered
k=4
4.2.
scenario
second
scenario
used
semantic
label-
ing
algorithm
learn
semantic
types
trained
labeling
classiﬁer
data
sources
whose
semantic
models
already
known
applied
learned
labeling
function
target
source
assign
set
candidate
semantic
types
source
attribute
figure
shows
mrr
diagram
dsedm
dscrm
two
cases
top
semantic
type
type
highest
conﬁdence
value
considered
k=1
top
four
learned
semantic
types
taken
ac-
count
candidate
semantic
types
k=4
note
k=1
mrr
value
equal
accuracy
i.e.
many
attributes
labeled
correct
semantic
types
labeling
done
feed
learned
se-
mantic
types
rest
algorithm
learn
semantic
model
source
average
precision
re-
call
learned
models
illustrated
figure
12.
black
color
shows
precision
recall
k=1
blue
color
illustrates
precision
recall
k=4
experiment
computed
precision
re-
call
links
including
links
class
nodes
data
nodes
links
associated
learned
semantic
types
results
show
using
known
semantic
models
background
knowledge
yields
remarkable
improvement
precision
recall
compared
case
con-
sider
domain
ontology
provide
example
help
understanding
correlation
mrr
precision
values
i.e.
accuracy
learned
semantic
types
af-
fects
accuracy
learned
semantic
models
average
mrr
value
dscrm
use
k=1
m28
leave-one-out
setting
0.75
figure
11b
means
labeling
algorithm
learn
correct
semantic
types
attributes
table
know
gold
standard
models
dscrm
totally
418
data
nodes
thus
418
links
gold
standard
models
correspond
source
attributes
since
attributes
labeled
cor-
rectly
313
links
418
links
corresponding
source
attributes
correct
learned
semantic
models
even
predict
internal
links
correct
785-418=367
links
maximum
precision
would
367+313
/785
however
input
steiner
tree
algorithm
nodes
coming
learned
se-
mantic
types
leaves
tree
incorrect
semantic
types
may
prompt
steiner
tree
algorithm
select
in-
taheriyan
web
semantics
science
services
agents
world
wide
web
dsedm
dsedm
dscrm
dscrm
figure
average
precision
recall
learned
semantic
models
k=1
k=4
figure
average
semantic
model
learning
time
attributes
labeled
correct
semantic
types
correct
links
higher
levels
internal
links
see
figure
12b
k=1
m28
setting
aver-
age
precision
learned
semantic
models
considering
top
four
semantic
types
k=4
instead
top
one
semantic
type
k=1
algorithm
recovers
correct
semantic
types
even
top
predictions
label-
ing
function
example
dataset
dscrm
using
k=4
rather
k=1
known
models
m28
improves
precision
recall
figure
12b
improvement
mainly
coherence
factor
take
account
scoring
mappings
also
ranking
candidate
semantic
models
running
time
algorithm
second
sce-
nario
displayed
figure
13.
time
include
labeling
step
work
done
krishna-
murthy
contains
detailed
analysis
performance
labeling
algorithm
see
figure
13b
running
time
algorithm
higher
m10
m11
k=1
computing
top
steiner
trees
takes
longer
add
semantic
models
s10
s11
graph
adding
semantic
models
algorithm
runs
faster
example
average
time
m11
7.29
sec-
onds
1.21
seconds
m12
result
combination
several
reasons
first
training
data
learning
semantic
types
source
m12
aﬀects
output
mapping
algo-
rithm
algorithm
second
structure
graph
diﬀerent
m12
results
diﬀerent
mappings
source
attributes
graph
finally
new
semantic
model
s12
adds
new
paths
graph
allowing
steiner
tree
algorithm
ﬁnd
top
trees
faster
mentioned
earlier
used
value
branching
factor
mapping
source
attributes
graph
line
algorithm
branching
factor
essential
scalability
mapping
algorithm
value
conﬁgured
trying
sample
val-
ues
choosing
value
yielding
good
accuracy
keeping
running
time
algorithm
rea-
sonably
low
diﬀerent
dataset
evaluation
using
branching
factor=50
worked
well
datasets
figure
illustrates
changing
value
branching
factor
aﬀects
precision
recall
running
time
algorithm
setting
considered
candidate
semantic
types
k=4
semantic
models
sources
known
m28
experiment
ﬁxed
value
num
candidates
line
algorithm
equal
taheriyan
web
semantics
science
services
agents
world
wide
web
traditional
data
integration
mapping
genera-
tion
problem
usually
decomposed
schema
match-
ing
phase
followed
schema
mapping
phase
schema
matching
ﬁnds
correspondences
elements
source
target
schemas
exam-
ple
imap
discovers
complex
correspondences
using
set
special-purpose
searchers
ranging
data
overlap
machine
learning
equation
discov-
ery
techniques
analogous
semantic
la-
beling
step
work
learn
labeling
function
learn
candidate
semantic
types
source
attribute
every
semantic
type
maps
attribute
element
domain
ontology
class
property
domain
ontology
schema
mapping
deﬁnes
appropriate
transforma-
tion
populates
target
schema
data
sources
mappings
may
arbitrary
procedures
greater
interest
declarative
mappings
expressible
queries
sql
xquery
datalog
map-
ping
formulas
generated
taking
account
schema
matches
schema
constraints
much
research
schema
mapping
sem-
inal
work
clio
provided
practical
sys-
tem
furthered
theoretical
foundations
data
exchange
recent
systems
support
ad-
ditional
schema
constraints
alexe
generate
schema
mappings
examples
source
data
tuples
corresponding
tuples
target
schema
generate
declarative
mapping
expressions
two
tables
diﬀerent
schemas
starting
element
correspondences
create
graph
conceptual
model
schema
suggest
plausible
mappings
exploring
low-
cost
steiner
trees
connect
nodes
graph
attributes
participating
element
corre-
spondences
work
similar
previous
semi-
automatic
approach
build
semantic
models
derive
graph
domain
ontology
learned
semantic
types
exploited
knowl-
edge
ontology
assign
weights
links
based
types
e.g.
direct
properties
get
lower
weight
inherited
properties
wanted
give
priority
speciﬁc
relations
also
allow
user
correct
mappings
interactively
current
paper
addition
ontology
con-
sider
previous
known
semantic
models
improve
modeling
unknown
source
work
learning
semantic
models
structured
sources
complementary
schema
mapping
techniques
instead
focusing
satisfying
schema
constraints
analyze
known
source
models
pro-
pose
mappings
capture
closely
seman-
dsedm
dscrm
figure
impact
branching
factor
precision
re-
call
running
time
k=4
m28
value
branching
factor
means
generated
mappings
given
steiner
tree
al-
gorithm
candidate
mappings
see
figure
14b
increasing
value
branching
fac-
tor
200
dscrm
provides
improvement
precision
however
increases
average
run-
ning
time
2.14
seconds
chose
ignore
in-
signiﬁcant
increase
precision
used
branching
factor
gain
better
running
time
related
work
problem
describing
semantics
data
sources
core
data
integration
exchange
main
approach
reconcile
semantic
hetero-
geneity
among
sources
consists
deﬁning
logical
map-
pings
source
schemas
common
target
schema
one
way
deﬁne
mappings
local-as-
view
lav
descriptions
every
source
deﬁned
view
domain
schema
semantic
models
generate
graphical
representation
lav
rules
domain
schema
domain
on-
tology
although
logical
mappings
declarative
deﬁning
requires
signiﬁcant
technical
expertise
much
interest
techniques
facilitate
generation
taheriyan
web
semantics
science
services
agents
world
wide
web
tics
target
source
ways
schema
constraints
could
disambiguate
example
suggesting
dcterms
creator
relationship
likely
dbpedia
owner
given
domain
moreover
algo-
rithm
incrementally
reﬁne
mappings
based
user
feedback
learn
feedback
improve
future
predictions
semantic
web
meant
source
de-
scription
semantic
model
describing
source
terms
concepts
relationships
deﬁned
do-
main
ontology
many
studies
mapping
data
sources
ontologies
several
approaches
proposed
generate
semantic
web
data
databases
spreadsheets
d2r
d2rq
mapping
languages
enable
user
deﬁne
mapping
rules
ta-
bles
relational
databases
target
ontologies
or-
der
publish
semantic
data
rdf
format
r2rml
another
mapping
language
w3c
recommendation
expressing
customized
mappings
relational
databases
rdf
datasets
writing
mapping
rules
hand
tedious
task
users
need
understand
source
table
maps
target
ontology
also
need
learn
syntax
writing
mapping
rules
rdote
tool
provides
graphical
user
interface
facilitate
mapping
relational
databases
ontologies
developers
rdote
said
incorporate
export/import
mech-
anism
d2rq
compliant
mapping
ﬁles
well
query
builder
graphical
user
interface
hasten
mapping
creation
process
rdf123
xlwrap
tools
deﬁne
mappings
spreadsheets
rdf
graphs
although
tools
facilitate
mapping
process
users
still
need
manually
deﬁne
mappings
source
target
ontologies
recent
years
eﬀorts
automat-
ically
infer
implicit
semantics
tables
polﬂiet
ichise
use
string
similarity
column
names
names
properties
ontology
ﬁnd
mapping
table
columns
on-
tology
wang
detect
header
web
tables
use
along
values
rows
map
columns
attributes
corresponding
entity
rich
general
purpose
taxonomy
worldly
facts
built
corpus
one
million
web
pages
data
approach
deal
tables
containing
information
single
entity
type
limaye
used
yago21
annotate
web
ta-
bles
generate
binary
relationships
using
machine
21http
//www.mpi-inf.mpg.de/yago-naga/yago
learning
approaches
however
approach
limited
labels
relations
deﬁned
yago
ontology
less
100
binary
relationships
venetis
presented
scalable
approach
describe
semantics
tables
web
recover
semantics
tables
leverage
database
class
labels
relationships
automatically
extracted
web
attach
class
label
column
suﬃcient
number
val-
ues
column
identiﬁed
label
database
class
labels
analogously
binary
re-
lationships
although
approaches
useful
publishing
semantic
data
tables
limited
learning
semantics
relations
ap-
proaches
infer
individual
binary
relationships
be-
tween
pair
columns
able
ﬁnd
re-
lation
two
columns
direct
relation-
ship
values
columns
approach
connect
one
column
another
one
path
ontology
example
suppose
table
including
two
columns
person
city
city
location
company
person
work-
ing
approach
learn
semantic
model
connects
class
person
class
city
chain
personworksfor−→
organizationlocation−→
city
also
work
exploits
data
available
linked
open
data
lod
cloud
capture
se-
mantics
tables
publish
data
rdf
munoz
mine
rdf
triples
wikipedia
tables
linking
cell
values
resources
avail-
able
dbpedia
approach
limited
wikipedia
tables
simple
linking
algo-
rithm
cell
value
contains
hyperlink
wikipedia
page
wikipedia
url
maps
dbpedia
entity
uri
replacing
namespace
http
//en.wikipedia
org/wiki/
url
http
//dbpedia.org/
resource/
work
mulwad
used
wikitology
ontology
combines
existing
manu-
ally
built
knowledge
systems
dbpedia
free-
base
link
cells
table
wikipedia
entities
query
background
lod
generate
initial
lists
candidate
classes
column
headers
cell
values
candidate
properties
relations
columns
use
probabilistic
graphical
model
ﬁnd
correlation
columns
headers
cell
val-
ues
relation
assignments
quality
seman-
tic
data
generated
category
work
highly
de-
pendent
well
data
linked
entities
lod
popular
named
entities
good
matches
lod
many
tables
contain
domain-
speciﬁc
information
numeric
values
e.g.
tempera-
taheriyan
web
semantics
science
services
agents
world
wide
web
ture
age
linked
lod
moreover
approaches
able
identify
individual
bi-
nary
relationships
columns
table
how-
ever
integrated
semantic
model
frag-
ments
binary
relationships
columns
complete
semantic
model
columns
may
con-
nected
path
including
nodes
correspond
column
table
parundekar
previously
developed
ap-
proach
automatically
generate
conjunctive
dis-
junctive
mappings
ontologies
linked
data
sources
exploiting
existing
linked
data
instances
however
system
model
arbitrary
sources
present
paper
carman
knoblock
use
known
source
descriptions
learn
semantic
description
precisely
describes
relationship
be-
tween
inputs
outputs
source
expressed
datalog
rule
however
approach
limited
learn
sources
whose
models
subsumed
models
known
sources
descrip-
tion
new
source
conjunctive
combination
known
source
descriptions
exploring
paths
domain
ontology
addition
patterns
known
sources
hypothesize
target
mappings
general
previous
source
descriptions
combinations
earlier
karma
work
build
graph
learned
semantic
types
domain
ontology
use
graph
map
source
ontology
interactively
work
system
uses
knowledge
domain
ontology
propose
models
user
correct
needed
system
remembers
seman-
tic
type
labels
assigned
user
however
learn
structure
previously
modeled
sources
closely
related
work
exploit-
ing
known
semantic
models
learn
model
new
unknown
source
however
previous
approach
less
scalable
many
source
at-
tributes
large
number
mappings
source
attributes
nodes
graph
even
though
used
beam
search
algorithm
map-
ping
step
ameliorate
problem
graph
grows
number
known
semantic
models
grows
makes
computing
semantic
models
ineﬃcient
paper
presented
compact
graph
struc-
ture
merges
overlapping
segments
known
se-
mantic
models
also
use
new
algorithm
gener-
ate
rank
candidate
semantic
models
gener-
ate
candidate
models
computing
top-k
steiner
trees
rank
based
coherence
links
new
approach
addition
generating
ac-
curate
semantic
models
signiﬁcantly
improves
run-
ning
time
learning
process
integrating
al-
gorithm
karma
enables
user
reﬁne
au-
tomatically
learned
models
resulting
accurate
predictions
future
data
sources
recent
years
ontology
matching
received
much
attention
semantic
web
community
ontology
matching
ontology
alignment
ﬁnds
correspondence
semantically
related
entities
diﬀerent
ontologies
problem
analogous
schema
matching
databases
schemas
on-
tologies
provide
vocabulary
terms
describe
domain
interest
however
schemas
often
pro-
vide
explicit
semantics
data
work
ben-
eﬁts
techniques
developed
ontol-
ogy
matching
example
instance-based
ontology
matching
exploits
similarities
instances
on-
tologies
matching
process
semantic
label-
ing
algorithm
adopts
idea
map
data
new
source
classes
properties
target
on-
tology
algorithm
computes
similarity
cosine
similarity
tf/idf
vectors
data
new
source
data
sources
whose
se-
mantic
models
known
ontology
matching
diﬀerent
problem
addressed
paper
sense
work
data
mapped
target
ontology
bound
source
ontology
makes
problem
complicated
since
explicit
semantics
nec-
essarily
attached
data
sources
moreover
work
ontology
matching
ﬁnds
simple
cor-
respondences
equivalence
subsumption
be-
tween
ontology
classes
properties
therefore
explicit
relationships
within
data
elements
often
missed
aligning
source
data
target
ontol-
ogy
suppose
want
ﬁnd
correspondences
source
ontology
target
ontology
using
ontology
matching
ﬁnd
class
maps
class
class
maps
class
assume
one
prop-
erty
connecting
multiple
paths
connecting
align
source
data
target
ontology
using
correspondences
found
ontology
matching
instances
mapped
class
instances
mapped
class
however
alignment
tell
path
captures
correct
mean-
ing
source
data
discussion
paper
presented
scalable
approach
learn
semantic
models
structured
data
sources
taheriyan
web
semantics
science
services
agents
world
wide
web
mappings
sources
domain
ontology
models
key
ingredients
process
pub-
lishing
data
lod
knowledge
graph
core
idea
exploit
domain
ontology
previously
learned
semantic
models
hypothesize
plausible
se-
mantic
model
new
source
evaluation
shows
approach
learns
rich
semantic
models
min-
imal
user
input
ﬁrst
step
learning
semantic
models
learn-
ing
semantic
types
system
labels
source
attribute
class
property
ontol-
ogy
output
labeling
step
set
candidate
semantic
types
conﬁdence
values
rather
one
ﬁxed
semantic
type
taking
account
un-
certainty
labeling
algorithm
important
be-
cause
machine
learning
techniques
often
distin-
guish
types
source
attributes
similar
data
values
e.g.
birthdate
deathdate
system
produces
candidate
semantic
types
attribute
creates
graph
known
seman-
tic
models
augments
adding
nodes
links
corresponding
semantic
types
adding
paths
inferred
ontology
next
step
mapping
source
attributes
nodes
graph
use
search
algorithm
enables
sys-
tem
mapping
even
source
many
attributes
algorithm
processing
source
attribute
prunes
existing
mappings
scoring
removing
ones
lower
scores
pro-
posed
scoring
function
contributes
scal-
ability
method
also
increases
accuracy
learned
models
ﬁnal
part
approach
computing
min-
imal
tree
connects
nodes
candidate
map-
pings
step
might
computationally
ineﬃcient
large
graph
however
algorithm
construct
graph
consolidates
overlapping
seg-
ments
known
semantic
models
making
scalable
huge
number
known
semantic
models
learning
algorithms
play
important
role
making
karma
interactive
user
interface
easy
use
key
design
goal
given
many
users
do-
main
experts
semantic
web
experts
experience
observing
users
understand
critique
models
displayed
interactive
user
interface
easily
verify
models
accu-
rately
capture
semantics
source
easily
spot
errors
controversial
modeling
decisions
users
click
corresponding
elements
screen
local
modiﬁcations
replacing
prop-
erty
link
changing
source
destination
link
also
observe
much
harder
users
model
source
scratch
necessary
tools
open
reﬁne.22
even
though
user
interface
easy
use
task
ﬁlling
blank
page
model
daunting
many
users
karma
helps
users
gives
almost-correct
model
starting
point
users
easily
ﬁnd
elements
agree
easily
change
possi-
ble
direction
future
work
perform
user
evalua-
tions
measure
quality
models
produced
us-
ing
learning
algorithms
although
time
create
mod-
els
important
hypothesize
users
museum
users
primarily
concerned
pro-
ducing
correct
models
time
model
secondary
concern
using
previous
models
users
likely
model
sources
correct
way
work
also
plays
role
helping
communities
produce
consistent
linked
data
sources
con-
taining
type
data
use
classes
properties
published
rdf
often
mul-
tiple
correct
ways
model
type
data
example
users
use
dublin
core
foaf
model
creator
relationship
person
object
dcterms
creator
foaf
maker
community
bet-
ter
served
data
semantics
modeled
using
classes
properties
work
encourages
consistency
learning
al-
gorithms
bias
selection
classes
properties
to-
wards
used
frequently
existing
models
future
direction
work
improve
qual-
ity
automatically
generated
models
leveraging
signiﬁcant
amount
data
available
linked
open
data
lod
cloud
vast
growing
collection
semantic
data
published
various
data
providers
current
estimate
lod
cloud
contains
billion
rdf
triples
even
new
york
times
publishing
meta-
data
linked
open
data.23
noted
nontrivial
portion
lod
data
limited
semantic
descriptions
much
data
linked
sources
form
se-
mantic
description
given
growing
availability
type
data
lod
provide
invaluable
source
semantic
content
exploit
background
knowledge
given
huge
repository
data
available
lod
given
set
values
provided
new
source
search
classes
provide
even
subsume
22http
//openrefine.org/
23see
http
//data.nytimes.com
taheriyan
web
semantics
science
services
agents
world
wide
web
data
given
property
source
ex-
ample
set
values
people
names
temperature
likely
ﬁnd
classes
lod
provides
set
values
re-
quire
perfect
overlap
set
values
source
class
linked
open
data
rather
statistically
signiﬁcant
overlap
similar
done
parundekar
important
chal-
lenge
eﬃciently
ﬁnd
classes
closely
match
set
attribute
values
han-
dle
problem
classes
match
best
may
come
form
diﬀerent
ontologies
cid:104
aac
culturalheritageobject
dcterms
title
cid:105
also
exploit
lod
disambiguate
relationships
attributes
identiﬁed
semantic
types
source
attributes
search
corresponding
classes
lod
ana-
lyze
properties
connecting
prop-
erties
candidates
relationships
attributes
new
source
consider
semantic
model
source
dia
figure
identify
cid:104
aac
person
foaf
name
cid:105
semantic
types
ﬁrst
fourth
attributes
search
lod
possible
properties
instances
classes
aac
culturalheritageobject
aac
person
ﬁnd
properties
dcterms
creator
acc
sitter
better
candidates
properties
ontology
suggests
e.g.
dbpedia
owner
combining
information
extract
pair
classes
narrow
search
classes
properties
commonly
occur
together
acknowledgements
research
supported
part
national
science
foundation
grant
1117913
part
defense
advanced
research
projects
agency
darpa
via
afrl
contract
numbers
fa8750-14-c-
0240
fa8750-16-c-0045
u.s.
government
authorized
reproduce
distribute
reprints
gov-
ernmental
purposes
notwithstanding
copyright
an-
notation
thereon
views
conclusions
contained
herein
authors
in-
terpreted
necessarily
representing
oﬃcial
policies
endorsements
either
expressed
implied
nsf
darpa
afrl
u.s.
government
would
like
thank
anonymous
reviewers
valuable
comments
suggestions
improve
paper
also
grateful
yinyi
chen
help
creating
gold
standard
models
evaluation
references
doan
halevy
ives
principles
data
integration
morgan
kauﬀman
2012
han
finin
parr
sachs
joshi
rdf123
spreadsheets
rdf
2008
451–466
sheth
gomadam
ranabahu
semantics
enhanced
services
meteor-s
sawsdl
sa-rest
ieee
data
eng
bulletin
2008
8–12
langegger
w¨oß
xlwrap
querying
integrat-
ing
arbitrary
spreadsheets
sparql
bernstein
karger
heath
feigenbaum
maynard
motta
thirunarayan
eds
international
semantic
web
confer-
ence
vol
5823
lecture
notes
computer
science
springer
2009
359–374
sahoo
halb
hellmann
idehen
auer
sequeda
ezzat
survey
current
approaches
map-
ping
relational
databases
rdf
2009
polﬂiet
ichise
automated
mapping
generation
con-
verting
databases
linked
data
polleres
chen
eds
iswc
posters
demos
vol
658
ceur
workshop
proceedings
ceur-ws.org
2010
limaye
sarawagi
chakrabarti
annotating
searching
web
tables
using
entities
types
relationships
pvldb
2010
1338–1347
vavliakis
grollios
mitkas
rdote
trans-
forming
relational
databases
semantic
web
data
polleres
chen
eds
iswc
posters
demos
vol
658
ceur
workshop
proceedings
ceur-ws.org
2010
ding
difranzo
graves
michaelis
mcguinness
hendler
twc
data-gov
corpus
incremen-
tally
generating
linked
government
data
data.gov
rappa
jones
freire
chakrabarti
eds
www
acm
2010
1383–1386
saquicela
bl´azquez
´oscar
corcho
lightweight
semantic
annotation
geospatial
restful
services
proceedings
8th
extended
semantic
web
conference
eswc
2011
330–344
venetis
halevy
madhavan
pas¸ca
shen
miao
recovering
semantics
tables
web
proc
vldb
endow
2011
528–538
wang
wang
wang
zhu
understanding
ta-
bles
web
atzeni
cheung
ram
eds
vol
7532
lecture
notes
computer
science
springer
2012
141–155
mulwad
finin
joshi
semantic
message
passing
generating
linked
data
tables
semantic
web
iswc
2013
springer
2013
363–378
krishnamurthy
mittal
knoblock
szekely
as-
signing
semantic
labels
data
sources
proceedings
12th
extended
semantic
web
conference
eswc
2015
taheriyan
knoblock
szekely
ambite
scal-
able
approach
learn
semantic
models
structured
sources
semantic
computing
icsc
2014
ieee
international
con-
ference
2014
183–190
taheriyan
knoblock
szekely
ambite
graph-based
approach
learn
semantic
descriptions
data
sources
procs
12th
international
semantic
web
conference
iswc
2013
hennicke
olensky
boer
isaac
wielemaker
data
model
cross-domain
data
representation
eu-
ropeana
data
model
case
archival
museum
data
schriften
zur
informationswissenschaft
proceedings
des
12.
internationalen
symposiums
der
informationswissenschaft
isi
2011
2011
136–147
taheriyan
web
semantics
science
services
agents
world
wide
web
doerr
cidoc
conceptual
reference
module
on-
tological
approach
semantic
interoperability
metadata
mag
2003
75–92
das
sundara
cyganiak
r2rml
rdb
rdf
map-
ping
language
w3c
recommendation
september
2012
http
//www.w3.org/tr/r2rml/
2012
knoblock
szekely
ambite
goel
gupta
lerman
muslea
taheriyan
mallick
semi-
automatically
mapping
structured
sources
semantic
web
proc
9th
extended
semantic
web
conference
2012
szekely
knoblock
yang
zhu
fink
allen
goodlander
connecting
smithsonian
american
art
mu-
seum
linked
data
cloud
proceedings
10th
ex-
tended
semantic
web
conference
eswc
montpellier
2013
593–607
szekely
knoblock
gupta
taheriyan
ex-
ploiting
semantics
web
services
geospatial
data
fusion
proceedings
sigspatial
international
workshop
spatial
semantics
ontologies
sso
2011
chicago
2011
taheriyan
knoblock
szekely
ambite
semi-
automatically
modeling
web
apis
create
linked
apis
proceedings
linked
apis
semantic
web
work-
shop
lapis
2012
taheriyan
knoblock
szekely
ambite
rapidly
integrating
services
linked
data
cloud
iswc
boston
2012
559–574
lehmann
romano
testing
statistical
hypotheses
3rd
edition
springer
texts
statistics
springer
new
york
2005
winter
steiner
problem
networks
survey
networks
1987
129–167
takahashi
matsuyama
approximate
solution
steiner
problem
graphs
math.japonica
1980
573–577
kou
markowsky
berman
fast
algorithm
steiner
trees
acta
informatica
1981
141–145
mehlhorn
faster
approximation
algorithm
steiner
problem
graphs
information
processing
letters
1988
125
128
bhalotia
hulgeri
nakhe
chakrabarti
sudarshan
keyword
searching
browsing
databases
using
banks
proceedings
18th
international
conference
data
engineering
2002
431–440
craswell
mean
reciprocal
rank
encyclopedia
database
systems
2009
1703
arenas
barcelo
libkin
murlak
relational
xml
data
exchange
morgan
claypool
san
rafael
2010
bellahsene
bonifati
rahm
schema
matching
mapping
1st
edition
springer
2011
rahm
bernstein
survey
approaches
automatic
schema
matching
vldb
journal
2001
334–350
dhamankar
lee
doan
halevy
domin-
gos
imap
discovering
complex
semantic
matches
database
schemas
international
conference
manage-
ment
data
sigmod
new
york
2004
383–394
fagin
haas
hern´andez
miller
popa
velegrakis
clio
schema
mapping
creation
data
ex-
change
conceptual
modeling
foundations
applica-
tions
2009
fagin
kolaitis
miller
popa
data
exchange
semantics
query
answering
theoretical
computer
sci-
ence
336
2005
124
marnette
mecca
papotti
raunich
santoro
++spicy
opensource
tool
second-generation
schema
mapping
data
exchange
procs
vldb
seattle
2011
1438–1441
alexe
ten
cate
kolaitis
w.-c.
tan
designing
reﬁning
schema
mappings
via
data
examples
proceedings
2011
acm
sigmod
international
conference
man-
agement
data
sigmod
acm
new
york
usa
2011
133–144
borgida
miller
mylopoulos
semantic
ap-
proach
discovering
schema
mapping
expressions
pro-
ceedings
23rd
international
conference
data
engineer-
ing
icde
istanbul
turkey
2007
206–215
bizer
d2r
map
database
rdf
mapping
language
www
posters
2003
bizer
cyganiak
d2r
server
publishing
relational
databases
semantic
web
poster
5th
interna-
tional
semantic
web
conference
2006
bizer
seaborne
d2rq
treating
non-rdf
databases
virtual
rdf
graphs
iswc2004
posters
2004
mu˜noz
hogan
mileo
triplifying
wikipedia
tables
gentile
zhang
amato
paulheim
eds
ld4ie
iswc
vol
1057
ceur
workshop
proceedings
ceur-ws.org
2013
auer
bizer
kobilarov
lehmann
cyganiak
ives
dbpedia
nucleus
web
open
data
proceedings
6th
international
semantic
web
2nd
asian
conference
asian
semantic
web
confer-
ence
iswc
07/aswc
springer-verlag
berlin
heidel-
berg
2007
722–735
syed
finin
creating
exploiting
hybrid
knowledge
base
linked
data
agents
artiﬁcial
intelligence
springer
2011
3–21
bollacker
evans
paritosh
sturge
taylor
free-
base
collaboratively
created
graph
database
structur-
ing
human
knowledge
proceedings
2008
acm
sig-
mod
international
conference
management
data
sig-
mod
acm
new
york
usa
2008
1247–1250
parundekar
knoblock
ambite
discovering
con-
cept
coverings
ontologies
linked
data
sources
pro-
ceedings
11th
international
semantic
web
conference
iswc
boston
2012
carman
knoblock
learning
semantic
deﬁnitions
online
information
sources
journal
artiﬁcial
intelligence
research
2007
1–50
kalfoglou
schorlemmer
ontology
mapping
state
art
knowl
eng
rev
2003
1–31
pavel
euzenat
ontology
matching
state
art
future
challenges
ieee
trans
knowl
data
eng
2013
158–176
taheriyan
knoblock
szekely
ambite
chen
leveraging
linked
data
infer
semantic
relations
within
structured
sources
proceedings
6th
international
workshop
consuming
linked
data
cold
2015
