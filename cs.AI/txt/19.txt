simpleds
simple
deep
reinforcement
learning
dialogue
system
heriberto
cuay´ahuitl1
abstract
paper
presents
simpleds
simple
publicly
available
dialogue
system
trained
deep
reinforcement
learning
contrast
previous
reinforce-
ment
learning
dialogue
systems
system
avoids
manual
feature
engineering
performing
action
selection
directly
raw
text
last
system
noisy
user
responses
initial
results
restaurant
domain
report
indeed
possible
induce
reasonable
behaviours
approach
aims
higher
levels
automation
dialogue
control
intelligent
interactive
agents
introduction
almost
two
decades
ago
spoken
dialogue
systems
community
adopted
reinforcement
learning
paradigm
since
offered
possibility
treat
di-
alogue
design
optimisation
problem
rl-based
systems
im-
prove
performance
time
experience
although
large
number
methods
proposed
training
spoken
dialogue
systems
using
question
train
dialogue
policies
efﬁcient
scalable
effective
way
across
domains
still
remains
open
problem
one
limitation
current
approaches
fact
rl-based
dialogue
systems
still
require
high-levels
hu-
man
intervention
system
developers
opposed
automating
dialogue
design
training
system
kind
requires
system
developer
provide
set
features
describe
dialogue
state
set
actions
control
interaction
performance
function
reward
penalise
action-selection
process
elements
carefully
engineered
order
learn
good
dialogue
policy
policies
suggests
one
way
advancing
state-of-the-art
ﬁeld
reducing
amount
human
intervention
dialogue
de-
sign
process
higher
degrees
automation
i.e
moving
towards
truly
autonomous
learning
1computer
science
heriot-watt
university
edinburgh
scotland
e-mail
hc213
hw.ac.uk
heriberto
cuay´ahuitl1
recent
advances
machine
learning
proposed
machine
learning
methods
way
reduce
human
intervention
creation
intelligent
agents
partic-
ular
ﬁeld
deep
reinforcement
learning
drl
targets
feature
learning
policy
learning
simultaneously—which
reduces
effort
feature
engineering
relevant
vast
majority
previous
rl-based
dialogue
systems
make
use
carefully
engineered
features
represent
dialogue
state
motivated
advantages
drl
methods
traditional
methods
paper
present
extended
dialogue
system
recently
applied
strategic
di-
alogue
management
makes
use
raw
noisy
text—without
engineered
features
represent
dialogue
state
using
representation
dialogue
system
require
spoken
language
understanding
slu
component
bypass
slu
learning
dialogue
policies
directly
simulated
speech
recog-
nition
outputs
rest
paper
describes
proof
concept
system
trained
based
idea
deep
reinforcement
learning
dialogue
control
reinforcement
learning
agent
learns
behaviour
interaction
environment
physical
virtual
agents
within
situations
mapped
actions
maximising
long-term
reward
signal
agent
typically
characterised
ﬁnite
inﬁnite
set
states
ﬁnite
inﬁnite
set
actions
iii
state
transition
function
cid:48
speciﬁes
next
state
cid:48
given
current
state
action
reward
function
cid:48
speciﬁes
reward
given
agent
choosing
action
state
transitioning
state
cid:48
policy
deﬁnes
mapping
states
actions
goal
agent
select
actions
maximising
cumulative
discounted
reward
deﬁned
maxπ
γrt+1
γ2rt+1
...
|st
function
represents
maximum
sum
rewards
discounted
factor
time
step
agent
takes
actions
probability
a|s
training
takes
best
actions
maxa
a|s
test
time
induce
function
use
deep
reinforcement
learning
approximates
using
multilayer
convolutional
neural
network
function
drl
agent
parameterised
parameters
weights
neural
net
iteration
speciﬁcally
training
drl
agent
requires
dataset
experiences
...
also
referred
experience
re-
play
memory
every
experience
described
tuple
st+1
function
induced
applying
q-learning
updates
minibatches
experience
cid:48
drawn
uniformly
random
dataset
q-learning
update
iteration
thus
deﬁned
loss
function
emb
neural
net
iteration
target
parameters
neural
net
iter-
ation
latter
updated
every
steps
process
implemented
learning
algorithm
deep
q-learning
experience
replay
described
cid:2
maxa
cid:48
cid:48
cid:48
cid:3
parameters
simpleds
simple
deep
reinforcement
learning
dialogue
system
simpleds
dialogue
system
fig
high-level
architecture
simpleds
dialogue
system–see
text
details
figure
shows
high-level
diagram
simpleds
dialogue
system
bottom
learning
environment
receives
action
dialogue
act
outputs
next
environment
state
numerical
reward
environment
ﬁrst
gen-
erates
word
sequence
last
system
action
user
simulator
generates
word
sequence
response
action
user
response
distorted
given
noise
level
word-level
conﬁdence
scores
based
system
verbal-
isation
noisy
user
response
next
dialogue
state
reward
calculated
given
result
executed
given
action
top
diagram
deep
reinforcement
learning
drl
agent
receives
state
reward
updates
policy
learning
outputs
action
according
learnt
policy
system
runs
client-server
architecture
environment
acts
server
learning
agent
acts
client
communicate
ex-
changing
messages
client
tells
server
action
execute
server
tells
client
dialogue
state
reward
observed
simpleds
learning
agent
based
convnetjs
tool
implements
algorithm
deep
learning
experience
replay
proposed
extended
tool
support
multi-threaded
client-server
processing
constrained
search
spaces.1
state
space
includes
100
word-based
features
depending
vocabu-
lary
simpleds
agent
restaurant
domain
initial
release
simpleds
provides
support
english
german
spanish
words
derived
sys-
tem
responses
treated
binary
variables
i.e
word
present
absent
words
derived
noisy
user
responses
seen
continuous
variables
taking
code
simpleds
available
https
//github.com/cuayahuitl/simpleds
heriberto
cuay´ahuitl1
conﬁdence
scores
account
since
use
single
variable
per
word
user
fea-
tures
override
system
ones
case
overlaps
action
space
includes
dialogue
acts
restaurant
domain2
in-
clude
salutations
requests
apologies
explicit
conﬁrmations
implicit
con-
ﬁrmations
retrieve
information
provide
information
rather
learning
whole
action
sets
simpleds
supports
learning
constrained
actions
ap-
plying
q-learning
learning
updates
set
valid
actions
constrained
actions
come
likely
actions
e.g
a|s
0.01
probabilities
derived
naive
bayes
classiﬁer
trained
example
dialogues
latter
motivated
fact
new
system
training
data
apart
small
number
demonstration
dialogues
addition
probable
data-like
actions
constrained
action
set
extended
legitimate
requests
apolo-
gies
conﬁrmations
state
fact
constrained
actions
data-driven
driven
application
independent
heuristics
facilitates
usage
across
domains
state
transition
function
based
numerical
vector
representing
last
system
user
responses
former
straightforward
absent
present
latter
correspond
conﬁdence
level
0..1
noisy
user
responses
given
simpleds
targets
simple
extensible
dialogue
system
uses
tem-
plates
language
generation
rule-based
user
simulator
conﬁdence
scores
generated
uniformly
random
words
scores
threshold
distorted
reward
function
motivated
fact
human-machine
dialogues
conﬁrm
information
required
interactions
human-like
deﬁned
cid:48
cr×w
dr×
1−w
−dl
number
positively
conﬁrmed
slots
divided
slots
conﬁrm
weight
conﬁrmation
reward
used
w=0.5
data-like
probability
observed
action
state
used
encourage
efﬁcient
interactions
used
dl=0.1
scores
derived
statistical
classiﬁer
allows
statistical
inference
actions
given
states
a|s
model
architecture
consists
fully-connected
multilayer
neural
net
100
nodes
input
layer
depending
vocabulary
nodes
ﬁrst
hidden
layer
nodes
second
hidden
layer
nodes
action
set
output
layer
hidden
layers
use
rectiﬁed
linear
units
normalise
weights
finally
learning
parameters
follows
experience
replay
size=10000
discount
factor=0.7
minimum
epsilon=0.01
batch
size=32
learning
steps=20000
comprehensive
analysis
comparing
multiple
state
representations
action
sets
reward
functions
learning
parameters
left
future
work
figure
shows
learning
curve
simpleds
agent
using
3000
simulated
dialogues
agent
uses
smaller
set
actions
per
state
actions
actions
salutation
greeting
request
hmihy
request
food
request
price
request
area
request
food
price
request
food
area
request
price
area
request
food
price
area
ask-
apology
food
apology
price
apology
area
apology
food
price
apology
food
area
apology
price
area
apology
food
price
area
expconﬁrm
food
expconﬁrm
price
expconﬁrm
area
expconﬁrm
food
price
expconﬁrm
food
area
expconﬁrm
price
area
expconﬁrm
food
price
area
impconﬁrm
food
impconﬁrm
price
impconﬁrm
area
imp-
conﬁrm
food
price
impconﬁrm
food
area
impconﬁrm
price
area
impconﬁrm
food
price
area
retrieve
info
provide
unknown
provide
known
salutation
closing
simpleds
simple
deep
reinforcement
learning
dialogue
system
fig
learning
curve
simpleds
deep
reinforcement
learning
agent–see
text
details
rather
whole
action
set
per
state—according
application-independent
heuristics
mentioned
previous
section
reduction
advantage
policies
learnt
quicker
sensible
dialogues
potentially
learnt
inherent
domains
make
use
legitimate
actions
interaction
case
complex
systems
higher
amounts
features
actions
learning
valid
actions
rather
actions
make
huge
difference
terms
computational
resources
learning
time
quality
learnt
policies
depend
learning
environment
given
constraints
table
shows
example
dialogue
learnt
policy
user
inputs
derived
simulated
speech
recognition
results
initial
tests
suggest
reasonable
interactions
generated
using
proposed
learning
approach
simpleds
demonstrated
mobile
app
human
evaluation
left
future
work
summary
describe
publicly
available
dialogue
system
motivated
idea
future
dialogue
systems
trained
almost
intervention
system
devel-
opers
contrast
previous
reinforcement
learning
dialogue
systems
simpleds
selects
dialogue
actions
directly
raw
noisy
text
last
system
user
responses
remains
demonstrated
far
one
approach
future
work
includes
compare
different
model
architectures
training
param-
eters
reward
functions
extend
improve
abilities
proposed
dia-
logue
system
train
deep
learning
agents
larger
scale
domains
evaluate
end-to-end
systems
real
users
compare
combine
different
types
neural
nets
perform
fast
learning
based
parallel
computing
heriberto
cuay´ahuitl1
environment
state
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
verbalisation
action
salutation
greeting
request
food
price
area
area
looking
hello
type
food
price
range
reasonably
priced
mexican
...
food
east
town
okay
reasonably
priced
0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0.53,0,0,0,0,0.63,1,0,0,0,0,0,0,0.83,0,0,0,0,0,0,0,0,1,0,0
0,0.78,0,0,0,0,0.31,0,0,0,1,0.36,1,0.25,0,0,0,0,0,0,0,0,0,0.57,0,0,0.82,1,0,0,0,0,1,0,0,0,0,0,1
food
price
area
mexican
food
east
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0
0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0
let
see
restaurant
excellent
choice
located
retrieve
info
provide
known
askfor
impconﬁrm
anything
else
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0.72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1
table
example
dialogue
using
policy
fig.2
states
numerical
representations
last
system
noisy
user
inputs
actions
dialogue
acts
user
resposes
brackets
okay
talk
soon
bye
salutation
closing
acknowledgments
funding
european
research
council
erc
project
stac
strategic
con-
versation
269427
gratefully
acknowledged
references
mnih
kavukcuoglu
silver
graves
antonoglou
wierstra
riedmiller
nips
deep
learning
workshop
playing
atari
deep
reinforcement
learning
2013
paek
pieraccini
automating
spoken
dialogue
management
design
using
machine
learning
industry
perspective
speech
communication
8-9
2008
cuay´ahuitl
keizer
lemon
strategic
dialogue
management
via
deep
reinforcement
learning
nips
deep
reinforcement
learning
workshop
2015
szepesv´ari
algorithms
reinforcement
learning
morgan
claypool
pub
2010
karpathy
library
training
deep
learning
models
convnetjs
javascript
https
//github.com/karpathy/convnetjs
2015
nair
hinton
g.e
rectiﬁed
linear
units
improve
restricted
boltzmann
machines
icml
2010
cuay´ahuitl
renals
lemon
shimodaira
evaluation
hierarchical
reinforce-
ment
learning
spoken
dialogue
system
computer
speech
language
2010
cuay´ahuitl
dethlefs
spatially-aware
dialogue
control
using
hierarchical
reinforce-
ment
learning
tslp
2011
cuay´ahuitl
kruijff-korbayov´a
dethlefs
nonstrict
hierarchical
reinforcement
learning
interactive
systems
robots
tiis
2014
10.
sainath
t.n.
vinyals
senior
a.w.
sak
convolutional
long
short-term
memory
fully
connected
deep
neural
networks
icassp
2015
