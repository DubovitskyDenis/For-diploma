machine
olfaction
using
time
scattering
sensor
multiresolution
graphs
leonid
gugel
yoel
shkolnisky
shai
dekel
abstract
paper
construct
learning
architecture
high
dimensional
time
series
sampled
sensor
arrangements
using
redundant
wavelet
decomposition
graph
constructed
sensor
locations
algorithm
able
construct
discriminative
features
exploit
mutual
information
sensors
algorithm
applies
scattering
networks
time
series
graphs
create
feature
space
demonstrate
method
machine
olfaction
problem
one
needs
classify
gas
type
location
originates
data
sampled
array
sensors
experimental
results
clearly
demonstrate
method
outperforms
classical
machine
learning
techniques
used
previous
studies
contents
introduction
olfaction
datasets
related
studies
odor
classiﬁcation
mathematical
background
4.1.
redundant
wavelet
decomposition
graph
4.2.
scattering
convolution
network
graph
time
series
4.3.
random
forest
main
algorithm
results
6.1.
feature
space
6.2.
classiﬁcation
scenarios
6.3.
gas
classiﬁcation
results
6.4.
detection
co-concentration
6.5.
source
localization
conclusions
references
date
february
2016.
key
words
phrases
sensor
array
electronic
nose
metal-oxide
sensors
odor
classiﬁcation
odor
location
classiﬁcation
high
dimensional
time
series
scattering
deep
learning
random
forest
introduction
developing
chemo-sensing
solutions
standards
early
warning
chemical
bi-
ological
hazards
active
research
area
construct
accurate
reliable
chemical
warning
system
information
several
sensors
must
integrated
provide
clear
indication
composition
chemical
substances
well
propagation
proﬁle
propose
machine
learning
approach
based
recent
advances
classiﬁcation
regression
problems
machine
olfaction
machine
olfaction
problems
include
odor
classiﬁcation
problems
gas
consecration
detection
chemical
source
localization
algorithm
consists
two
steps
feature
generation
classiﬁcation
transform
raw
data
sensor
array
platform
discriminative
features
propose
scattering
time
series
graphs
stsg
transform
hierarchical
feature
extraction
method
multiple
time
series
transform
extension
recently
proposed
scattering
transform
time
series
graph
signals
multivariate
time
series
deﬁned
graph
resulting
features
classiﬁed
using
random
forest
based
classiﬁer
demonstrate
evaluate
algorithm
means
dataset
chemical
gas
sensor
array
turbulent
wind
tunnel
available
uci
machine
learning
repository
dataset
used
validate
existing
algorithms
structure
paper
follows
section
describe
set
machine
olfaction
problems
wish
solve
dataset
used
section
review
prior
art
methods
section
present
theoretical
building
blocks
method
redundant
haar
wavelet
decomposition
possibly
irregular
graph
scattering
convolution
network
random
forests
equipped
building
blocks
present
section
main
contribution
paper
stsg
scattering
time
series
graphs
algorithm
finally
section
show
experimental
results
methodology
applied
machine
olfaction
setting
odor
discrimination
odor
consecration
odor
localization
compare
performance
method
prior
techniques
machine
olfaction
figure
wind
tunnel
used
collect
time
series
data
sensor
arrays
olfaction
datasets
paper
use
dataset
gas
sensor
arrays
open
sampling
settings
uci
archive
machine
learning
repository
dataset
collection
multidimensional
time
series
data
along
static
environmental
parameters
include
responses
chem-
ical
detection
platform
diﬀerent
gases
diﬀerent
levels
concentration
challenge
develop
machine
learning
techniques
gas
classiﬁcation
source
prediction
models
section
review
dataset
details
data
collected
2.5m×1.2m×0.4m
wind
tunnel
test-bed
facility
see
figure
gaseous
substances
interest
released
wind
tunnel
operates
propulsion
open-cycle
mode
continuously
drawing
external
turbulent
air
throughout
tunnel
exhausting
back
outside
creating
relatively
less
turbulent
airﬂow
moving
downstream
towards
end
test
ﬁeld
order
construct
various
distinct
artiﬁcial
airﬂows
wind
tunnel
wind
tunnel
contains
motor-driven
exhaust
fan
outlet
test
section
motor
set
rotate
three
diﬀerent
constant
speeds
wind
tunnel
measures
ambient
temperature
relative
humidity
entire
experiment
chemical
detection
platform
inside
wind
tunnel
consists
boards
board
eight
commercialized
metal-oxide
gas
sensors
mox
sensitive
rapid
changes
analytes
concentration
thus
output
board
8-dimensional
time
series
chemical
detection
platform
consists
columns
nine
boards
located
six
equally-spaced
positions
along
wind
tunnel
total
sensors
per
location
see
figure
figure
depicts
typical
time-series
response
one
board
sensor
responses
aﬀected
air
turbulence
wind
tunnel
depend
concentration
gas
substance
operating
temperature
sensors
aﬀects
performance
adjustable
setting
voltage
built-in
heater
sensor
one
ﬁve
diﬀerent
levels
figure
multivariate
response
8-sensor
array
methane
released
wind
tunnel
dataset
generated
releasing
ten
diﬀerent
types
gas
wide
tunnel
acetone
acetaldehyde
ammonia
butanol
butyl-alcohol
ethylene
methane
methanol
carbon
monoxide
benzene
toluene
carbon
monoxide
kind
chemical
substance
released
nominal
concentration
values
outlet
gas
source
parts-per-million
volume
ppmv
.the
released
two
diﬀerent
nominal
concentrations
value
concentration
gas
source
100
ppm
400
ppm
note
actual
concentration
wind
tunnel
decreases
generated
gas
plume
spreads
along
tunnel
gas
released
motor
exhaust
fan
set
one
three
rotation
speeds
turbulent
airﬂow
thereby
generated
within
wind
tunnel
outputs
sensors
six
locations
wind
tunnel
measured
separately
resulting
six
72-dimensional
time
series
datasets
capturing
chemical
analyte
circulated
throughout
wind
tunnel
temperature
sensors
remained
ﬁxed
measurement
test
wind
tunnel
thoroughly
ventilated
measurement
repeated
three
diﬀerent
air
velocities
ﬁve
operating
temperatures
combination
type
gas
airﬂow
velocity
temperature
measurement
generation
time-series
repeated
times
time-series
measure
location
sampled
approximately
250
seconds
samples
per
second
total
2500
samples
per
location
per
experiment
time
series
measured
locations
fully
synchronized
although
slightly
diﬀerent
length
data
ten
gas
classes
collected
times
three
speeds
ﬁve
temperatures
modes
six
locations
resulting
dataset
thus
consists
18,000
72-dimensional
time
series
addition
experiment
recorded
ambient
temperature
relative
humidity
experiment
although
parameters
also
represented
time
series
low
variance
thus
represented
average
values
detailed
description
experimental
protocol
see
related
studies
odor
classification
several
previous
studies
considered
problem
odor
classiﬁcation
studies
follow
approach
extracting
features
data
followed
classiﬁcation
scheme
earlier
approaches
odor
classiﬁcation
problems
use
features
extracted
applying
stepwise
discriminant
analysis
short-time
fourier
transform
stft
followed
classiﬁcation
features
lvq
learning
vector
quantization
neural
network
fourier
power
spectrum
time
series
deﬁned
cid:12
cid:12
cid:12
cid:12
e−iξτ
cid:12
cid:12
cid:12
cid:12
short-time
low
pass
ﬁlter
normalized
smoothing
window
frequency
value
fourier
power
spectrum
deﬁned
expected
value
square
modulus
short
time
fourier
transform
stft
l2-moments
3.1
¯fw
stft-based
feature
mapping
time
series
¯fω
given
set
frequencies
stft
feature
extraction
method
constitutes
prior
art
scattering
approach
applied
data
performance
benchmark
recent
approaches
use
elaborate
statistical
modeling
data
described
moreover
applied
dataset
described
section
thus
greater
interest
section
brieﬂy
describe
algorithms
used
section
performance
benchmarks
study
models
time
series
output
sensors
denoted
using
auto-regressive
linear
model
order
stochastic
noise
term
parameters
determined
given
observations
aix
xi=1
parameters
represent
time
series
sense
parameters
predict
value
time
past
observations
allowing
error
parameters
estimated
map
time
series
feature
vector
use
vectors
input
classiﬁcation
step
classiﬁcation
step
uses
kernel
svm
gaussian
kernel
function
idea
behind
kernel
svms
use
function
measures
similarity
features
corresponding
pair
instances
dataset
commonly
used
function
gaussian
exp
−γkx
x′k2
hyper-parameter
usually
learned
cross-validation
shown
kernel
svm
algorithm
equivalent
mapping
feature
vector
high
possibly
inﬁnite
dimensional
space
followed
linear
partitioning
space
passing
points
kernel
function
gives
rise
non-linear
decision
boundaries
exist
linear
classiﬁcation
results
reported
pertain
reduced
dataset
simpliﬁed
clariﬁcation/prediction
used
four
gases
source
location
classiﬁed
either
right
left
sides
wind
tunnel
study
particular
interest
since
conditions
exactly
study
namely
classiﬁcation
gases
similar
training
scenarios
features
space
maximum
normalized
response
sensors
board
classiﬁcation
scheme
based
inhibitory
svm
classiﬁer
gaussian
kernel
whose
main
concept
train
classier
possible
label
function
constitutes
distance
correct
label
oﬀending
incorrect
answer
detailed
description
see
mathematical
background
section
present
theoretical
background
approach
section
4.1
present
generalization
critically
sampled
haar
wavelet
transform
graphs
over-complete
representation
transform
allows
exploit
correlations
diﬀerent
sensing
boards
plays
critical
role
feature
extraction
process
section
4.2
review
scattering
convolution
network
introduced
mallat
one
building
blocks
method
finally
section
4.3
provide
details
random
forest
algorithm
4.1.
redundant
wavelet
decomposition
graph
let
undirected
unweighed
graph
i=1
vertex
set
edge
set
multiscale
folder-decomposition
j=0
collection
vertex
set
partitions
resolution
zero
i=1
2−jn
υj−1
υj−1
i-folder
scale
level
obtained
grouping
two
folders
υj−1
υj−1
previous
function
graph
deﬁned
mapping
vertex
dot-product
two
functions
deﬁned
4.1
hx1
x2ig
=xv∈g
deﬁne
haar
wavelet
ortho-basis
transform
folder
decomposition
haar
wavelet
function
graph
deﬁned
folder
4.2
1vj−1
1vj−1
indicator
function
set
graph
given
otherwise
according
set
functions
orthogonal
system
deﬁned
graph
set
4.3
1vj
i=0
2−jn
deﬁnes
redundant
wavelets
graph
note
level
2−jn
folders
maximum
scale
folder-decomposition
kmax
⌊log2
application
haar
transform
signal
deﬁned
graph
proceeds
follows
ﬁrst
scale
haar
coeﬃcients
4.4
...
kmax
4.5
h1v1
xig
hϕi,1
xig
h1vk
hϕi
k−1
k−1
2−kd
observe
fact
time
series
signal
graph
use
notation
time
dependent
multiscale
haar
coeﬃcients
next
introduce
generalization
redundant
wavelet
transform
functions
de-
ﬁned
graph
approach
eﬀective
signal
processing
pattern
recognition
problems
image
denoising
speech
recognition
approach
build
redundant
scheme
wavelet
decomposition
overlapping
folders
level
figure
illustrates
multiscale
decomposition
folder
overlapping
leads
over-complete
wavelet
repre-
sentation
signal
graph
domain
easy
demonstrate
system
redundant
haar-functions
deﬁned
4.3
folder
decomposition
overlapping
nec-
essarily
orthogonal
basis
however
redundant
haar
functions
provide
mutual
information
vertices
olfaction
problem
overlapped
folder
decomposition
using
neighborhood
relation-
ships
boards
figure
see
haar
wavelet
lifting
scheme
overlapping
figure
multiscale
folder-decomposition
overlapping
figure
multiscale
folder-decomposition
overlapping
board
position
applied
center
boards
line
position
due
wind
direction
tunnel
air
wind
tunnel
generates
diﬀusion
chemical
analyte
therefore
centralized
sensing
boards
contain
informative
time
series
data
4.2.
scattering
convolution
network
graph
time
series
section
review
scattering
convolution
networks
adaptations
graph
time
series
4.2.1
review
fundamentals
convolutional
networks
deep
learning
4.2.2
review
wavelet-based
scattering
network
time
series
4.2.3
emphasize
stability
properties
wavelet
approach
constitute
advantage
fourier
power
spectrum
4.2.4
deﬁne
feature
extraction
classiﬁcation
methods
based
scattering
4.2.1.
fundamentals
convolution
networks
deep
learning
deep
learning
architec-
tures
neural
network-based
algorithms
modeled
mimic
functionality
human
nervous
system
methods
successfully
applied
variety
pattern
recognition
problems
computer
vision
face
recognition
image
classiﬁcation
annotation
natural
language
processing
speech
recognition
audio
representations
signals
learning
achieved
hierarchical
feature
extraction
observed
data
main
idea
apply
nonlinear
processing
data
ﬂows
layers
fact
hierarchical
features
ﬁtted
weight
parameters
neural
networks
free
parameters
unit
calculated
results
one
complex
optimization
process
convolutional
neural
network
cnn
one
popular
deep
learning
architectures
pattern
recognitions
problems
grid-based
signals
time
series
images
videos
imagenet
cnn
consists
units
use
overlapping
patches
input
signals
apply
neurons
words
cnn
learns
hierarchical
net
convolutions
ﬁlters
signals
mallat
introduced
mathematical
class
deep
convolution
networks
called
scat-
tering
convolution
networks
scattering
convolution
networks
unsupervised
cnn
architec-
ture
grid-based
signals
obtained
cascading
wavelet
transforms
modulus
pooling
operators
average
amplitude
iterated
wavelet
coeﬃcients
scattering-based
feature
extraction
translation
invariant
lipschitz
continuous
deformations
trying
apply
dl/cnn
techniques
problems
diﬃculty
arises
since
geometric
conﬁguration
sensors
necessarily
regular
image
processing
pixels
well
aligned
uniform
grid
thus
work
concept
uniform
grid
replaced
graph
structure
4.2.2.
scattering
convolution
network
work
scattering
network
applied
separately
time
series
type
computed
graph
analysis
section
4.1.
scattering
convolution
network
obtained
based
cascade
wavelet
convolution
modulus
operators
smoothing
operator
low-pass
ﬁlter
let
complex
wavelet
whose
real
imaginary
parts
orthogonal
l2-norm
dyadic
dilations
wavelet
transform
time
series
scale
2−jψ
2−jt
calculate
absolute
value
complex
value
coeﬃcient
=zr
sequence
indices
order-m
scattering
propagator
deﬁned
||x
ψj1|
ψj2|
ψjm
figure
two
levels
scattering
convolution
network
time
series
scat-
tering
propagators
windowed
scattering
scattering
coeﬃcients
order-m
deﬁned
4.1
||x
ψj1|
ψj2|
ψjm
2−j
2−j
low-pass
ﬁlter
scale
scattering
operator
aggregates
scattering
coeﬃcients
order
layer
4.2
0≤m≤m
iterated
procedure
scattering
convolution
network
time
series
illustrated
figure
types
signals
audio
images
biomedical
signals
ﬁnance
time
series
suﬃcient
compute
scattering
coeﬃcient
layers
0,1
m=2
j1
j2∈λ
4.2.3.
scattering
deformation
stability
eﬃciency
scattering
representation
comes
invariance
local
translations
due
convolutions
ability
linearize
deformations
stability
time-warping
fourier
transform
unstable
deformation
dilating
sinusoidal
wave
yields
new
sinusoidal
wave
diﬀerent
frequency
orthogonal
original
one
let
deﬁne
deformation
operator
signal
non-constant
deformation
term
proven
theorem
2.12
scattering
trans-
form
signal
compact
support
lipschitz
continuous
action
deformation
operator
4.3
supt
|∇τ
supt
|∇τ
ksj
cmkxk
cid:0
2−j|τ
|∇τ
cid:1
property
guarantees
stability
signals
clear
deformation
error
small
scaling
factor
signal
smooth
meaning
words
scattering
metric
satisﬁes
invariance
local
transformations
deformations
4.2.4.
scattering
moments
noted
section
4.2.3
scattering
network
stable
un-
der
small
deformation
therefore
used
eﬀective
feature
space
many
kinds
classiﬁcation
regression
problems
state-of-the-art
results
scattering
approach
obtained
handwritten
digit
recognition
texture
classiﬁcation
compared
convolution
neural
networks
cnn
dictionary
learning
scattering
moments
deﬁned
expected
values
time
scattering
coeﬃcients
path
ﬁnite
time
series
signal
xt=1
||x
ψj1|
ψj2|
ψjm
according
standard
way
build
feature
space
based
scattering
moments
ﬁnite
time
series
signal
|x|
4.4
j2∈λ
scaling
set
2z1/q1
2z2/q2
deﬁnes
ﬁlter
bank
scattering
transform
number
wavelets
per
octave
ﬁrst
second
layer
scattering
moments
used
features
space
time
series
classiﬁcation
problems
musical
genre
classiﬁcation
gitzan
phone
segment
classiﬁcation
kinds
signals
best
state-of-the-art
results
obtained
svm
classiﬁer
gaussian
kernel
4.3.
random
forest
random
forest
popular
ensemble
learning
method
clas-
siﬁcation
regression
training
time
diverse
set
decision
trees
constructed
using
randomization
techniques
output
averaged
overcome
potential
bias
tree
implementations
decision
trees
pruned
reduce
variance
easily
allows
parallel
architecture
implemented
applications
testing
training
scenarios
implemented
many
recent
applications
classiﬁcation
regression
problems
current
study
found
eﬀective
classiﬁer
machine
olfaction
problem
due
fact
approach
based
ensemble
decision
trees
feature
set
consists
variables
diﬀerent
domains
including
categorical
continuous
variables
allows
add
set
static
parameters
airﬂow
velocity
operating
temperature
feature
space
time
series
let
set
vectors
training
set
consisting
samples
d-dimension
feature
vector
associated
response
values
categorical
variables
classiﬁcation
problem
continuous
variables
regression
problem
training
data
interpreted
samples
governed
unknown
distribution
goal
classiﬁer
learn
approximate
oracle
function
learned
function
best
approximation
respect
error
metric
loss
function
tree
bagging
approach
algorithm
randomly
selects
samples
replacement
training
set
order
build
decision
trees
ﬁnal
prediction
function
average
predictions
decision
tree
weighted
voting
ensemble
main
algorithm
section
present
main
algorithm
developed
paper
elements
introduced
previous
sections
brought
together
feature
construction
performed
using
scattering
time
series
graph
stsg
.the
computed
feature
vectors
along
response
variables
serve
training
set
algorithm
stsg
algorithm
combines
haar
scattering
transform
graph
standard
wavelet-
based
scattering
net
described
previously
haar
scattering
network
architecture
signal
deﬁned
graphs
time
series
described
scattering
architecture
obtained
cascading
multiscale
haar
wavelet
transform
deﬁned
embedded
subset
folders
construc-
tion
without
redundant
wavelet
decomposition
denotes
multivariate
time
series
deﬁned
unweighted
graph
domain
dim
ﬁnite
time
domain
scattering
time
series
graphs
deﬁned
5.1
consists
two
actions
ﬁrst
two
actions
calculation
k-levels
redundant
haar
wavelet
coeﬃcients
4.5
respect
selected
folder
decomposition
architecture
folder
decomposition
derived
understanding
geometry
sensing
platform
second
action
calculation
ℓ-levels
scattering
coeﬃcients
time
series
scaling
paths
4.1
feature
space
signal
consists
stsg
moments
expected
value
scattering
time
series
graphs
transform
time
5.2
¯sv
ethsj
machine
learning
task
follows
given
set
training
signals
instance
time
series
deﬁned
graph
learning
algorithm
must
seek
prediction
function
equipped
training
set
calculate
stsg
moments
¯sv
see
5.2
second
step
applying
dimensionality
reduction
stsg
moments
principal
components
¯sv
∀xi
dimensionality
reduction
increases
stability
scattering
domain
lies
low
dimensional
manifold
classiﬁcation
scenarios
additional
information
instance
added
feature
space
since
learning
algorithm
based
classiﬁer
trees
constructed
bagging
training
set
iteration
begins
random
sampling
full
training
set
followed
feature
mapping
¯sv
algorithm
training
random
forest
scattering
graph
net
procedure
trainrf
bagging
¯sv
stsg
¯sv
treegrow
end
return
end
procedure
loop
ensemble
trees
bagging
ran-
dom
sampling
replacement
computing
stsg
moments
features
dimensionality
tion
components
space
reduc-
principal
growing
decision
tree
feature
bagging
ensemble
tree
building
final
classiﬁer
uniform
normalization
output
final
tree
ensemble
learned
pca
transform
results
section
demonstrate
application
approach
machine
olfaction
problems
section
6.1
review
raw
feature
space
section
6.2
deﬁne
classiﬁcation
scenarios
finally
sections
6.3
6.4
6.5
compare
results
prior-art
scattering
techniques
state-of-the-art
machine
olfaction
techniques
described
section
6.1.
feature
space
stsg
features
see
section
add
pre-established
conditioning
parameters
described
section
heater
voltage
4.0v
4.5v
5.0v
5.5v
airﬂow
velocity
measured
rotation
per
minute
rmp
1500
3900
550
nominal
concentration
measured
parts-per-million
volume
ppmv
features
ambient
temperature
relative
humidity
included
since
low
variance
experiments
clearly
show
adding
static
features
signiﬁcantly
improves
performance
prediction
algorithm
addition
location
time
series
known
namely
position
board
number
respect
chemical
source
location
sensing
board
6.1
floc
xpos
xbord
xpos
0.25
0.5
0.98
1.18
1.40
1.45
xboard
0.13
0.13
1.2
6.2.
classiﬁcation
scenarios
results
complex
scenarios
gas
classiﬁcation
source
detection
scenarios
motivated
proposals
department
defense
dod
development
chemo-sensing
solutions
standards
early
warning
protection
military
forces
potential
chemical
biological
attacks
see
speciﬁcally
scenarios
follows
gas
classiﬁcation
problem
labels
gas
concentration
prediction
binary
classiﬁcation
problem
000
ppm
ppm
source
localization
problem
prediction
source
location
respect
local
coordinates
wind
tunnel
scenarios
applied
learning
with/without
static
features
with/without
source
location
information
based
prior
studies
constructed
two
ways
aggregate
raw
features
board
column
aggregating
nine
boards
position
72-dimension
time
series
single
board
using
8-dimension
time
series
single
board
single
board
scenario
signiﬁcantly
diﬃcult
fewer
features
used
compared
results
frequency-domain
features
based
short-time
fourier
transformation
3.1
simple
features
based
ﬁrst
two
statistical
moments
time
series
sensor
response
words
compared
three
groups
features
stsg
features
5.2
statistical
moments
fourier
power
spectrum
stft
l2-moments
3.1
three
groups
features
applied
classiﬁer
200
grown
trees
error
rate
calculated
expected
value
variance
5-folder
cross
validation
6.3.
gas
classiﬁcation
results
table
shows
classiﬁcation
performance
board
column
suitable
conditions
performance
random
forest
classiﬁer
three
groups
features
signiﬁcantly
better
mean
results
previous
study
shown
using
stsg
features
provides
signiﬁcantely
better
performance
complex
scenarios
table
classiﬁcation
performance
board
column
scenario.testing
error
rate
models
proposed
stsg-algorithm
short
time
fourier
trans-
form
stft
statistical
moments
features
with/withput
static
features
with/withput
location
information
static
feature
false
true
location
stft
statistical
moments
stsg
false
true
false
true
0.574
±0.07
0.47
±0.07
2.52
±0.09
0.58
±0.06
0.48
±0.03
2.41
±0.16
0.26
±0.08
1.26
±0.15
0.09
±0.07
1.31
±0.25
0.09
±0.02
0.24
±0.07
7.89
comparison
single
board
scenario
presented
table
table
classiﬁcation
performance
single
board
scenario
testing
error
rate
models
stsg
stft
statistic
moments
features
with/without
static
location
information
static
features
false
true
location
stft
statistic
moments
stsg
false
true
false
true
19.68
±0.37
24.96
±0.15
18.11
±0.11
14.74
±0.20
18.20
±0.11
13.63
±00.20
3.15
±0.12
2.80
±00.08
2.14
±0.03
2.30
±0.07
4.78
±0.08
3.15
±0.05
figure
shows
error
bars
learning
curves
validation
error
out-of-bag
error
number
grown
classiﬁcation
trees
random
forest
ensemble
kind
features
stsg
learning
curves
fastest
decay
rate
proves
learnability
proposed
method
0.05
0.045
0.04
0.035
0.03
0.025
0.02
learning
curves
validation
error
statistic
moments
stft
stsg
100
120
140
160
180
200
number
grown
trees
0.05
0.045
0.04
0.035
0.03
0.025
0.02
learning
curves
out-of-bag
error
statistic
moments
stft
stsg
100
120
140
160
180
200
number
grown
trees
figure
learning
curves
validation
error
out-of-bag
errors
classiﬁ-
cation
performance
single
board
scenario
scenario
6.4.
detection
co-concentration
address
binary
classiﬁcation
problem
goal
determine
concentration
substance
carbon
monoxide
note
given
dataset
includes
every
chemical
substance
experiment
one
nominal
concentration
except
carbon
monoxide
collected
two
diﬀerent
concentrations
000
ppm
000
ppm
built
subset
binary
labeling
given
dataset
contained
experiments
co.
applied
classiﬁer
compared
feature
space
table
presents
classiﬁcation
performance
single
board
scenario
binary
classiﬁcation
problem
note
scenario
compare
results
static
features
features
simulated
diﬀerent
unique
static
parameters
table
classiﬁcation
performance
single
board
scenario
con-
centration
testing
error
rate
classiﬁer
proposed
stsg
stft
sta-
tistical
moments
features
space
with/without
location
information
location
stft
statistic
moments
stsg
false
true
0.30
±0.05
1.00
±0.16
0.24
±0.07
0.26
±0.06
0.61
±0.10
0.20
±0.05
proposed
stsg
feature
space
clearly
demonstrates
performance
superior
methods..
apply
problem
board
column
board
column
scenario
gases
perfect
performance
yet
6.5.
source
localization
source
localization
scenario
learning
regression
model
high
accuracy
detection
mox-sensors
location
respect
gas
substance
tables
show
rate
error
compared
features
space
two
types
features
aggregation
board
column
single
board
scenarios
used
respectively
error
rate
l2-norm
error
meters
sensor
board
location
predicted
location
note
use
feature
aggregation
single
board
classiﬁer
predicts
location
sensing
board
floc
6.1
feature
aggregation
board
column
used
classiﬁer
predicts
distance
line
position
xpos
table
location
prediction
performance
board
column
l2-norm
error
meters
respect
source
location
static
stft
features
false
0.02155
±0.00063
0.00745
±0.00028
0.00477
±0.00060
true
0.02025
±0.00076
0.00773
±0.00032
0.00481
±0.00043
stsg
statistic
moments
table
location
prediction
performance
single
board
scenarios
l2-
norm
error
meters
respect
source
location
stft
static
features
false
0.174
±0.001
0.288
±0.001
0.162
±0.001
0.161
±0.010
0.280
±0.006
0.150
±0.008
true
statistic
moments
stsg
conclusions
current
study
presented
novel
methodology
used
pattern
recognition
problems
signals
collected
array
possibly
non-uniform
ensemble
sensors
deﬁned
novel
scattering
transform
multidimensional
time
series
graph
stsg
used
redundant
wavelet
graph
decomposition
study
focused
machine
olfaction
problems
dataset
obtained
chemical
gas
sensor
array
turbulent
wind
tunnel
applied
methodology
three
machine
learning
problems
classiﬁcation
diﬀerent
gases
various
concentrations
detection
consecration
chemical
substance
localization
next
step
research
develop
proposed
method
formachine
olfaction
cases
involving
turbulent
gas
mixtures
another
interesting
research
direction
would
add
soft
supervised
learning
scattering
net
recent
advances
classical
deep
learning
cnn
demonstrated
high
accuracy
performance
methods
based
learning
convolutional
ﬁlters
however
must
noted
deep
learning
architecture
typically
requires
large
training
dataset
learning
process
computationally
intensive
recall
learning
process
using
scattering
networks
faster
since
use
pre-designed
ﬁlters
one
could
consider
soft
learning
variant
scattering
network
standard
wavelet
ﬁlters
used
initial
ﬁlters
optimization
applied
wavelet
parameters
references
chemical
biological
sensors
standards
study.
http
//handle.dtic.mil/100.2/ada458370
accessed
2015-04-08
figaro
usa
inc.
http
//www.figarosensor.com/
accessed
2015-04-08
niosh
pocket
guide
chemical
hazard.
http
//www.cdc.gov/niosh/npg/
accessed
2015-04-08
uci
machine
set
http
//archive.ics.uci.edu/ml/datasets/gas+sensor+arrays+in+open+sampling+settings
accessed
2013-06-05.
open
sampling
repository
learning
settings
sensor
array
data
gas
joakim
and´en
st´ephane
mallat
deep
scattering
spectrum
2013
yoshua
bengio
learning
deep
architectures
foundations
trends
cid:13
machine
learning
2009
1–127
gregory
beylkin
representation
operators
bases
compactly
supported
wavelets
siam
journal
numerical
analysis
1992
1716–1740
leo
breiman
random
forests
machine
learning
2001
5–32
leo
breiman
jerome
friedman
charles
stone
richard
olshen
classiﬁcation
regression
trees
1984
bruna
mallat
bacry
muzy
multiscale
intermittent
process
analysis
scattering
arxiv
preprint
arxiv:1311.4104
joan
bruna
st´ephane
mallat
classiﬁcation
scattering
operators
arxiv
preprint
arxiv:1011.3023
2010
audio
texture
synthesis
scattering
moments
arxiv
preprint
arxiv:1311.0407
2013
invariant
scattering
convolution
networks
pattern
analysis
machine
intelligence
ieee
transac-
tions
2013
1872–1886
joan
bruna
stephane
mallat
emmanuel
bacry
jean-francois
muzy
intermittent
process
analysis
scattering
moments
arxiv
preprint
arxiv:1311.4104
2013
chen
xiuyuan
cheng
st´ephane
mallat
unsupervised
deep
haar
scattering
graphs
advances
neural
information
processing
systems
2014
1709–1717
marco
cuturi
arnaud
doucet
autoregressive
kernels
time
series
arxiv
preprint
arxiv:1101.0673
2011
jordi
fonollosa
irene
rodr´ıguez-luj´an
marco
trincavelli
ram´on
huerta
dataset
chemical
gas
sensor
array
turbulent
wind
tunnel
data
brief
2015
169–174
jordi
fonollosa
irene
rodr´ıguez-luj´an
marco
trincavelli
alexander
vergara
ram´on
huerta
chemical
discrimination
turbulent
gas
mixtures
mox
sensors
validated
gas
chromatography-mass
spectrometry
sensors
2014
19336–19353
matan
gavish
boaz
nadler
ronald
coifman
multiscale
wavelets
trees
graphs
high
dimensional
data
theory
applications
semi
supervised
learning
proceedings
27th
international
conference
machine
learning
icml-10
2010
367–374
ram´on
huerta
shankar
vembu
jos´e
amig´o
thomas
nowotny
charles
elkan
inhibition
multiclass
classiﬁcation
neural
computation
2012
2473–2507
alex
krizhevsky
ilya
sutskever
geoﬀrey
hinton
imagenet
classiﬁcation
deep
convolutional
neural
networks
advances
neural
information
processing
systems
2012
1097–1105
yann
lecun
l´eon
bottou
yoshua
bengio
patrick
haﬀner
gradient-based
learning
applied
document
recognition
proceedings
ieee
1998
2278–2324
yann
lecun
koray
kavukcuoglu
cl´ement
farabet
convolutional
networks
applications
vision
circuits
systems
iscas
proceedings
2010
ieee
international
symposium
ieee
2010
253–
256
helmut
l¨utkepohl
new
introduction
multiple
time
series
analysis
springer
science
business
media
2007
julien
mairal
francis
bach
jean
ponce
task-driven
dictionary
learning
pattern
analysis
machine
intelligence
ieee
transactions
2012
791–804
stephane
mallat
group
invariant
scattering
communications
pure
applied
mathematics
2012
1331–1398
nimsuk
nakamoto
improvement
capability
classifying
odors
dynamically
changing
concentra-
tion
using
qcm
sensor
array
short-time
fourier
transform
sensors
actuators
chemical
127
2007
491–496
study
odor
classiﬁcation
dynamical
concentration
robust
humidity
temperature
changes
sensors
actuators
chemical
134
2008
252–257
idan
ram
michael
elad
israel
cohen
redundant
wavelets
graphs
high
dimensional
data
clouds
signal
processing
letters
ieee
2012
291–294
ranzato
jie
huang
y-l
boureau
yann
lecun
unsupervised
learning
invariant
feature
hierar-
chies
applications
object
recognition
computer
vision
pattern
recognition
2007.
cvpr
ieee
conference
ieee
2007
1–8
mark
shensa
discrete
wavelet
transform
wedding
trous
mallat
algorithms
signal
processing
ieee
transactions
1992
2464–2482
ronen
talmon
st´ephane
mallat
hitten
zaveri
ronald
coifman
manifold
learning
latent
variable
inference
dynamical
systems
2014
hamid
reza
tohidypour
seyyed
ali
seyyedsalehi
hossein
behbood
hossein
roshandel
new
represen-
tation
speech
frame
recognition
based
redundant
wavelet
ﬁlter
banks
speech
communication
2012
256–271
shankar
vembu
alexander
vergara
mehmet
muezzinoglu
ramon
huerta
time
series
features
kernels
machine
olfaction
sensors
actuators
chemical
174
2012
535–546
alexander
vergara
jordi
fonollosa
jonas
mahiques
marco
trincavelli
nikolai
rulkov
ramon
huerta
performance
gas
sensor
arrays
open
sampling
systems
using
inhibitory
support
vector
machines
sensors
actuators
chemical
185
2013
462–477
antanas
verikas
adas
gelzinis
marija
bacauskiene
mining
data
random
forests
survey
results
new
tests
pattern
recognition
2011
330–349
school
mathematical
sciences
tel
aviv
university
ramat
aviv
6997801
tel
aviv
israel
e-mail
address
leong
post.tau.ac.il
school
mathematical
sciences
tel
aviv
university
ramat
aviv
6997801
tel
aviv
israel
e-mail
address
yoelsh
post.tau.ac.il
url
https
//sites.google.com/site/yoelshkolnisky/
school
mathematical
sciences
tel
aviv
university
ramat
aviv
6997801
tel
aviv
israel
e-mail
address
shai.dekel
ge.com
url
http
//www.shaidekel.com/
