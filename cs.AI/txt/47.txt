spatial
concept
acquisition
mobile
robot
integrates
self-localization
unsupervised
word
discovery
spoken
sentences
akira
taniguchi
tadahiro
taniguchi
member
ieee
tetsunari
inamura
member
ieee
abstract—in
paper
propose
novel
unsupervised
learning
method
lexical
acquisition
words
related
places
visited
robots
human
continuous
speech
signals
address
problem
learning
novel
words
robot
prior
knowledge
words
except
primitive
acoustic
model
propose
method
allows
robot
effectively
use
learned
words
meanings
self-localization
tasks
proposed
method
nonparametric
bayesian
spatial
concept
acquisition
method
spcoa
integrates
generative
model
self-localization
unsupervised
word
segmentation
uttered
sentences
via
latent
variables
related
spatial
concept
implemented
proposed
method
spcoa
sigverse
simulation
environment
turtlebot
mobile
robot
real
environment
conducted
experiments
evaluating
performance
spcoa
experimental
results
showed
spcoa
enabled
robot
acquire
names
places
speech
sentences
also
revealed
robot
could
effectively
utilize
acquired
spatial
concepts
reduce
uncertainty
self-localization
index
terms—learning
place
names
lexical
acquisition
self-
localization
spatial
concept
introduction
utonomous
robots
service
robots
operating
human
living
environment
humans
able
perform
various
tasks
language
communication
end
robots
required
acquire
novel
concepts
vocabulary
basis
information
obtained
sensors
e.g.
laser
sensors
microphones
cameras
recognize
variety
objects
places
situations
ambient
environment
consider
important
robot
learn
names
humans
associate
places
environment
spatial
areas
corresponding
names
i.e.
robot
able
understand
words
related
places
therefore
important
deal
considerable
uncertainty
robot
movement
errors
sensor
noise
speech
recognition
errors
several
studies
language
acquisition
robots
assumed
robots
prior
lexical
knowledge
studies
differ
speech
recognition
studies
based
large
vocabulary
natural
language
processing
studies
based
lexical
syntactic
semantic
knowledge
studies
akira
taniguchi
tadahiro
taniguchi
university
1-1-1
noji
higashi
kusatsu
shiga
525-8577
mail
a.taniguchi
em.ci.ritsumei.ac.jp
taniguchi
em.ci.ritsumei.ac.jp
tetsunari
inamura
national
institute
informatics/the
graduate
university
advanced
studies
2-1-2
hitotsubashi
chiyoda-ku
tokyo
101-
8430
japan
e-mail
inamura
nii.ac.jp
ritsumeikan
japan
fig
schematic
representation
target
task
learning
targets
three
places
near
objects
utterer
robot
came
front
utterer
spoke
front
tv.
holds
true
places
robot
performs
word
discovery
uttered
sentences
learns
related
spatial
concepts
words
related
place
robot
front
actually
however
hypothesis
self-position
robot
uncertain
robot
asks
neighbor
current
place
utilizing
spatial
concepts
uttered
sentence
robot
narrow
hypothesis
self-position
language
acquisition
robots
also
constitute
constructive
approach
human
developmental
process
emer-
gence
symbols
objectives
study
build
robot
learns
words
related
places
efﬁciently
utilizes
learned
vocabulary
self-localization
lexical
acquisition
related
places
expected
enable
robot
improve
spatial
taniguchilaboratory
teachings
multipletaniguchilaboratory
place
taniguchilaboratorylaboratory
front
tv.
/dis
afroqtabutibe/
teaching
isthe
front
tv.
place
white
shelf.
learningutilization
spatial
concepts
place
learning
targetbefore
modification
localizationafter
modification
localization/afroqtabutibe//waitosherfu//bigbuqkkais/
cognition
schematic
representation
depicting
target
task
study
shown
fig
study
assumes
robot
vocabularies
advance
recognize
syllables
phonemes
robot
performs
self-localization
moving
around
environment
shown
fig
utterer
speaks
sentence
including
name
place
robot
shown
fig
purposes
study
need
consider
problems
self-localization
lexical
acquisition
simultaneously
robot
learns
novel
words
utterances
difﬁcult
determine
segmentation
boundaries
identity
different
phoneme
sequences
speech
recognition
results
lead
errors
first
let
consider
case
lexical
acquisition
isolated
word
example
robot
obtains
speech
recognition
results
aporu
epou
aqpuru
incorrect
phoneme
recognition
apple
difﬁcult
robot
determine
whether
denote
referent
without
prior
knowledge
second
let
consider
case
lexical
acquisition
utterance
sentence
example
robot
obtains
speech
recognition
result
thisizanaporu.
robot
necessarily
segment
sentence
individual
words
e.g.
aporu
addition
necessary
robot
recognize
words
referring
referent
e.g.
fruit
apple
among
many
segmented
results
contain
errors
case
fig
possibility
learning
names
including
phoneme
errors
e.g.
afroqtabutibe
robot
lexical
knowledge
hand
robot
performs
online
probabilis-
tic
self-localization
assume
robot
uses
sensor
data
control
data
e.g.
values
obtained
using
range
sensor
odometry
position
robot
global
map
unclear
difﬁculties
associated
identiﬁcation
self-position
using
local
sensor
information
become
problematic
case
global
localization
using
local
problem
hypothesis
self-position
present
multiple
remote
locations
frequently
occurs
shown
fig
information
e.g.
range
sensor
order
solve
abovementioned
problems
study
adopted
following
approach
utterance
recognized
single
phoneme
sequence
set
candidates
multiple
phonemes
attempt
suppress
variability
speech
recognition
results
performing
word
discovery
taking
account
multiple
candidates
speech
recognition
addition
names
places
learned
associating
words
positions
lexical
acquisition
complemented
using
certain
particular
spatial
information
i.e.
information
obtained
hearing
utter-
ances
including
word
place
many
times
furthermore
study
attempt
address
problem
uncertainty
self-localization
improving
self-
position
errors
using
recognized
utterance
including
name
current
place
acquired
spatial
concepts
shown
fig
paper
propose
nonparametric
bayesian
spatial
concept
acquisition
method
spcoa
basis
unsupervised
word
segmentation
nonparametric
bayesian
generative
model
integrates
self-localization
clustering
words
places
main
contributions
paper
follows
proposed
learning
method
spatial
concepts
perform
lexical
acquisition
related
places
i.e.
names
places
continuous
speech
signal
unsupervised
manner
achieved
relatively
accurate
lexical
acquisition
reduced
variability
errors
phonemes
performing
word
discovery
using
multiple
candidates
speech
recognition
results
i.e.
using
lattice
format
addition
general
self-localization
method
mobile
robots
showed
self-localization
proposed
method
reduce
uncertainty
self-
position
utilizing
learned
spatial
concepts
uttered
sentence
current
position
remainder
paper
organized
follows
section
previous
studies
language
acquisition
lexical
acquisition
relevant
study
described
section
iii
proposed
method
spcoa
presented
sections
discuss
effectiveness
spcoa
simulation
real
environment
section
concludes
paper
related
works
lexical
acquisition
studies
lexical
acquisition
typically
focus
lexi-
cons
objects
many
studies
able
address
lexical
acquisition
words
related
objects
e.g.
words
places
roy
proposed
computational
model
enables
robot
learn
names
objects
object
im-
age
spontaneous
infant-directed
speech
results
showed
model
performed
speech
segmentation
word
discovery
visual
categorization
iwahashi
reported
robot
properly
understands
situation
acquires
relationship
object
behaviors
sentences
chai
focused
conjunction
speech
eye
gaze
use
domain
knowledge
lexical
acquisition
proposed
unsupervised
learning
method
automatically
acquires
novel
words
interactive
system
chai
method
based
ibm
translation
model
estimates
word-entity
association
probability
nakamura
proposed
method
learn
object
concepts
word
meanings
multimodal
information
verbal
information
method
proposed
categoriza-
tion
method
based
multimodal
latent
dirichlet
allocation
mlda
enables
acquisition
object
concepts
multimodal
information
visual
auditory
haptic
information
araki
addressed
development
method
combining
unsupervised
word
segmentation
uttered
sentences
nested
pitman-yor
language
model
npylm
learning
object
concepts
mlda
however
disadvantage
using
npylm
phoneme
sequences
errors
result
appropriate
word
segmentation
studies
address
lexical
acquisition
space
place
also
tolerate
uncertainty
phoneme
recognition
however
introduction
robots
human
living
environment
robots
need
acquire
lexicon
related
objects
also
places
study
focuses
lexical
acquisition
related
places
robots
adaptively
learn
names
places
various
human
living
environments
using
spcoa
consider
acquired
names
places
useful
various
tasks
e.g.
tasks
movement
robots
speech
instruction
simultaneous
learning
places
vocabulary
following
studies
addressed
lexical
acquisition
related
places
however
studies
could
utilize
learned
language
knowledge
estimations
self-localization
robot
taguchi
proposed
method
unsupervised
learning
phoneme
sequences
relationships
words
objects
various
user
utterances
without
prior
linguistic
knowledge
acoustic
model
phonemes
proposed
method
simultaneous
categorization
self-position
coordinates
lexical
learning
experimental
results
showed
possible
learn
name
place
utterances
cases
output
words
corresponding
places
location
used
learning
milford
proposed
ratslam
inspired
biological
knowledge
pose
cell
hippocampus
rodents
milford
proposed
method
enables
robot
acquire
spatial
concepts
using
ratslam
lingodroids
mobile
robots
learn
language
robot-to-robot
communication
studied
robot
communicated
name
place
robots
various
locations
experimental
results
showed
two
robots
acquired
lexicon
places
common
researchers
showed
possible
learn
temporal
concepts
manner
analogous
acquisition
spatial
concepts
studies
reported
robots
created
vocabulary
however
studies
consider
acquisition
lexicon
human-to-
robot
speech
interactions
welke
proposed
method
acquires
spatial
rep-
resentation
integration
representation
continuous
state
space
sensorimotor
level
discrete
symbolic
entities
used
high-level
reasoning
method
estimates
probable
spatial
domain
word
given
objects
using
spatial
lexical
knowledge
extracted
google
corpus
position
information
object
study
different
study
consider
lexicon
learning
human
speech
case
global
localization
hypothesis
self-
position
often
remains
multiple
remote
places
case
possibility
performing
incorrect
estimation
increasing
estimation
error
problem
exists
teaching
tasks
self-localization
lexical
acquisition
abovementioned
studies
could
deal
problem
paper
proposed
method
enables
robot
perform
accurate
self-localization
reducing
estimation
error
teaching
time
using
smoothing
method
teaching
task
utilizing
words
acquired
lexical
acquisition
strengths
study
learning
spatial
concept
self-localization
represented
one
generative
model
robots
able
utilize
acquired
lexicon
self-localization
autonomously
iii
spatial
concept
acquisition
propose
nonparametric
bayesian
spatial
concept
ac-
quisition
method
spcoa
integrates
nonparametric
morphological
analyzer
lattice
i.e.
latticelm1
spatial
clustering
method
monte
carlo
localization
mcl
generative
model
study
deﬁne
position
speciﬁc
coordinate
local
point
environment
position
distribution
spatial
area
environment
deﬁne
spatial
concept
names
places
position
distributions
corresponding
names
model
developed
spatial
concept
acquisi-
tion
probabilistic
generative
model
integrates
self-
localization
simultaneous
clustering
places
words
fig
shows
graphical
model
spatial
concept
acquisition
table
shows
variable
graphical
model
number
words
sentence
time
denoted
generative
model
proposed
method
deﬁned
equation
1-10
gem
mult
dir
mult
wct
gem
σ/κ0
xt−1
probability
distribution
equation
deﬁned
follows
cid:80
µit
σit
mult
φct
it=j
mult
φct
prior
distribution
conﬁgured
using
stick
breaking
process
sbp
denoted
gem
multinomial
distribution
mult
dirichlet
distribution
dir
inverse–wishart
distribution
multivariate
gaussian
normal
distribution
motion
model
sensor
model
self-localization
denoted
xt−1
equations
respectively
1latticelm
name
tool
implemented
treated
name
method
study
http
//www.phontron.com/latticelm/
element
graphical
model
table
self-position
robot
control
data
sensor
data
index
spatial
concepts
segmented
word
uttered
sentence
multinomial
distribution
word
probability
names
places
gaussian
distribution
position
distribution
mean
vector
covariance
matrix
index
position
distribution
multinomial
distribution
index
gaussian
distribution
multinomial
distribution
index
spatial
concepts
hyperparameter
multinomial
distributions
hyperparameter
multinomial
distribution
hyperparameter
dirichlet
prior
distribution
hyperparameters
gaussian–inverse–wishart
prior
distribution
includes
word
dictionary
japanese
syllables
speech
recognition
results
obtained
lattice
format
word
segmentation
performed
using
lattices
speech
recognition
results
robot
learns
spatial
concepts
words
obtained
word
segmentation
robot
positions
obtained
self-localization
teaching
times
details
learning
given
iii-c.
procedure
self-localization
utilizing
spatial
concepts
follows
words
learned
spatial
concepts
registered
word
dictionary
speech
recognition
system
robot
obtains
speech
signal
speech
recognition
performed
word
sequence
1-best
speech
recognition
result
obtained
robot
modiﬁes
self-localization
words
obtained
speech
recognition
position
like-
lihood
obtained
spatial
concepts
details
self-
localization
provided
iii-d.
proposed
method
learn
words
related
places
utterances
sentences
use
unsupervised
word
segmentation
method
latticelm
directly
segment
words
lattices
speech
recognition
results
uttered
sentences
lattice
represent
compact
set
promising
hypotheses
speech
recognition
result
n-best
directed
graph
format
unsupervised
word
segmentation
using
lattices
syllable
recognition
expected
able
reduce
variability
errors
phonemes
compared
npylm
i.e.
word
segmentation
using
1-best
speech
recognition
results
self-localization
method
adopts
mcl
method
generally
used
localization
mobile
robots
simultaneous
localization
mapping
slam
fig
graphical
model
proposed
method
spcoa
model
learn
appropriate
number
spatial
concepts
depending
data
using
nonparametric
bayesian
approach
use
sbp
one
methods
based
dirichlet
process
particular
model
consider
theoretically
inﬁnite
number
spatial
concepts
position
distributions
sbp
computations
difﬁcult
generate
inﬁnite
number
parameters
study
approximate
number
parameters
setting
sufﬁciently
large
values
i.e.
weak-
limit
approximation
possible
correlate
name
multiple
places
e.g.
staircase
two
different
places
place
multiple
names
e.g.
toilet
restroom
refer
place
spatial
concepts
represented
word
distribution
names
place
several
position
distributions
indicated
multinomial
distribution
words
model
capable
relating
mixture
gaussian
distributions
multinomial
distribution
names
places
noted
arrows
connecting
surrounding
nodes
proposed
graphical
model
differ
ordinal
gaussian
mixture
model
gmm
assume
words
obtained
robot
change
position
position
robot
affects
distribution
words
therefore
proposed
generative
process
assumes
index
position
distribution
i.e.
category
place
generated
position
robot
change
naturally
introduced
without
troubles
introducing
equation
overview
proposed
method
spcoa
assume
robot
performs
self-localization
using
control
data
sensor
data
times
procedure
learning
spatial
concepts
follows
utterer
teaches
robot
names
places
shown
fig
every
time
robot
arrives
place
designated
learning
target
utterer
says
sentence
including
name
current
place
robot
performs
speech
recognition
uttered
speech
signal
data
thus
speech
recognition
system
1−txxttztutcbto
wσµtiγlφαkllܤ௧0β00
κm00
νv1−tz1−tu1+tz1+tuπ1+tx
assume
robot
generates
environment
map
using
mcl-based
slam
fastslam
advance
performs
localization
using
generated
map
environment
map
occupancy
grid
map
landmark
map
acceptable
learning
spatial
concept
spatial
concepts
learned
multiple
teaching
data
control
data
sensor
data
teaching
data
set
uttered
sentences
teaching
times
segmented
words
uttered
sentence
converted
bag-of-words
bow
representation
vector
occurrence
counts
words
set
teaching
times
denoted
number
teaching
data
items
denoted
model
parameters
denoted
initial
values
model
parameters
set
arbitrarily
accordance
con-
dition
sampling
values
model
parameters
following
joint
posterior
distribution
obtained
performing
gibbs
sampling
ito
cto
oto
hyperparameters
model
denoted
algorithm
learning
spatial
concepts
shown
algorithm
conditional
posterior
distribution
element
used
performing
gibbs
sampling
expressed
follows
index
position
distribution
sampled
data
posterior
distribution
follows
µk=it
σk=it
mult
φl=ct
index
spatial
concepts
sampled
data
item
posterior
distribution
follows
mult
wl=ct
mult
φl=ct
mult
denotes
vector
occurrence
counts
words
sentence
time
posterior
distribution
representing
word
probabilities
name
place
calculated
follows
cto
oto
cid:20
cid:89
cid:21
wl=ct
cid:89
l∈l
l=ct
t∈to
variables
subscript
denote
set
teaching
times
word
probability
name
place
sampled
follows
mult
dir
dir
βnl
βnl
represents
posterior
parameter
denotes
bow
representation
sentences
posterior
distribution
representing
position
distribution
calculated
follows
ito
xto
cto
µk=it
σk=it
cid:21
cid:89
k∈k
cid:20
cid:89
k=it
t∈to
position
distribution
sampled
follows
niw
mnk
κnk
vnk
νnk
niw
niw
denotes
gaussian–inverse–wishart
distri-
bution
mnk
κnk
vnk
νnk
represent
posterior
param-
eters
indicates
set
teaching
positions
topic
probability
distribution
spatial
concepts
sampled
follows
mult
cto
dir
dir
cto
posterior
distribution
representing
mixed
weights
position
distributions
calculated
follows
cid:21
xto
ito
cto
φl=ct
cid:89
cid:20
cid:89
l∈l
l=ct
t∈to
mixed
weight
position
distributions
sampled
follows
mult
dir
dir
denotes
vector
counting
indices
gaussian
distribution
self-positions
sampled
using
monte
carlo
ﬁxed-lag
smoother
learning
phase
smoother
estimate
self-position
i.e.
sequential
estimation
given
data
time
estimate
i.e.
estimation
given
data
time
later
general
smoothing
method
provide
accurate
estimation
mcl
online
estimation
contrast
self-position
robot
sampled
like
direct
assignment
sampling
time
sampling
divided
case
teaching
time
another
time
follows
xt−1
xt+1
ut+1
xt+1
ut+1
xt−1
xt−1
xt+1
ut+1
xt+1
ut+1
xt−1

end
localization
speech
recognition
monte
carlo
smoother
t−1
speech
signal
observed
latticet
speech
recognition
speech
signal
add
latticet
registering
lattice
add
registering
teaching
time
algorithm
learning
spatial
concepts
end
oto
latticelm
initialize
parameters
ito
cto
iteration
number
ito
ito
xto
cto
cto
cto
xto
ito
oto
cto
oto
ito
xto
cto
cto
xto
ito
cto
word
segmentation
using
lattices
gibbs
sampling
xt−1
xt+1
ut+1
xt−1
xt+1
ut+1

end
end
return
self-localization
learning
spatial
concepts
robot
acquires
spatial
concepts
leverage
spatial
concepts
self-localization
estimated
model
parameters
speech
recognition
sentence
time
given
condition
part
probability
formula
mcl
follows
xt−1
t−1
t−1
t−1
t−1
robot
hears
name
place
spoken
utterer
addition
likelihood
sensor
model
mcl
likelihood
respect
speech
recognition
sentence
calculated
follows
cid:88
cid:104
cid:105
xt|µit
σit
it|φct
cid:20
cid:88
b|wct
ct|π
cid:21
algorithm
self-localization
utilizing
spatial
concepts
shown
algorithm
set
particles
denoted
temporary
set
stores
pairs
particle
cid:105
denoted
¯xt
num-
weight
ber
particles
function
sample
motion
model
i.e.
cid:104
¯xt
sample
motion
model
t−1
sensor
model
speech
signal
observed
algorithm
self-localization
utilizing
spatial
concepts
procedure
localization
xt−1
end
return
end
procedure
draw
probability
add
cid:105
¯xt
end
add
cid:104
end
function
moves
particle
previous
state
xt−1
current
state
using
control
data
function
sensor
model
calculates
likelihood
particle
using
sensor
data
functions
normally
used
mcl
details
please
refer
case
speech
recognition
sentence
obtained
speech
recognition
system
using
word
dictionary
containing
learned
words
experiment
experiment
validate
evidence
proposed
method
spcoa
environment
simulated
simulator
platform
sigverse2
enables
simulation
social
interactions
speech
recognition
performed
using
japanese
continuous
speech
recognition
system
julius3
set
japanese
phonemes
deﬁned
acoustical
society
japan
asj
speech
database
com-
mittee
adopted
julius
representation
phonemes
also
adopted
study
julius
system
uses
word
dictionary
containing
115
japanese
syllables
microphone
attached
robot
shure
pg27-usb
unsupervised
morphological
analyzer
latticelm
0.4
implemented
experiment
compare
following
three
types
word
segmentation
methods
set
syllable
sequences
given
graphical
model
spcoa
method
set
used
learning
spatial
concepts
recognized
uttered
sentences
oto
latticelm
proposed
method
syllable
recognition
results
lattice
format
segmented
using
latticelm
1-best
npylm
syllable
recognition
results
1-best
method
segmented
using
latticelm
case
latticelm
almost
equivalent
npylm
2sigserver-2.2.2
sigviewer-2.2.0
http
//www.sigverse.com/wiki/
3julius
dictation-kit-v4.3.1-linux
gmm-hmm
decoding
http
//julius
sourceforge.jp/
fig
environment
used
learning
localization
sigverse
pseudo-room
simulated
real
world
robot
center
room
size
room
500
1,000
size
robot
fig
learning
result
position
distribution
point
group
color
represent
position
distribution
drawn
map
considered
environment
colors
point
groups
determined
randomly
balloon
shows
index
number
position
distribution
table
various
phrases
japanese
sentence
used
placeholder
name
place
examples
phrases
here.
place
**.
place
name
**.
came
**.
english
desu
koko
kochira
desu
kochira
nari
masu
kono
basho
koko
desu
mashi
kono
basho
namae
koko
namae
bag-of-syllables
bos
syllable
recognition
results
1-best
method
segmented
syllable
words
method
used
segmenting
words
ele-
ments
recognized
syllable
sequences
directly
bos
bag-of-letters
representation
remainder
section
organized
follows
section
iv-a
conditions
results
learning
spatial
concepts
described
experiments
performed
using
learned
spatial
concepts
described
section
iv-b
iv-e.
section
iv-b
evaluate
accuracy
phoneme
recognition
word
segmentation
uttered
sentences
section
iv-c
evaluate
clustering
accuracy
estimation
results
index
spatial
concepts
teaching
utterance
section
iv-d
evaluate
accuracy
acquisition
names
places
section
iv-e
show
spatial
concepts
utilized
effective
self-
localization
learning
spatial
concepts
conditions
conduct
experiment
spatial
con-
cept
acquisition
environment
prepared
sigverse
experimental
environment
shown
fig
mobile
robot
move
performing
forward
backward
right
rotation
left
rotation
movements
two-dimensional
plane
experiment
robot
use
approximately
correct
map
considered
environment
robot
range
fig
learning
result
multinomial
distributions
names
places
top
multinomial
distributions
index
position
distribution
bottom
words
obtained
experiment
shown
/genkan//gomibako//kiqchin//daidokoro//terebimae//teeburunoatari//teeburunoatari//hondana//sofaamae/k=0k=7k=17k=1k=2k=6k=4k=3
sensor
front
performs
self-localization
basis
occupancy
grid
map
initial
particles
deﬁned
true
initial
position
robot
number
particles
1000.
lag
value
monte
carlo
ﬁxed-lag
smoothing
ﬁxed
100.
parameters
experiment
follows
1.5
0.5
0.001
diag
1000
1000
number
iterations
used
gibbs
sampling
100.
experiment
include
direct
assign-
ment
sampling
equation
i.e.
lines
22–24
algorithm
omitted
consider
self-
position
obtained
sufﬁciently
good
accuracy
using
monte
carlo
smoothing
eight
places
selected
learning
targets
eight
types
place
names
considered
uttered
place
name
shown
fig
utterances
include
name
different
places
i.e.
teeburunoatari
means
near
table
english
different
names
place
i.e.
kiqchin
daidokoro
mean
kitchen
english
teaching
names
genkan
means
entrance
doorway
english
terebimae
means
front
english
gomibako
means
trash
box
english
hondana
means
bookshelf
english
sofaamae
means
front
sofa
english
teaching
utterances
including
types
phrases
spoken
total
times
phrases
uttered
sentence
listed
table
results
learning
results
spatial
concepts
obtained
using
proposed
method
presented
fig
shows
position
distributions
learned
experimental
environment
fig
top
shows
word
distributions
names
places
spatial
concept
fig
bottom
shows
multinomial
distributions
indices
position
distributions
consequently
proposed
method
learn
names
places
corresponding
place
learning
target
spatial
concept
index
highest
probability
words
sofamae
highest
probability
indices
position
distribution
therefore
name
place
sofamae
learned
correspond
position
distribution
spatial
concept
index
kiqchi
daidokoro
learned
correspond
position
distribution
therefore
result
shows
multiple
names
learned
place
spatial
concept
index
durunoatari
one
word
normal
situation
learned
correspond
position
distributions
therefore
result
shows
name
learned
multiple
places
phoneme
recognition
accuracy
uttered
sentences
conditions
compared
performance
three
types
word
segmentation
methods
considered
uttered
sentences
difﬁcult
weigh
ambiguous
syllable
recognition
unsupervised
word
segmentation
separately
therefore
experiment
considered
positions
delimiter
single
letter
calculated
matching
comparison
phoneme
accuracy
rates
uttered
sentences
different
word
segmentation
methods
table
iii
latticelem
used
spcoa
par
0.82
1-best
npylm
bos
0.67
0.71
rate
phoneme
string
recognition
result
uttered
sentence
correct
phoneme
string
teaching
data
suitably
segmented
japanese
morphemes
using
mecab4
off-the-shelf
japanese
morphological
analyzer
widely
used
natural
language
processing
matching
rate
phoneme
string
calculated
using
phoneme
accuracy
rate
par
follows
par
numerator
equation
calculated
using
levenshtein
distance
correct
phoneme
string
recognition
phoneme
string
denotes
number
substitutions
number
deletions
number
insertions
represents
number
phonemes
correct
phoneme
string
results
table
iii
shows
results
par
table
presents
examples
word
segmentation
results
three
considered
methods
found
unsupervised
morphological
analyzer
capable
using
lattices
improved
accuracy
phoneme
recognition
word
segmentation
consequently
result
suggests
word
segmentation
method
considers
multiple
hypothesis
speech
recogni-
tion
whole
reduces
uncertainty
variability
recognition
using
syllable
recognition
results
lattice
format
estimation
accuracy
spatial
concepts
conditions
compared
matching
rate
estimation
results
index
spatial
concepts
teaching
utterance
classiﬁcation
results
correct
answer
given
humans
evaluation
experiment
used
adjusted
rand
index
ari
ari
measure
degree
similarity
two
clustering
results
compared
proposed
method
method
word
clustering
without
location
information
in-
vestigation
effect
lexical
acquisition
using
location
information
particular
method
word
clustering
with-
location
information
used
dirichlet
process
mixture
dpm
unigram
model
sbp
representation
parameters
corresponding
proposed
method
parameters
proposed
method
estimated
using
gibbs
sampling
results
fig
shows
results
average
ari
values
trials
learning
gibbs
sampling
found
proposed
method
showed
best
score
results
results
reported
section
iv-b
suggest
learning
uttered
sentences
obtained
better
phoneme
4mecab
http
//mecab.googlecode.com/svn/trunk/mecab/doc/index.html
examples
word
segmentation
results
uttered
sentences
denotes
word
segment
point
table
correct
word
sequence
latticelm
1-best
npylm
bos
genkan|wa|kochira|desu
genkan|wakochiradesu
ki|nika|n|wa|kochira|de|su
ki|ni|ka|n|wa|ko|chi|ra|de|su
gomibako|ni|ki|mashi|ta
komibako|o|ni|kimashita
go|mibako|niki|na|shita
go|mi|ba|ko|ni|ki|na|shi|ta
kono|basho|no|namae|wa|hondana
konobashuno|namae|wa|fondana
kono|bo|shu|no|namae|wa|fo|n|da|na
ko|no|bo|shu|no|na|ma|e|wa|fo|n|da|na
fig
comparison
accuracy
rates
estimation
results
spatial
concepts
fig
par
scores
word
considered
name
place
recognition
better
word
segmentation
produces
good
result
acquisition
spatial
concepts
furthermore
comparison
two
clustering
methods
found
spcoa
considerably
better
dpm
word
clustering
method
without
location
information
irrespective
word
segmentation
method
used
experimental
results
showed
possible
improve
estimation
accuracy
spatial
concepts
vocabulary
performing
word
clustering
considered
location
information
accuracy
acquired
phoneme
sequences
representing
names
places
conditions
evaluated
whether
names
places
properly
learned
considered
teaching
places
experiment
assumes
request
best
phoneme
sequence
best
representing
self-position
robot
robot
moves
close
teaching
place
probability
word
best
self-position
robot
given
best
obtained
using
equation
word
best
probability
selected
compared
par
correct
phoneme
sequence
selected
name
place
kiqchin
daidokoro
taught
place
word
whose
par
higher
score
adopted
results
fig
shows
results
par
word
considered
name
place
spcoa
latticelm
pro-
posed
method
using
results
unsupervised
word
seg-
mentation
basis
speech
recognition
results
lattice
format
showed
best
par
score
1-best
bos
methods
part
syllable
sequence
name
place
minutely
segmented
shown
table
therefore
robot
could
learn
name
teaching
place
coherent
phoneme
sequence
contrast
robot
could
learn
names
teaching
places
accurately
using
proposed
method
self-localization
utilizes
acquired
spatial
concepts
conditions
experiment
validate
robot
make
efﬁcient
use
acquired
spatial
concepts
compare
estimation
accuracy
localization
proposed
method
spcoa
mcl
conventional
mcl
robot
comes
learning
target
utterer
speaks
sentence
containing
name
place
robot
moving
trajectory
robot
uttered
positions
trials
particular
uttered
sentence
kokowa
dayo
learning
task
phrase
used
number
particles
1000
initial
particles
uniformly
distributed
considered
environment
robot
performs
control
operation
time
step
estimation
error
localization
evaluated
follows
running
localization
record
estimation
error
equation
plane
ﬂoor
time
step
¯yt
represent
i=1
i=1
obtained
simulator
¯xt
cid:80
¯yt
cid:80
denote
true
position
coordinates
robot
weighted
mean
values
localization
coordinates
normalized
weight
obtained
sensor
model
mcl
likelihood
utterance
time
likelihood
multiplied
value
calculated
using
equation
denote
coordinate
y-coordinate
index
particle
time
running
localization
calculated
average
compared
estimation
accuracy
rate
ear
global
localization
trial
calculated
proportion
time
step
estimation
error
less
cid:112
¯xt
spcoaspcoa
1-best
npylm
spcoa
bos
dpm
latticelm
dpm
1-best
npylm
dpm
bos
0.00.20.40.60.81.0arispcoaspcoa
1-best
npylm
spcoa
bos
0.00.20.40.60.81.0par
fig
results
estimation
errors
ears
self-localization
fig
10.
teaching
places
names
places
shown
generated
map
teaching
places
included
places
two
names
multiple
places
names
fig
autonomous
mobile
robot
turtlebot
robot
based
yujin
robot
kobuki
microsoft
kinect
use
range
sensor
results
fig
shows
results
estimation
error
ear
trials
method
trials
spcoa
mcl
latticelm
almost
trials
method
using
1-best
npylm
bos
showed
relatively
small
estimation
errors
results
second
trial
1-best
npylm
ﬁfth
trial
bos
showed
higher
estimation
errors
trials
many
particles
converged
places
instead
place
robot
based
utterance
information
nevertheless
compared
conventional
mcl
results
obtained
using
spatial
concepts
showed
obvious
improvement
estimation
accuracy
consequently
spatial
concepts
acquired
using
proposed
method
proved
helpful
improving
localization
accuracy
experiment
experiment
effectiveness
proposed
method
tested
using
autonomous
mobile
robot
turtlebot
real
environment
fig
shows
turtlebot
used
experiments
mapping
self-localization
performed
robot
operating
system
ros
speech
recognition
system
microphone
unsupervised
morphological
analyzer
described
section
learning
spatial
concepts
real
environment
conditions
conducted
experiment
spatial
concept
acquisition
real
environment
entire
ﬂoor
building
experiment
self-localization
performed
using
map
generated
slam
initial
particles
deﬁned
true
initial
position
robot
generated
map
real
environment
names
teaching
places
shown
fig
10.
number
teaching
places
5turtlebot
http
//turtlebot.com/
number
teaching
names
16.
teaching
utterances
performed
total
100
times
results
fig
shows
position
distributions
learned
map
table
shows
ﬁve
best
elements
multinomial
distributions
name
place
wct
multinomial
distributions
indices
position
distribution
φct
index
spatial
concept
ct.
thus
found
proposed
method
learn
names
places
corresponding
considered
teaching
places
real
environment
example
spatial
concept
index
torire
learned
correspond
position
distribution
42.
similarly
kidanoken
corresponded
kaigihitsu
corresponded
32.
spatial
concept
index
part
syllable
sequences
minutely
segmented
sohatsuke
tani
guchi
case
robot
taught
two
types
names
words
learned
correspond
position
distribution
55.
gomibako
showed
high
probability
corresponded
three
distributions
position
59.
position
distribution
fourth
highest
probability
spatial
concept
therefore
raqkuken
ﬁfth
highest
probability
spatial
concept
expected
relate
spatial
concept
estimated
word
drawn
spatial
concept
however
practice
situation
cause
severe
problems
spatial
concept
index
highest
probabilities
word
rapuken
position
distribution
probabilistic
model
relative
probability
integrative
information
important
robot
listened
utterance
related
raqkuken
could
make
use
spatial
concept
index
self-
localization
high
probability
appropriately
updated
estimated
self-location
expected
spatial
concept
index
learned
two
separate
spatial
concepts
however
watarirooka
kaidanmae
learned
spatial
concept
therefore
multinomial
distri-
bution
showed
higher
probability
indices
position
distribution
corresponding
teaching
places
watarirooka
kaidanmae
proposed
method
adopts
nonparametric
bayesian
method
possible
form
spatial
concepts
allow
many-to-many
correspondences
names
spcoa
mclspcoa
mcl
1-best
npylm
spcoa
mcl
bos
mclmean57.20100.92125.87223.38s.e.9.8940.2345.4988.86ear0.810.700.650.5602004006008001000estimation
error
/kyouinbeya//toire//tsuboken//kitanoken//nishikawaken//raqkuken//kameikuupaaken//gomibako//purintaabeya//watarirouka//kaigishitsu//shinodaseyaken//hagiwaraken//gomibako//gomibako//watarirouka//kaidanmae//kaidanmae//souhatsuken//taniguchiken/
fig
11.
learning
result
position
distribution
point
group
color
denoting
position
distribution
drawn
map
colors
point
groups
determined
randomly
index
number
denoted
learning
result
high-probability
words
indices
position
distribution
spatial
concept
table
index
word
wct
wct
probability
index
φct
probability
watarirooka
kaidanmae
desu
nikimashita
ewa
noken
shinozaseya
tsu
nayo
ken
desu
koko
desu
koko
gomibako
rapuken
torire
kokoga
nikimashita
sohatsuke
byayo
tani
guchi
desu
desu
dayo
kidanoken
konobashoga
probability
0.165
0.151
0.117
0.069
0.068
0.189
0.185
0.046
0.045
0.045
0.178
0.174
0.075
0.042
0.041
0.195
0.180
0.102
0.081
0.043
0.154
0.118
0.080
0.045
0.043
0.098
0.098
0.098
0.096
0.078
0.209
0.091
0.090
0.050
0.050
index
φct
probability
index
0.175
0.174
0.142
0.141
0.039
0.342
0.008
0.008
0.008
0.008
0.339
0.008
0.008
0.008
0.008
0.174
0.136
0.136
0.135
0.006
0.340
0.008
0.008
0.008
0.008
0.507
0.006
0.006
0.006
0.006
0.336
0.009
0.008
0.008
0.008
word
kaigihitsu
nikimashita
gomirako
dayo
ewa
kameikukache
konobashunonama
ninarimasu
raken
hagiwa
desu
wakochira
ewa
burin
bea
ewa
dayo
waken
nishikya
desu
nishi
rapuken
nikimashita
nayo
noken
waken
bea
kyoi
dayo
desu
0.181
0.113
0.079
0.078
0.076
0.113
0.112
0.109
0.108
0.043
0.159
0.157
0.080
0.046
0.045
0.132
0.130
0.107
0.083
0.078
0.133
0.132
0.103
0.071
0.040
0.145
0.081
0.080
0.017
0.016
0.153
0.151
0.149
0.064
0.062
0.301
0.065
0.064
0.007
0.007
0.197
0.075
0.075
0.009
0.008
0.296
0.009
0.008
0.008
0.008
0.321
0.067
0.008
0.008
0.008
0.332
0.008
0.008
0.008
0.008
0.173
0.011
0.010
0.010
0.010
0.343
0.008
0.008
0.008
0.008
places
contrast
create
ambiguity
classiﬁes
originally
different
spatial
concepts
one
spatial
concept
side
effect
possibility
ambiguity
concepts
negative
effect
self-
localization
even
though
self-localization
performance
overall
clearly
increased
employing
proposed
method
solution
problem
considered
future
work
terms
par
uttered
sentences
evaluation
value
evaluation
method
used
section
iv-b
0.83
value
comparable
result
section
iv-b
however
terms
par
name
place
evaluation
value
evaluation
method
used
section
iv-d
0.35
lower
section
iv-d.
consider
increase
uncertainty
real
environment
increase
number
teaching
words
reduced
performance
expect
problem
could
improved
using
experience
related
places
e.g.
number
utterances
per
place
increased
additional
sensory
information
provided
k=0k=1k=7k=8k=10k=11k=12k=13k=14k=23k=29k=35k=36k=42k=50k=55k=58k=60k=69k=59
modiﬁcation
localization
acquired
spatial
con-
cepts
conditions
experiment
veriﬁed
modi-
ﬁcation
results
self-localization
using
spatial
concepts
global
self-localization
experiment
used
learning
results
spatial
concepts
presented
section
v-a
experimental
procedures
shown
initial
particles
uniformly
distributed
entire
ﬂoor
robot
begins
move
little
distance
away
target
place
robot
reached
target
place
utterer
spoke
sentence
containing
name
place
robot
upon
obtaining
speech
information
robot
modiﬁes
self-
localization
basis
acquired
spatial
concepts
number
particles
mentioned
section
v-a
results
fig
shows
results
self-localization
top
part
ﬁgure
bottom
part
ﬁgure
utterance
three
places
particle
states
denoted
red
arrows
moving
trajectory
robot
indicated
green
dotted
arrow
figs
show
results
names
places
toire
souhat-
suken
gomibako
three
spatial
concepts
i.e.
learned
gomibako
experiment
utterer
uttered
robot
robot
came
close
place
36.
examples
shown
top
part
ﬁgure
particles
dispersed
several
places
contrast
number
particles
near
true
position
robot
showed
almost
accurate
increase
examples
shown
bottom
part
ﬁgure
thus
conclude
proposed
method
modify
self-localization
using
spatial
concepts
conclusion
future
work
paper
discussed
spatial
concept
acquisition
lexical
acquisition
related
places
self-localization
us-
ing
acquired
spatial
concepts
proposed
nonparametric
bayesian
spatial
concept
acquisition
method
spcoa
in-
tegrates
latticelm
spatial
clustering
method
mcl
conducted
experiments
evaluating
performance
spcoa
simulation
real
environment
spcoa
showed
good
results
experiments
experiments
learning
spatial
concepts
robot
could
form
spatial
concepts
places
learning
targets
human
continuous
speech
signals
room
simulation
environment
entire
ﬂoor
real
environment
unsupervised
word
segmentation
method
latticelm
could
reduce
variability
errors
recognition
phonemes
utterances
spcoa
achieved
accurate
lexical
acquisition
performing
word
segmentation
using
lattices
speech
recognition
results
self-
localization
experiments
robot
could
effectively
utilize
acquired
spatial
concepts
recognizing
self-position
reducing
estimation
errors
self-localization
method
improves
performance
lexical
acquisition
mutual
learning
method
proposed
nakamura
basis
integration
learning
object
concepts
language
model
following
similar
approach
heymann
proposed
method
alternately
repeatedly
updates
phoneme
recognition
results
language
model
using
unsupervised
word
segmenta-
tion
result
achieved
robust
lexical
acquisition
study
expect
improve
accuracy
lexical
acquisition
spatial
concepts
estimating
spatial
concepts
language
model
furthermore
future
work
consider
necessary
robots
learn
spatial
concepts
online
recognize
whether
uttered
word
indicates
current
place
desti-
nation
furthermore
developing
method
simultaneously
acquires
spatial
concepts
builds
map
one
future
objectives
believe
spatial
concepts
positive
effect
mapping
also
intend
examine
method
associates
image
landscape
spatial
concepts
method
estimates
spatial
concepts
object
concepts
references
roy
pentland
learning
words
sights
sounds
computational
model
cognitive
science
vol
113–146
2002
taguchi
iwahashi
nose
funakoshi
nakano
learning
lexicons
spoken
utterances
based
statistical
model
selection
annual
conference
international
speech
communi-
cation
association
interspeech
2009
2731–2734
iwahashi
language
acquisition
human–robot
interface
combining
speech
visual
behavioral
information
information
sciences
vol
156
109–121
2003
robots
learn
language
developmental
approach
situated
intech
human-robot
conversations
human
robot
interaction
2007
95–118
iwahashi
taguchi
sugiura
funakoshi
nakano
robots
learn
converse
developmental
approach
situated
language
processing
proceedings
international
symposium
speech
language
processing
2009
532–537
gorniak
roy
probabilistic
grounding
situated
speech
using
plan
recognition
reference
resolution
proceedings
7th
international
conference
multimodal
interfaces
acm
2005
138–143
chai
incorporating
temporal
semantic
information
eye
gaze
automatic
word
acquisition
multimodal
conversa-
tional
systems
proceedings
conference
empirical
methods
natural
language
processing
2008
244–253
context-based
word
acquisition
situated
dialogue
virtual
world
journal
artiﬁcial
intelligence
research
vol
247–278
2010
h¨ornstein
gustavsson
santos-victor
lacerda
multi-
modal
language
acquisition
based
motor
learning
interaction
motor
learning
interaction
learning
robots
springer
2010
467–489
nakamura
araki
nagai
iwahashi
grounding
word
meanings
latent
dirichlet
allocation-based
multimodal
concepts
advanced
robotics
vol
2189–2206
2011
araki
nakamura
nagai
nagasaka
taniguchi
iwahashi
online
learning
concepts
words
using
multimodal
lda
hierarchical
pitman-yor
language
model
ieee/rsj
international
conference
intelligent
robots
systems
iros
ieee
2012
1623–1630
brown
pietra
pietra
mercer
mathematics
statistical
machine
translation
parameter
estimation
computational
linguistics
vol
263–311
1993
nakamura
nagai
iwahashi
multimodal
categorization
hierarchical
dirichlet
process
ieee/rsj
international
conference
intelligent
robots
systems
iros
ieee
2011
1520–1525
mochihashi
yamada
ueda
bayesian
unsupervised
word
segmentation
nested
pitman-yor
language
modeling
proceedings
joint
conference
47th
annual
meeting
acl
4th
international
joint
conference
natural
language
processing
afnlp
acl-ijcnlp
2009
100–108
name
place
toire.
name
place
souhatsuken.
name
place
gomibako.
fig
12.
states
particles
teaching
utterance
top
teaching
utterance
bottom
uttered
sentence
kokowa
dayo
means
**.
name
place
inamura
shibata
sena
hashimoto
kawai
miyashita
sakurai
shimizu
otake
hosoda
al.
simulator
platform
enables
social
interaction
simulation
–sigverse
socioin-
telligenesis
simulator–
ieee/sice
international
symposium
system
integration
2010
212–217
kawahara
kobayashi
takeda
minematsu
itou
ya-
mamoto
yamada
utsuro
shikano
sharable
software
repository
japanese
large
vocabulary
continuous
speech
recognition
fifth
international
conference
spoken
language
processing
1998
lee
kawahara
shikano
julius—an
open
source
real-
time
large
vocabulary
recognition
engine
european
conference
speech
communication
technology
eurospeech
2001
hubert
arabie
comparing
partitions
journal
classiﬁca-
tion
vol
193–218
1985
nakamura
araki
nagai
nagasaka
taniguchi
iwa-
hashi
multimodal
concept
word
learning
using
phoneme
sequences
errors
ieee/rsj
international
conference
intelligent
robots
systems
iros
2013
157–162
nakamura
nagai
funakoshi
nagasaka
taniguchi
iwahashi
mutual
learning
object
concept
language
model
based
mlda
npylm
ieee/rsj
international
conference
intelligent
robots
systems
iros
2014
600–607
heymann
walter
haeb-umbach
raj
iterative
bayesian
word
segmentation
unsupervised
vocabulary
discovery
phoneme
lattices
39th
international
conference
acoustics
speech
signal
processing
icassp
2014
taguchi
iwahashi
funakoshi
nakano
nose
nitta
learning
physically
grounded
lexicons
spoken
utter-
ances
human
machine
interaction–getting
closer
69–84
2012
taguchi
yamada
hattori
umezaki
hoguro
iwa-
hashi
funakoshi
nakano
learning
place-names
spoken
utterances
localization
results
mobile
robot
annual
conference
international
speech
communication
association
interspeech
2011
1325–1328
milford
wyeth
prasser
ratslam
hippocampal
model
simultaneous
localization
mapping
ieee
international
conference
robotics
automation
icra
2004
403–408
milford
schulz
prasser
wyeth
wiles
learning
spatial
concepts
ratslam
representations
robotics
au-
tonomous
systems
vol
403–410
2007
schulz
wyeth
wiles
lingodroids
socially
grounding
place
names
privately
grounded
cognitive
maps
adaptive
behavior
vol
409–424
2011
heath
ball
schulz
wiles
communication
lingodroids
different
cognitive
capabilities
ieee
international
conference
robotics
automation
icra
ieee
2013
490–
495
schulz
wyeth
wiles
yet
grounding
tem-
poral
concepts
shared
journeys
ieee
transactions
autonomous
mental
development
vol
163–175
2011
welke
kaiser
kozlov
adermann
asfour
lewis
steedman
grounded
spatial
symbols
task
planning
based
experience
13th
international
conference
humanoid
robots
humanoids
ieee/ras
2013
neubig
mimura
kawahara
bayesian
learning
language
model
continuous
speech
ieice
transactions
information
systems
vol
614–625
2012
dellaert
fox
burgard
thrun
monte
carlo
localization
mobile
robots
ieee
international
conference
robotics
automation
icra
vol
ieee
1999
1322–1328
sethuraman
constructive
deﬁnition
dirichlet
priors
statistica
sinica
vol
639–650
1994
fox
sudderth
jordan
willsky
sticky
hdp-hmm
application
speaker
diarization
annals
applied
statistics
1020–1056
2011
thrun
burgard
fox
probabilistic
robotics
mit
press
2005
montemerlo
thrun
koller
wegbreit
fastslam
factored
solution
simultaneous
localization
mapping
prob-
lem
proceedings
aaai
national
conference
artiﬁcial
intelligence
american
association
artiﬁcial
intelligence
2002
593–598
hahnel
burgard
fox
thrun
efﬁcient
fastslam
algorithm
generating
maps
large-scale
cyclic
environments
raw
laser
range
measurements
ieee/rsj
international
conference
intelligent
robots
systems
iros
2003
206–211
kitagawa
computational
aspects
sequential
monte
carlo
ﬁlter
smoother
annals
institute
statistical
mathematics
vol
443–471
2014.
beforeafterbeforeafterbeforeafter
