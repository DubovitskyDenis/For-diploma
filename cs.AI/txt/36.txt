федеральное
государственное
автономное
образовательное
учреждение
высшего
профессионального
образования
сибирский
федеральный
университет
институт
математики
фундаментальной
информатики
базовая
кафедра
математического
моделирования
процессов
управления
бакалаврская
работа
направление
010101.62
математика
порождающее
вероятностное
программирование
выпускник
юрий
перов1
научный
руководитель
сфу
татьяна
валерьевна
крупкина
кембридж-оксфорд-красноярск
2012–2014
адрес
корреспонденции
yuraperov
gmail.com
_________
реферат
выпускная
квалификационная
бакалаврская
работа
теме
cid:190
порождающее
веро-
ятностное
программирование¿
содержит
страниц
текста
использованных
источни-
ков
рисунков
ключевые
слова
вероятностное
программирование
машинное
обучение
искусственный
интеллект
вероятностные
модели
ав-
томатическое
моделирование
работа
посвящена
новому
направлению
области
машинного
обучения
компью-
терных
наук
cid:22
вероятностному
программированию
работе
дается
краткое
рефератив-
ное
введение
языки
вероятностного
программирования
church/venture/anglican
так-
описываются
результаты
первых
экспериментов
автоматической
генерации
вероят-
ностных
программ
содержание
введение
краткое
введение
языки
вероятностного
программирования
church
venture
anglican
1.1
первое
знакомство
church
venture
anglican
1.2
статистический
вывод
вероятностных
языках
программирования
помо-
щью
алгоритма
метрополиса-гастингса
1.2.1
метод
cid:190
выборки
отклонением¿
1.2.2
пространство
историй
выполнений
вероятностных
программ
1.2.3
апостериорное
распределение
историй
выполнений
программ
1.2.4
использование
методов
монте-карло
схеме
марковских
цепей
1.2.5
программная
реализация
статистического
вывода
1.3
эффективность
вывода
1.4
порождающее
вероятностное
программирование
распознавании
образов
1.5
различиях
church
venture
anglican
автоматическая
генерация
вероятностных
программ
2.1
обзор
литературы
2.2
описание
подхода
2.3
грамматика
порождающие
правила
2.4
вероятности
использования
порождающих
правил
2.5
эксперименты
2.5.1
выборки
сгенерированных
вероятностных
программ
2.5.2
вывод
вероятностных
программ
определяющих
распределения
сов-
падающие
приближающие
классические
одномерные
распреде-
ления
2.5.3
обобщение
произвольных
эмпирических
данных
помощью
порож-
дающего
вероятностного
программирования
2.5.4
cid:190
компиляция¿
вероятностных
программ
2.6
обобщение
порождающего
вероятностного
программирования
заключение
список
использованных
источников
моей
любимой
маше
всем
другим
моим
любимым
родным
введение
данная
бакалаврская
работа
посвящена
вероятностному
программированию
но-
вому
направлению
областях
машинного
обучения
искусственного
интеллекта
ком-
пьютерных
наук
именно
реферативному
краткому
введению
вероятностное
програм-
мирование
описанию
языков
вероятностного
программирования
church
venture
anglican
описанию
подхода
порождающего
вероятностного
программирования
решения
задач
распознавания
образов
также
представлению
полученных
предвари-
тельных
результатов
автоматизации
вывода
вероятностных
моделей
вероятностно-
программирования
описание
структуры
работы
первая
часть
данной
работы
начинается
общих
сведений
вероятностном
программиро-
вании
затем
кратко
описываются
результаты
полученные
коллегами
автора
самим
работе
научными
проектами
протяжении
двух
лет
массачусетском
тех-
нологическом
инситуте
руководством
профессора
джошуа
тененбаума
доктора
ви-
каша
мансингхи
кембридж
штат
массачусетс
сша
оксфордском
университете
руководством
профессора
френка
вуда
великобритания
оксфорд
эта
часть
работы
являясь
сути
переводом
представляет
собой
реферативную
выдержку
вероятност-
ном
программировании
приложениях
русском
языке
насколько
автору
известно
литературы
вероятностном
программировании
русском
языке
практически
по-
этому
надеется
данная
чисто
реферативная
часть
работы
принесет
существенную
пользу
русскоговорящему
научному
сообществу
особенно
заинтересованным
студентам
школьникам
которые
впервые
захотят
познакомиться
развивающимся
направлением
вероятностного
программирования
второй
части
данной
работы
автор
описывает
новые
результаты
области
ве-
роятностного
программирования
связанные
автоматизированным
полуавтоматизи-
рованным
выводом
вероятностных
моделей
вероятностного
программирования
по-
лученные
время
стажировки
автора
департаменте
технических
наук
оксфордского
университета
научной
лаборатории
профессора
френка
вуда
руководством
вторая
часть
завершается
рассуждениями
автора
обобщении
автоматизированного
изу-
чения
вывода
компьютером
вероятностных
моделей
виде
вероятностных
программ
возможностях
порождающего
вероятностного
программирования
вероятностное
программирование
вероятностное
программирование
определить
компактный
композиционный
способ
представления
порождающих
вероятностных
моделей
проведения
статистическо-
вывода
учетом
данных
помощью
обобщенных
алгоритмов
вероятностная
модель
является
важным
понятием
машинного
обучения
одного
основных
направлений
искусственного
интеллекта
сегодняшний
день
общем
слу-
чае
рамках
теории
машинного
обучения
компьютером
ставится
задача
произвести
какое-то
действие
основе
входных
данных
априорных
знаний
возможности
взаи-
модействовать
средой
ограничений
общности
целевым
действием
компьютера
считать
производство
ответа
виде
выходных
данных
представленных
виде
ин-
формации
например
робототехнике
эта
информация
являться
инструкциями
моторов
механических
устройств
выполнения
тех
иных
физических
дей-
ствий
роботом
использовании
различных
подходов
рамках
машинного
обучения
использу-
ются
модели
которые
являются
формальным
cid:190
описанием
компонентов
функций
отоб-
ражающих
существенные
свойства
моделируемого
объема
процесса¿
рамках
машинного
обучения
используются
вероятностные
модели
свойства
элементы
связи
ними
являются
фиксированными
стохастическими
классическим
примером
одного
подходов
машинном
обучении
является
способ
cid:190
обучение
учителем¿
существует
прецедентов
пар
входных
выходных
данных
обучающей
выборки
необходимо
найти
алгоритм
описывающий
зависимость
алгоритм
который
позволяет
ос-
нове
каждого
элемента
входных
данных
получать
абсолютно
достаточно
точный
элемент
выходных
данных
помощью
данного
алгоритма
затем
известных
элементов
входных
данных
находятся
значения
неизвестных
элементов
выходных
данных
рамках
машин-
ного
обучения
эта
проблема
числе
решается
помощью
методов
регрессионного
анализа
приведенной
пример
модели
неизвестными
скрытыми
парамет-
рами
информация
характеристиках
модели
которые
подлежат
выводу
данной
обучающей
выборке
виде
пар
приведем
простой
пример
линейной
регрессии
независимых
переменных
значениями
независимых
переменных
будут
значениями
зависимой
переменной
будут
параметрами
модели
будут
tl+1
алгоритмом
ft1
...
tl+1
xi,1
tl+1
простоты
ограничений
общности
будем
считать
можем
по-
лучить
детерминированно
зная
порождающих
вероятностных
моделях
задается
совместное
распределение
веро-
ятностей
обычно
сначала
путем
задания
априорного
распределения
затем
задания
условного
распределения
называется
моделью
заданной
модели
известных
задачей
являться
поиск
апостериор-
ного
распределения
таким
образом
одним
способов
поиска
данного
апостериорного
распределения
является
применение
теоремы
байеса
теоретически
найти
cid:82
решении
практиче-
ских
задач
часто
невозможно
перебор
пространства
поддается
аналитическому
решению
решению
помощью
численных
методов
разумное
вре-
поэтому
чаще
решении
задач
рамках
байесовского
подхода
стоит
задача
поиска
ненормированного
значения
символ
часто
встречающийся
зарубежной
литературе
очень
редко
встречаю-
щийся
означает
cid:190
пропорционально¿
нормировочную
константу
затем
найти
приближенно
значение
вычисляют
бывает
достаточно
найти
работать
дальше
наиболее
вероятными
элементами
апостериорного
распределения
обычно
особенно
решении
практических
задач
большим
объемом
данных
рамках
сложных
моделей
апостериорное
распределение
находят
точно
помощью
приближенных
методов
числе
помощью
методов
монте-карло
которые
позволяют
сгенерировать
выборку
интересующего
распределения
отмечалось
самом
начале
данного
подраздела
вероятностное
программиро-
вание
позволяет
композиционно
компактно
записывать
порождающую
вероятностную
модель
помощью
задания
априорных
вероятностей
виде
алгоритма
вероятностной
программы
использованием
стохастических
функций
напри-
мер
стохастическая
функция
normal
вспомогательных
детерминирован-
ных
функций
например
снабжать
модель
данными
таким
образом
теоретически
определяя
условное
распределение
производить
статистический
вывод
генерации
выборки
условного
распре-
деления
помощью
обобщенных
алгоритмов
статистического
вывода
подходя-
щих
большого
множества
моделей
ознакомления
машинным
обучением
искусственным
интеллектом
автор
рекомендует
следующие
источники
информацию
вероятностных
моделях
байесовских
методах
русском
языке
найти
краткое
введение
языки
вероятностного
программирования
church
venture
anglican
существует
языков
вероятностного
программирования
перечень
кратким
опи-
санием
каждого
найти
данной
работе
реферативно
будут
рассмот-
рены
языка
вероятностного
программирования
church
venture
anglican
языки
venture
anglican
являются
продолжениями
языка
church
church
очередь
основан
языке
cid:190
обычного¿
программирования
lisp
scheme
заинтересованному
чи-
тателю
крайне
рекомендуется
ознакомиться
книгой
являющейся
одним
лучших
способов
начать
знакомство
языком
cid:190
обычного¿
программирования
scheme
1.1
первое
знакомство
church
venture
anglican
текущий
момент
любой
язык
вероятностного
программирования
напрямую
связан
методами
статистического
вывода
которые
используются
нем
поэтому
часто
язык
ас-
социируется
платформой
вероятностного
программирования
технической
реализацией
виде
компьютерной
программы
рассмотрим
задание
простой
вероятностной
модели
байесовской
линейной
регрес-
сии
языке
вероятностного
программирования
venture/anglican
виде
вероят-
ностной
программы
assume
normal
assume
normal
assume
assume
noisy_x
lambda
time
observe
noisy_x
observe
noisy_x
observe
noisy_x
predict
predict
predict
noisy_x
normal
time
скрытые
искомые
параметры
cid:22
значения
коэффициентов
линейной
функции
time
time
априорные
предположения
данных
коэффициентах
именно
предполагаем
распределены
закону
нормального
распределения
normal
средним
стандартным
отклонением
таким
образом
определили
первых
двух
строках
вероятностной
программы
вероятность
описанную
предыду-
щем
раздел
инструкцию
assume
name
expression
рассматривать
определе-
ние
случайной
величины
именем
name
принимающей
значение
вычисляемого
выражение
программного
кода
expression
которое
содержит
неопределенность
вероятностные
языки
программирования
далее
будут
иметься
виду
кон-
кретно
church
venture
anglican
указано
иное
lisp/scheme
являются
функциональными
языками
программирования
используют
польскую
нотацию1
записи
выражений
вычисления
означает
выражении
вызова
функции
сна-
чала
располагается
оператор
аргументы
вызов
функции
обрамляется
круглыми
скобками
других
языках
программирования
таких
c++
python
эквивалентно
коду
вероятностных
языках
программирования
выражение
вызова
функции
принято
разделять
разных
вида
вызов
детерминированных
процедур
primitive-procedure
arg1
...
argn
ко-
торые
одних
тех
аргументах
возвращают
одно
значение
таким
процедурам
например
относятся
арифметические
операции
вызов
вероятностных
стохастических
процедур
stochastic-procedure
arg1
...
argn
которые
каждом
вызове
генерируют
случайным
образом
элемент
соответствующего
распределения
вызов
определяет
новую
случайную
величину
например
вызов
вероятностной
процедуры
normal
определя-
случайную
величину
распределенную
закону
нормального
распределения
normal
√10
результатом
выполнения
каждый
какое-то
веще-
ственное
число
вызов
составных
процедур
compound-procedure
arg1
...
argn
compound-procedure
cid:22
введенная
пользователем
процедура
помощью
специ-
ального
выражения
lambda
lambda
arg1
...
argn
body
body
cid:22
тело
процедуры
состоящее
выражений
общем
случае
составная
процедура
является
стохастической
недетерминированной
составной
процедурой
1venture
имеет
отдельный
дополнительный
вид
синтаксиса
venturescript
использующий
инфиксную
нотацию
тре-
бующий
обрамления
вызова
функций
скобками
схожий
своей
сути
привычными
большинству
людей
языками
программирования
c++
python
т.д
тело
содержать
вызовы
вероятностных
процедур
хотим
задать
условную
вероятность
наблюдаемых
пе-
ременных
заданных
значениях
скрытых
переменных
параметра
time
вводом
непосредственно
самих
наблюдений
помощью
выражения
observe
...
определяем
общий
закон
наблюдаемых
переменных
рамках
нашей
модели
именно
предполагаем
данные
наблюдаемые
случайные
величины
заданных
заданном
уровне
шума
noise
распределены
закону
нормального
рас-
пределения
normal
t1+t2·time
√noise
средним
t1+t2·time
стандартным
отклонением
noise
данная
условная
вероятность
определена
строках
данной
вероятностной
программы
noisy_x
определена
функция
принимающая
параметр
time
возвраща-
ющая
случайное
значение
определенное
помощью
вычисления
выражение
normal
time
noise
обусловленное
значениями
случайных
величин
пере-
менной
noise
отметим
выражение
normal
time
noise
содержит
неопределенность
поэтому
каждый
вычислении
будем
получать
общем
случае
разное
значение
строках
cid:22
непосредственно
вводим
известные
значения
ˆx1
10.3
ˆx2
11.1
ˆx3
11.9.
инструкция
вида
observe
expression
value
фиксирует
наблюдение
случайная
величина
принимающая
значение
согласно
выполнению
выражения
expression
приняла
значение
value
повторим
данном
этапе
всё
сделали
строках
cid:22
помощью
ин-
струкций
вида
assume
...
задали
непосредственно
саму
вероятностную
модель
строках
cid:22
непосредственно
задали
известные
нам
значения
наблюдаемых
случайных
величин
помощью
инструкций
вида
observe
...
строках
cid:22
запрашиваем
системы
вероятностного
программирования
апо-
стериорное
распределение
скрытых
случайных
величин
сказано
большом
объеме
данных
достаточно
сложных
моделях
получить
точное
аналитическое
представление
невозможно
поэтому
инструкции
вида
predict
...
гене-
рируют
выборку
значений
случайных
величин
апостериорного
распределения
приближения
инструкция
вида
predict
expression
общем
случае
генери-
рует
элемент
выборки
значений
случайной
величины
принимающей
значение
согласно
выполнению
выражения
expression
инструкциями
вида
predict
...
расположены
инструкции
вида
observe
...
выборка
апостериорного
распределения2
обусловленного
перечисленными
ранее
введенными
наблюдениями
отметим
завершении
можем
также
предсказать
значение
функции
time
точке
например
time
4.0.
предсказанием
данном
слу-
чае
понимается
генерация
выборки
апостериорного
распределения
новой
случайной
величины
значениях
скрытых
случайных
величин
параметре
time
4.0.
генерации
выборки
апостериорного
распределения
языке
программирования
church
качестве
основного
используется
алгоритм
метрополиса-
гастингса
который
относится
методам
монте-карло
схеме
марковских
цепей
следующем
подразделе
произведено
подробное
описание
применения
данного
ал-
горитма
обобщенного
статистического
вывода
вероятностных
языках
cid:190
обоб-
щенным¿
выводом
данном
случае
понимается
алгоритм
применен
любым
вероятностным
программам
написанным
данном
вероятностном
языке
про-
граммирования
1.2
статистический
вывод
вероятностных
языках
программирования
по-
мощью
алгоритма
метрополиса-гастингса
описание
алгоритма
метрополиса-гастингса
применении
cid:190
семейству¿
вероятностных
языков
church
впервые
опубликовано
подробно
описано
получить
выборку
элементов
априорного
распределения
скрытых
пара-
метров
наблюдаемых
величин
совместного
распределение
какой-либо
порождающей
вероятностной
модели
записанной
виде
вероятностной
про-
граммы
составляет
труда
достаточно
выполнить
вероятностную
программу
отметим
очевидный
факт
данном
случае
вероятностная
программа
со-
держать
лишь
инструкции
вида
assume
...
задание
вероятностной
модели
predict
...
перечисление
случайных
величин
выборку
которых
генерируем
1.2.1
метод
cid:190
выборки
отклонением¿
заданных
наблюдениях
помощью
инструкций
вида
observe
expression
value
наиболее
простым
способом
получения
апостериорного
распределения
является
метод
2говоря
точнее
приближения
апостериорного
распределения
cid:190
выборки
отклонением¿
понимания
рассмотрим
следующую
вероятностную
программу
assume
uniform−d
assume
uniform−d
observe
predict
отметим
стохастическая
процедура
uniform-continuous
возвращает
значение
случайной
величины
распределенной
равномерному
дискретному
закону
рас-
пределения
носителем
текстом
задачу
записанную
выше
помощью
вероятностной
программы
сформулировать
следующим
образом
подбрасываются
шестигранных
игральных
ку-
бика
сумме
выпало
каково
распределение
произведения
очков
этих
двух
куби-
ках
метод
cid:190
выборки
отклонением¿
заключается
генерировать
значения
очков
первом
втором
кубиках
априорного
распределения
таким
образом
независимых
дискретных
равномерных
распределения
проверять
равна
сумма
данная
попытка
отвергается
учитывается
произведение
очков
кубиках
добавляется
множество
элементов
выборки
данная
выборка
бу-
дет
аппроксимацией
апостериорного
распределения
значений
произведения
очков
двух
кубиках
известно
сумма
очков
равна
данный
метод
является
неэффективным
решении
сложных
задач
про-
сто
вычислительно
неосуществимым
также
отметим
подходит
дискретных
значений
случайных
промежуточных
переменных
1.2.2
пространство
историй
выполнений
вероятностных
программ
выполнении
вероятностной
программы
каждая
случайная
величина
принимает
опре-
деленное
значение
например
следующая
вероятностная
программа
содержит
слу-
чайных
величины
каждая
которых
распределена
закону
нормального
распределе-
ния
assume
normal
assume
normal
assume
normal
predict
выполнении
данной
вероятностной
программы
каждая
трех
случайных
ве-
личин
примет
свое
случайное
значение
назовем
историей
выполнения
вероятностной
программы
отображение
сопоставляющее
каждой
случайной
величине
значение
мощ-
ность
истории
выполнения
совпадает
количеством
случайных
величин
которые
созданы
выполнении
каждой
программы
определить
соответствующее
вероятностное
про-
странство
элементарными
событиями
которого
будут
являться
истории
выпол-
нения
вероятностью
каждого
элементарного
события
являться
произведение
ве-
роятностей
принятие
иного
значения
каждой
случайные
величины
данной
истории
выполнения
очевидно
история
выполнения
однозначным
образом
определяет
выполнение
вероятностной
программы
принимаемые
значения
случайных
зависящих
детерминированных
выражений
примера
рассмотрим
простую
вероятностную
программу
assume
assume
predict
predict
обе
случайных
величины
имеют
свое
название
облегчает
запись
историй
выполнений
иначе
необходимо
вводить
адресную
схему
наименования
случайных
величин
однозначно
идентифицировать
данная
вероятностная
программа
имеет
четыре
различных
возможных
историй
выполнений
именно
вероятностями
0.09
0.21
0.21
0.49
соответственно
отметим
также
количество
cid:190
активных¿
случайных
величин
выполнении
одной
той
вероятностной
программы
меняться
например
следующей
программе
assume
geometric
lambda
geometric
predict
geometric
данная
программа
генерирует
элемент
т.е
одноэлементную
выборку
геомет-
рического
распределения
параметром
0.5
помощью
составной
процедуры
geometric
параметризованной
параметром
выполнении
данной
вероятностной
программы
истории
выполнения
количество
cid:190
активных¿
случайных
величин
лю-
бым
1.2.3
апостериорное
распределение
историй
выполнений
программ
добавлении
наблюдений
фиксации
значения
определенных
случайных
ве-
личин
считать
рассматривается
подмножество
множества
элементарных
со-
бытий
именно
элементы
историях
выполнений
которых
наблюдаемые
случайные
величины
принимают
желаемое
значение
описать
другое
вероятностное
пространство
множеством
элементарных
со-
бытий
которого
являться
описанное
подмножество
вероятностная
мера
новом
вероятностном
пространстве
cid:190
индуцирована¿
вероятностной
мерой
первоначального
вероятностного
пространства
учетом
нормировочной
константы
описанный
переход
полностью
сочетается
теоремой
байеса
которая
нашем
случае
записывается
следующим
образом
cid:22
множество
случайных
величин
которых
знаем
фиксированные
наблю-
даемые
значения
cid:22
множество
случайных
величин
ассоциируемых
скрытыми
па-
раметрами
апостериорное
распределение
которых
заинтересованы
получить
грубо
говоря
всё
остальные
случайные
величины
cid:22
наблюдаемые
значения
случайных
величин
отметим
часто
заинтересованы
апостериорном
распределении
апостериорном
распределении
лишь
части
скрытых
параметров
cid:48
функции
общем
случае
являющейся
биекцией
стороны
ставим
задачу
получить
анали-
тическое
представление
данных
апостериорных
распределений
лишь
выборку
играет
большой
роли
нашем
случае
решении
задач
методами
монте-карло
можем
генерировать
элементы
выборки
затем
использовать
значения
нужных
нам
скрытых
случайных
величин
и/или
действовать
функцией
1.2.4
использование
методов
монте-карло
схеме
марковских
цепей
математическо-статистический
аппарат
методов
монте-карло
схеме
марковских
цепей
кратко
cid:190
современно¿
изложен
интуитивно
опишем
собираемся
делать
вероятностная
про-
грамма
определяющая
множество
скрытых
наблюдаемых
случайных
величин
вероятностная
программа
своей
записью
задает
априорное
распределение
значит
совместное
распределение
каждый
путем
выполнения
данной
программы
получаем
одну
возможных
реализаций
данной
программы
которая
би-
ективно
описывается
соответствующей
историей
выполнения
множество
cid:22
множество
возможных
историй
выполнений
данной
вероятностной
программы
ко-
торое
рассматривать
множество
элементарных
событий
каждой
истории
выполнения
определена
вероятностная
мера
также
cid:190
экспериментальное¿
значение
каждой
наблюдаемой
случайной
величины
ˆxi
множество
ˆxi
существует
подмножество
историй
выполнений
cid:48
котором
наблюдаемые
случайные
величины
принимают
желаемое
значение
данное
подмножество
рассматривать
множество
элементарных
событий
друго-
вероятностного
пространства
вероятностную
меру
котором
cid:190
индуцировать¿
предыдущего
путем
деления
нормирующую
постоянную
cid:48
будем
обозначать
ненормированную
вероятностную
меру
cid:48
рассмотрим
цепь
маркова
исходами
которой
являются
истории
выполнений
cid:48
cid:48
качестве
начального
распределения
выбрать
априорное
распределение
котором
значения
наблюдаемых
случайных
величин
выбираются
случайным
образом
согласно
распределению
устанавливаются
согласно
значени-
например
вероятностной
программе
assume
gamma
assume
lambda
normal
observe
первая
случайная
величина
распределенная
gamma
являться
скрытой
сгенерирована
согласно
данному
закону
распределения
наблюдаемая
случайная
величина
распределенная
нормальному
закону
гамма-распределения
закону
normal
сгенерирована
установлена
соответствии
на-
блюдаемым
значением
хотим
установить
такие
правила
перехода
схеме
метрополиса-гастингса
одного
состояния
исхода
цепи
маркова
другое
стационарное
распределение
данной
цепи
маркова
совпадало
распределением
cid:48
таком
случае
получения
аппроксимации
искомого
апостериорного
распределения
виде
выборки
нам
доста-
точно
имитировать
данную
цепь
маркова
алгоритме
метрополиса-гастингса
вероятностная
мера
известна
точностью
нормировочной
константы
происходит
нашем
случае
каждом
шаге
алгоритма
дано
текущее
состояние
cid:48
соответствии
заданным
заранее
условным
распределение
предлагается
новое
состояние
cid:48
таким
образом
на-
звать
распределением
предлагаемых
переходов
подсчитывается
коэффициент
cid:48
cid:190
принятия¿
нового
состояния
cid:32
min
cid:33
cid:48
cid:48
cid:48
cid:48
cid:48
cid:48
состояние
cid:48
принимается
качестве
следующего
состояния
cid:48
t+1
вероятностью
противном
случае
cid:48
t+1
cid:48
новое
состояние
предлагается
следующим
образом
случайным
образом
равномерно
выбирается
одна
cid:190
активная¿
скрытая
случай-
ная
величина
dom
cid:48
cid:190
вариации¿
предлагается
новое
значение
данной
случайной
величины
cid:48
условная
вероятность
данном
случае
локальным
распределением
предлагаемых
переходов
случайная
величина
влияет
поток
выполнения
вероятностной
програм-
результате
нового
значения
должны
исполнены
другие
ветви
выполнения
вероятностной
программы
исполняются
общем
случае
про-
исходит
генерация
новых
случайных
величин
которые
прежде
неактивны
примера
рассмотрим
следующую
вероятностную
программу
assume
assume
normal
gamma
predict
данной
вероятностной
программе
случайных
величины
первая
распределена
закону
бернулли
вторая
закону
нормального
распределения
третья
закону
гамма-распределения
также
называть
cid:190
имени
переменной
хотя
пере-
менная
cid:190
является
сама
случайной
величиной
зависит
значения
определяющей
поток
выполнения
вероятностной
программы
значения
либо
либо
отметим
также
каждом
выполнении
данной
вероятностной
программы
существовать
две
активных
случайных
величины
предположим
текущим
состоянием
вероятностной
программы
момент
вре-
мени
история
выполнения
cid:48
3.2
означает
случайная
величина
приняла
значение
поэтому
задания
переменной
сгенерирован
элемент
нормального
распределения
cid:190
реализована¿
случайная
величина
normal
очевидно
cid:48
3.2
0.3
fnormal
0,1
3.2
0.0007152264603.
предложим
новое
состояние
cid:48
выберем
случайным
образом
одну
двух
cid:190
активных¿
случайных
величин
пусть
предложим
случайным
образом
новое
значение
данной
случайной
величины
со-
гласно
априорному
распределению
bernoulli
0.3
пусть
случайная
величина
действительно
влияет
поток
выполнения
ве-
роятностной
программы
изменении
значения
данном
случае
должна
выполнена
другая
ветвь
выполним
данную
ветвь
генерируя
значения
cid:190
ак-
тивирующихся¿
случайных
величин
нашем
случае
предположим
стало
равным
12.3.
общем
случае
cid:48
cid:48
0.7
fgamma
1,1
12.3
cid:48
cid:48
cid:48
cid:48
rnew
cid:48
cid:22
количество
активных
случайных
величин
текущей
истории
выполнения
cid:48
cid:22
вероятность
нового
значения
варьируемой
случайной
величины
rnew
cid:22
совместная
вероятность
выбора
своих
значений
cid:190
активирующихся¿
случайных
вели-
чин
фиксированном
cid:48
обратное
cid:48
cid:48
коэффициента
принятия
ал-
горитма
метрополиса-гастингса
общем
случае
посчитано
аналогичным
об-
разом
cid:48
cid:48
cid:48
cid:48
rold
rold
cid:22
совместная
вероятность
выбора
своих
значений
случайных
величин
активных
cid:48
являющихся
активными
cid:48
рассмотренном
примере
cid:48
cid:48
0.3
fnormal
0,1
3.2
учетом
cid:48
0.7
fgamma
1,1
12.3
0.000003186221124
получаем
cid:18
min
0.7
fgamma
1,1
12.3
0.3
fnormal
0,1
3.2
поэтому
данном
конкретном
примере
cid:48
0.3
fnormal
0,1
3.2
0.7
fgamma
1,1
12.3
t+1
cid:48
любом
случае
веро-
ятностью
выбор
локального
распределения
предлагаемых
переходов
раз-
cid:19
ным
простейшем
случае
cid:22
независимая
случайная
величина
данное
распреде-
ление
выбирается
идентичным
априорному
распределению
cid:22
перестано-
вочная
случайная
величина
такие
случайные
величины
поддерживаются
рассмат-
риваемыми
языками
вероятностного
программирования
распределение
выбрано
учетом
накопленных
значений
l=j
+n·k
таким
образом
описали
алгоритм
предложения
нового
состояния
cid:48
текущем
состоянии
cid:48
описали
рамках
метода
метрополиса-гастингса
по-
лучить
выборку
cid:48
j=1
элементов
желаемого
апостериорного
распределения
нам
необходимо
имитировать
данную
цепь
маркова
согласно
описанному
выше
алгоритму
получить
cid:48
элементов
данной
цепи
затем
необходимо
отсеять
первые
элемен-
тов
оставшихся
выбрать
каждый
n-й
элемент
полученное
множество
являться
j=1
любая
история
выполнений
cid:48
од-
аппроксимацией
искомой
выборки
cid:48
нозначно
определяет
значение
случайных
величин
вероятностной
программе
аппроксимацией
выборки
выбирается
единицы
исключить
автокорреляцию
cid:48
которая
есте-
ственным
образом
возникает
цепи
маркова
выбирается
достаточно
больш´им
независимо
выбора
начальной
точки
cid:48
цепь
успела
cid:190
забыть¿
данный
первоначальный
выбор
особенно
важно
начальное
априорное
распределение
очень
силь-
отличается
апостериорного
какого-то
общего
правила
выбора
данных
величин
обычно
выбираются
эмпирически
1.2.5
программная
реализация
статистического
вывода
предыдущем
подпункте
теоретически
описан
алгоритм
обобщенного
статисти-
ческого
вывода
вероятностных
языках
программирования
простая
программная
реализация
впервые
достаточно
подробно
описана
инициализации
cid:48
выбирается
случайным
образом
путем
выполнения
ве-
роятностной
программы
фиксации
наблюдаемых
случайных
величин
соот-
ветствии
имеющимися
данными
памяти
компьютера
сохраняется
база
данных
активных
случайных
величин
вместе
значениями
также
со-
храняется
cid:48
которое
подсчитывается
время
первоначального
выполнения
программы
учетом
вероятности
наблюдаемых
случайных
величин
принять
значение
которое
приняли
описывается
схема
адресации
которая
позволяет
различать
случайные
величины
собой
затем
выбора
последующего
cid:48
t+1
каждый
базы
данных
случайным
равномерным
образом
выбирается
случайная
величина
случайным
об-
разом
варьируется
соответствии
своим
локальным
распределением
пред-
лагаемых
переходов
cid:48
которое
предварительно
задается
используемых
примитивных
несоставных
случайных
величин
создается
копия
базы
данных
которой
значение
случайной
величины
заменяется
новое
вероятностная
программа
выполняется
случайные
вели-
чины
которых
базе
данных
имеется
запись
согласно
схеме
адреса-
ции
принимают
соответствующие
старые
значения
принимает
свое
новое
полученное
значение
общем
случае
влияет
поток
выполнения
программы
генерируются
значения
новых
случайных
величин
которые
становятся
активными
этих
случайных
величин
прежде
базе
данных
записей
также
влияет
поток
выполнения
программы
некоторые
случайные
величины
могут
перестать
активными
данном
случае
соответствующие
записи
базе
данных
будут
невостребованы
cid:48
выполнения
программы
второй
считать
получили
cid:48
также
отметим
выполнении
программы
cid:48
получили
использовали
всё
необходимые
компоненты
подсчета
cid:48
cid:48
вероятность
обратного
перехода
cid:48
cid:48
получена
разными
спо-
собами
вероятностной
программе
независимые
случайные
величины
перестановочных
первые
две
компоненты
cid:48
cid:48
могут
найдены
тривиально
знаем
количество
случайных
величин
cid:48
можем
посчитать
cid:48
третьей
компоненты
нам
нужно
по-
считать
произведение
вероятностей
случайных
величин
которые
перестали
активными
cid:48
невостребованные
случайные
величины
базе
дан-
ных
случае
наличия
использования
перестановочных
случайных
величин
можем
имитировать
ситуацию
cid:48
является
нашим
старым
состоянием
новое
состояние
получаем
точном
соответствии
cid:48
имея
cid:48
cid:48
cid:48
cid:48
cid:48
cid:48
подсчитываем
коэффициент
при-
нятия
алгоритма
метрополиса-гастингса
либо
принимаем
cid:48
вероят-
ностью
означает
следующий
будем
использовать
новую
базу
данных
случайных
величин
значением
соответствующими
cid:48
либо
от-
клоняем
вероятностью
означает
следующем
шаге
cid:48
t+1
снова
будем
использовать
старую
базы
данную
cid:48
алгоритм
повторяется
шага
1.3
эффективность
вывода
использовании
вероятностных
языков
программирования
встает
вопрос
эффек-
тивности
статистического
вывода
другими
словами
быстро
генерируем
выборку
желаемой
точности
апостериорного
распределения
описанная
секции
1.2.5
программная
реализация
статистического
вывода
является
неэффективной
про-
исходит
перевыполнение
всей
вероятностной
программы
хотя
вариация
случайной
вели-
чины
обычно
имеет
локальный
эффект
рассмотрим
подробно
данную
проблему
примере
следующей
вероятност-
ной
программы
assume
rainy−season
assume
cloudy
assume
rainy−season
cloudy
assume
cloudy
assume
wet−g
0.99
данная
вероятностная
программа
описывает
статистически
простую
упрощенную
модель
зависимости
сезоном
облачностью
дождем
работой
разбрызгивателя
состоянием
травы
мокрая
какой-то
день
значение
переменных
следующее
рисунок
cid:22
пример
байесовской
сети
rainy-season
входит
день
сезон
дождей
cloudy
облачно
день
rain
дождь
день
sprinkler
работал
разбрызгиватель
день
wet-grass
трава
мокрой
день
данная
модель
представлена
помощью
байесовской
сети
доверия
рис
таблицами
условных
вероятностей
отметим
любая
байесовская
сеть
доверия
представлена
виде
вероятностной
программы
языке
church/venture/anglican
любая
вероят-
ностная
программа
представлена
байесовской
сетью
случае
время
очередной
итерации
алгоритма
метрополиса-гастингса
качестве
варьируемой
случайной
величины
выбрана
случайная
величина
rain
соответ-
ствующий
узел
рис
выделен
самым
темным
цветом
подсчета
коэффициента
принятия
достаточно
лишь
рассмотреть
значения
вероятности
данных
значениях
узлов
cid:190
дождь¿
cid:190
трава
мокрая¿
остальные
значения
вероятности
останутся
прежними
иллюстрацию
распространения
возмущений
связи
вариацией
случайной
величины
cid:190
дождь¿
рис
подобном
простом
примере
факт
играет
большой
роли
отношение
случайных
величин
требующих
cid:190
переучета¿
общему
количеству
активных
случайных
величин
невелико
однако
большом
объеме
данных
играет
решающую
роль
выполнении
статистического
вывода
многих
моделях
помощи
программных
ре-
ализаций
вероятностных
языков
программирования
например
скрытых
марковских
моделях
латентном
размещении
дирихле
например
простой
скрытой
марковской
модели
скрытых
наблю-
даемых
величин
реализации
статистического
вывода
алгоритмом
описанным
сек-
рисунок
cid:22
байесовская
сеть
виде
cid:190
отпечатка¿
выполнения
вероятностной
программы
ции
1.2.5
одна
итерация
алгоритма
метрополиса-гастингса
имеет
сложность
времени
хотя
желаемая
возможная
сложность
крайней
мере
log
достижения
желаемой
сложности
каждой
истории
выполнений
необходимо
отслеживать
зависимости
случайными
величинами
следует
отметить
за-
висимости
общем
случае
могут
изменяться
вероятностных
программах
например
следующей
программе
assume
assume
gamma
assume
normal
случайная
величина
т.о
normal
...
зависит
случайной
величины
т.о
gamma
...
случайная
величина
принимает
значение
cid:190
исти-
на¿
описание
структур
данных
алгоритмов
необходимых
отслеживания
зависи-
мостей
режиме
реального
времени
предварительно
приведено
затем
обширно
подробно
использовании
данных
структур
данных
алгорит-
мов
временная
сложность
одной
итерации
алгоритма
метрополиса-гастингса
простой
скрытой
марковской
модели
равна
log
использовать
упорядоченный
перебор
случайных
величин
временная
сложность
снизиться
лога-
рифмический
фактор
появляется
связи
необходимостью
выбирать
случайным
образом
следующий
узел
т.е
случайную
величину
вариации
простой
скрытой
марковской
модели
количество
cid:190
активных¿
случайных
вели-
чин
постоянно
вид
зависимости
тривиален
каждой
скрытой
случайной
величины
напрямую
зависит
одна
наблюдаемая
случайная
величина
следующая
скрытая
случайная
величина
сложных
моделях
виды
зависимостей
изощ-
рены
количество
случайных
величин
меняется
одной
истории
выполнений
стороны
большого
количества
порождающих
моделей
используемых
настоя-
щее
время
машинном
обучении
необходимо
время
одну
итерацию
оставалось
постоянным
росло
хотя
логарифмически
вместе
линейным
ростом
количества
наблюдений
иначе
статистический
вывод
невозможен
разумное
время
рис
показаны
результаты
применения
алгоритмов
структур
данных
описан-
ных
использовании
старого
подхода
описанного
секцию
1.2.5
время
итераций
алгоритма
метрополиса-гастингса
росло
квадратично
линейным
ростом
размерности
модели
скрытых
наблюдаемых
случайных
величин
использовании
предлагаемого
подхода
время
растет
квазилинейно
рисунке
видно
благодаря
локализации
выполнения
одной
итера-
ции
метрополиса-гастингса
стало
возможным
проводить
приближенный
статистический
вывод
параллельно
следует
отметить
пространственная
сложность
алгоритма
объем
памяти
необходимый
применения
равна
грубо
говоря
cid:22
стои-
мость
хранения
памяти
зависимостей
случайными
величинами
общем
случае
эта
величина
достаточно
большой
работе
описаны
возможности
эффективного
расходования
памяти
1.4
порождающее
вероятностное
программирование
распознавании
обра-
зов
отмечено
начале
цель
вероятностного
программирования
cid:22
облегчить
задачу
моделирования
порождающих
вероятностных
моделей
проведения
вывода
приме-
ром
иллюстрации
успешного
предварительного
применения
вероятностного
программиро-
вания
служить
работа
которой
вероятностное
программирование
использует-
рисунок
cid:22
эффективность
статистической
вывода
различных
реализациях
красный
график
соответствует
простейшему
алгоритму
описанному
1.2.5
котором
каждый
происходит
перевыполнение
всей
вероятностной
программы
зеленый
гра-
фик
соответствует
использованию
новых
алгоритмов
структур
данных
позволяет
производить
статистический
вывод
асимптотически
эффективно
синий
голубой
график
показывают
применение
предлагаемого
подхода
также
позволяет
производить
статистический
вывод
параллельно
крайней
мере
приближенно
рис
моделирования
вероятностной
модели
находящихся
изображении
объектов
взаимодействия
собой
байесовский
подход
интерпретации
изображений
путем
задания
априорного
распределения
расположение
объектов
связи
ними
предложен
задолго
появления
рассматриваемых
языков
программирования
одна-
именно
появлением
исследование
осуществление
данного
подхода
стало
проще
вероятностные
языки
программирования
позволяют
композиционно
компактно
представлять
вероятностные
порождающие
модели
проводить
статистический
вывод
работе
рассматриваются
примера
проблема
графической
captcha
cid:22
cid:190
компьютерного
теста
используемого
определения
кем
является
пользователь
систе-
человеком
компьютером¿
знакомого
каждому
пользователю
интерне-
проблема
нахождения
изображении
камеры
автомобиля
дороги
разделительной
полосы
левого
правого
оврагов
полученные
результаты
своей
эффективности
рассматриваемых
простых
примерах
уступают
другим
современным
подходам
реше-
нию
этих
задач
однако
представление
моделирование
вывод
проще
осуществляется
100
120
140
160среднее
время
итерацийалгоритма
метрополиса-гастингса
статистический
вывод
оптимизации
красный
предложенные
алгоритмы
структуры
данных
зел
100
150
200
250
количество
наблюдений
скрытой
модели
маркова—//—
потока
син
—//—
потока
гол
помощью
вероятностного
программирования
1.5
различиях
church
venture
anglican
целью
данной
главы
очевидно
подробное
описание
этих
вероятностных
языков
краткое
введение
заинтересованному
читателю
можем
порекомендовать
продолжить
свое
знакомство
вероятностным
языком
church
venture
cid:22
anglican
cid:22
хотя
многое
объединяет
вероятностные
языки
некоторых
принципиальных
вещах
различаются
например
venture
данный
момент
позиционируется
универсальная
платформа
включающая
разные
виды
алгоритмов
методов
статистического
вывода
запроектированной
возможностью
добавлять
новые
помощью
использования
базовых
компонент
методов
рамках
работы
anglican
развивают-
методы
обобщенного
вывода
использованием
методов
фильтрации
частиц
church
стороны
позволяет
производить
статистический
запрос
внутри
другого
статисти-
ческого
запроса
venture
anglican
пока
делать
могут
автоматическая
генерация
вероятностных
программ
использовании
полных
тьюрингу
вероятностных
языков
программирования
включающих
функции
высших
порядков3
которыми
числе
являются
языки
church
venture
anglican
вероятностная
программа
одновременно
является
порождаю-
щей
моделью
записанной
процедурой
генерации
элементов
выборки
модели
путем
выполнения
исходного
кода
данной
процедуры
любая
процедура
вероятностном
программировании
является
формально
программным
кодом
который
описывает
процесс
генерации
элемента
выборки
заданных
аргументах
данной
функции
таким
образом
процедуры
вероятностных
программ
являются
конструктивным
способом
описания
услов-
ных
распределений
полные
тьюрингу
допускающие
функции
высших
порядков
вероятностные
языки
программирования
открывают
возможность
проведения
вывода
исходного
текста
самих
вероятностных
программ
задано
априорное
распределение
множестве
ис-
ходного
текста
помощью
операторов
eval
apply
грубо
говоря
необходимо
представить
вероятностную
порождающую
мета-модель
которая
генерировать
вероятностные
модели
виде
исходного
кода
вероятностных
программ
данная
глава
основана
работе
которая
включает
первые
предваритель-
ные
результаты
амбициозной
задаче
вывода
самих
порождающих
вероятностных
моделей
наличии
какой-либо
информации
искомом
распределении
которое
опре-
деляется
искомой
вероятностной
программой
отметим
статистический
вывод
про-
странстве
исходного
кода
сложен
какого-то
простого
подхода
построению
вероятностных
порождающих
моделей
исходного
кода
выводу
рамках
нашей
предварительной
работы
поставили
задачу
найти
помощью
статистического
вывода
предлагаемой
нами
порождающей
вероятностной
мета-модели
такие
вероятностные
программы
которые
будут
генерировать
выборку
элементов
схо-
жую
своим
статистическим
характеристикам
каким-то
заранее
заданным
распреде-
лением
эта
задача
интересна
сама
нахождение
эффективных
алгоритмов
генерации
моделирования
случайных
величин
cid:22
нетривиальная
задача
людей-
3функциями
процедурами
высших
порядков
называются
функции
аргументами
значениями
которых
могут
другие
функции
ученых
которой
занимаются
протяжении
десятков
лет
наши
предварительные
результаты
показывают
подобный
автоматизирован-
ный
вывод
порождающих
вероятностных
моделей
виде
вероятностных
программ
дей-
ствительно
возможен
частности
приводим
результаты
успешного
эксперимента
рамках
которого
автоматически
нашли
обобщенную
вероятностную
программу
ко-
торая
подлинно
приближенно
генерирует
случайные
величины
распределенные
закону
бернулли
произвольным
параметром
2.1
обзор
литературы
рассматриваемые
нами
идеи
относятся
разным
областям
числе
автоматизации
процесса
программирования
индуктивному
программированию
автоматическому
моделированию
компьютерному
определению
представле-
нию
плотности
распределений
подходы
решению
проблемы
включают
статистический
вывод
поиск
оптимизацию
числе
эволюционные
алгоритмы
особенности
ге-
нетическое
программирование
идеи
методы
использования
вероятностного
программирования
изучения
автоматизированного
представления
вероятностных
моделей
предлагались
ранее
насколько
автору
известно
описываемый
подход
порождению
вероятностных
программам
мета-вероятностной
программой
ранее
рассматривался
качестве
отдель-
ной
проблемы
достаточно
подробно
хотя
первые
шаги
исследовании
формулировке
проблемы
сделаны
работах
2.2
описание
подхода
наш
подход
описан
рамках
приближенных
байесовских
вычислений
использованием
метода
монте-карло
схеме
цепей
маркова
выбором
качестве
искомого
апостериорного
распределения
ˆx|t
cid:22
вероятностная
мера
измеряющая
расстояние
значения
статистик
вычисленных
соответственно
выборке
искомого
распределения
выборке
по-
productions
lambda
program−text
assume
program−text
assume
program
eval
assume
samples
observe
normal
observe
normal
observe
normal
observe
normal
predict
program−text
predict
apply−n−times
рисунок
cid:22
вероятностная
программа
вывода
исходного
кода
вероятностной
про-
граммы
генерации
случайных
чисел
распределенных
закону
стандартного
нор-
мального
распределения
normal
apply−n−times
program
10000
mean
samples
var
ian
samples
samples
skewness
samples
program
лученной
путем
выполнения
исходного
кода
вероятностной
программы-кандидата
пусть
существует
распределение
параметрами
вероятностную
программу
генерации
элементов
выборки
которого
хотим
вывести
пусть
i=1
·|θ
выборкой
элементов
распределения
каком-то
фиксированном
значении
параметров
рассмотрим
задачу
вывода
исходного
кода
вероятностной
про-
граммы
которая
неоднократном
выполнении
сгенерирует
выборку
эле-
j=1
ˆxj
статистически
близких
распределению
заданных
ментов
ˆxj
параметрах
пусть
статистикой
выборки
cid:22
значение
стати-
стики
элементах
выборки
соответственно
пусть
вероятностная
мера
простоты
ненормированная
принимает
б´ольшие
значения
интерпретировать
расстояние
штраф
используем
вероятностное
программирование
представления
мета-модели
порождающей
другие
вероятностные
программы
виде
исходного
текста
проведе-
ния
статистического
вывода
пространстве
искомых
вероятностных
моделей
стати-
стического
вывода
использовали
программную
реализацию
вероятностного
языка
про-
граммирования
anglican
которая
поддерживает
статистический
вывод
методом
частиц
методом
метрополиса-гастингса
методу
монте-карло
схеме
цепей
маркова
вероятностная
мета-модель
представлена
рис
первой
строке
уста-
навливаем
соответствие
переменной
program-text
которая
содержать
сгенерированный
элемент
распределения
исходный
код
определенное
априорно
порождающую
процедуру
production
помощью
адаптивной
граммати-
типу
подробнее
разделе
2.3
указываем
задача
вывода
данном
случае
найти
вероятност-
ную
программу
генерирующую
элементы
стандартного
нормального
распределения
переменная
samples
второй
строке
представляет
описанную
выше
выборку
веро-
ятностной
программы-кандидата
примере
10000.
вычисляются
следующих
четырех
строках
вероятностной
программы
статистика
определяется
четырехмерный
вектор
включающий
соответственно
выборочные
среднее
дисперсию
коэффициент
асимметрии
коэффициент
эксцесса
вы-
борки
элементов
распределения
определенного
вероятностной
программой
полученной
распределения
мера
расстояния
определяется
плотность
многомерного
нор-
мального
распределения
средними
0.0
1.0
0.0
0.0
диагональной
ковариационной
матрицей
σ2i
отметим
означает
ищем
вероятностные
программы
ре-
зультат
выполнения
которых
определяет
распределение
средним
равным
дисперсией
cid:22
коэффициентами
асимметрии
эксцесса
равными
cid:190
штрафуем¿
отклонения
этих
значений
помощью
квадратичной
экспоненциальной
функции
потерь
коэффи-
определена
noise-level
эта
функция
потерь
представляет
собой
циентом
функцию
плотности
нормального
распределения
данный
пример
служит
хорошей
иллюстрацией
основных
особенностей
нашего
под-
хода
поиска
виде
вероятностной
программы
генератора
случайных
чисел
стан-
дартного
нормального
распределения
используем
аналитическую
информацию
стандартном
нормальном
распределении
вычислении
расстояния
статистика-
существует
крайней
мере
различных
ситуации
включая
данную
которых
могут
вычисляться
различными
способами
рамках
первой
ситуации
ищем
вероятностную
программу
которая
эффек-
тивно
генерирует
элементы
аналитически
известных
распределений
эф-
фективностью
данном
случае
понимать
вычислительную
временную
сложность
среднее
количество
использованной
энтропии
генерации
эле-
мента
выборки
среднем
практически
ситуации
подобной
постановке
задачи
статистики
распределения
известны
аналитически
вторая
ситуация
возникает
можем
генерировать
элементы
вы-
борки
например
подобная
ситуация
возникает
генерируем
эле-
менты
апостериорного
распределения
помощью
cid:190
дорогостоящего¿
вычис-
bool
productions
samples−1
lambda
program−text
assume
program−text
assume
program
eval
assume
100
assume
samples−1
apply−n−times
program
observe
g−test−p−value
assume
samples−n
apply−n−times
program
observe
g−test−p−value
predict
program−text
predict
apply−n−times
program
рисунок
cid:22
вероятностная
программа
вывода
исходного
кода
вероятностной
программы
генерирующей
случайные
числа
распределенные
закону
бернулли
bernoulli
предпоследней
строчке
выводится
текст
вероятностной
программы-
кандидата
последней
строчке
вероятностная
программа-кандидат
выполняется
генерации
выборки
элементов
параметризации
0.3
причем
предыдущие
т.о
тренировочные
значения
параметров
содержали
0.3.
samples−n
true
true
лительно
метода
монте-карло
схеме
марковских
цепей
заинтересо-
ваны
получить
другое
представление
апостериорного
распределения
виде
ве-
роятностной
программы
чье
априорное
распределение
точно
хотя
приблизительно
совпадать
искомым
апостериорным
третьей
ситуации
нам
заранее
дана
фиксированного
размера
выборка
хотим
найти
вероятностную
программу
которая
позволит
генерировать
выборку
произвольного
размера
дальнейшем
начали
раздел
постановки
задачи
именно
рамках
третьей
ситуации
следует
отметить
возможная
польза
представления
генератора
случайных
чи-
сел
потенциально
эффективно
быстро
генерировать
выборку
желаемого
распределения
получить
формальное
представление
желаемого
распределения
приближения
виде
исходного
кода
вероятностной
программы
виде
формальной
сущности
дальнейшие
действия
которой
производить
числе
проводить
анализ
выведенным
исходным
кодом
использовать
найденные
блоки
исходного
кода
решения
других
задач
рис
иллюстрирует
другое
важное
обобщение
решение
задачи
сформулированной
самом
начале
апостериорным
распределением
постановке
задачи
вывод
генератора
случайных
чисел
распределенных
со-
гласно
стандартному
нормальному
распределению
параметризовали
искомое
рас-
assume
box−muller−normal
lambda
mean
std
mean
std
cos
3.14159
uniform−continuous
sqrt
log
uniform−continuous
assume
lambda
begin
exp
inner−loop
lambda
dec
begin
uniform−continuous
inner−loop
inner−loop
uniform−continuous
рисунок
cid:22
найденные
записанные
людьми
исходные
коды
вероятностных
программ
слева
общего
нормального
распределения
normal
справа
распределения
пуассона
poisson
исходные
коды
входят
собранный
нами
корпус
помощью
которого
определяем
априорные
вероятности
наших
порождающих
правил
путем
подсчета
количества
встречающихся
констант
процедур
разных
видов
т.д
пределение
никаким
образом
стандартного
нормального
распределения
параметров
т.е
общем
случае
распределения
которые
хотим
представить
виде
вероятностных
программ
имеют
нетривиальную
параметризацию
представля-
собой
сути
семейство
распределений
хотим
найти
вероятностную
программу
входные
аргументы
которой
являлись
параметрами
искомого
распределения
таким
образом
эта
вероятностная
программа
позволяла
генерировать
случайные
ве-
личины
семейства
наглядности
рассмотрим
алгоритм
генерации
случайных
чисел
распределенных
закону
нормального
распределения
помощью
преобразования
бокса-мюллера
представленный
виде
вероятностной
программы
рис
эта
вероятностная
процедура
параметризована
двумя
параметрами
средним
стандартным
отклонением
постановки
обобщенной
задачи
вывода
параметризован-
ных
вероятностных
программам
нам
необходимо
изменить
наше
искомое
апостериорное
распределение
включив
параметр
параметризующий
искомое
распределение
ˆx|t
нам
хотелось
вывести
вероятностную
программу
которая
смогла
обобщить
возможные
значения
параметра
допущением
выберем
конечное
чис-
различных
параметризаций
ˆθi
получим
обобщение
семейства
распределе-
ний
виде
вероятностной
программы
формулируем
нашу
задачу
виде
следующего
приближения
использованием
приближенных
байесовских
вычислений
рамках
метода
монте-карло
схеме
цепей
маркова
cid:88
n=1
xn|
ˆxn
ˆxn|t
|θn
cid:90
ˆx|t
вероятностная
программа
поиска
параметризованной
вероятностной
програм-
генерирующей
случайные
числа
распределенных
закону
бернулли
bernoulli
представлена
рис
наглядным
образом
иллюстрирует
применение
данного
допуще-
ния
приближения
выбранных
различных
параметризациях
параметра
распре-
деления
бернулли
каждый
генерируем
элементов
вероятностной
программы-
кандидата
аккумулируя
расстояние
штраф
искомым
распределением
получен-
ным
распределением
представляющим
вероятностную
программу-кандидата
каждом
конкретном
случае
высчитываем
расстояние
использованием
статисти-
g-теста
cid:190
современный¿
аналог
критерия
согласия
пирсона
соответствующей
статистики
виде
cid:88
i∈0,1
ˆxn
cid:32
cid:33
ˆxn
1−i
ˆxn|
ˆxn
cid:22
количество
элементов
выборки
ˆxn
принимающих
значение
также
соответствующее
p-значение
нулевой
гипотезой
утверждающей
элементы
выборки
ˆxn
являются
элементами
выборки
распределения
bernoulli
распределение
статистики
g-теста
приблизительно
распределено
закону
распределения
хи-квадрат
т.е
нашем
примере
можем
представить
находить
расстояние
данном
случае
путем
вычисления
вероятности
ложного
отклонения
нулевой
гипотезы
ˆxn
bernoulli
ложное
отклонение
нулевой
гипотезы
эквивалентно
успеху
проведении
испытания
бернулли
вероятностью
успеха
равной
p-значению
2.3
грамматика
порождающие
правила
учетом
наличия
нашем
распоряжении
выразительного
вероятностного
языка
про-
граммирования
допускающего
функции
высших
порядков
полного
тьюрингу
наше
априорное
распределение
исходном
коде
искомых
вероятностных
программ
также
до-
статочно
выразительно
общих
чертах
оно
схоже
адаптивными
грамматиками
используемыми
имеет
отличия
частности
связанные
созданием
сред
ло-
кальными
переменными
виде
псевдокода
наше
априорное
распределение
представлено
следующим
образом
символ
означает
cid:190
перейти
выражение
exprtype|env
имя
переменной
случайно
выбираемой
среды
переменных
env
типом
type
выражение
exprtype|env
случайную
константу
типа
type
константы
различ-
ных
типов
целочисленные
вещественные
т.д
генерируются
отдельного
каждого
типа
type
процесса
дирихле4
dptype
htype
базовое
распределе-
ние
htype
само
общем
случае
являются
смесью
нескольких
распределе-
ний
например
констант
вещественного
типа
используем
смесь
нормаль-
ного
распределения
normal
равномерного
непрерывного
распределения
uniform-continuous
-100
100
равномерного
дискретного
распределения
множества
выражение
exprtype|env
proceduretype
exprarg_1_type
...
exprarg_n_type
про-
цедура
procedure
является
случайно
выбираемой
примитивной
детерминирован-
ной
стохастической
составной
процедурой
определенной
заранее
гло-
бальной
среде
типом
возвращаемого
значения
type
выражение
exprtype|env
compound_proceduretype
exprarg_1_type
...
exprarg_n_type
compound_proceduretype
является
составной
процедурой
также
генерируемой
соответствии
процессом
дирихле
dptype
gtype
базовое
распределение
gtype
случайным
образом
генерирует
составную
процедуру
типом
возвра-
щаемого
значения
type
количеством
входных
аргументов
распределенным
закону
пуассона
каждый
входной
аргумент
имеет
свой
произвольный
тип
тело
body
составной
процедуры
генерируется
также
случайным
образом
согласно
этим
порождающим
правилам
грамматике
учетом
введение
локальной
среды
включающей
входные
аргументы
процедуры
выражение
exprtype|env
let
gensym
exprreal
exprtype|env
gensym
env
gensym
означает
среду
дополненную
переменной
именем
gensym
значением
вычисляемым
соответствии
генерируемым
случайным
образом
выражением
согласно
этих
порождающих
правил
выражение
exprtype|env
exprbool
exprtype
exprtype
выражение
exprtype|env
recur
exprarg_1_type
...
exprarg_m_type
таким
образом
4не
нужно
путать
распределением
дирихле
рекурсивный
вызов
текущей
составной
процедуры
избежание
вычислительных
ошибок
время
выполнения
сгенерированных
про-
цедур
заменяем
примитивные
функции
cid:190
защищенными¿
аналогами
например
log
заменяется
safe-log
причем
последний
возвращает
напри-
мер
uniform-continuous
заменяется
safe-uc
которая
случае
меняет
аргументы
местами
также
возвращает
просто
аргументы
равны
множество
типов
которые
использовали
рамках
наших
экспериментов
вклю-
чало
вещественные
булевы
типы
общее
множество
примитивных
процедур
включен-
ных
нами
глобальную
среду
включало
такие
функции
safe-div
safe-uc
safe-normal
2.4
вероятности
использования
порождающих
правил
задания
априорных
вероятностей
порождающих
правил
вероятностей
ко-
торой
каждое
правил
применяться
случае
возможности
применения
вручную
составили
небольшой
корпус
вероятностных
программ
которые
повторяют
най-
денные
учеными
алгоритмы
генераторов
случайных
чисел
примеры
таких
программ
представлены
рис
заметим
требуют
наличия
одной
стохастиче-
ской
процедуры
именно
uniform-continuous
включили
глобаль-
ную
среду
положительной
вероятностью
экспериментов
описанных
2.5.2.
используя
данный
корпус
вычислили
априорные
вероятности
каждого
порож-
дающего
правила
выводе
вероятностной
программы
генерации
слу-
чайных
величин
искомого
распределения
например
распределения
бернулли
исключали
корпуса
элементы
которые
генерируют
случайные
величины
согласно
закону
распределения
вероятности
использования
порождающих
правил
cid:190
смягчены¿
помощью
распределения
дирихле
будущем
использовать
бо-
лее
обширные
корпусы
вероятностных
программ
примером
зарождающегося
подобного
корпуса
служить
2.5
эксперименты
эксперименты
разработаны
таким
образом
проиллюстрировать
вида
возможных
ситуаций
описанных
ранее
начале
проиллюстрируем
выразитель-
ность
нашего
априорного
распределения
исходного
кода
вероятностных
программ
рисунок
cid:22
гистограммы
выборок
некоторых
порожденных
вероятностных
программ
априорного
распределения
форме
распределений
видно
наши
порождаю-
щие
правила
достаточно
обширны
соответствующие
порождающим
вероятностным
программам
распределения
нетривиальны
опишем
постановку
результаты
экспериментов
рамках
использования
нашего
подхода
трех
различных
ситуациях
возможности
вычисления
расстояния
2.5.1
выборки
сгенерированных
вероятностных
программ
иллюстрации
выразительности
нашего
априорного
распределения
исходных
кодов
вероятностных
программ
приводим
выборки
случайным
образом
сгенерированных
вероятностных
программ
априорного
распределения
шесть
выборок
виде
ги-
стограмм
шести
различных
автоматически
сгенерированных
вероятностных
програм-
мам
расположены
рис
рисунка
видно
разные
случайным
образом
сгенерированные
вероятностные
программы
определяют
общем
случае
достаточно
различные
структурно
распределения
частности
заметить
разнообразие
носителе
дисперсии
количестве
cid:190
режимов¿
т.е
островков
носителя
высокой
вероятностью
отношению
очень
низковероятност-
ным
пространствам
островками
2.5.2
вывод
вероятностных
программ
определяющих
распределения
совпадающие
приближающие
классические
одномерные
распределения
отмечено
классических
одномерных
распределений
существуют
алгоритмы
позволяющие
точно
приближенно
генерировать
любое
количество
элемен-
тов
данных
параметризованных
распределений
аналитически
выведены
учеными
алгоритмы
числе
очевидно
могут
записаны
вероятностные
программы
виде
исходного
кода
−6−5−4−3−2y0.00.10.20.30.40.50.60.70.80.9ˆp
−3.0−2.5−2.0−1.5−1.0−0.50.0y0.000.050.100.150.200.250.300.350.40ˆp
−4−2024y0.00.10.20.30.40.50.6ˆp
−1.0−0.50.00.51.0y0.00.20.40.60.81.01.21.41.61.8ˆp
−14.56636−7.28318y0.00.20.40.60.81.01.2ˆp
−2.0−1.5−1.0−0.50.0y0.00.20.40.60.81.01.21.4ˆp
провели
серию
экспериментов
проверить
возможность
автоматическо-
вывода
вероятностных
программ
генерирующих
выборки
классических
одномерных
распределений
именно
распределения
бернулли
bernoulli
распределения
пуассона
poisson
гамма-распределения
gamma
1.0
бета-распределения
beta
стандарт-
ного
нормального
распределения
normal
cid:190
общего¿
нормального
распределения
normal
каждого
семейства
распределений
проводили
статистический
вывод
выбирая
качестве
целевого
апостериорного
распределения
частное
распределение
ˆx|t
маргинализированное
параметру
приближения
каждом
случае
выбирали
малое
множество
значений
параметров
определяли
апо-
стериорное
распределение
ограничениями
p−значению
распределения
бернулли
близости
моментам
ожидаемым
других
рассматриваемых
распределений
отметим
задании
априорного
распределения
порождающие
правила
каждом
конкретном
случае
корпуса
исключались
вероятностные
программы
от-
носящиеся
искомому
распределению
образцы
гистограмм
выборок
лучших
найденных
результате
вывода
вероят-
ностных
программ
представлены
рис
лучшими
понимаем
вероятностные
программы
наименьшим
расстоянием
тренировочных
значениях
параметров
со-
ответствующих
значениях
моментов
максимального
p-значения
стоит
особенно
отметить
результат
эксперимента
распределением
бернулли
рамках
которого
найден
исходный
код
вероятностной
программы
статистически
под-
линно
точно
генерирующей
выборку
семейства
распределения
бернулли
па-
раметром
найденная
вероятностная
программа
представлена
рис
рис
представлен
выведенный
исходный
текст
вероятностной
программы
генерации
элементов
гамма-распределения
gamma
параметризованного
парамет-
ром
2.5.3
обобщение
произвольных
эмпирических
данных
помощью
порождающего
вероят-
ностного
программирования
также
проверили
наш
метод
выводе
порождающих
моделей
виде
вероятностных
программ
объяснения
настоящих
синтетических
данных
аналитическое
распре-
деление
которых
неизвестно
рисунок
cid:22
зеленые
сплошные
линии
гистограммы
выборок
распределений
соот-
ветствующих
вероятностным
программам
имеющим
cid:190
высокую¿
вероятность
апостери-
орном
распределении
поиске
порождающих
моделей
соответствующих
распределе-
ниям
слева
направо
сверху
вниз
bernoulli
normal
poisson
gamma
1.0
normal
beta
1.0
синие
пунктирные
линии
гистограммы
выборок
cid:190
настоя-
щих¿
распределений
параметризация
семейства
распределений
каждом
случае
произ-
водилась
другими
значениями
параметров
которые
входили
обучающее
множество
значений
отметим
семейства
распределений
бернулли
bernoulli
вы-
ведена
вероятностная
программа
статистически
точно
генерирующая
элементы
выборки
любой
параметризации
рис
стороны
распределения
получи-
хорошее
приближение
найденными
вероятностными
программами
время
проводили
вывод
например
случае
бета-распределение
beta
1.0
uniform−continuous
par
lambda
par
lambda
par
stack−id
stack−id
stack−id
safe−uc
par
par
safe−div
par
lambda
par
safe−uc
par
dec
par
cos
par
рисунок
cid:22
сверху
написанный
человеком
исходный
код
генератора
случайных
чисел
распределенных
закону
бернулли
bernoulli
внизу
две
программы
выведенные
ис-
ходные
коды
первая
двух
выведенных
вероятностных
программ
определяет
настоящее
семейство
распределений
бернулли
bernoulli
параметризованное
вторая
программа
генерирует
распределение
приближенное
распределению
бернулли
параметризованное
01y0.00.20.40.60.81.01.2ˆp
405060708090100110y0.000.010.020.030.040.05ˆp
-2-101234567891011y0.000.050.100.150.200.250.300.350.400.45ˆp
02468101214y0.000.050.100.150.200.250.300.350.40ˆp
−4−2024y0.000.050.100.150.200.250.300.350.40ˆp
0.00.51.01.5y0.00.51.01.52.0ˆp
lambda
par
stack−id
begin
sym0
exp
safe−uc
−1.0
safe−div
safe−uc
safe−uc
safe−uc
par
safe−uc
begin
sym2
lambda
var1
var2
stack−id
dec
var2
sym2
safe−uc
−2.0
safe−uc
begin
sym4
safe−uc
sym0
begin
sym5
lambda
var1
var2
stack−id
safe−div
dec
−1.0
var1
sym5
exp
par
safe−uc
par
sym4
sym0
safe−uc
sym0
safe−div
sym0
exp
par
lambda
stack−id
−1.0
safe−uc
safe−uc
safe−uc
−1.0
safe−div
safe−uc
−55.61617747203855
safe−uc
27.396810474207317
safe−uc
−1.0
рисунок
cid:22
исходный
код
выведенных
вероятностных
программ
слева
гамма-
распределения
gamma
справа
третьей
эмпирической
выборки
индикаторов
используемых
рассмотрения
заявок
выдачу
кредита
выборки
сгенерированные
помощью
выполнения
этих
программ
расположены
соответственно
рис
рис
последняя
гистограмма
трех
экономии
места
исходный
код
сокращен
возможно
например
путем
замены
1.0
0.0
0.0.
рисунок
cid:22
гистограммы
зеленые
сплошные
линии
выборок
распределений
опре-
деляемых
найденными
процессе
статистического
вывода
вероятностными
программами
аппроксимации
эмпирических
данных
синие
пунктирные
линии
трех
вещественных
показателей
базы
данных
используемой
анализа
заявок
выдачу
кредита
данного
эксперимента
выбрали
набора
данных
признаков
обращающих-
банк
клиентов
получения
кредита
производили
вывод
вероятностной
программы
используя
сравнения
p-значения
двухвыборочного
теста
колмогорова-
смирнова
аналогично
тому
использовали
g-тест
дискретных
распределе-
ний
гистограммы
выборок
лучших
найденных
вероятностных
программ
сравнении
гистограммами
истинных
эмпирическими
данными
признаков
клиентов
приведены
рис
11.
пример
выведенной
вероятностной
программы
показан
рис
справа
2.5.4
cid:190
компиляция¿
вероятностных
программ
генерация
выборок
апостериорного
распределения
методом
монте-карло
схеме
мар-
ковских
цепей
особенно
случае
байесовского
вывода
обычно
достаточно
дорогостояща
cid:190
компиляцией¿
вероятностных
программ
имеем
виду
поиск
вероятностных
про-
грамм
априорное
распределение
которых
согласовывалось
точно
приблизительно
искомым
апостериорным
распределением
вероятностном
программировании
общем
случае
генерация
выборки
же-
102030405060708090y0.000.010.020.030.040.05ˆp
051015202530y0.000.050.100.150.20ˆp
−5051015202530y0.000.050.100.150.200.25ˆp
assume
theta
beta
observe
theta
true
observe
theta
true
observe
theta
true
observe
theta
true
predict
theta
predict
theta
assume
theta
safe−beta
4.440
assume
theta
assume
theta
safe−beta
safe−beta
e−l
assume
theta
beta
predict
theta
рисунок
cid:22
слева
вероятностная
модель
бета-биномиального
распределения
несжа-
той
форме
виде
вероятностной
программы
рамках
эксперимента
поставлена
задача
найти
формализацию
апостериорного
распределения
скрытого
параметра
ви-
вероятностной
программы
чье
априорное
распределение
совпадать
приближать
данное
апостериорное
справа
сверху
найденные
вероятностные
програм-
т.е.
результат
cid:190
компиляции¿
вероятностных
программ
априорное
распределение
которых
приближает
заданное
апостериорное
распределение
справа
внизу
записанный
человеком
исходный
код
вероятностной
программы
чье
априорное
распределение
совпа-
дает
априорным
распределением
данном
конкретном
случае
данная
вероятностная
программа
просто
выведена
аналитически
бета-распределение
явля-
ется
сопряженным
биномиальному
общем
случае
нетривиальная
задача
лаемого
апостериорного
распределения
путем
использования
методом
монте-карло
аналогичным
является
единственным
доступным
средством
разумное
время
эта
проблема
стоит
острее
качестве
самых
предварительных
результатов
провели
эксперимент
рам-
ках
которого
наша
априорная
модель
моделью
бета-биномиального
распределения
несжатой
форме
априорным
распределением
скрытый
параметр
beta
1.0
1.0
использовали
алгоритм
метрополиса-гастингса
получения
выборки
апосте-
риорного
распределения
скрытого
параметра
учетом
проведения
четырех
успешных
испытаний
схеме
бернулли
bernoulli
соответствующая
вероятностная
программа
представлена
рис
12.
затем
использовали
наш
подход
выводу
вероятностных
программ
априорное
распределение
которых
статистически
схожим
полученной
выборкой
желае-
мого
апостериорного
распределения
примеры
найденных
вероятностных
программ
даны
рис
12.
данном
конкретном
случае
можем
аналитически
найти
записать
виде
вероятностной
программы
апостериорное
распределение
равное
beta
5.0
1.0
та-
ким
образом
полученные
результаты
показывают
нашли
хорошее
приближение
апостериорного
распределения
2.6
обобщение
порождающего
вероятностного
программирования
отмечено
ранее
порождающие
вероятностные
модели
определяют
совместное
распределение
часто
задаваемое
сначала
помощью
распределения
затем
помощью
условного
распределения
порождающие
вероятностные
модели
мо-
гут
использоваться
либо
генерации
выборок
напрямую
либо
качестве
промежуточного
этапа
нахождения
условного
распределения
скрытых
параметров
обычно
помощью
приближенных
методов
статистического
вывода
оп-
тимизации
рамках
наших
экспериментов
описанных
выше
решали
задачу
вывода
веро-
ятностной
программы
которая
определяет
вероятностную
модель
общем
случае
пара-
метризованную
априорное
распределение
которой
соответствует
приближает
иско-
мое
распределение
заданное
аналитически
виде
выборки
виде
дорогостоя-
щего
генератора
элементов
выборки
языке
вероятностного
программирования
church
поддерживающего
проведение
статистического
запроса
внутри
другого
статистического
запроса
данная
задача
сформулирована
следующим
образом
подобно
тому
формулировали
anglican/venture
query
program−text
program
productions
input−types
output−type
lambda
arg1
arg
program−text
eval
program−text
noisy−distance−equal
multiple−query
program
arg1_1
arg1_n
true
noisy−distance−equal
multiple−query
program
argm_1
argm_n
true
expected−statisticsm
query
defines
expression
predicate
cid:22
задание
запроса
church
input-types
cid:22
перечисление
типов
входных
аргументов
output-type
cid:22
тип
выход-
ного
значения
процедуры
noisy-distance-equal
cid:22
функция
сравнения
статистик
get-statistics
cid:22
функция
извлечения
статистик
распределения
multiple-query
cid:22
аналог
query
возвращающий
несколько
элементов
распределения
вместо
одного
эле-
мента
expected-statistics
...
cid:22
значений
статистик
искомого
распределения
автор
считает
общо
нахождения
вероятностной
модели
служащей
вспомогательным
инструментом
нахождении
условного
апостериорного
распределения
можем
заинтересованы
постановке
задачи
следующим
обра-
зом
query
program−text
latent−productions
latent−types
productions
latent−types
input−types
output−type
program
eval
lambda
arg1
argn
program−text
program−text
noisy−latents−equal
multiple−query
noisy−outputs−equal
program
arg1_1
arg1_n
output1
expected−latents1
noisy−latents−equal
multiple−query
noisy−outputs−equal
expected−latentsm
program
argm_1
argm_n
outputm
latent-productions
cid:22
правила
порождения
объекта
представляющего
скрытые
па-
раметры
типов
latent-types
cid:190
лениво¿
создаваемые
помощью
процедуры
mem
latent-variables
cid:22
объект
представляющий
скрытые
параметры
arg
...
...
cid:22
зна-
чений
аргументов
output
...
cid:22
значений
наблюдаемых
данных
expected-latents
...
cid:22
значений
ожидаемых
скрытых
параметров
таким
образом
рамках
данной
формулировки
ищем
вероятностную
програм-
содержащую
скрытые
переменные
определяемые
latent-variables
наблюдаемые
переменные
определяемые
выполнением
program
вывод
производится
учетом
тре-
нировочных
троек
ˆti
ˆxi
cid:22
дополнительная
параметризация
ˆxi
cid:22
значения
наблюдаемых
переменных
ˆti
cid:22
ожидаемые
значения
скрытых
переменных
следует
отметить
настоящее
время
обобщенный
статистический
вы-
вод
использованием
вероятностных
языков
программирования
производится
достаточно
медленно
решение
практических
задач
таким
образом
пока
имеет
смысла
стороны
дальнейшим
развитием
обобщенных
методов
статистического
вывода
других
решений
например
оптимизации
поиска
использовании
продуман-
ных
алгоритмов
программной
реализации
структур
данных
специализиро-
ванным
аппаратным
обеспечением
автоматизированная
генерация
использова-
ние
порождающих
вероятностных
моделей
успешно
продуктивно
применяться
практике
заключение
первой
части
данной
работы
очень
кратко
реферативно
представлено
введение
вероятностное
программирование
примере
языков
church/venture/anglican
первое
подобное
введение
русском
языке
насколько
известно
автору
второй
части
данной
работы
представлен
подход
порождению
вероятност-
ных
программ
обобщающих
распределения
представленные
либо
виде
выборки
либо
виде
аналитического
представления
например
виде
значения
статистик
причем
мета-
вероятностная
модель
вероятностных
моделей
также
записывается
виде
вероятностной
программы
используя
данный
подход
получены
предварительные
положительные
результаты
статистического
вывода
апостериорного
распределения
искомых
вероят-
ностных
программ
методами
монте-карло
схеме
цепей
маркова
числе
ав-
томатически
выведена
вероятностная
программа
генерирующая
элементы
выборки
семейства
распределений
бернулли
список
использованных
источников
goodman
noah
principles
practice
probabilistic
programming
acm
sigplan
notices
acm
cid:22
vol
cid:22
2013
cid:22
399–402
church
language
generative
models
noah
goodman
vikash
mansinghka
daniel
roy
cid:22
2008
cid:22
220–229
mansinghka
vikash
selsam
daniel
perov
yura
venture
higher-order
probabilistic
programming
platform
programmable
inference
arxiv
preprint
arxiv:1404.0099
cid:22
2014
wood
frank
van
meent
jan
willem
mansinghka
vikash
new
approach
probabilistic
programming
inference
proceedings
17th
international
conference
artiﬁcial
intelligence
statistics
cid:22
2014
approximate
bayesian
image
interpretation
using
generative
probabilistic
graphics
programs
vikash
mansinghka
tejas
kulkarni
yura
perov
josh
tenenbaum
advances
neural
information
processing
systems
cid:22
2013
cid:22
1520–1528
perov
yura
wood
frank
learning
probabilistic
programs
статья
отправлена
конференцию
cid:22
2014
лопатников
леонид
исидорович
экономико-математический
словарь
cid:22
5-е
изд.
пе-
рераб
доп
cid:22
дело
2003
ветров
дмитрий
петрович
кропотов
дмитрий
александрович
байесовские
мето-
машинного
обучения
курс
лекций
методы
монте-карло
схеме
марковских
цепей
cid:22
2011
cid:22
url
http
//www.machinelearning.ru/wiki/images/6/6b/bmmo11_
10.pdf
рассел
стюарт
норвиг
питер
искусственный
интеллект
современный
подход
2-е
издание
cid:22
cid:190
вильямс¿
2007
bishop
christopher
pattern
recognition
machine
learning
cid:22
springer
new
york
2006
murphy
kevin
machine
learning
probabilistic
perspective
cid:22
mit
press
2012
ветров
дмитрий
петрович
кропотов
дмитрий
александрович
байесовские
методы
машинного
обучения
курс
лекций
cid:22
2013
cid:22
url
http
//www.machinelearning
ru/
сайт
вероятностном
программировании
cid:22
2014
cid:22
url
http
probabilistic-programming.org/
абельсон
харольд
сассман
джеральд
джей
структура
интерпретация
компью-
терных
программ
cid:22
добросвет
кду
2010
freer
cameron
mansinghka
vikash
roy
daniel
probabilistic
programs
probably
computationally
tractable
nips
2010
workshop
monte
carlo
methods
modern
applications
cid:22
2010
wingate
david
stuhlmueller
andreas
goodman
noah
lightweight
implementations
probabilistic
programming
languages
via
transformational
compilation
cid:22
2011
cid:22
131
николенко
сергей
игоревич
вероятностное
обучение
курс
лекций
cid:22
2007
cid:22
url
http
//logic.pdmi.ras.ru/~sergey/index.php
page=mlbayes
chib
siddhartha
greenberg
edward
understanding
metropolis-hastings
algorithm
american
statistician
cid:22
1995
cid:22
vol
cid:22
327–335
зубков
шуваев
вычисление
моментов
комбинаторных
статистик
пе-
рестановочных
случайных
величин
дискретная
математика
cid:22
2005
perov
yura
mansinghka
vikash
exploiting
conditional
independence
eﬃcient
automatic
multicore
inference
church
cid:22
2012
blei
david
andrew
jordan
michael
latent
dirichlet
allocation
journal
machine
learning
research
cid:22
2003
cid:22
vol
cid:22
993–1022
jeﬀ
reduced
traces
jiting
church
thesis
jeﬀ
massachusetts
institute
technology
cid:22
2013
captcha
using
hard
problems
security
luis
von
ahn
manuel
blum
nicholas
hopper
john
langford
advances
cryptology
cid:22
eurocrypt
2003
cid:22
springer
2003
cid:22
294–311
goodman
tenenbaum
probabilistic
models
cognition
cid:22
2014
cid:22
url
https
//probmods.org/
repository
generative
models
composite
authors
edited
andreas
stuhlm¨uller
cid:22
2014
cid:22
url
http
//forestdb.org/
wood
frank
probabilistic
programming
tutorial
machine
learning
summer
school
iceland
cid:22
2014
cid:22
url
http
//www.robots.ox.ac.uk/~fwood/anglican/teaching/
mlss2014/
paige
brooks
wood
frank
compilation
target
probabilistic
programming
languages
cid:22
2014
maddison
chris
tarlow
daniel
structured
generative
models
natural
source
code
cid:22
2014
liang
percy
jordan
michael
klein
dan
learning
programs
hierarchical
bayesian
approach
cid:22
2010
cid:22
639–646
marsaglia
george
bray
thomas
convenient
method
generating
normal
variables
cid:22
1964
cid:22
vol
cid:22
260–264
box
george
muller
mervin
note
generation
random
normal
deviates
cid:22
1958
cid:22
vol
cid:22
610–611
devroye
luc
non-uniform
random
variate
generation
cid:22
1986
gulwani
sumit
kitzelmann
emanuel
schmid
ute
approaches
applications
inductive
programming
dagstuhl
seminar
13502
cid:22
2014
cid:22
vol
cid:22
43–
cid:22
url
http
//drops.dagstuhl.de/opus/volltexte/2014/4507
looks
moshe
program
evolution
general
intelligence
frontiers
artificial
intelligence
applications
cid:22
2007
cid:22
vol
157
cid:22
125
muggleton
stephen
raedt
luc
inductive
logic
programming
theory
methods
cid:22
1994
cid:22
vol
cid:22
629–679
muggleton
stephen
feng
cao
eﬃcient
induction
logic
programs
cid:22
1992
cid:22
vol
cid:22
281–298
raedt
luc
kersting
kristian
probabilistic
inductive
logic
programming
cid:22
springer
2008
kersting
kristian
inductive
logic
programming
approach
statistical
relational
learning
ios
press
cid:22
2005
cid:22
1–228
cid:22
url
http
//people.csail.mit.edu/
kersting/faiailpsrl/
muggleton
stephen
stochastic
logic
programs
cid:22
1996
cid:22
vol
cid:22
254–264
exploiting
compositionality
explore
large
space
model
structures
roger
grosse
ruslan
salakhutdinov
william
freeman
joshua
tenenbaum
cid:22
2012
structure
discovery
nonparametric
regression
compositional
kernel
search
david
duvenaud
james
robert
lloyd
roger
grosse
cid:22
2013
hwang
irvin
stuhlm¨uller
andreas
goodman
noah
inducing
probabilistic
programs
bayesian
program
merging
cid:22
2011
gordon
andrew
agenda
probabilistic
programming
usable
portable
ubiquitous
workshop
probabilistic
programming
democratizing
machine
learning
cid:22
2013
markov
chain
monte
carlo
without
likelihoods
paul
marjoram
john
molitor
vincent
plagnol
simon
tavar´e
cid:22
2003
cid:22
vol
100
cid:22
15324–15328
johnson
mark
griﬃths
thomas
goldwater
sharon
adaptor
grammars
framework
specifying
compositional
nonparametric
bayesian
models
cid:22
2007
cid:22
vol
cid:22
641
knuth
donald
art
computer
programming
3rd
edn.
vol
cid:22
1998
quinlan
ross
simplifying
decision
trees
cid:22
1987
cid:22
vol
cid:22
221–234
bache
lichman
uci
machine
learning
repository
cid:22
2013
cid:22
url
http
//archive.ics.uci.edu/ml
tenenbaum
joshua
jonas
eric
mansinghka
vikash
stochastic
digital
circuits
probabilistic
inference
cid:22
2008
jonas
eric
michael
stochastic
architectures
probabilistic
computation
thesis
eric
michael
jonas
massachusetts
institute
technology
cid:22
2014
