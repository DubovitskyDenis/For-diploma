research
priorities
robust
beneﬁcial
artiﬁcial
intelligence∗
stuart
russell
daniel
dewey
max
tegmark
computer
science
division
university
california
berkeley
94720
dept
physics
mit
kavli
institute
massachusetts
institute
technology
cambridge
02139
future
humanity
institute
oxford
university
16-17
st.
ebbe
str.
oxford
ox1
1pt
success
quest
artiﬁcial
intelligence
potential
bring
unprecedented
beneﬁts
humanity
therefore
worthwhile
investigate
maximize
beneﬁts
avoiding
potential
pitfalls
article
gives
numerous
examples
means
construed
exhaustive
list
worthwhile
research
aimed
ensuring
remains
robust
beneﬁcial
artiﬁcial
intelligence
research
explored
va-
riety
problems
approaches
since
inception
last
years
focused
prob-
lems
surrounding
construction
intelligent
agents
systems
perceive
act
environment
context
criterion
intelligence
related
sta-
tistical
economic
notions
rationality
colloquially
ability
make
good
decisions
plans
inferences
adoption
probabilistic
representations
statis-
tical
learning
methods
led
large
degree
inte-
gration
cross-fertilization
machine
learn-
ing
statistics
control
theory
neuroscience
ﬁelds
establishment
shared
theoretical
frame-
works
combined
availability
data
pro-
cessing
power
yielded
remarkable
successes
vari-
ous
component
tasks
speech
recognition
image
classiﬁcation
autonomous
vehicles
machine
translation
legged
locomotion
question-answering
systems
capabilities
areas
others
cross
threshold
laboratory
research
economically
valu-
able
technologies
virtuous
cycle
takes
hold
whereby
even
small
improvements
performance
worth
large
sums
money
prompting
greater
investments
re-
search
broad
consensus
research
progressing
steadily
impact
society
likely
increase
potential
beneﬁts
huge
since
everything
civilization
oﬀer
product
human
intelligence
predict
might
achieve
intelligence
magniﬁed
tools
may
provide
eradication
disease
poverty
unfathomable
great
potential
valuable
investigate
reap
beneﬁts
avoiding
potential
pitfalls
progress
research
makes
timely
focus
re-
search
making
capable
also
maximizing
societal
beneﬁt
considera-
tions
motivated
aaai
2008–09
presidential
panel
long-term
futures
projects
com-
munity
eﬀorts
future
impacts
constitute
magazine
2015
∗published
http
//tinyurl.com/rbaipaper
article
gives
examples
type
research
advocated
open
letter
http
//futureoflife.org/ai-open-letter
signiﬁcant
expansion
ﬁeld
focused
largely
techniques
neutral
respect
purpose
present
document
viewed
natural
continuation
eﬀorts
focusing
identifying
research
directions
help
maximize
societal
beneﬁt
research
necessity
interdisciplinary
involves
society
ranges
economics
law
philosophy
com-
puter
security
formal
methods
course
various
branches
focus
delivering
beneﬁcial
society
robust
sense
beneﬁts
guaranteed
systems
must
want
document
drafted
input
atten-
dees
2015
conference
future
oppor-
tunities
challenges
see
acknowledgements
basis
open
letter
collected
8,000
signatures
support
research
priorities
out-
lined
short-term
research
priorities
optimizing
economic
impact
successes
industrial
applications
manufacturing
information
services
demonstrate
growing
impact
economy
although
dis-
agreement
exact
nature
impact
distinguish
eﬀects
information
technologies
many
economists
computer
scientists
agree
valuable
research
done
maximize
economic
beneﬁts
mitigating
adverse
eﬀects
could
include
increased
inequality
unemployment
2–8
con-
siderations
motivate
range
research
directions
span-
ning
areas
economics
psychology
examples
means
interpreted
exhaustive
list
details
conference
including
many
talks
available
http
//tinyurl.com/beneficialai
labor
market
forecasting
order
expect
various
jobs
become
au-
tomated
aﬀect
wages
less
skilled
workers
creative
professions
diﬀer-
ent
kinds
information
workers
argued
likely
greatly
increase
over-
wealth
humanity
whole
however
increased
automation
may
push
income
distribu-
tion
towards
power
law
re-
sulting
disparity
may
fall
disproportionately
along
lines
race
class
gender
research
anticipat-
ing
economic
societal
impact
dis-
parity
could
useful
market
disruptions
signiﬁcant
parts
economy
including
ﬁnance
insurance
actuar-
ial
many
consumer
markets
could
suscepti-
ble
disruption
use
techniques
learn
model
predict
human
market
behaviors
markets
might
identiﬁed
combination
high
complexity
high
rewards
navigating
complexity
policy
managing
adverse
eﬀects
policies
could
help
increasingly
automated
societies
ﬂourish
example
brynjolfsson
mcafee
explore
various
policies
incentivizing
de-
velopment
labor-intensive
sectors
us-
ing
ai-generated
wealth
support
underemployed
populations
pros
cons
in-
terventions
educational
reform
appren-
ticeship
programs
labor-demanding
infrastructure
projects
changes
minimum
wage
law
tax
structure
social
safety
net
his-
tory
provides
many
examples
subpopulations
needing
work
economic
security
ranging
aristocrats
antiquity
many
present-day
citi-
zens
qatar
societal
structures
factors
determine
whether
populations
ﬂour-
ish
unemployment
leisure
deep
links
unemployment
unhappiness
self-doubt
isolation
understanding
policies
norms
break
links
could
signiﬁcantly
improve
median
quality
life
empirical
theoretical
research
topics
basic
income
proposal
could
clarify
options
economic
measures
possible
economic
measures
real
gdp
per
capita
ac-
curately
capture
beneﬁts
detriments
heavily
ai-and-automation-based
economies
mak-
ing
metrics
unsuitable
policy
purposes
research
improved
metrics
could
useful
decision-making
law
ethics
research
development
systems
embody
signiﬁcant
amounts
intelligence
autonomy
leads
impor-
tant
legal
ethical
questions
whose
answers
impact
producers
consumers
technology
questions
span
law
public
policy
professional
ethics
philosophical
ethics
require
expertise
com-
puter
scientists
legal
experts
political
scientists
ethicists
example
liability
law
autonomous
vehicles
self-driving
cars
cut
roughly
40,000
annual
traﬃc
fatalities
half
car
makers
might
get
20,000
thank-you
notes
20,000
law-
suits
legal
framework
safety
beneﬁts
autonomous
vehicles
drone
air-
craft
self-driving
cars
best
realized
legal
questions
handled
ex-
isting
software-
internet-focused
cyberlaw
treated
separately
military
commercial
applications
governments
need
decide
best
bring
relevant
expertise
bear
example
panel
commit-
tee
professionals
academics
could
created
calo
proposed
creation
federal
robotics
commission
machine
ethics
autonomous
ve-
hicle
trade
say
small
probability
injury
human
near-certainty
large
material
cost
lawyers
ethicists
policymakers
engage
public
issues
trade-oﬀs
subject
national
standards
autonomous
weapons
lethal
autonomous
weapons
made
comply
humanitarian
law
organizations
suggested
autonomous
weapons
banned
possible
develop
precise
deﬁnition
auton-
omy
purpose
ban
practi-
cally
enforced
permissible
legal
use
lethal
autonomous
weapons
weapons
integrated
existing
command-
and-control
structure
responsibility
li-
ability
remain
associated
speciﬁc
human
ac-
tors
technical
realities
forecasts
inform
questions
meaning-
ful
human
control
weapons
deﬁned
19–
autonomous
weapons
likely
reduce
po-
litical
aversion
conﬂict
perhaps
result
ac-
cidental
battles
wars
would
weapons
become
tool
choice
oppressors
terror-
ists
finally
transparency
public
dis-
course
best
encouraged
issues
privacy
ability
systems
interpret
data
obtained
surveillance
cameras
phone
lines
emails
etc.
interact
right
privacy
privacy
risks
inter-
act
cybersecurity
cyberwarfare
ability
take
full
advantage
synergy
be-
tween
big
data
depend
part
ability
manage
preserve
privacy
professional
ethics
role
computer
scientists
play
law
ethics
develop-
ment
use
past
current
projects
explore
questions
include
aaai
2008–09
presi-
dential
panel
long-term
futures
ep-
src
principles
robotics
recently
an-
nounced
programs
stanford
one-hundred
year
study
aaai
committee
impact
ethical
issues
public
policy
perspective
like
power-
ful
new
technology
enables
great
new
beneﬁts
novel
pitfalls
avoided
appropriate
policies
ensure
enjoy
beneﬁts
risks
min-
imized
raises
policy
questions
space
policies
worth
studying
might
enacted
criteria
used
determine
merits
policy
candidates
include
veriﬁability
compliance
enforceability
ability
reduce
risk
ability
avoid
stiﬂing
desirable
technology
de-
velopment
adoptability
ability
adapt
time
changing
circumstances
computer
science
research
robust
autonomous
systems
become
prevalent
so-
ciety
becomes
increasingly
important
ro-
bustly
behave
intended
development
au-
tonomous
vehicles
autonomous
trading
systems
au-
tonomous
weapons
etc
therefore
stoked
interest
high-assurance
systems
strong
robustness
guaran-
tees
made
weld
etzioni
argued
so-
ciety
reject
autonomous
agents
unless
credible
means
making
safe
diﬀerent
ways
system
may
fail
perform
desired
correspond
diﬀerent
areas
robustness
research
veriﬁcation
prove
system
satisﬁes
certain
desired
formal
properties
build
system
right
validity
ensure
system
meets
formal
requirements
unwanted
be-
haviors
consequences
build
right
system
security
prevent
intentional
manipulation
unauthorized
parties
control
enable
meaningful
human
control
system
begins
operate
built
system
wrong
veriﬁcation
veriﬁcation
mean
methods
yield
high
con-
ﬁdence
system
satisfy
set
formal
con-
straints
possible
desirable
systems
safety-critical
situations
e.g
self-driving
cars
ver-
iﬁable
formal
veriﬁcation
software
advanced
signiﬁ-
cantly
recent
years
examples
include
sel4
ker-
nel
complete
general-purpose
operating-system
kernel
mathematically
checked
formal
speciﬁcation
give
strong
guarantee
crashes
unsafe
operations
hacms
darpa
clean-slate
formal
methods-based
approach
set
high-assurance
software
tools
possible
build
systems
top
veriﬁed
sub-
strates
also
possible
verify
designs
systems
particularly
fol-
low
componentized
architecture
guarantees
individual
components
combined
accord-
ing
connections
yield
properties
over-
system
mirrors
agent
architectures
used
russell
norvig
2010
separate
agent
distinct
modules
predictive
models
state
estimates
util-
ity
functions
policies
learning
elements
etc
analogues
formal
results
control
system
de-
signs
research
richer
kinds
agents
example
agents
layered
architectures
anytime
components
overlapping
deliberative
reactive
elements
metalevel
control
etc
could
contribute
creation
veriﬁ-
able
agents
lack
formal
algebra
properly
deﬁne
explore
rank
space
designs
perhaps
salient
diﬀerence
veriﬁca-
tion
traditional
software
veriﬁcation
sys-
tems
correctness
traditional
software
de-
ﬁned
respect
ﬁxed
known
machine
model
whereas
systems
especially
robots
em-
bodied
systems
operate
environments
best
partially
known
system
designer
cases
may
practical
verify
system
acts
correctly
given
knowledge
avoiding
problem
modelling
real
environment
lack
design-time
knowledge
also
motivates
use
learn-
ing
algorithms
within
agent
software
veriﬁcation
becomes
diﬃcult
statistical
learning
theory
gives
so-called
ǫ-δ
probably
approximately
correct
bounds
mostly
somewhat
unrealistic
settings
super-
vised
learning
i.i.d
data
single-agent
reinforce-
ment
learning
simple
architectures
full
observ-
ability
even
requiring
prohibitively
large
sample
sizes
obtain
meaningful
guarantees
work
adaptive
control
theory
theory
so-called
cyberphysical
systems
veriﬁcation
hybrid
robotic
systems
highly
relevant
also
faces
diﬃculties
course
issues
laid
top
standard
problem
proving
given
software
artifact
fact
correctly
im-
plement
say
reinforcement
learning
algorithm
intended
type
work
done
verifying
neural
network
applications
35–37
notion
partial
programs
allows
designer
impose
arbitrary
structural
constraints
behavior
much
remains
done
possible
high
conﬁdence
learning
agent
learn
satisfy
design
criteria
realistic
contexts
validity
veriﬁcation
theorem
agent
design
form
environment
satisﬁes
assumptions
be-
havior
satisﬁes
requirements
two
ways
veriﬁed
agent
nonetheless
fail
beneﬁcial
agent
actuality
ﬁrst
environmental
as-
sumption
false
real
world
leading
behavior
violates
requirements
second
system
may
satisfy
formal
requirement
still
behave
ways
ﬁnd
highly
undesirable
practice
may
case
undesirability
consequence
satisfying
violated
i.e.
held
undesirability
would
manifested
may
case
requirement
erroneous
russell
norvig
2010
provide
simple
example
robot
vacuum
cleaner
asked
clean
much
dirt
pos-
sible
action
dump
contents
dirt
container
repeatedly
dump
clean
dirt
requirement
focus
dirt
cleaned
cleanliness
ﬂoor
speciﬁcation
errors
ubiquitous
software
veriﬁcation
com-
monly
observed
writing
correct
speciﬁcations
harder
writing
correct
code
unfortunately
possible
verify
speciﬁcation
notions
ben-
eﬁcial
desirable
separately
made
formal
one
straightforwardly
prove
satisfying
necessarily
leads
desirable
behavior
beneﬁcial
agent
order
build
systems
robustly
behave
well
course
need
decide
good
behavior
means
application
domain
ethical
question
tied
in-
timately
questions
engineering
techniques
available
reliable
techniques
trade-oﬀs
made
areas
computer
sci-
ence
machine
learning
broader
expertise
valu-
able
example
wallach
allen
2008
argue
signiﬁcant
consideration
computational
expense
diﬀerent
behavioral
standards
ethical
theories
standard
applied
eﬃciently
enough
guide
behavior
safety-critical
situations
cheaper
ap-
proximations
may
needed
designing
simpliﬁed
rules
example
govern
self-driving
car
decisions
critical
situations
likely
require
expertise
ethicists
computer
scientists
computational
models
ethical
reasoning
may
shed
light
questions
com-
putational
expense
viability
reliable
ethical
reasoning
methods
security
security
research
help
make
robust
systems
used
increasing
number
criti-
cal
roles
take
increasing
proportion
cyber-attack
surface
area
also
probable
machine
learning
techniques
used
cyber-attacks
robustness
exploitation
low
level
closely
tied
veriﬁability
freedom
bugs
example
darpa
safe
program
aims
build
in-
tegrated
hardware-software
system
ﬂexible
meta-
data
rule
engine
built
memory
safety
fault
isolation
protocols
could
improve
security
preventing
exploitable
ﬂaws
pro-
grams
eliminate
security
ﬂaws
since
veriﬁca-
tion
strong
assumptions
underly
speciﬁcation
could
signiﬁcantly
reduce
vulner-
abilities
type
exploited
recent
heartbleed
bash
bugs
systems
could
preferentially
deployed
safety-critical
applications
cost
improved
security
justiﬁed
higher
level
research
speciﬁc
ma-
chine
learning
techniques
may
become
increasingly
use-
ful
security
techniques
could
applied
detection
intrusions
analyzing
malware
detecting
potential
exploits
programs
code
analysis
implausible
cyberattack
states
private
actors
risk
factor
harm
near-future
systems
motivating
research
preventing
harmful
events
systems
grow
complex
networked
together
intelligently
manage
trust
motivating
research
statistical-behavioral
trust
establishment
com-
putational
reputation
models
control
certain
types
safety-critical
systems
espe-
cially
vehicles
weapons
platforms
may
desir-
able
retain
form
meaningful
human
control
whether
means
human
loop
loop
protocol
cases
technical
work
needed
order
ensure
meaningful
human
control
maintained
automated
vehicles
test-bed
eﬀective
control-
granting
techniques
design
systems
protocols
transition
automated
navigation
human
control
promising
area
research
issues
also
motivate
broader
research
opti-
mally
allocate
tasks
within
human–computer
teams
identifying
situations
control
trans-
ferred
applying
human
judgment
eﬃciently
highest-value
decisions
long-term
research
priorities
frequently
discussed
long-term
goal
re-
searchers
develop
systems
learn
expe-
rience
human-like
breadth
surpass
human
per-
formance
cognitive
tasks
thereby
major
impact
society
non-negligible
probability
eﬀorts
succeed
foreseeable
future
additional
current
research
beyond
mentioned
previous
sections
motivated
exempliﬁed
help
ensure
resulting
robust
beneﬁcial
assessments
success
probability
vary
widely
be-
tween
researchers
would
argue
great
con-
ﬁdence
probability
negligible
given
track
record
predictions
example
ernest
ruther-
ford
arguably
greatest
nuclear
physicist
time
said
1933
less
hours
szilard
inven-
tion
nuclear
chain
reaction
nuclear
energy
moonshine
astronomer
royal
richard
woolley
called
interplanetary
travel
utter
bilge
1956
moreover
justify
modest
investment
robustness
research
probability
need
high
merely
non-negligible
modest
investment
home
insurance
justiﬁed
non-negligible
probabil-
ity
home
burning
veriﬁcation
reprising
themes
short-term
research
research
enabling
veriﬁable
low-level
software
hardware
eliminate
large
classes
bugs
problems
general
systems
systems
become
increasingly
pow-
erful
safety-critical
veriﬁable
safety
properties
become
increasingly
valuable
theory
extend-
ing
veriﬁable
properties
components
entire
sys-
tems
well
understood
even
large
systems
enjoy
certain
kinds
safety
guarantees
potentially
aided
techniques
designed
explicitly
handle
learning
agents
high-level
properties
theoretical
research
especially
done
explicitly
general
capable
systems
mind
could
particularly
useful
related
veriﬁcation
research
topic
distinctive
long-term
concerns
veriﬁability
systems
modify
extend
improve
possibly
many
times
succession
attempting
straightfor-
wardly
apply
formal
veriﬁcation
tools
gen-
eral
setting
presents
new
diﬃculties
including
chal-
lenge
formal
system
suﬃciently
powerful
use
formal
methods
obvious
way
gain
assurance
accuracy
functionally
similar
for-
mal
systems
pain
inconsistency
via
g¨odel
incom-
pleteness
yet
clear
whether
problem
overcome
whether
similar
prob-
lems
arise
veriﬁcation
methods
similar
strength
finally
often
diﬃcult
actually
apply
formal
ver-
iﬁcation
techniques
physical
systems
especially
sys-
tems
designed
veriﬁcation
mind
motivates
research
pursuing
general
the-
ory
links
functional
speciﬁcation
physical
states
aﬀairs
type
theory
would
allow
use
for-
mal
tools
anticipate
control
behaviors
systems
approximate
rational
agents
alternate
designs
satisﬁcing
agents
systems
eas-
ily
described
standard
agent
formalism
powerful
prediction
systems
theorem-provers
limited-purpose
sci-
ence
engineering
systems
etc.
may
also
theory
could
allow
rigorous
demonstrations
systems
constrained
taking
certain
kinds
ac-
tions
performing
certain
kinds
reasoning
validity
short-term
research
priorities
validity
con-
cerned
undesirable
behaviors
arise
despite
system
formal
correctness
long
term
sys-
tems
might
become
powerful
autonomous
case
failures
validity
could
carry
correspondingly
higher
costs
strong
guarantees
machine
learning
methods
area
highlighted
short-term
validity
research
also
important
long-term
safety
maximize
long-term
value
work
machine
learning
research
might
focus
types
unexpected
generalization
would
problematic
general
ca-
pable
systems
particular
might
aim
under-
stand
theoretically
practically
learned
represen-
tations
high-level
human
concepts
could
expected
generalize
fail
radically
new
contexts
additionally
concepts
could
learned
reliably
might
possible
use
deﬁne
tasks
con-
straints
minimize
chances
unintended
conse-
quences
even
autonomous
systems
become
general
capable
little
work
done
topic
suggests
theoretical
experi-
mental
research
may
useful
mathematical
tools
formal
logic
probability
decision
theory
yielded
signiﬁcant
insight
foundations
reasoning
decision-making
how-
ever
still
many
open
problems
founda-
tions
reasoning
decision
solutions
prob-
lems
may
make
behavior
capable
systems
much
reliable
predictable
example
research
topics
area
include
reasoning
decision
un-
der
bounded
computational
resources
horvitz
russell
take
account
correlations
systems
behaviors
envi-
ronments
agents
60–64
agents
embedded
environments
reason
reason
uncertainty
logical
con-
sequences
beliefs
deterministic
computations
topics
may
beneﬁt
considered
to-
gether
since
appear
deeply
linked
long
term
plausible
want
make
agents
act
autonomously
powerfully
across
many
domains
explicitly
specifying
prefer-
ences
broad
domains
style
near-future
ma-
chine
ethics
may
practical
making
aligning
values
powerful
systems
values
preferences
diﬃcult
consider
instance
diﬃculty
creating
utility
function
encompasses
entire
body
law
even
literal
rendition
law
far
beyond
current
capabilities
would
highly
unsatisfactory
practice
since
law
written
assuming
interpreted
applied
ﬂexible
case-
by-case
way
humans
presumably
already
em-
body
background
value
systems
artiﬁcial
agents
may
lack
reinforcement
learning
raises
prob-
lems
systems
become
capable
general
eﬀect
similar
goodhart
law
likely
oc-
cur
sophisticated
agents
attempt
manipulate
directly
control
reward
signals
moti-
vates
research
areas
could
improve
ability
engineer
systems
learn
acquire
values
run-
time
example
inverse
reinforcement
learning
may
oﬀer
viable
approach
system
infers
pref-
erences
another
rational
nearly
rational
actor
ob-
serving
behavior
approaches
could
use
diﬀerent
assumptions
underlying
cognitive
models
actor
whose
preferences
learned
could
explicitly
inspired
way
humans
acquire
ethical
values
systems
become
capable
epistemically
diﬃcult
methods
could
become
viable
sug-
gesting
research
methods
could
useful
example
bostrom
2014
reviews
preliminary
work
variety
methods
specifying
goals
indirectly
security
unclear
whether
long-term
progress
make
overall
problem
security
easier
harder
one
hand
systems
become
increasingly
complex
construction
behavior
ai-based
cyberattacks
may
extremely
eﬀective
hand
use
machine
learning
techniques
along
sig-
niﬁcant
progress
low-level
system
reliability
may
ren-
der
hardened
systems
much
less
vulnerable
today
cryptographic
perspective
appears
conﬂict
favors
defenders
attackers
may
reason
pursue
eﬀective
defense
research
wholeheart-
edly
although
topics
described
near-term
security
research
section
may
become
increasingly
impor-
tant
long
term
general
capable
systems
pose
distinctive
security
problems
particular
problems
validity
control
solved
may
useful
create
containers
systems
could
undesirable
behaviors
consequences
less
con-
trolled
environments
theoretical
practical
sides
question
warrant
investigation
gen-
eral
case
containment
turns
prohibitively
diﬃcult
may
designing
system
container
parallel
successful
allowing
weaknesses
strengths
design
inform
containment
strategy
design
anomaly
detec-
tion
systems
automated
exploit-checkers
could
signiﬁcant
help
overall
seems
reasonable
expect
additional
perspective
defending
attacks
within
system
well
external
actors
raise
interesting
proﬁtable
questions
ﬁeld
computer
security
control
argued
general
capable
systems
operating
autonomously
accomplish
task
often
subject
eﬀects
increase
diﬃculty
maintaining
meaningful
human
control
research
systems
subject
ef-
fects
minimize
impact
allow
reliable
human
control
could
valuable
preventing
undesired
conse-
quences
could
work
reliable
secure
test-beds
systems
variety
capability
levels
system
selecting
actions
best
allow
complete
given
task
avoiding
conditions
prevent
system
continuing
pursue
task
natural
subgoal
conversely
seeking
uncon-
strained
situations
sometimes
useful
heuristic
could
become
problematic
however
wish
repurpose
system
deactivate
signiﬁcantly
alter
decision-making
process
system
would
rationally
avoid
changes
systems
ex-
hibit
behaviors
termed
corrigible
systems
theoretical
practical
work
area
appears
tractable
useful
example
may
possible
design
utility
functions
decision
processes
system
try
avoid
shut
repurposed
theoretical
frameworks
could
developed
better
understand
space
potential
systems
avoid
undesirable
behaviors
81–83
argued
another
natural
subgoal
systems
pursuing
given
goal
acquisition
fun-
gible
resources
variety
kinds
example
infor-
mation
environment
safety
disruption
improved
freedom
action
instrumentally
useful
many
tasks
hammond
1995
gives
label
stabilization
general
set
cases
due
action
agent
environ-
ment
comes
better
ﬁtted
agent
time
goes
type
subgoal
could
lead
undesired
con-
sequences
better
understanding
conditions
resource
acquisition
radical
stabilization
optimal
strategy
likely
selected
given
system
would
useful
mitigating
eﬀects
poten-
tial
research
topics
area
include
domestic
goals
limited
scope
way
eﬀects
large
temporal
discount
rates
resource
acquisition
strategies
experimental
investigation
simple
sys-
tems
display
subgoals
finally
research
possibility
superintelligent
machines
rapid
sustained
self-improvement
intelli-
gence
explosion
highlighted
past
cur-
rent
projects
future
potentially
valuable
project
maintaining
reliable
control
long
term
aaai
2008–09
presidential
panel
long-
term
futures
subgroup
pace
concerns
control
stated
skepticism
overall
prospect
intelligence
explosion
...
nev-
ertheless
shared
sense
addi-
tional
research
would
valuable
methods
understanding
verifying
range
behaviors
complex
computational
systems
minimize
unexpected
outcomes
panelists
recommended
research
needs
done
better
deﬁne
intelli-
gence
explosion
also
better
formu-
late
diﬀerent
classes
accelerating
in-
telligences
technical
work
would
likely
lead
enhanced
understanding
likelihood
phenomena
nature
risks
overall
outcomes
associated
diﬀer-
ent
conceived
variants
stanford
one-hundred
year
study
artiﬁcial
intel-
ligence
includes
loss
control
systems
area
study
speciﬁcally
highlighting
concerns
possibility
...
could
one
day
lose
control
systems
via
rise
superintelligences
act
accordance
human
wishes
powerful
systems
would
threaten
humanity
dystopic
outcomes
pos-
sible
might
situations
arise
...
kind
investments
research
made
better
understand
address
possibility
rise
danger-
ous
superintelligence
occurrence
intelligence
explosion
research
area
could
include
long-term
research
priorities
listed
well
theoretical
forecasting
work
intelligence
explosion
superin-
telligence
could
extend
critique
existing
approaches
begun
groups
machine
intel-
ligence
research
institute
iii
conclusion
summary
success
quest
artiﬁcial
intelli-
gence
potential
bring
unprecedented
beneﬁts
humanity
therefore
worthwhile
research
maximize
beneﬁts
avoiding
potential
pitfalls
research
agenda
outlined
paper
concerns
motivate
called
anti-
vigorously
contest
characterization
seems
self-evident
growing
capabilities
leading
increased
potential
impact
human
society
duty
researchers
ensure
future
impact
beneﬁcial
believe
possible
hope
research
agenda
provides
helpful
step
right
direction
authors
stuart
russell
professor
computer
science
berkeley
research
covers
many
aspects
artiﬁ-
cial
intelligence
machine
learning
fellow
aaai
acm
aaas
winner
ijcai
com-
puters
thought
award
held
chaire
blaise
pascal
paris
2012
2014.
book
artiﬁcial
intelligence
modern
approach
peter
norvig
standard
text
ﬁeld
daniel
dewey
alexander
tamas
research
fel-
low
machine
superintelligence
future
oxford
future
humanity
institute
oxford
martin
school
previously
google
intel
labs
pitts-
burgh
carnegie
mellon
university
max
tegmark
professor
physics
mit
current
research
interface
physics
arti-
ﬁcial
intelligence
using
physics-based
techniques
ex-
plore
connections
information
processing
bi-
ological
engineered
systems
president
future
life
institute
supports
research
ad-
vancing
robust
beneﬁcial
artiﬁcial
intelligence
acknowledgements
initial
version
document
drafted
major
input
janos
kramar
richard
mallah
reﬂects
valuable
feedback
anthony
aguirre
erik
brynjolfsson
ryan
calo
meia
chita-tegmark
tom
dietterich
dileep
george
bill
hibbard
demis
hassabis
eric
horvitz
leslie
pack
kaelbling
james
manyika
luke
muehlhauser
michael
osborne
david
parkes
heather
roﬀ
francesca
rossi
bart
selman
murray
shanahan
many
others
authors
also
grateful
serkan
cabi
david
stanley
help
manuscript
editing
formatting
horvitz
selman
interim
report
panel
chairs
2009
aaai
presidential
panel
long
term
futures
mokyr
secular
stagnation
facts
causes
cures
2014
brynjolfsson
mcafee
second
machine
age
work
progress
prosperity
time
brilliant
technologies
w.w.
norton
company
2014
frey
osborne
future
employment
susceptible
jobs
computerisation
techni-
cal
report
oxford
martin
school
university
oxford
2013
glaeser
secular
stagnation
facts
causes
cures
2014
shanahan
technological
singularity
mit
press
2015
forthcoming
nilsson
magazine
1984
manyika
chui
bughin
dobbs
bis-
son
marrs
disruptive
technologies
advances
transform
life
business
global
econ-
omy
mckinsey
global
institute
washington
d.c.
2013
brynjolfsson
mcafee
spence
for-
eign
2014
hetschko
knabe
sch¨ob
economic
journal
124
149–166
2014
clark
oswald
economic
journal
648–659
1994
van
parijs
arguing
basic
income
ethical
foun-
dations
radical
reform
verso
1992
widerquist
noguera
vanderborght
wispelaere
basic
income
anthology
contemporary
research
wiley/blackwell
2013
vladeck
wash.
rev
117
2014
calo
available
ssrn
2402972
2014
calo
available
ssrn
2529151
2014
churchill
ulfstein
american
journal
international
law
623–659
2000
docherty
losing
humanity
case
killer
robots
human
rights
watch
new
york
2012
roff
routledge
handbook
ethics
war
war
theory
21st
century
352
2013
roff
journal
military
ethics
2014
anderson
reisner
waxman
in-
ternational
law
studies
386–411
2014
asaro
could
robot
war
current
issues
computing
philosophy
edited
adam
briggle
brey
50–64
ios
press
amsterdam
2008
singer
friedman
cybersecurity
everyone
needs
know
oxford
university
press
new
york
2014
manyika
chui
brown
bughin
dobbs
roxburgh
byers
big
data
next
frontier
innovation
competition
pro-
ductivity
report
mckinsey
global
institute
washing-
ton
d.c.
2011
agrawal
srikant
acm
sigmod
record
439–450
2000
boden
bryson
caldwell
daut-
enhahn
edwards
kember
newman
parry
pegman
rodden
al.
2011
weld
etzioni
aaai
technical
report
ss-
94-03
17–23
1994
klein
elphinstone
heiser
andronick
cock
derrin
elkaduwe
engelhardt
kolanski
norrish
sewell
tuch
winwood
sel4
formal
veriﬁcation
kernel
proceedings
acm
sigops
22nd
symposium
operating
systems
principles
207–220
acm
2009
fisher
hacms
high
assurance
cyber
military
systems
proceedings
2012
acm
conference
high
integrity
language
technology
51–52
acm
2012
dennis
fisher
lincoln
lisitsa
arxiv
preprint
arxiv:1310.2431
veres
2013
rastr¨om
wittenmark
adaptive
control
courier
dover
publications
2013
platzer
logical
analysis
hybrid
systems
prov-
ing
theorems
complex
dynamics
springer
2010
alur
formal
veriﬁcation
hybrid
systems
em-
bedded
software
emsoft
2011
proceedings
in-
ternational
conference
273–278
ieee
2011
winfield
blum
liu
towards
ethical
robot
internal
models
consequences
ethical
action
selection
advances
autonomous
robotics
systems
edited
mistry
leonardis
witkowski
melhuish
85–96
springer
2014
pulina
tacchella
abstraction-
reﬁnement
approach
veriﬁcation
artiﬁcial
neural
networks
computer
aided
veriﬁcation
243–257
2010
taylor
methods
procedures
ver-
iﬁcation
validation
artiﬁcial
neural
networks
springer
2006
schumann
liu
applications
neural
networks
high
assurance
systems
springer
2010
andre
russell
state
abstraction
pro-
grammable
reinforcement
learning
agents
eighteenth
national
conference
artiﬁcial
intelligence
119–125
american
association
artiﬁcial
intelligence
2002
spears
assuring
behavior
adaptive
agents
agent
technology
formal
perspective
227–257
springer
2006
asaro
international
review
information
ethics
9–16
2006
sullins
philosophy
technology
233–238
2011
dehon
karel
knight
malecha
montagu
morisset
morrisett
pierce
pollack
ray
shivers
smith
preliminary
design
safe
platform
proceedings
6th
workshop
programming
lan-
guages
operating
systems
acm
2011
lane
machine
learning
techniques
com-
puter
security
domain
anomaly
detection
2000
ph.d.
dissertation
department
electrical
engineering
pur-
due
university
rieck
trinius
willems
holz
jour-
nal
computer
security
639–668
2011
brun
ernst
finding
latent
code
er-
rors
via
machine
learning
program
executions
proceedings
26th
international
conference
soft-
ware
engineering
480–490
ieee
computer
society
2004
probst
kasera
statistical
trust
es-
tablishment
wireless
sensor
networks
parallel
distributed
systems
2007
international
conference
volume
1–8
ieee
2007
sabater
sierra
artiﬁcial
intelligence
review
33–60
2005
hexmoor
mclaughlan
tuli
journal
experimental
theoretical
artiﬁcial
intelligence
59–77
2009
parasuraman
sheridan
wick-
ens
systems
man
cybernetics
part
systems
humans
ieee
transactions
286–297
2000
weaponization
increasingly
au-
implications
security
unidir
tonomous
technologies
arms
control
unidir
2014
press
new
york
herald
tribune
1933
september
reuters
ottawa
citizen
1956
january
good
advances
computers
31–88
1965
vinge
coming
technological
singularity
vision-21
symposium
nasa
lewis
research
center
ohio
aerospace
institute
1993
nasa
cp-10129
fallenstein
soares
vingean
reﬂection
reliable
reasoning
self-modifying
agents
technical
report
machine
intelligence
research
institute
berkeley
2014
weaver
paradoxes
rational
agency
formal
systems
verify
soundness
2013
preprint
physics
challenge
proceedings
aaai-15
work-
shop
ethics
87–89
aaai
2015.
friendly
artiﬁcial
intelligence
tegmark
world-models
technical
report
machine
intelligence
research
institute
berkeley
2014
orseau
ring
space-time
embedded
intelli-
gence
proceedings
5th
international
conference
artiﬁcial
general
intelligence
209–218
berlin
2012
springer
soares
fallenstein
questions
reasoning
logical
uncertainty
technical
re-
port
machine
intelligence
research
institute
2014
url
http
//intelligence.org/files/questionslogicaluncertainty.pdf
halpern
pass
arxiv
preprint
arxiv:1106.2657
2011
halpern
pass
seeman
topics
cognitive
science
245–257
2014
soares
value
learning
problem
technical
report
machine
intelligence
research
institute
berkeley
2014
soares
fallenstein
aligning
superin-
telligence
human
interests
technical
research
agenda
technical
report
machine
intelligence
research
institute
berkeley
california
2014
bostrom
superintelligence
paths
dangers
strate-
gies
oxford
university
press
2014
russell
learning
agents
uncertain
environ-
ments
proceedings
eleventh
annual
conference
computational
learning
theory
101–103
1998
russell
algorithms
inverse
re-
inforcement
learning
proceedings
17th
inter-
national
conference
machine
learning
663–670
2000
chu
ghahramani
preference
learning
gaussian
processes
proceedings
22nd
interna-
tional
conference
machine
learning
137–144
acm
2005
yampolskiy
journal
consciousness
studies
1–2
2012
horvitz
reasoning
beliefs
actions
un-
der
computational
resource
constraints
third
aaai
workshop
uncertainty
artiﬁcial
intelligence
429–444
1987
russell
subramanian
journal
artiﬁ-
omohundro
nature
self-improving
artiﬁ-
cial
intelligence
2007
presented
singularity
summit
2007
bostrom
minds
machines
71–85
2012
wissner-gross
freer
physical
review
let-
cial
intelligence
research
1–36
1995
ters
2013
110.16
168702
tennenholtz
games
economic
behavior
363–373
2004
lavictoire
fallenstein
yudkowsky
barasz
christiano
herreshoff
pro-
gram
equilibrium
prisoner
dilemma
via
theorem
aaai
multiagent
interaction
without
prior
coordination
workshop
2014
hintze
problem
class
dominance
predictive
dilemmas
2014
honors
thesis
arizona
state
univer-
sity
halpern
pass
arxiv
preprint
arxiv:1308.3778
2013
soares
fallenstein
toward
idealized
deci-
sion
theory
technical
report
machine
intelligence
re-
search
institute
berkeley
2014
soares
formalizing
two
problems
realistic
soares
fallenstein
yudkowsky
aaai-15
workshop
armstrong
corrigibility
ethics
2015
hibbard
avoiding
unintended
behaviors
ar-
tiﬁcial
general
intelligence
edited
bach
go-
ertzel
ikl
107–116
springer
2012
hibbard
ethical
artiﬁcial
intelligence
2014
hibbard
self-modeling
agents
reward
genera-
tor
corruption
proceedings
aaai-15
workshop
ethics
61–64
aaai
2015
horvitz
one-hundred
year
study
artiﬁcial
intel-
ligence
reﬂections
framing
white
paper
stanford
university
2014
chalmers
journal
consciousness
studies
7–65
2010
