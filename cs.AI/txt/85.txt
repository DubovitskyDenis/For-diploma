learning
physical
intuition
block
towers
example
adam
lerer
facebook
research
sam
gross
facebook
research
rob
fergus
facebook
research
alerer
fb.com
sgross
fb.com
robfergus
fb.com
abstract
wooden
blocks
common
toy
infants
al-
lowing
develop
motor
skills
gain
in-
tuition
physical
behavior
world
paper
explore
ability
deep
feed-
forward
models
learn
intuitive
physics
using
game
engine
create
small
towers
wooden
blocks
whose
stability
randomized
render
collapsing
remaining
up-
right
data
allows
train
large
convolu-
tional
network
models
accurately
pre-
dict
outcome
well
estimating
block
trajectories
models
also
able
gener-
alize
two
important
ways
new
physical
scenarios
e.g
towers
additional
block
images
real
wooden
blocks
obtains
performance
comparable
human
subjects
introduction
interaction
world
requires
common-sense
under-
standing
operates
physical
level
example
quickly
assess
walk
surface
without
falling
object
behave
push
making
judgements
require
invoke
newton
laws
mechanics
instead
rely
intuition
built
interaction
world
paper
explore
deep
neural
network
cap-
ture
type
knowledge
dnns
shown
re-
markable
success
perceptual
tasks
visual
recog-
nition
krizhevsky
al.
2012
speech
understanding
hinton
al.
2012
rarely
applied
prob-
lems
involving
higher-level
reasoning
particularly
involving
physical
understanding
however
needed
move
beyond
object
classiﬁcation
detection
true
understanding
environment
e.g
happen
next
scene
indeed
fact
humans
develop
physical
intuition
early
age
carey
2009
well
types
high-level
reasoning
suggests
importance
comprehending
world
learn
common-sense
understanding
model
needs
way
interact
physical
world
robotic
plat-
form
one
option
explored
e.g
agrawal
al.
2015
inherent
complexities
limit
diversity
quantity
data
acquired
instead
use
unreal
engine
ue4
epic
games
2015
platform
modern
game
development
provide
realistic
envi-
ronment
chose
ue4
realistic
physics
simulation
modern
rendering
open
source
license
inte-
grate
torch
collobert
al.
2011
machine
learning
framework
directly
ue4
game
loop
allowing
online
interaction
ue4
world
one
ﬁrst
toys
encountered
infants
wooden
blocks
provide
simple
setting
implicit
exploration
basic
newtonian
concepts
center-of-mass
stability
momentum
asking
deep
models
predict
behav-
ior
blocks
hope
might
internalize
notions
another
reason
selecting
scenario
possible
construct
real
world
examples
enabling
generalization
ability
models
probed
see
fig
two
tasks
explored
blocks
fall
blocks
end
former
bi-
nary
classiﬁcation
problem
based
stability
block
conﬁguration
latter
predict
image
masks
show
location
block
contrast
ﬁrst
task
requires
models
capture
dynam-
ics
system
tasks
require
effective
visual
system
analyze
conﬁguration
blocks
explore
models
based
contemporary
convolutional
networks
ar-
chitectures
lecun
al.
1989
notably
googlenet
ioffe
szegedy
2015
deepmask
pinheiro
al.
2015
learning
physical
intuition
block
towers
example
experiments
vision
physical
reasoning
embodied
learning
1.1.
related
work
closely
related
work
battaglia
al.
2013
explore
physics
involved
falling
blocks
generative
simulation
model
used
predict
out-
come
variety
block
conﬁgurations
varying
physical
properties
found
closely
match
human
judgment
work
complements
uses
top-down
approach
based
sophisticated
graphics
engine
incorporates
explicit
prior
knowledge
newtonian
mechanics
contrast
model
purely
bottom-up
estimating
stability
directly
image
pixels
learnt
examples
pairing
top-down
rendering
engines
data
genera-
tion
high
capacity
feed-forward
regressors
similar
spirit
kinect
body
pose
estimation
work
shotton
al.
2013
although
application
quite
different
al.
2015
recently
investigated
learning
sim-
ple
kinematics
context
objects
sliding
ramps
similar
battaglia
al.
2013
also
used
top-down
physics
engine
map
hypothesis
object
mass
shape
friction
etc
image
space
inference
relies
mcmc
initialized
output
convnet-based
estimates
attributes
work
evalua-
tions
performed
real
data
model
predictions
correlate
reasonably
human
judgement
prior
work
reinforcement
learning
used
synthetic
data
games
train
bottom-up
models
particu-
lar
mnih
al.
2015
lillicrap
al.
2015
trained
deep
convolutional
networks
reinforcement
learning
directly
image
pixels
simulations
learn
policies
atari
games
torcs
driving
simulator
respec-
tively
number
works
cognitive
science
explored
intu-
itive
physics
example
context
liquid
dynamics
bates
al.
2015
ballistic
motion
smith
al.
2013
gears
pulleys
hegarty
2004
latter
ﬁnds
peo-
ple
perform
mental
simulation
answer
questions
gears
pulleys
etc.
form
implicit
bottom-up
reasoning
involved
computer
vision
number
works
used
physical
reasoning
aid
scene
understanding
zheng
al.
2015
koppula
saxena
2016
example
jia
al.
2015
cuboids
rgbd
data
use
centroids
search
scene
interpretations
statically
stable
figure
block
tower
examples
synthetic
left
real
right
datasets
top
bottom
rows
show
ﬁrst
last
frames
respectively
resnets
al.
2015
designed
classiﬁca-
tion
segmentation
adapt
novel
task
us-
ing
integrated
approach
lower
layers
perceive
arrangement
blocks
upper
layers
implicitly
capture
inherent
physics
paper
makes
following
contributions
convnet-based
prediction
static
stability
show
standard
convnet
models
reﬁned
synthetic
data
accurately
predict
stability
stacks
blocks
cru-
cially
models
successfully
generalize
new
im-
ages
real-world
blocks
new
physical
scenarios
encountered
training
models
purely
bottom-up
nature
contrast
existing
approaches
rely
complex
top-down
graphics
engines
prediction
dynamics
models
also
able
pre-
dict
reasonably
accuracy
trajectories
blocks
fall
showing
capture
notions
accelera-
tion
momentum
purely
feed-forward
man-
ner
comparison
human
subjects
evaluation
test
datasets
participants
shows
models
match
performance
held-out
real
data
signiﬁcantly
better
synthetic
data
furthermore
model
predic-
tions
reasonably
high
correlation
human
judge-
ments
uetorch
introduce
open-source
combination
unreal
game
engine
torch
deep
learning
en-
vironment
simple
efﬁcient
use
uetorch
viable
environment
variety
machine
learning
learning
physical
intuition
block
towers
example
figure
recorded
screenshots
masks
1-second
intervals
unreal
engine
block
simulation
methods
2.1.
uetorch
uetorch
package
embeds
lua/torch
machine
learning
environment
directly
ue4
game
loop
al-
lowing
ﬁne-grained
scripting
online
control
ue4
simulations
torch
torch
well-suited
game
engine
integration
lua
dominant
scripting
language
games
many
games
including
ue4
sup-
port
lua
scripting
uetorch
adds
additional
interfaces
capture
screenshots
segmentation
masks
optical
ﬂow
data
control
game
user
input
direct
mod-
iﬁcation
game
state
since
torch
runs
inside
ue4
process
new
capabilities
easily
added
ffi
without
deﬁning
additional
interfaces/protocols
inter-
process
communication
uetorch
simulations
run
faster
real
time
aiding
large-scale
training
uetorch
package
downloaded
freely
http
//github.com/facebook/uetorch
2.2.
data
collection
synthetic
simulation
developed
uetorch
generated
ver-
tical
stacks
colored
blocks
random
conﬁg-
urations
block
position
orientation
camera
po-
sition
background
textures
lighting
randomized
trial
improve
transferability
learned
fea-
tures
simulation
recorded
outcome
fall
captured
screenshots
segmentation
masks
frames/sec
frames
masks
representative
block
simulation
shown
fig
total
180,000
simulations
performed
balanced
across
number
blocks
stable/unstable
conﬁgurations
12,288
exam-
ples
reserved
testing
figure
interface
used
human
experiments
turn
subject
shown
image
left
tries
predict
stack
fall
time
limit
imposed
train-
ing
phase
subject
receives
feedback
prediction
showing
outcome
image
right
real
four
wooden
cubes
fabricated
spray
painted
red
green
blue
yellow
respectively
manufacturing
imper-
fections
added
certain
level
randomness
stability
real
stacked
blocks
attempt
match
physical
properties
real
synthetic
blocks
blocks
manually
stacked
conﬁgurations
high
white
bedsheet
tripod
mounted
dslr
camera
used
ﬁlm
blocks
falling
frames/sec
white
pole
held
top
block
exam-
ple
rapidly
lifted
upwards
allowing
unstable
stacks
fall
stick
see
fig
blurred
due
rapid
motion
note
performed
even
stable
conﬁgurations
avoid
bias
motion
blocks
noticeable
time
stick
several
inches
away
top
block
493
examples
captured
bal-
anced
stable/unstable
conﬁgurations
totals
block
towers
115
139
239
exam-
ples
respectively
2.3.
human
subject
methodology
better
understand
challenge
posed
datasets
real
synthetic
asked
human
subjects
evaluate
images
controlled
experiment
par-
ticipants
asked
give
binary
prediction
regarding
outcome
blocks
i.e
falling
training
phase
consisting
randomly
drawn
examples
participants
shown
ﬁnal
frame
example
along
feedback
whether
choice
correct
see
fig
subsequently
tested
using
100
randomly
drawn
examples
disjoint
training
set
test
phase
feedback
provided
individuals
regarding
correctness
responses
2.4.
model
architectures
trained
several
convolutional
network
cnn
architec-
tures
synthetic
blocks
dataset
trained
ar-
blocks
fall
yes
prediction
stay
incorrect
learning
physical
intuition
block
towers
example
chitectures
binary
fall
prediction
task
oth-
ers
jointly
fall
prediction
mask
prediction
tasks
fall
prediction
trained
resnet-34
al.
2015
googlenet
szegedy
al.
2014
networks
fall
prediction
task
models
pre-trained
imagenet
dataset
russakovsky
al.
2015
replaced
ﬁnal
linear
layer
single
logistic
output
ﬁne-tuned
entire
network
sgd
blocks
dataset
grid
search
performed
learning
rates
fall+mask
prediction
used
deep
mask
networks
predict
segmenta-
tion
trajectory
falling
blocks
multiple
future
times
0s,1s,2s,4s
based
input
image
mask
pixel
multi-class
classiﬁcation
across
background
class
four
foreground
block
color
classes
fall
prediction
also
computed
deepmask
pinheiro
al.
2015
existing
mask
pre-
diction
network
trained
instance
segmentation
appropriate
architecture
purposes
replaced
binary
mask
head
multi-class
softmax
repli-
cated
times
mask
prediction
multiple
points
time
also
designed
mask
prediction
network
phys-
net
suited
mask
prediction
rather
segmentation
block
masks
desired
spatially
local
translation-invariant
i.e
convolutional
upsam-
pling
coarse
image
features
masks
network
depth
coarsest
spatial
resolution
network
could
reason
block
movement
therefore
physnet
take
outputs
resnet-34
per-
forms
alternating
upsampling
convolution
arrive
56×56
masks
physnet
architecture
shown
fig
use
resnet-34
trunk
physnet
historical
rea-
sons
experiments
show
comparable
results
googlenet
trunk
training
loss
mask
networks
sum
binary
cross-entropy
loss
fall
prediction
pixelwise
multi-
class
cross-entropy
loss
mask
hyperparameter
controls
relative
weight
losses
baselines
baseline
perform
logistic
regression
ei-
ther
directly
image
pixels
pretrained
googlenet
features
predict
fall
masks
reduce
number
parameters
pixels-to-mask
matrix
factored
intermediate
dimension
128.
fall
prediction
also
try
k-nearest-neighbors
using
googlenet
last-layer
image
features
2.5.
evaluation
cid:35
cid:34
cid:88
n=1
cid:88
c∈cn
|cn|
compare
fall
prediction
accuracy
synthetic
real
images
models
also
model
human
performance
also
train
models
held-out
block
tower
size
test
held
tower
size
evaluate
transfer
learning
capability
models
models
different
block
tower
sizes
evaluate
mask
predictions
two
criteria
mean
mask
iou
log
likelihood
per
pixel
deﬁne
mean
mask
iou
intersection-over-union
mask
label
binarized
prediction
mask
averaged
foreground
class
present
mask
label
iou
iou
mnc
ˆqnc
|m1∩m2|
|m1∪m2|
mnc
set
pixels
class
mask
|mnc|
set
fore-
ground
classes
present
mask
ˆqnc
set
pixels
model
output
highest-scoring
class
iou
mask
iou
metric
intuitive
problematic
uses
binarized
masks
example
model
predicts
mask
probability
region
mask
iou
block
whether
block
fell
region
quality
predicted
mask
conﬁdences
better
captured
log
likelihood
log
likelihood
per
pixel
deﬁned
log
likelihood
correct
ﬁnal
mask
predicted
softmax
dis-
tribution
divided
number
pixels
essen-
tially
negative
mask
training
loss
since
real
data
small
number
examples
493
across
blocks
sizes
report
estimated
conﬁ-
dence
interval
model
prediction
real
examples
estimate
interval
standard
deviation
bi-
nomial
distribution
approximated
observed
accuracy
model
results
3.1.
fall
prediction
results
table
compares
accuracy
fall
prediction
sev-
eral
deep
networks
baselines
described
section
2.4.
convolutional
networks
perform
well
fall
prediction
whether
trained
isolation
jointly
mask
predic-
tion
best
accuracy
synthetic
data
achieved
physnet
jointly
trained
masks
fall
predic-
tion
accuracy
real
data
convnets
within
standard
deviation
ablation
study
also
measured
performance
learning
physical
intuition
block
towers
example
figure
architecture
physnet
network
model
fall
acc
synthetic
fall
acc
real
baselines
random
pixel
log
reg
googlenet
log
reg
googlenet
knn
classiﬁcation
models
resnet-34
googlenet
googlenet
pretraining
mask
prediction
models
deepmask
physnet
50.0
52.9
65.8
59.6
84.7
86.5
86.5
83.5
89.1
50.0
2.2
49.3
2.2
62.5
2.2
50.9
2.2
67.1
2.1
69.0
2.1
59.2
2.2
66.1
2.1
66.7
2.1
table
fall
prediction
accuracy
convolutional
networks
synthetic
real
data
models
substantially
outperform
baselines
similar
performance
whether
trained
singly
jointly
mask
prediction
task
training
googlenet
with-
imagenet
pretraining
affect
performance
synthetic
examples
degrades
generalization
real
examples
baselines
described
section
2.4.
googlenet
without
imagenet
pretraining
interestingly
model
performed
equally
well
synthetic
data
without
pretraining
pretrained
model
generalized
well
real
images
table
occlusion
experiments
performed
occlusion
experiments
determine
regions
block
images
affected
models
fall
pre-
dictions
gaussian
patch
gray
pixels
standard
de-
viation
image
width
superimposed
image
sliding
window
occlude
parts
image
shown
fig
physnet
model
evalu-
ated
occluded
image
difference
fall
probability
predicted
baseline
occluded
im-
ages
used
produce
heatmaps
shown
fig
5b-d.
ﬁgures
suggest
model
makes
prediction
based
relevant
local
image
features
rather
memo-
rizing
particular
scene
example
fig
model
prediction
affected
unstable
interface
middle
top
blocks
model
vs.
human
performance
fig
compares
physnet
human
subjects
set
synthetic
real
test
images
roc
curves
compar-
ing
human
model
performance
generated
using
fraction
test
subjects
predicting
fall
proxy
conﬁdence
comparing
model
conﬁdences
overall
model
convincingly
outperforms
human
subjects
synthetic
data
comparable
real
data
interestingly
correlation
human
model
conﬁdences
real
synthetic
data
0.69
0.45
higher
human
conﬁdence
ground
truth
0.60
0.41
showing
model
agrees
quite
closely
human
judgement
3.2.
mask
prediction
results
table
compares
mask
prediction
accuracy
deep-
mask
physnet
networks
described
section
2.4.
physnet
achieves
best
performance
mean
mask
iou
log
likelihood
per
pixel
see
section
2.5
sub-
stantially
outperforming
deepmask
baselines
predict-
ing
mask
equal
initial
mask
high
mask
iou
due
deﬁciencies
metric
described
section
2.5.
examples
physnet
mask
outputs
synthetic
real
data
shown
fig
show
masks
exam-
ples
predicted
fall
predicting
masks
learning
physical
intuition
block
towers
example
figure
physnet
mask
predictions
synthetic
a–f
real
g–l
towers
blocks
image
left
example
initial
frame
shown
model
top
row
masks
ground
truth
masks
simulation
seconds
bottom
row
model
predictions
color
intensity
representing
predicted
probability
physnet
correctly
predicts
fall
direction
occlusion
patterns
synthetic
examples
real
examples
physnet
overestimates
stability
difﬁcult
cases
physnet
produces
diffuse
masks
due
uncertainty
d–f
particularly
notable
physnet
predicts
red
block
location
small
patch
visible
initial
image
learning
physical
intuition
block
towers
example
figure
example
gaussian
occlusion
mask
applied
sliding
window
generate
fall
prediction
heatmaps
b–d
heatmaps
predictions
occluded
images
green
over-
lay
means
occlusion
region
increases
predicted
probability
falling
red
overlay
means
occlusion
decreases
predicted
probability
falling
model
focuses
unstable
interfaces
stabilizing
blocks
prevent
tower
falling
figure
plots
comparing
physnet
accuracy
human
perfor-
mance
real
top
synthetic
bottom
test
examples
left
roc
plot
comparing
human
model
predictions
right
breakdown
performance
differing
numbers
blocks
humans
mean
performance
shown
along
per-
formance
individual
subjects
green
circles
overall
phys-
net
model
better
even
best
performing
human
subjects
synthetic
data
real
data
physnet
performs
simi-
larly
humans
stable
towers
easy
outputs
typically
perfect
mask
outputs
physnet
typically
quite
reason-
able
falling
3-block
synthetic
towers
errors
uncertainty
4-block
synthetic
towers
real
examples
cases
masks
often
highly
diffuse
showing
high
uncertainty
trajec-
tory
real
examples
model
predictions
masks
also
skewed
overstable
likely
different
physical
properties
real
simulated
blocks
3.3.
evaluation
held-out
number
blocks
table
compares
performance
networks
ei-
ther
4-block
conﬁgurations
excluded
training
set
accuracy
networks
lower
untrained
class
relative
fully-trained
model
still
relatively
high
comparable
human
performance
predicted
masks
untrained
number
blocks
also
continue
capture
fall
dynamics
reasonably
ac-
curacy
examples
shown
fig
model
deepmask
physnet
baseline
pixel
log
reg
googlenet
log
reg
mask
class-constant
mask
iou
log
likelihood/px
synthetic
synthetic
42.4
75.4
29.6
23.8
72.0
-0.299
-0.107
-0.562
-0.492
-0.490
table
mask
prediction
accuracy
deepmask
physnet
network
metrics
used
described
section
2.5
baselines
described
section
2.4.
additional
iou
baseline
evaluate
mask
prediction
ﬁnal
mask
log
likelihood
baseline
predict
pixel
average
likelihood
class
data
physnet
network
provides
highest
accuracy
metrics
mask
examples
shown
fig
00.20.40.60.8100.10.20.30.40.50.60.70.80.91p
false
positive
rate
true
positive
rate
synthetic
test
examples
humanphysnet00.20.40.60.8100.10.20.30.40.50.60.70.80.91p
false
positive
rate
true
positive
rate
real
test
examples
humanphysnet
learning
physical
intuition
block
towers
example
model
googlenet
googlenet
googlenet
physnet
physnet
physnet
blocks
training
2,3,4
2,3
2,4
2,3,4
2,3
2,4
accuracy
synth
92.6
93.7
93.3
94.5
95.0
93.5
86.7
85.9
82.0
87.9
87.4
84.5
82.3
71.3
79.5
84.7
77.3
83.6
accuracy
real
69.6
4.3
65.2
4.4
69.6
4.3
66.1
4.4
60.0
4.6
55.7
4.6
69.8
3.9
66.9
4.0
66.9
4.0
65.5
4.0
64.0
4.1
67.6
4.0
69.9
3.0
69.0
3.0
70.7
2.9
73.2
2.9
70.1
2.9
69.9
3.0
mask
log
likelihood/px
synth
-0.035
-0.042
-0.040
-0.096
-0.125
-0.154
-0.190
-0.362
-0.268
table
fall
prediction
accuracy
googlenet
physnet
trained
subsets
block
tower
sizes
tested
held-out
block
tower
size
blue
cells
prediction
accuracy
held-out
class
reduced
still
comparable
human
performance
see
fig
real
block
data
performance
held
class
equivalent
fully-trained
model
within
standard
deviation
physnet
mask
predictions
held-out
classes
moderately
degraded
log
likelihood
scores
still
superior
deepmask
predictions
table
physnet
masks
held-out
class
shown
fig
figure
physnet
mask
predictions
tower
size
blocks
network
trained
mask
predictions
blocks
a–b
still
capture
dynamics
well
even
though
network
never
saw
towers
blocks
mask
predictions
blocks
capture
dynamics
show
degradation
discussion
results
indicate
bottom-up
deep
cnn
models
attain
human-level
performance
predicting
towers
blocks
fall
also
ﬁnd
models
per-
formance
generalizes
well
real
images
models
pretrained
real
data
table
several
experiments
provide
evidence
deep
models
train
gaining
knowledge
dynamics
block
towers
rather
simply
memorizing
mapping
conﬁgurations
outcomes
convincingly
relatively
small
degradation
performance
models
tower
size
shown
training
table
fig
demonstrates
model
must
making
prediction
based
local
features
rather
memorized
exact
block
conﬁgurations
occlusion
experiments
fig
also
suggest
models
focus
particular
regions
confer
stability
instability
block
conﬁguration
finally
poor
performance
k-nearest-neighbors
googlenet
features
table
suggests
nearby
conﬁgu-
rations
googlenet
pretrained
feature
space
pre-
dictive
stability
given
conﬁguration
compared
top-down
simulation-based
models
battaglia
al.
2013
deep
models
require
far
train-
ing
data
many
thousands
examples
achieve
high
level
performance
deep
models
also
difﬁculty
generalizing
examples
far
training
data
difﬁculties
arise
deep
models
must
learn
physics
scratch
whereas
simulation-based
models
start
strong
priors
encoded
physics
simulation
engine
bottom-up
top-down
approaches
ad-
vantages
precise
combination
systems
human
reasoning
subject
debate
e.g
davis
marcus
2016
goodman
al.
2015
results
suggest
deep
models
show
promise
directly
captur-
ing
common-sense
physical
intuitions
world
could
lead
powerful
visual
reasoning
systems
believe
synthetic
data
realistic
physical
sim-
learning
physical
intuition
block
towers
example
ulations
uetorch
useful
machine
learning
experiments
vision
physics
agent
learning
combination
synthetic
data
mask
prediction
consti-
tutes
general
framework
learning
concepts
object
permanence
extent
occlusion
containment
so-
lidity
gravity
collisions
may
explored
future
acknowledgements
authors
would
like
thank
soumith
chintala
arthur
szlam
early
feedback
experimental
design
sainbayar
sukhbaatar
assistance
collecting
real-
world
block
examples
y-lan
boureau
useful
advice
regarding
human
subject
experiments
piotr
dollar
feedback
manuscript
learning
physical
intuition
block
towers
example
references
agrawal
pulkit
carreira
joao
malik
jitendra
learning
see
moving
june
2015.
bates
c.j.
yildirim
tenenbaum
battaglia
humans
predict
liquid
dynamics
using
probabilis-
proc
37th
ann
conf
cognitive
tic
simulation
science
society
2015.
battaglia
peter
hamrick
jessica
tenenbaum
joshua
simulation
engine
physical
scene
understanding
proceedings
national
academy
sciences
110
:18327–18332
2013.
doi
10.1073/
pnas.1306572110
url
http
//www.pnas.org/
content/110/45/18327.abstract
carey
susan
origin
concepts
oxford
university
press
2009.
collobert
ronan
kavukcuoglu
koray
farabet
cl´ement
torch7
matlab-like
environment
ma-
biglearn
nips
workshop
number
chine
learning
epfl-conf-192376
2011.
davis
ernest
marcus
gary
scope
limits
simulation
automated
reasoning
artiﬁcial
intel-
ligence
233:60–72
2016.
epic
games
unreal
engine
unrealengine.com
2015.
https
//www
goodman
noah
frank
michael
grifﬁths
thomas
tenenbaum
joshua
battaglia
peter
hamrick
jessica
relevant
robust
response
marcus
davis
2013
psychological
science
:539–541
2015.
zhang
ren
sun
deep
residual
learning
image
recognition
arxiv
e-prints
decem-
ber
2015.
hegarty
mary
mechanical
reasoning
mental
simula-
tion
trends
cognitive
sciences
:280–285
2004.
hinton
geoffrey
deng
dong
dahl
george
mohamed
abdel-rahman
jaitly
navdeep
senior
an-
drew
vanhoucke
vincent
nguyen
patrick
sainath
tara
deep
neural
networks
acoustic
mod-
eling
speech
recognition
shared
views
four
research
groups
signal
processing
magazine
ieee
:82–97
2012.
ioffe
sergey
szegedy
christian
batch
normalization
accelerating
deep
network
training
reducing
inter-
nal
covariate
shift
corr
abs/1502.03167
2015.
url
http
//arxiv.org/abs/1502.03167
jia
zhaoyin
gallagher
a.c.
saxena
chen
tsuhan
reasoning
blocks
stability
pattern
analysis
machine
intelligence
ieee
transactions
:905–918
2015.
koppula
hema
saxena
ashutosh
anticipating
human
activities
using
object
affordances
reactive
robotic
response
pattern
analysis
machine
intel-
ligence
ieee
transactions
:14–29
2016.
krizhevsky
alex
sutskever
ilya
hinton
geoffrey
imagenet
classiﬁcation
deep
convolutional
neural
networks
pereira
burges
c.j.c.
bottou
weinberger
k.q
eds
advances
neural
informa-
tion
processing
systems
1097–1105
curran
as-
sociates
inc.
2012.
lecun
boser
denker
henderson
howard
hubbard
jackel
back-
propagation
applied
handwritten
zip
code
recognition
neural
computation
:541–551
winter
1989.
lillicrap
timothy
hunt
jonathan
pritzel
alexander
heess
nicolas
erez
tom
tassa
yuval
silver
david
wierstra
daan
continuous
control
deep
rein-
forcement
learning
corr
abs/1509.02971
2015.
url
http
//arxiv.org/abs/1509.02971
mnih
volodymyr
kavukcuoglu
koray
silver
david
rusu
andrei
veness
joel
bellemare
marc
graves
alex
riedmiller
martin
fidjeland
andreas
ostrovski
georg
petersen
stig
beattie
charles
sadik
amir
antonoglou
ioannis
king
helen
kumaran
dharshan
wierstra
daan
legg
shane
hassabis
demis
human-level
control
deep
reinforcement
learning
nature
518
7540
:529–533
2015.
url
http
//dx.doi.org/10.1038/nature14236
pinheiro
pedro
collobert
ronan
dollar
piotr
learning
segment
object
candidates
advances
neural
information
processing
systems
1981–1989
2015.
russakovsky
olga
deng
jia
hao
krause
jonathan
satheesh
sanjeev
sean
huang
zhiheng
karpa-
thy
andrej
khosla
aditya
bernstein
michael
berg
alexander
fei-fei
imagenet
large
scale
visual
recognition
challenge
international
journal
computer
vision
ijcv
115
:211–252
2015.
doi
10.1007/s11263-015-0816-y
shotton
jamie
sharp
toby
kipman
alex
fitzgibbon
andrew
finocchio
mark
blake
andrew
cook
mat
moore
richard
real-time
human
pose
recognition
parts
single
depth
images
communications
acm
:116–124
2013.
learning
physical
intuition
block
towers
example
smith
battaglia
vul
consistent
physics
underlying
ballistic
motion
prediction
proc
35th
ann
conf
cognitive
science
society
2013.
szegedy
christian
liu
wei
jia
yangqing
sermanet
pierre
reed
scott
anguelov
dragomir
erhan
du-
mitru
vanhoucke
vincent
rabinovich
andrew
going
deeper
convolutions
corr
abs/1409.4842
2014.
jiajun
yildirim
ilker
lim
joseph
freeman
bill
tenenbaum
josh
galileo
perceiving
physical
ob-
ject
properties
integrating
physics
engine
deep
learning
cortes
lawrence
n.d.
lee
d.d.
sugiyama
garnett
eds
advances
neu-
ral
information
processing
systems
127–135
curran
associates
inc.
2015.
zheng
zhao
yibiao
joey
ikeuchi
katsushi
zhu
song-chun
scene
understanding
reasoning
sta-
bility
safety
international
journal
computer
vi-
sion
112
:221–238
2015
