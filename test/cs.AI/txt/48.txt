uniform
solution
sampling
using
constraint
solver
oracle∗
stefano
ermon
carla
gomes
bart
selman
department
computer
science
department
computer
science
department
computer
science
cornell
university
ermonste
cs.cornell.edu
cornell
university
gomes
cs.cornell.edu
cornell
university
selman
cs.cornell.edu
abstract
consider
problem
sampling
so-
lutions
deﬁned
set
hard
constraints
combinatorial
space
propose
new
sam-
pling
technique
enforcing
uniform
exploration
search
space
leverages
rea-
soning
power
systematic
constraint
solver
black-box
scheme
present
series
challenging
domains
energy
barri-
ers
highly
asymmetric
spaces
reveal
difﬁculties
introduced
hard
constraints
demonstrate
standard
approaches
simulated
annealing
gibbs
sampling
greatly
affected
new
technique
overcome
many
difﬁculties
finally
show
sampling
scheme
naturally
deﬁnes
new
approximate
model
counting
technique
empirically
show
accurate
range
benchmark
problems
introduction
recent
years
seen
signiﬁcant
interest
proba-
bilistic
reasoning
approaches
combine
hard
log-
ical
constraints
probabilistic
information
soft
weighted
constraints
markov
logic
networks
prominent
example
modeling
language
hard
constraints
used
capture
deﬁnitional
ir-
refutable
relationships
underlying
domain
soft
constraints
capture
less
categorical
information
generally
better
modeling
real-world
data
dependencies
markov
chain
monte
carlo
mcmc
methods
simulated
annealing
gibbs
sampling
among
prominent
approaches
probabilistic
rea-
soning
especially
exact
inference
beyond
reach
fact
guaranteed
asymptotically
converge
stationary
distribution
theoretically
provide
uni-
form
samples
however
sampling
solutions
set
hard
constraints
believed
hard
worst
case
closely
related
complete
prob-
lems
model
counting
partic-
ular
time
required
markov
chain
reach
stationary
distribution
mixing
time
often
exponential
number
problem
variables
hard
constraints
present
difﬁculties
led
introduction
alternate
sampling
strategies
example
sam-
plesat
approach
markov
chain
constructed
combines
moves
proposed
according
simulated
an-
nealing
markov
chain
so-called
walksat
moves
in-
spired
local
search
constraint
solvers
samplesat
method
provides
signiﬁcant
advance
since
sampling
constraint
problems
practical
interest
generally
reach
solutions
best
small
subset
possible
solutions
samplesat
subsequently
incor-
porated
mc-sat
alchemy
package
reason-
ing
learning
markov
logic
networks
key
limitation
samplesat
guaranteed
con-
verge
uniform
distribution
solution
set
fact
one
create
examples
stationary
distri-
bution
samplesat
arbitrarily
biased
non-uniform
terms
solution
samples
still
negate
value
samplesat
many
practical
settings
al-
though
sa-like
sampling
sample
limit
uniform
stationary
distribution
solution
set
reaching
stationary
distribution
often
requires
exponential
time
making
strategy
little
use
practice
paper
revisit
question
devise
prac-
tical
methods
sampling
solutions
deﬁned
set
hard
constraints
combinatorial
space
present
series
challenging
domains
reveal
difﬁculties
in-
troduced
constraints
include
high
energy1
barriers
large
energy
plateaus
golf-course
like
energy
landscapes
highly
asymmetric
sampling
spaces
present
data
demonstrating
gibbs
sampling
samplesat
greatly
affected
problems
∗this
work
supported
nsf
grant
0832782
1energy
deﬁned
number
violated
constraints
however
also
show
highly
structured
energy
land-
scapes
actually
present
new
opportunities
solution
samplers
combinatorially
deﬁned
energy
functions
rich
structure
embedded
traditional
mcmc
meth-
ods
general
therefore
treat
energy
black-box
effectively
ignoring
underlying
structure
hand
modern
day
constraint
solvers
use
clever
heuristic
exploit
constraint
structure
much
possi-
ble
solve
large
structured
industrial
problems
millions
variables
however
solvers
can-
used
directly
solution
samplers
tend
oversample
certain
solutions
designed
ﬁnd
one
satisfying
assignment
uniform
paper
propose
novel
sampling
scheme
called
searchtreesampler
leverages
reasoning
power
systematic
constraint
solver
enforcing
uniform
exploration
search
space
constraint
solvers
previously
applied
samplesearch
context
importance
sampling
frame-
work
performance
known
heavily
depend
choice
proposal
distribution
contrast
searchtreesampler
introduces
new
way
explor-
ing
search
space
rely
heuristically
chosen
proposal
distribution
directly
provides
ap-
proximately
uniform
samples
constraint
solver
used
black-box
systematic
solver
plugged
modiﬁcations
required
empiri-
cally
demonstrate
leveraging
constraint
structure
searchtreesampler
overcome
many
difﬁ-
culties
encountered
solution
samplers
particu-
lar
show
orders
magnitude
faster
com-
peting
methods
providing
uniform
samples
time
show
sampling
scheme
naturally
deﬁnes
new
technique
approximately
count-
ing
number
distinct
solutions
model
counting
empirically
show
accurate
range
benchmark
problems
clause
least
one
signed
variable
true
say
truth
assignment
satisfying
assignment
also
called
model
solution
satisﬁes
clauses
let
set
solutions
let
|sf
number
distinct
solutions
given
boolean
formula
deﬁne
discrete
probabil-
ity
distribution
set
possible
truth
assign-
ments
cid:26
1/z
i.e.
solution
otherwise
paper
consider
problem
sampling
problem
hard
fact
simply
deciding
whether
support
empty
np-complete
cnf-sat
problem
sampling
however
believed
even
harder
closely
related
complete
problems
inference
model
counting
instance
sat
solvers
directly
used
solution
samplers
tend
oversample
certain
solutions
designed
ﬁnd
one
satisfying
assignment
uniform
background
solution
sampling
section
brieﬂy
describe
main
techniques
solution
sampling
3.1
simulated
annealing
simulated
annealing
mcmc
algorithm
deﬁnes
reversible
markov
chain
space
truth
assignments
sample
boltzmann
distribution
transition
probabilities
steady
state
probability
dis-
tribution
depend
property
truth
assign-
ments
called
energy
energy
gives
number
clauses
violated
truth
assignment
deﬁned
follows
problem
deﬁnition
c|σ
satisfy
consider
problem
sampling
combinatorial
search
space
deﬁned
boolean
variables
con-
straints
speciﬁed
boolean
formula
conjunctive
normal
form
cnf
constraint
clause
logical
disjunction
set
possibly
negated
variables
for-
mula
said
cnf
form
logical
conjunc-
tion
set
clauses
deﬁne
set
propositional
variables
formula
variable
assignment
function
assigns
value
variable
usual
value
interpreted
false
value
true
let
formula
cnf
set
variables
|c|
clauses
let
variable
truth
assignment
say
satisﬁes
boltzmann
steady
state
probability
distribution
given
formal
parameter
called
temperature
normalization
constant
notice
assigns
probability
solutions
i.e
necessarily
zero
non-solutions
given
algorithm
produces
samples
construct
algorithm
samples
i.e
uniformly
solution
set
using
rejection
sampling
speciﬁcally
take
samples
produced
discard
ones
fundamental
tradeoff
involved
want
probability
distribu-
tion
easier
sample
compared
time
probability
mass
concen-
trated
satisfying
assignments
i.e
close
enough
generate
many
unwanted
samples
i.e
non-solutions
closely
related
simulated
annealing
gibbs
sampler
boltzmann
distribution
deﬁnes
similar
markov
chain
steady
state
probability
distribution
analy-
sis
consider
ﬁxed
temperature
annealing
ﬁxed
run
markov
chain
3.2
samplesat
wei
propose
use
hybrid
approach
interleave
moves
moves
based
focused
random
walk
procedure
inspired
local
search
sat
solvers
approach
based
result
papadimitriou
proving
random
walk
procedure
sat
ﬁnd
solution
satisﬁable
2cnf
for-
mula
time
number
variables
formula
role
focused
random
walk
moves
ﬁnd
solution
clusters
role
moves
heuristically
provide
level
uniformity
sam-
pling
drawback
approach
maintain
detailed
balance
equation
con-
trol
resulting
steady
state
probability
distribution
samplesat
therefore
loses
theoretical
guarantees
uniformity
sampling
provided
show
experimental
section
lead
poor
uniformity
also
practice
3.3
samplesearch
samplesearch
importance
sampling
tech-
nique
draws
samples
so-called
backtrack-free
distribution
although
uniform
sampler
samples
used
compute
expectations
using
impor-
tance
sampling
correcting
non
uniformity
backtrack-free
distribution
support
backtrack-
free
distribution
corresponds
exactly
set
solutions
greatly
reduces
number
rejected
samples
however
importance
sampling
schemes
per-
formance
highly
dependent
choice
proposal
distribution
usually
precomputed
using
gener-
alized
belief
propagation
scheme
sampling
backtrack-free
distribution
achieved
either
using
complete
solver
black-box
using
sample-
search
scheme
integrates
backtracking
search
sampling
approach
similar
sense
also
use
complete
solver
oracle
explore
search
tree
however
search
tree
explored
different
way
speciﬁcally
recursive
approach
aims
uniformly
exploring
search
tree
level
level
directly
provides
approximately
uniform
samples
without
need
heuristically
chosen
proposal
distribution
e.g.
using
variational
methods
compare
perfor-
mance
two
methods
model
counting
black-box
sampling
modern
day
sat
solvers
effective
ﬁnding
so-
lution
explore
search
space
highly
non-
uniform
way
use
heuristics
as-
signing
pure
literals
e.g.
variable
appears
positive
sign
formula
safely
set
true
heavily
bias
search
towards
certain
parts
search
space
modifying
pure
dpll-style
algorithm
produce
uni-
form
samples
challenging
task
suppose
choice
ordering
variables
set
chosen
uniformly
random
polarity
whether
assign
true
false
variable
search
also
chosen
uniformly
ran-
dom
general
ﬁrst
solution
found
uni-
form
sample
simple
counterexample
formula
seen
solution
less
likely
found
possible
variables
orderings
order
obtain
uniform
samples
one
could
choose
polarity
variables
according
marginal
probabilities
respect
would
defy
purpose
sampling
since
often
want
obtain
samples
precisely
estimate
quantities
marginals
instead
modifying
existing
search
procedure
pro-
duce
uniform
samples
introduce
novel
recursive
sam-
pling
scheme
aims
enforcing
level
level
uniform
exploration
search
tree
leveraging
reason-
ing
power
complete
sat
solver
4.1
recursive
sampling
strategy
method
based
notion
pseudosolution
de-
ﬁned
follows
deﬁnition
let
ordering
variables
pseudosolution
level
truth
assignment
ﬁrst
variables
completed
form
solution
i.e
node
search
tree
level
solution
descendant
denote
set
pseudosolutions
level
recursive
strategy
algorithm
based
idea
dividing
search
tree
levels
recursively
sam-
pling
pseudosolutions
using
previously
generated
samples
pseudosolutions
higher
level
see
figure
words
assume
access
uniform
samples
ancestors
solutions
level
generate
samples
ancestors
solutions
level
using
algorithm
procedure
initialized
pseudosolution
level
i.e
empty
variable
assignment
note
generat-
ing
samples
pseudosolutions
level
variables
equivalent
original
problem
sampling
solutions
complete
sat
solver
used
algorithm
generate
algorithm
searchtreesampler
algorithm
blackboxsampler
input
formula
vars
parameters
output
set
solutions
satisﬁable
return
else
let
true
empty
variable
assignment
let
number
levels
blackboxsampler
φi−1
end
return
end
figure
representation
algorithm
explores
search
tree
set
pseudosolutions
level
ancestor
accomplished
repeatedly
checking
satisﬁability
sjvd∈d
provably
un-
satisﬁable
adding
pseudosolution
time
one
found
completeness
required
order
enumerate
elements
i.e
prove
unsatisﬁability
elements
found
4.2
analysis
easy
verify
induction
sets
algo-
rithm
satisfy
property
|φi|
min
|si|
key
property
algorithm
set
returned
sampling
approximately
equivalent
sam-
pling
si+ℓ
set
pseudosolutions
level
parameter
controls
uniformity
sam-
pling
formalized
following
theorem
theorem
let
output
algorithm
input
|φ|
min
|si|
si+ℓ
two
pseudosolutions
level
probability
uniformly
sampled
element
equal
input
set
uniformly
sampled
pseudosolutions
level
parameters
output
set
pseudosolutions
level
ap-
proximately
uniformly
sampled
2ℓ|φ|
|s|
|φ|
min
|φ|
sample
without
replacement
generate
set
pseudosolutions
level
i+ℓ
ancestor
using
complete
sat
solver
end
return
proof
suppose
|φ|
otherwise
means
con-
tains
pseudosolutions
level
hence
deﬁnition
si+ℓ
therefore
set
uniformly
sampled
pseudosolutions
level
think
pseudosolution
urn
contains
certain
number
pseu-
dosolutions
lower
level
descendants
let
|si|
|φ|
total
number
pseudosolutions
level
since
contains
uniform
samples
algo-
rithm
also
uniform
samples
pseudosolutions
level
let
algorithm
union
contents
urns
selected
let
si+ℓ
pseudosolution
level
let
unique
ancestor
level
k−1
clearly
probability
equal
probability
selecting
ancestor
level
let
randomly
selected
element
ideally
would
like
probability
constant
independent
uniform
sampling
how-
ever
intuitively
exactly
constant
bias
towards
elements
small
speciﬁcally
cid:1
xℓ1···ℓk−1
cid:0
sℓ1
sℓk−1
since
sets
disjoint
cid:0
k−1
cid:1
cid:1
cid:0
k−1
xt=1
k−1
cid:1
cid:0
sℓ1
sℓk−1
let
si+ℓ
another
pseudosolution
level
rewrite
k−2
t=1
cid:0
cid:1
k−1
t=1
suppose
wlog
lemma
using
fact
k−1
xt=1
hence
k−1
xt=1
ﬁnally
cid:16
k−2
cid:17

t=1
cid:16
k−1
cid:17
t=1


cid:16
k−2
cid:17

t=1
gives
cid:16
k−1
cid:17
t=1
lemma
given
ﬁnite
sequence
c+bjpj
d+bj
c+k−1
proof
notice
d+k−1
monotonically
decreasing
func-
tion
desired
result
follows
summing
sides
dividing
d+bj
c+bj
equation
shows
sampling
becomes
uni-
form
allows
bound
uniformity
output
algorithm
function
pseudoso-
lution
much
likely
another
one
instance
100
pseudosolution
likely
sampled
another
one
notice
larger
values
would
im-
prove
uniformity
sampling
time
increase
number
output
samples
sampling
with-
replacement
however
larger
values
would
also
require
calls
sat
solver
remark
algorithm
used
recursively
al-
gorithm
samples
received
input
usually
truly
uniform
unless
larger
total
number
so-
lutions2
even
though
general
sets
algorithm
2uniformity
also
guaranteed
ﬁrst
levels
|sb|
meet
assumptions
theorem
tend
satisfy
effect
rather
small
practi-
cal
values
investigated
empirically
evaluate
statistical
properties
output
samples
4.3
complexity
number
variables
input
formula
al-
gorithm
requires
log
calls
sat
solver
get
least
min
solutions
samples
larger
values
require
calls
sat
solver
intu-
itively
also
improve
uniformity
sampling
re-
ducing
number
recursions
particular
ex-
treme
impractical
case
obtain
truly
uniform
sampling
corresponds
exact
model
counting
explicitly
enumerating
solutions
notice
also
al-
though
experiments
use
constant
values
could
chosen
function
level
evaluating
sampling
methods
veriﬁed
simulated
annealing
er-
godic
temperatures
new
conﬁgura-
tions
generated
randomly
ﬂipping
variable
cho-
sen
uniformly
random
chains
irreducible
since
according
steady
state
probability
distri-
bution
satisfying
assignments
probabil-
ity
principle
provide
uniform
samples
willing
wait
stationary
distribution
reached
however
amount
time
wait
chain
reaches
steady
state
two
consecutive
sam-
ples
paramount
importance
practical
applica-
tion
hand
samplesat
often
much
faster
ﬁnding
solutions
focused
random
walk
component
provide
guarantee
uniformity
sampling
evaluate
practical
utility
methods
therefore
important
quantitatively
measure
uniformity
samples
provided
ﬁnite
amounts
time
experiments
run
set
formulas
know
analytically
using
exact
model
counters
number
distinct
solutions
|sf
relatively
small
1000
therefore
taking
sufﬁciently
large
num-
ber
samples
able
check
uniformity
methods
particular
let
number
times
ith
solution
sampled
|sf
given
samples
truly
uniform
solution
sampler
expect
close
p/|sf
since
law
large
num-
bers
ni/p
converges
1/|sf
probability
quantitatively
measure
uniformity
sampler
use
pearson
statistic
deﬁned
p/|sf
|xi
p/|sf
p/|sf
expected
theoretical
frequency
hypothesis
distribution
truly
uniform
value
used
test
null
hypothesis
stating
frequencies
observed
consistent
uniform
distribution
particular
null
hypothesis
rejected
value
larger
cutoff
value
depends
number
distinct
solutions
|sf
specifying
number
degrees
freedom
distribution
statistical
signiﬁcance
desired
e.g.
0.05
experiments
use
minisat
2.2
com-
plete
solver
algorithm
pseudosolutions
deﬁned
according
lexicographical
variable
ordering
πlx
efﬁciency
experiments
run
wish
obtain
samples
keep
running
searchtreesampler
parameter
|sf
obtain
least
samples
taking
exactly
sam-
ples
without
replacement
per
run
report
total
running
time
note
choosing
|sf
e.g.
let
evaluate
performance
method
approximately
uniform
sampler
would
correspond
enumerating
solutions
hence
per-
fectly
uniform
sampling
evaluated
follows
run
chain
random
initial
truth
assignment
discarding
samples
ﬁrst
107
steps
burn-in
phase
burn-in
phase
assume
markov
chain
reached
steady
state
distribution
start
taking
samples
every
steps
current
truth
assignment
taken
sample
steady
state
distribution
wait
steps
en-
sure
consecutive
samples
sufﬁciently
independent
sample
solution
output
oth-
erwise
discard
process
carried
ﬁnd
prescribed
number
solutions
non
necessarily
distinct
samplesat
executed
default
parame-
ters
methods
run
3ghz
machine
4gb
memory
challenging
sample
spaces
6.1
golf-course
energy
landscape
ﬁrst
consider
class
instances
call
plateau
deﬁned
¬x1
¬x1
¬z1
class
instances
hard
local
search
methods
large
plateau
truth
assign-
ments
size
least
2b+1
energy
corre-
sponding
assignments
effect
last
two
clauses
enforce
two
distinct
solutions
intuitively
instance
difﬁcult
order
reach
one
solutions
needs
set
setting
likely
violate
several
ﬁrst
clauses
making
uphill
move
unlikely
accepted
formally
shown
theorem
ﬁxed
temperature
probability
going
takes
time
exponential
ﬁnd
satisfying
assignment
shown
samplesat
affected
en-
ergy
plateaus
uses
focused
moves
quickly
reach
solutions
since
based
local
informa-
tion
searchtreesampler
affected
energy
plateaus
fact
since
plateau
instances
belong
cnf
formulas
variables
per
clause
two
solutions
use
following
result
theorem
algorithm
provides
uniform
samples
polynomial
time
2-cnf
instances
proof
follows
fact
2-sat
solvable
polynomial
time
uniformity
follows
fact
al-
gorithm
output
solutions
6.2
energy
barriers
deﬁne
energy
barrier
two
variable
assign-
ments
minimum
set
possible
paths
boolean
hypercube
be-
tween
maximum
energy
conﬁgu-
rations
path
simulated
annealing
designed
deal
energy
barriers
ones
encountered
around
local
minimum
allowing
occasional
uphill
moves
stochastic
hill
climbing
i.e
moves
lead
increase
energy
function
particular
larger
val-
ues
temperature
parameter
make
acceptance
uphill
moves
likely
section
show
deal
rel-
atively
low
energy
barriers
want
maintain
reason-
able
efﬁciency
rejection
sampling
scheme
consider
following
cnf
formula
call
xorbarrier
¬x1
¬y1
¬x1
¬y2
¬x1
¬yb
use
term
xorbarrier
equiv-
alent
conjunction
xor
constraints
form
xor
xor
easy
see
value
instances
two
so-
lutions
seen
n|e
steady
state
probability
conﬁguration
energy
cid:1
value
temperature
parameter
cid:19
xσ|e
cid:0
cid:18
key
feature
type
instances
follow-
ing
since
simulated
annealing
gibbs
sampling
ﬂips
one
variable
time
easy
see
path
markov
chain
graph
brings
one
solution
asymmetric
space
energy
barrier
random
formula
energy
barrier
figure
uniformity
sampling
frequency
solution
sampled
different
methods
requency
one
contain
conﬁguration
violates
b/2
constraints
therefore
conclude
energy
barrier
height
b/2
two
solutions
large
values
one
ﬁnd
temperature
provides
high
enough
i.e
small
number
ﬂips
per
solution
b/2
i.e
probability
jump-
ing
barrier
obtain
practical
sampler
instance
get
10−9
i.e
climbing
barrier
average
billion
samples
needs
temperature
0.75
p0.75
7.4
10−9
means
average
need
108
sam-
ples
get
single
solution
similar
results
obtained
using
gibbs
sampling
gibbs
sam-
pler
boltzmann
steady
state
probability
dis-
tribution
also
proceeds
ﬂipping
single
variable
time
jump
barrier
single
move
since
instances
xorbarrier
belong
2-sat
solutions
theorem
algorithm
provides
uniform
samples
polynomial
time
common
strategy
partially
overcome
ergodic-
ity
problems
gibbs
sampling
simulated
anneal-
ing
use
multiple
parallel
chains
restarts
approaches
quite
effective
in-
stance
capable
producing
uniform
samples
xorbarrier
class
instances
presented
intu-
itively
average
random
initial
assignments
one
side
barrier
i.e.
half-
hypercube
side
i.e.
6.3
asymmetric
spaces
energy
barriers
approaches
however
sufﬁcient
sample
distributions
solution
clusters
i.e.
groups
solutions
close
hamming
distance
different
sizes
separated
energy
barriers
con-
sider
instance
following
class
instances
call
asymxorbarrier
xorbarrier
requency
effect
additional
clauses
create
cluster
solutions
one
side
barrier
exist
one
solution
shown
figure
table
bottom
rows
searchtreesampler
provides
much
uniform
sampling
compared
samplesat
type
in-
stances
speciﬁcally
uniformity
sampling
hypoth-
esis
rejected
samplesat
according
χ2-test
samplesat
employs
restarts
there-
fore
samples
ﬁrst
solution
figure
corresponding
isolated
solution
variables
set
of-
ten
i.e
times
similarly
biased
results
obtained
using
gibbs
sampler
multiple
paral-
lel
chains
implemented
alchemy
system
plain
gibbs
able
cross
barrier
reasonable
amount
time
see
table
4th
column
thanks
minisat
reasoning
power
searchtreesampler
orders
magnitude
faster
samplesat
6.4
embedded
energy
barriers
table
top
rows
evaluate
performance
methods
considered
three
types
instances
logis-
tic
one
generated
satplan
logistic
110
vari-
ables
461
clauses
512
solutions
graph
coloring
problem
satlib
coloring
variables
300
clauses
900
solutions
random
3-sat
formula
random
variables
315
clauses
solutions
collect
respectively
50000
200000
5000
samples
instance
also
artiﬁcially
introduce
energy
barrier
instances
choosing
variable
roughly
half
so-
lutions
half
solutions
original
formula
introduce
new
set
clauses
de-
ﬁned
xorbarrier
substitute
y40
fresh
variables
note
change
number
solutions
experimented
several
values
provide
summary
best
results
obtained
table
original
formulas
ones
em-
bedded
energy
barrier
carefully
choosing
tempera-
method
samplesat
searchtreesampler
searchtreesampler
searchtreesampler
samplesat
searchtreesampler
samplesat
searchtreesampler
searchtreesampler
searchtreesampler
samplesat
searchtreesampler
samplesat
searchtreesampler
searchtreesampler
searchtreesampler
samplesat
searchtreesampler
searchtreesampler
searchtreesampler
samplesat
searchtreesampler
searchtreesampler
searchtreesampler
samplesat
searchtreesampler
searchtreesampler
instance
logistic
logistic
logistic
logistic
logistic
logistic+barrier
logistic+barrier
logistic+barrier
coloring
coloring
coloring
coloring
coloring
coloring+barrier
coloring+barrier
coloring+barrier
random
random
random
random
random
random+barrier
random+barrier
random+barrier
random+barrier
random+barrier
asymxorbarrier
80,4
asymxorbarrier
80,4
asymxorbarrier
80,4
asymxorbarrier
80,4
asymxorbarrier
80,8
asymxorbarrier
80,8
asymxorbarrier
80,8
parameter
t=0.25
k=5
k=20
k=50
t=0.25
k=20
t=0.25
k=50
k=100
k=200
t=0.25
k=100
t=0.3
k=10
k=15
k=20
t=0.3
k=10
k=15
k=20
k=2
k=5
k=10
k=25
k=50
time
11028
7598
9.8
10.1
9.6
42845
7296
42.53
7589
28998
184
204
228
29434
29062
435
8673
740
2.5
71077
744
7.0
7.1
7.1
290
0.7
0.4
0.3
4260
1.9
1.6
550
534.9
545.82
487.43
407.01
50495.8
178860.2
469.23
875.131
132559
844
808.3
672.15
100905
141027
746.40
36.62
970.21
76.84
31.28
29.26
4211.40
1104.9
64.55
32.64
32.33
6508
51.54
17.35
7.84
1893391
220.14
197.17
p-value
0.11
0.23
0.14
0.77
0.99
0.90
0.71
0.90
0.98
1.00
0.99
0.88
0.96
0.98
0.04
0.94
0.95
0.36
0.95
0.94
0.99
table
uniformity
sampling
instances
without
embedded
energy
barriers
p-value
probability
observing
event
least
extreme
null
hypothesis
uniform
sampling
bold
null
hypothesis
rejected
ture
parameter
provide
uniform
samples
original
formulas
however
slow
compared
methods
smaller
would
make
faster
samples
would
uniform
hand
sam-
plesat
generally
much
faster
samples
provided
far
less
uniform
searchtreesampler
superior
samplesat
terms
running
time
least
orders
magnitude
faster
uniformity
expected
increasing
improves
uniformity
affect
running
time
also
produces
samples
per
run
expected
introduction
energy
barriers
severely
limits
ergodicity
shown
last
column
table
figure
result
sample-
sat
fail
provide
uniform
samples
according
test
instances
embedded
energy
barriers
hand
uniformity
searchtreesampler
affected
although
runtime
increases
search
tree
deeper
introduced
fresh
variables
new
model
counting
technique
typical
way
estimate
number
solutions
|sf
model
count
formula
using
sample
approximation
estimate
series
multipliers
xn−1
an−1
instance
x1=a1
given
fraction
solutions
number
solutions
green
vs.
yellow
part
search
tree
figure
challenging
task
one
heuristically
select
good
variable
ordering
polarities
condition
solve
multiple
sampling
tasks
variables
clamped
algorithm
provides
new
direct
way
estimating
number
solutions
let
set
pseudosolutions
level
suppose
|sn|
formula
satisﬁable
simplicity
let
|sn|
|sn|
|sn−1|
|sn−1|
|sn−2|
|sn−2|
|sn−3|
|s1|
see
right
panel
figure
estimate
multiplier
using
relation
|si|
|si−1|
|si−1|
xs∈si−1
|φi−1|
es∈φi−1
elements
φi−1
provided
algorithm
approximately
uniformly
sampled
elements
si−1
note
multiplier
corresponds
average
num-
ber
descendants
given
level
search
tree
estimate
single
run
searchtreesampler
i.e
need
solve
multiple
sampling
tasks
searchtreesampler
samplesearch
ground
truth
1011
1017
5.5
4.5
3.5
searchtreesampler
samplesearch
ground
truth
1000
2000
3000
time
4000
5000
6000
latin
square
ls8-normalized
1000
2000
3000
time
4000
5000
6000
latin
square
ls9-normalized
searchtreesampler
samplesearch
ground
truth
searchtreesampler
samplesearch
ground
truth
105
2.5
1.5
0.5
108
1000
2000
3000
time
4000
5000
6000
langoford
problem
lang-12
1000
2000
3000
time
4000
5000
6000
langford
problem
lang-15
figure
estimated
model
count
function
runtime
figure
pictorial
representation
traditional
left
new
model
counting
techniques
right
notice
ver-
tical
vs.
horizontal
division
search
tree
7.1
experimental
results
compare
new
counting
method
sample-
search
currently
best
model
counter
based
importance
sampling
several
large
instances
known
ground
truth
standard
model
counting
benchmark
figure
plot
estimated
model
count
time
samples
collected
two
methods
representative
instances
encod-
ings
latin
squares
langford
problems
note
methods
rely
minisat
internal
constraint
solver
methods
run
3ghz
machine
searchtreesampler
500
samplesearch
parameters
empirical
results
show
searchtreesampler
converges
faster
provides
accurate
estimates
similar
results
obtained
instances
benchmark
reported
space
reasons
note
instances
rather
large
number
solutions
dif-
ﬁcult
evaluate
uniformity
sampling
using
test
case
accuracy
estimates
indication
quality
sampling
scheme
conclusions
presented
searchtreesampler
new
method
sample
solutions
boolean
formulas
estimate
count
method
uses
constraint
solver
black-
box
therefore
leverage
reasoning
power
state-of-the-art
constraint
solving
technology
main-
taining
approximately
uniform
exploration
search
tree
presented
several
challenging
domains
energy
barriers
asymmetric
search
spaces
reveal
difﬁculties
sampling
presented
data
demon-
strating
standard
methods
simulated
anneal-
ing
gibbs
sampling
samplesat
seriously
suffer
difﬁculties
terms
runtime
unifor-
mity
sampling
results
also
demonstrate
searchtreesampler
overcome
many
dif-
ﬁculties
considerably
faster
set
benchmark
problems
show
intermediate
samples
pseudosolutions
provided
method
used
new
model
counting
technique
shown
effective
practice
references
richardson
domingos
markov
logic
net-
works
machine
learning
:107–136
2006
n.n
madras
lectures
monte
carlo
methods
american
mathematical
society
2002
c.p
gomes
hoffmann
sabharwal
sel-
man
sampling
model
counting
proc
20th
international
joint
conference
artiﬁcial
in-
telligence
ijcai
2007
l.g
valiant
complexity
enumeration
reli-
ability
problems
siam
journal
computing
8:410
1979
c.p
gomes
sabharwal
selman
near-
uniform
sampling
combinatorial
spaces
using
xor
constraints
advances
neural
information
process-
ing
systems
19:481
2007
dechter
kask
bin
emek
generat-
ing
random
solutions
constraint
satisfaction
prob-
lems
proc
18th
national
conference
artiﬁcial
intelligence
aaai
pages
15–21
2002
metropolis
rosenbluth
rosenbluth
teller
teller
equations
state
calcu-
lations
fast
computing
machines
chem
phys.
21:1087–1091
1953
selman
h.a
kautz
cohen
local
search
strategies
satisﬁability
testing
dimacs
series
discrete
mathematics
theoretical
computer
science
1996
c.h
papadimitriou
selecting
satisfying
truth
assignment
proc
32nd
annual
symposium
foundations
computer
science
pages
163–169
1991
sang
bacchus
beame
kautz
pitassi
combining
component
caching
clause
learning
effective
model
counting
theory
applications
satisﬁability
testing
sat
2004
e´en
s¨orensson
extensible
sat-solver
theory
applications
satisﬁability
testing
sat
pages
333–336
springer
2004
kautz
selman
planning
satisﬁability
proc
10th
european
conference
artiﬁcial
intelli-
gence
ecai
pages
359–363
1992
gogate
dechter
approximate
solution
sam-
pling
counting
and/or
spaces
principles
practice
constraint
programming
pages
534–
538.
springer
2008
h.h
hoos
stiitzle
satllb
online
re-
source
research
sat
sat2000
highlights
satisﬁability
research
year
2000
page
283
2000
wei
erenrich
selman
towards
efﬁ-
cient
sampling
exploiting
random
walk
strategies
proc
19th
national
conference
artiﬁcal
intelli-
gence
aaai
pages
670–676
2004
jerrum
sinclair
markov
chain
monte
carlo
method
approach
approximate
counting
integration
approximation
algorithms
np-
hard
problems
pages
482–520
1997
wei
selman
new
approach
model
counting
theory
applications
satisﬁability
testing
sat
pages
324–339
2005
gogate
dechter
approximate
counting
sampling
backtrack-free
search
space
proc
22nd
national
conference
artiﬁcal
intelligence
aaai
volume
page
198
2007
poon
domingos
sound
efﬁcient
infer-
ence
probabilistic
deterministic
dependen-
cies
proc
21st
national
conference
artiﬁcal
intelligence
aaai
volume
page
458
2006
kautz
selman
state
sat
discrete
applied
mathematics
155
:1514–1524
2007
gogate
dechter
samplesearch
scheme
searches
consistent
samples
proc
10th
in-
ternational
conference
artiﬁcial
intelligence
statistics
aistats
2007
gogate
dechter
samplesearch
importance
sampling
presence
determinism
artiﬁcial
intel-
ligence
175
:694–729
2011
gogate
dechter
studies
solution
sam-
pling
proc
23rd
national
conference
artiﬁ-
cial
intelligence
aaai
volume
page
271.
aaai
press
2008
