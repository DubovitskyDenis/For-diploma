local
optima
networks
performance
iterated
local
search
fabio
daolio
faculty
business
economics
desi
university
lausanne
fabio.daolio
unil.ch
gabriela
ochoa
school
computer
science
a.s.a.p
group
university
nottingham
gxo
cs.nott.ac.uk
sébastien
verel
université
nice-sophia
antipolis
inria
lille
nord
europe
verel
i3s.unice.fr
marco
tomassini
faculty
business
economics
desi
university
lausanne
marco.tomassini
unil.ch
abstract
local
optima
networks
lons
recently
proposed
alternative
model
combinatorial
ﬁtness
landscapes
model
compresses
information
given
whole
search
space
smaller
mathematical
object
graph
vertices
local
optima
edges
possible
weighted
transitions
be-
tween
new
set
metrics
derived
model
capture
distribution
connectivity
local
optima
underlying
conﬁguration
space.this
paper
departs
de-
scriptive
analysis
local
optima
networks
actively
studies
correlation
network
features
performance
lo-
cal
search
heuristic
family
landscapes
iterated
local
search
metaheuristic
considered
statistically-
sound
approach
based
multiple
linear
regression
shown
lons
features
strongly
inﬂuence
even
partly
predict
performance
heuristic
search
algorithm
study
validates
expressive
power
lons
model
combinato-
rial
ﬁtness
landscapes
categories
subject
descriptors
f.2.m
analysis
algorithms
problem
complexity
mis-
cellaneous
g.2.2
discrete
mathematics
graph
theory—net-
work
problems
i.2.8
artiﬁcial
intelligence
problem
solving
control
methods
search—heuristic
methods
general
terms
algorithms
measurement
performance
keywords
combinatorial
fitness
landscape
local
optima
network
local
search
heuristics
permission
make
digital
hard
copies
part
work
personal
classroom
use
granted
without
fee
provided
copies
made
distributed
proﬁt
commercial
advantage
copies
bear
notice
full
citation
ﬁrst
page
copy
otherwise
republish
post
servers
redistribute
lists
requires
prior
speciﬁc
permission
and/or
fee
copyright
20xx
acm
x-xxxxx-xx-x/xx/xx
...
10.00
introduction
one
conspicuous
limitations
heuristic
search
meth-
ods
combinatorial
optimization
ability
become
trapped
local
optimum
number
distribution
local
op-
tima
search
space
therefore
important
impact
performance
heuristic
search
algorithms
recently
proposed
model
local
optima
networks
provides
intermedi-
ate
level
description
combinatorial
ﬁtness
landscapes
model
higher
descriptive
power
single
statistical
metric
set
metrics
also
compresses
search
space
manageable
mathematical
object
speciﬁcally
graph
vertices
optima
conﬁgurations
problem
edges
possible
weighted
transitions
optima
network
representation
allows
application
new
analytical
tools
metrics
study
combinatorial
landscapes
namely
com-
plex
networks
analysis
e.g
degree
distribution
clustering
coefﬁ-
cient
assortativity
community
structure
name
previous
work
alternative
deﬁnitions
edges
studied
metrics
computed
network
ex-
tracted
two
combinatorial
problems
family
land-
scapes
quadratic
assignment
prob-
lem
studies
mainly
descriptive
although
distinctive
correlations
network
features
previ-
ous
knowledge
search
difﬁculty
landscapes
found
previous
related
work
explored
relationships
be-
tween
landscape
features
performance
hybrid
authors
use
standard
landscape
metrics
conduct
study
based
mainly
scatter
plots
suggest
work
necessary
gain
better
understanding
escape
rate
ac-
tual
problem
difﬁculty
present
study
addresses
exactly
point
goal
systematically
explore
correlations
local
optima
network
features
performance
stochas-
tic
local
search
algorithm
iterated
local
search
running
underlying
combinatorial
optimization
problem
study
family
landscapes
escape
rate
property
re-
lated
local
optimum
lon
could
considered
new
tool
better
understand
problem
difﬁculty
ultimate
goal
predictive
models
performance
speciﬁc
local
search
heuristics
solving
given
combinatorial
optimization
problem
paper
proposes
initial
predictive
model
perfor-
mance
based
inﬂuential
lon
features
methods
local
optima
network
model
combinatorial
landscapes
iterated
local
search
metaheuristic
considered
study
relevant
deﬁnitions
experimental
setup
given
2.1
local
optima
network
ﬁtness
landscape
triplet
set
search
space
potential
solutions
i.e
function
assigns
every
set
neighbors
i.e
neighborhood
structure
evaluation
corresponding
solutions
i.e
ﬁtness
function
cid:80
present
study
uses
well-known
k-landscapes
benchmark
set
problem-independent
model
construct-
ing
combinatorial
landscapes
tunably
rugged
model
refers
number
binary
genes
genotype
i.e
string
length
epistatic
interaction
i.e
number
loci
chosen
random
inﬂuence
ﬁtness
con-
tribution
particular
gene
starting
n-loci
2-allele
additive
model
increasing
non-linearity
landscapes
tuned
smooth
rugged
hence
search
space
n-bit
binary
strings
size
cid:93
neighborhood
deﬁned
minimum
possible
move
single
bit-ﬂip
operation
neighborhood
size
cid:93
ﬁtness
function
evaluates
genotype
i=1
si1
sik
values
loci
contributions
k+1
drawn
uniformly
ran-
dom
local
optimum
taken
maximum
solution
optima
determined
exhaustive
search
recursively
running
1-bit-ﬂip
best-improvement
hill-climber
algorithm
let
denote
operator
associates
solution
solution
obtained
applying
algorithm
conver-
gence
since
ﬁnite
size
neutrality
values
produces
partition
landscape
ﬁnite
number
basins
attraction
denote
lo1
lo2
lo3
lonv
local
optima
algorithm
best-improvement
hill-climber
choose
initial
solution
repeat
choose
cid:48
cid:48
maxx∈v
cid:48
cid:48
vertices
lo1
lonv
set
edges
eij|wij
local
optima
network
lon
2.2
iterated
local
search
iterated
local
search
relatively
simple
successful
algo-
rithm
operates
iteratively
alternating
applying
move
operator
incumbent
solution
restarting
local
search
perturbed
solution
search
principle
redis-
covered
multiple
times
within
different
research
communities
different
names
term
iterated
local
search
ils
proposed
algorithm
outlines
procedure
algorithm
iterated
local
search
generateinitialsolution
localsearch
repeat
cid:48
perturbation
cid:48
cid:48
localsearch
acceptancecriterion
cid:48
termination
condition
met
present
study
base
localsearch
heuristic
best-improvement
hill-climber
algorithm
stops
heuristic
uses
single
bit-ﬂip
move
operator
therefore
2-bit-ﬂip
mutation
chosen
perturbation
operator
different
found
search
process
accepts
move
ﬁtness
higher
assuming
maximization
settings
ils
performing
ﬁrst-improvement
hill-climbing
conﬁguration
space
lon
escape-edges
distance
deﬁned
section
2.1.
search
terminates
global
optimum
bench-
mark
problems
known
priori
reaching
pre-set
limit
ﬁtness
evaluations
emax
2.3
performance
evaluation
performance
criterion
selected
expected
number
function
evaluations
reach
global
optimum
success
independent
restarts
ils
algorithm
algorithm
measure
accounts
success
rate
theory
unsuccessful
runs
convergence
speed
stopped
tus-steps
ﬁnal
successful
one
running
ts-
k=1
tus
taking
expectation
considering
follows
geometric
distribution1
parameter
gives
steps
total
running
time
would
cid:80
n−1
cid:18
cid:19
local
optimum
tus
connections
among
account
chances
escap-
ing
jumping
another
one
controlled
move
exists
directed
transition
eij
loi
loj
exists
solution
loi
loj
distance
measured
number
moves
i.e
hamming
distance
bit-ﬂip
operator
case
distance-threshold
chosen
accordingly
ap-
plied
perturbation
work
set
weight
wij
transition
wij
cid:93
loi
loj
i.e
number
paths
distance
start-
ing
loi
reaching
basin
loj
normalized
number
solutions
within
reach
w.r.t
given
distance
threshold
i.e
cid:93
loi
weighted
directed
graph
set
present
case
tus
emax
ratio
successful
total
runs
estimator
estimated
average
running
time
successful
runs
ils
variant
detailed
sec
2.2
essentially
incomplete
i.e
soluble
problem
instances
success
prob-
ability
even
limit
inﬁnite
running
time
given
chosen
acceptance
criterion
search
eventually
get
stuck
indeed
test
runs
instance
instances
solved
theoretical
limita-
tion
could
overcome
performing
many
random
restart
cover
whole
search
space
solution
limited
1probability
distribution
number
failures
ﬁrst
success
bernoulli
trials
practical
interest
large
problems
present
study
suc-
cess
performance
estimated
instances
solved
least
benchmark
set
consists
k-landscapes
largest
pos-
sible
parameter
combinations
could
afford
ex-
haustive
extraction
local
optima
networks
order
mini-
mize
inﬂuence
random
generation
landscapes
in-
dependent
problem
instances
considered
combination
accounts
total
270
instances
problem
set
function-evaluations
limit
set
1/5
cid:93
i.e
emax
cid:39
5.2·
104
success
rate
running
time
successful
runs
estimated
500
random
restarts
per
instance
results
3.1
descriptive
statistics
table
summarises
lon
metrics
results
grouped
ac-
cording
value
corresponding
k-landscapes
present
averages
standard
deviations
independent
re-
alizations
per
group
number
local
optima
metric
familiar
description
rugged
landscape
met-
rics
particular
complex-network
perspective
provided
lon
model
left
right
table
represents
average
length
shortest
paths
reach
global
optimum
starting
local
optimum
cost
associated
edge
cid:126
lon
graph
dij
1/wij
measure
interpreted
expected
number
random
perturbations
escaping
loi
entering
exactly
basin
loj
gives
average
path
length
whole
graph
accounts
weighted
net-
work
characteristic
length
intuitively
directly
related
search
difﬁculty
indeed
increases
steadily
land-
scape
ruggedness
whilst
trend
less
clear
possible
explanation
network
growth
terms
nodes
might
counteracted
growth
nodes
connectivity
number
weighted
outgoing
transitions
given
i.e
out-degree
lon
increases
column
zout
tab
column
measures
correlation
ﬁtness
node
weighted
average
ﬁtness
nearest
neigh-
bors
relevant
ils
acceptance
criterion
takes
ﬁtness
values
account
respect
metric
landscapes
behave
level
solution
level
become
uncorrelated
approaching
see
column
general
expected
high
positive
correlation
would
help
search
process
column
wii
reports
average
number
perturbations
re-
main
basin
attraction
proxy
basin
size
larger
basins
difﬁcult
escape
table
shows
average
wii
value
decreases
landscape
ruggedness
column
reports
clustering
coefﬁcient
mea-
sures
ratio
connected
triples
lon
graph
social
network
coefﬁcient
measures
probability
one
friends
friends
among
networks
provides
index
topological
locality
transitions
local
optima
table
suggest
values
decrease
steadily
in-
creasing
lon
density
might
reason
column
zout
counts
number
transitions
departing
given
relevant
know
whether
transitions
rate
preferred
direction
aim
disparity
score
gauges
weight
heterogeneity
out-going
edges
connections
eij
leaving
given
loi
probability
wij
disparity
close
inverse
out-degree
1/zouti
otherwise
higher
value
column
shows
disparity
monotonically
decreases
increasing
point
view
metaheuristic
dynamic
low
disparity
means
transitions
almost
equiprobable
lon
topology
preferentially
guide
search
trajectory
makes
search
process
harder
column
knn
reports
nearest-neighbors
degree
correlation
assortativity
classical
description
mixing
pattern
nodes
network
assortativity
measures
afﬁnity
connect
high
low-degree
neighbors
lons
k-landscapes
strongly
disassortative
i.e
connections
tend
link
others
many
conversely
implications
observation
search
difﬁculty
worth
investigation
last
column
table
gives
values
success
perfor-
mance
indicator
detailed
sec
2.3
abbreviate
ets
following
clearly
expected
running
time
increases
landscape
ruggedness
problem
non-linearity
order
analyze
inter-correlations
studied
metrics
figure
displays
correlogram
whole
data
set
ﬁgure
depicts
possible
pairing
among
observed
variables
scatter
plot
panel
diagonal
corresponding
correlation
coefﬁcient
upper
panel
table
corresponds
ﬁrst
column
correlation
matrix
i.e
one
showing
different
network
metrics
shape
epistasis
mostly
interested
correlations
performance
metric
ets
thus
relevant
scatter
plots
last
row
figure
together
respective
pearson
coefﬁcients
last
column
inspecting
values
highest
positive
correlation
average
length
shortest
path
climbing
global
optimum
ets
cid:39
0.52
total
num-
ber
ets
cid:39
0.50
observation
seems
reasonable
rugged
landscape
i.e
larger
lon
higher
number
hops
lon
reach
global
optimum
thus
longer
expected
running
time
restarting
lo-
cal
search
conversely
larger
basins
higher
nearest-neighbors
ﬁtness-ﬁtness
correlation
shorter
running
time
ets
wii
cid:39
ets
cid:39
−0.40
catch
metrics
turn
correlated
among
e.g
wii
cid:39
0.92
prevents
one
drawing
relation-
ships
causality
simple
pair-wise
correlations
last
column
plots
also
suggest
strong
non-linearity
performance
estimator
w.r.t
lon
metrics
order
analyze
relationships
figure
zooms
relevant
scat-
ter
plots
displays
logarithm
ets
function
considered
landscape
measures
log-transformation
allows
approach
linearity
highlighting
conﬁrming
results
last
column
figure
namely
relationships
ets
metrics
appear
clearly
picture
suggests
posi-
tive
exponential
trend
zout
negative
exponential
trend
wii
case
relation
could
also
close
power-law
since
data
far
normal
bivariate
robust
measure
association
would
rank-based
spearman
statis-
tic
reported
table
results
complement
visual
in-
spection
scatter
plots
conﬁrm
previous
observations
3.2
statistical
modeling
figures
along
table
address
already
research
questions
asked
section
provide
explanatory
model
algorithm
performance
function
landscape
features
end
perform
multiple
linear
figure
correlation
matrix
pairs
observed
variables
read
diagonal
lower
panel
displays
scatter
plots
smoothing
splines
every
possible
pairing
upper
panel
gives
corresponding
pearson
correlation
coefﬁcient
text
size
proportional
absolute
value
lower
panel
smoothing
done
locally-weighted
polynomial
regressions
upper
panel
correlation
coefﬁcient
tested
null
hypothesis
resulting
p-value
symbolically
encoded
levels
0.1
0.05
0.01
0.001
***
k080000.96***0.96***1002500.0065
−0.93***2080−0.96***−0.77***20600.99***−0.83***−1.00.5−0.71***260.47***08000°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°nv0.93***0.15*−0.86***−0.85***−0.59***0.93***−0.65***−0.52***0.50***°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°lo0.079
−0.89***−0.92***−0.75***0.95***−0.80***−0.68***501500.52***100250°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°lv0.13*0.074
0.037
−0.039
0.11.0.055
0.098
°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°fnn0.92***0.74***−0.94***0.81***0.72***0.20.8−0.40***2080°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°wii0.89***−0.98***0.93***0.83***−0.40***°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°cc−0.79***0.98***0.94***0.10.5−0.27***2060°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°zout−0.85***−0.72***0.45***°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°y20.93***0.00.30.6−0.30***−1.00.5°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°knn−0.24***26°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°50150°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°0.20.8°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°0.10.5°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°0.00.30.6°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°0.0e+002.5e+070.0e+002.5e+07ets
figure
scatter
plots
logarithm
estimated
time
succeed
measured
variables
see
labels
x-axis
epistasis
value
treated
category
thus
results
box-and-whisker
diagram
per
group
ﬁst
plot
top-left
corner
llllllll246810121416176810121416klog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll020004000600080001000012000140006810121416nvlog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll501001506810121416lolog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1001502002506810121416lvlog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0.20.40.60.86810121416fnnlog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll204060801001206810121416wiilog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0.10.20.30.40.50.60.76810121416cclog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll204060806810121416zoutlog
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0.00.10.20.30.40.50.66810121416y2log
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll−1.0−0.50.00.56810121416knnlog
ets
table
group
averages
observed
variables
aggregated
epistasis
corresponding
k-landscape
standard
deviations
given
subscripts
number
vertices
local
optima
average
shortest
path
reach
global
optimum
average
path
length
dij
1/wij
spearman
coefﬁcient
nearest-neighbors
ﬁtness-ﬁtness
correlation
wii
average
non-normalized
weight
self-loops
global
clustering
coefﬁcient
zout
average
out-going
degree
average
weight
disparity
out-going
edges
knn
degree
assortativity
ets
estimated
time
succeed
aggregate
fnn
4328
22139
74870
166973
3148110
5270104
8100121
11688101
1380174
33.514
53.712
66.713
76.69.1
90.78.4
10812
1258.6
14611
15612
18751
21415
1884.8
1711.9
1661.2
1700.64
1810.6
1970.42
2050.42
0.7030.19
0.5870.07
0.5350.041
0.4310.025
0.3420.016
0.2550.015
0.190.011
0.1430.0073
0.1330.01
wii
10511
83.93
67.51.9
53.30.88
40.70.78
30.80.35
23.50.25
18.20.11
16.10.06
0.4250.086
0.2630.013
0.190.005
0.1590.0012
0.1430.00085
0.1330.00054
0.1280.00032
0.1250.00023
0.1250.00021
zout
6.91.8
14.31
24.80.86
35.70.57
47.20.57
57.80.39
66.90.33
74.60.17
78.20.13
knn
0.1550.4
0.3920.075
−0.5360.13
0.2190.016
−0.7780.035
0.1240.0059
−0.8560.022
0.07690.002
−0.9040.011
0.04910.0011
0.03340.00046
−0.9280.0093
0.02450.00022
−0.9440.0063
0.01967.8e−05
−0.9480.0055
0.01796.5e−05
−0.9440.0063
ets
×104
2.163.3
8.397.74
32.636.1
51.861.1
81.570.6
276544
300288
414632
793844
table
spearman
statistic
correlation
ets
lon
metrics
p-value
2.2e
pairings
zout
knn
0.885
−0.883
−0.850
0.006
−0.830
−0.883
−0.875
0.885
0.915
fnn
wii
regression
data
general
form
β1xi,1
β2xi,2
···
βpxi
response
variable
case
would
ets
dif-
ferent
predictors
chosen
among
lon
metrics
usual
random
noise
term
least
square
regression
produces
estimates
ˆβj
model
coefﬁcients
difference
predicted
values
actual
observed
values
regression
residuals
ˆyi
ˆβ1xi1
ˆβ2xi2
···
ˆβpxip
difﬁculty
analysis
several
possible
explanatory
variables
turn
intercorrelated
con-
sequence
could
confounding
effect
regression
general
confounders
known
measurable
measured
good
practice
include
model
therefore
start
ﬁtting
following
formula
log
ets
+β1k+β2
log
+β2lo+···+β10knn+
w.r.t
general
expression
response
one
predictors
log-transformed
order
better
approach
linearity
seen
figure
moreover
variable
qualitative
enters
model
ﬁxed
effect
translates
one
appro-
priate
dummy
variable
class
17.
summary
statistics
model
reported
table
table
caption
multiple
represents
proportion
variance
explained
linear
regression
would
equal
observed
data
points
lying
regression
plane
comparing
models
different
number
predictors
adjusted
used
instead
statistic
ratio
variance
explained
parameters
model
residual
unexplained
variance
p-value
probability
achieving
large
null
hypothesis
effect
estimated
coefﬁcient
ˆβj
estimated
standard
error
ˆσj
given
2nd
3rd
columns
respectively
ratio
t-statistic
4th
column
used
calculate
p-value
signiﬁcance
estimation
last
column
table
summary
statistics
linear
regression
model
variables
residual
standard
error
0.8702
248
de-
grees
freedom
observations
deleted
due
missingness
multiple
r-squared
0.8585
adjusted
r-squared
0.8488.
statistic
88.52
248
p-value
2.2e
16.
summary
intercept
k10
k12
k14
k16
k17
log
fnn
wii
zout
knn
estimate
std
error
value
16.06966
0.01542
−1.08926
−3.14529
−5.67316
−8.19327
−10.34765
−12.85523
−13.40456
−1.91370
0.04882
0.00198
0.54148
−0.00302
−7.22853
0.29514
−3.46837
−0.88961
7.39640
2.1726
0.63987
0.0241
1.39976
−0.7782
2.46616
−1.2754
3.76828
−1.5055
5.04638
−1.6236
6.17715
−1.6751
7.14074
−1.8003
7.59325
−1.7653
1.12656
−1.6987
9.7919
0.00499
0.00376
0.5265
0.89574
0.6045
0.02739
−0.1104
5.00042
−1.4456
0.15838
1.8636
5.00914
−0.6924
0.49062
−1.8132
|t|
3.08e
9.81e
4.37e
2.03e
1.33e
1.06e
9.52e
7.30e
7.87e
9.06e
2.37e
5.99e
5.46e
9.12e
1.50e
6.36e
4.89e
7.10e
initial
model
average
length
paths
global
optimum
predictor
regression
coefﬁcient
statistically-signiﬁcant
0.05
threshold
βlo
0.04882
p-value
2.37e
therefore
proceed
perform
step-wise
model
selection
backward
elimination
initial
formula
step
compute
change
could
produced
dropping
predictor
turn
eliminate
one
minimizes
aic
score
resulting
model
iterating
predictors
become
signiﬁcant
obtain
ﬁnal
model
log
ets
βlolo
βzoutzout
βy2y2
βknnknn
detailed
table
table
summary
statistics
ﬁnal
linear
regression
model
residual
standard
error
0.8751
261
degrees
freedom
observations
deleted
due
missingness
multiple
r-squared
0.8494
adjusted
r-squared
0.8471.
f-statistic
368.1
261
p-value
2.2e
16.
summary
intercept
zout
knn
estimate
std
error
value
10.3838
0.0439
−0.0306
−7.2831
−0.7457
0.58512
17.75
0.00434
10.11
0.00831
−3.68
1.63038
−4.47
0.40501
−1.84
|t|
9.24e
1.67e
2.81e
1.18e
6.67e
ﬁnal
model
able
explain
84.94
variance
ob-
served
log
ets
linear
regression
four
variables
lon
network
metrics
among
metrics
length
paths
global
optimum
weight
disparity
highest
relative
importance
without
check
model
assumptions
would
remain
observational
study
could
used
make
predictions
end
combination
parametric
tests
reported
space
reasons
provided
positive
conﬁrmation
however
visual
diagnostics
informative
particular
figure
helps
assess
regression
residuals
follow
normal
distribution
zero
mean
homogeneous
variance
whereas
figure
displays
contributions
model
predictor
turn
highlight-
residual
plot
asses
hypothesis
figure
top
zero-mean
constant-variance
regression
residu-
als
circle
dots
around
ﬁtted
values
dotted
line
visually-signiﬁcant
deviation
appears
red
smooth
line
bot-
tom
quantile-quantile
comparison
studentized
regres-
sion
residuals
circle
dots
theoretical
quantiles
red
thick
line
inspect
distribution
residuals
signiﬁ-
figure
component+residual
plots
linear
regression
model
circle
dots
observation
correspond-
ing
residual
error
regression
plus
value
ﬁtted
one
explanatory
variable
alone
plotted
variable
see
labels
x-axis
signiﬁcant
deviation
linearity
appears
smooth
green
line
red
dotted
line
partial
regression
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll6810121416−2−1012fitted
valuesresidualsllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll−3−2−10123−3−2−1012t−quantilesstudentized
residualsllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll50100150−4−2024locomp+res
log
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll20406080−2−10123zoutcomp+res
log
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0.00.10.20.30.40.50.6−4−3−2−10123y2comp+res
log
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll−1.0−0.50.00.5−3−2−1012knncomp+res
log
ets
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll
ing
possible
violations
linearity
hypothesis
assump-
tions
seem
acceptable
therefore
formula
could
used
make
inferences
words
formula
coefﬁcients
inter-
preted
conditional
expectations
average
change
re-
sponse
one
predictor
undergoes
unitary
change
others
remain
since
dependent
variable
log-transformed
effect
would
multiplicative
important
limitation
proposed
model
multi-
collinearity
due
complex
intercorrelations
among
lon
met-
rics
figure
predictors
really
independent
invalidate
multiple
linear
regression
analysis
inﬂates
variance
coefﬁcients
makes
harder
disentangle
respective
contributions
conclusions
article
explored
correlations
local
optima
network
features
performance
stochastic
local
search
algorithm
running
underlying
combinatorial
optimization
problem
family
landscapes
iterated
local
search
meta-heuristic
considered
shown
previous
work
e.g
features
lon
networks
related
landscapes
ruggedness
thus
problem
difﬁculty
however
statistically
testable
model
presented
contribution
study
investigate
statistically-sound
approach
features
lons
strong
inﬂuence
search
perfor-
mance
expressed
expected
running
times
success
results
obtained
use
multiple
linear
regression
model
show
lon
metrics
important
others
average
length
shortest
paths
optimum
average
out-degree
average
disparity
degree
assortativity
study
conﬁrms
provides
signiﬁcant
evidence
lon
model-
ing
compressed-but-relevant
view
ﬁtness
landscape
used
understand
predict
search
difﬁculty
worth
noticing
network
metrics
estimated
without
knowing
global
optimum
beforehand
aver-
age
out-degree
ﬁtness-ﬁtness
correlation
average
disparity
assortativity
using
metrics
adequate
statistical
model
done
work
opens
exciting
possibili-
ties
standard
sampling
methods
larger
search
spaces
could
studied
thereafter
using
performance
model
based
estimated
lon
metrics
search
heuristic
parameters
op-
erators
off-line
tuned
even
on-line
controlled
plan
continue
working
direction
extend
analysis
combinatorial
problems
qap
acknowledgments
fabio
daolio
marco
tomassini
gratefully
acknowledge
swiss
national
science
foundation
ﬁnancial
support
grant
number
200021-124578
references
auger
hansen
performance
evaluation
advanced
local
search
evolutionary
algorithm
evolutionary
computation
2005.
2005
ieee
congress
volume
pages
1777–1784
ieee
2005
barthélemy
barrat
pastor-satorras
vespignani
characterization
modeling
weighted
networks
physica
statistical
mechanics
applications
346
:34–43
2005
baxter
local
optima
avoidance
depot
location
journal
operational
research
society
32:815–819
1981
chambers
hastie
linear
models
statistical
models
chapter
chapman
hall
london
1992
cleveland
lowess
program
smoothing
scatterplots
robust
locally
weighted
regression
american
statistician
:54–54
1981
daolio
tomassini
vérel
ochoa
communities
minima
local
optima
networks
combinatorial
spaces
physica
statistical
mechanics
applications
390:1684–1694
2011
daolio
verel
ochoa
tomassini
local
optima
networks
quadratic
assignment
problem
evolutionary
computation
cec
2010
ieee
congress
pages
1–8
ieee
2010
fox
weisberg
companion
applied
regression
sage
thousand
oaks
second
edition
2011
glover
future
paths
integer
programming
links
artiﬁcial
intelligence
computers
operations
research
:533–549
1986
groemping
relative
importance
linear
regression
package
relaimpo
journal
statistical
software
:1–27
2006
hoos
stützle
stochastic
local
search
foundations
applications
morgan
kaufmann
2005
kauffman
origins
order
oxford
university
press
new
york
1993
lourenço
martin
stützle
iterated
local
search
handbook
metaheuristics
volume
international
series
operations
research
management
science
pages
321–353
kluwer
academic
publishers
2002
martin
otto
felten
large-step
markov
chains
tsp
incorporating
local
search
heuristics
operations
research
letters
:219–224
1992
newman
structure
function
complex
networks
siam
review
pages
167–256
2003
ochoa
tomassini
verel
darabos
study
landscapes
basins
local
optima
networks
genetic
evolutionary
computation
conference
gecco
2008
pages
555–562
acm
2008
ochoa
verel
tomassini
first-improvement
vs.
best-improvement
local
optima
networks
landscapes
parallel
problem
solving
nature
ppsn
volume
6238
lecture
notes
computer
science
pages
104–113
springer
2010
pelikan
landscapes
problem
difﬁculty
hybrid
evolutionary
algorithms
proceedings
12th
annual
conference
genetic
evolutionary
computation
gecco
pages
665–672
new
york
usa
2010.
acm
pena
slate
gvlma
global
validation
linear
models
assumptions
2010.
package
version
1.0.0.1
reidys
stadler
combinatorial
landscapes
siam
review
:3–54
2002
sakamoto
kitagawa
akaike
information
criterion
statistics
kluwer
academic
publishers
1987
tomassini
verel
ochoa
complex-network
analysis
combinatorial
spaces
landscape
case
phys
rev
:066114
2008
venables
ripley
modern
applied
statistics
springer
new
york
fourth
edition
2002.
isbn
0-387-95457-0
verel
daolio
ochoa
tomassini
local
optima
networks
escape
edges
procedings
international
conference
artiﬁcial
evolution
ea-2011
pages
angers
france
oct
2011
verel
ochoa
tomassini
local
optima
networks
landscapes
neutrality
evolutionary
computation
ieee
transactions
:783
797
2011
