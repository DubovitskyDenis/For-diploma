exploiting
uniform
assignments
first-order
mpe
udi
apsel
ronen
brafman
computer
science
dept
ben-gurion
university
negev
beer-sheva
israel
84105
apsel
brafman
cs.bgu.ac.il
abstract
mpe
probable
explanation
query
plays
important
role
probabilistic
inference
mpe
solution
algorithms
probabilistic
rela-
tional
models
essentially
adapt
existing
belief
assessment
method
replacing
summation
maximization
rich
structure
symme-
tries
captured
relational
models
together
properties
maximization
operator
of-
fer
opportunity
additional
simpliﬁcation
potentially
signiﬁcant
computational
rami-
ﬁcations
speciﬁcally
models
often
groups
variables
deﬁne
symmetric
distri-
butions
population
formulas
maximizing
choice
different
elements
group
realize
ahead
time
signiﬁcantly
reduce
size
model
eliminating
potentially
signiﬁcant
portion
random
variables
paper
deﬁnes
notion
uniformly
assigned
partially
uniformly
assigned
sets
variables
shows
one
recognize
sets
efﬁciently
model
greatly
simpliﬁed
rec-
ognize
little
computational
effort
demonstrate
effectiveness
ideas
em-
pirically
number
models
introduction
probabilistic
relational
models
prm
markov
logic
network
mln
parfactor
model
encapsulate
large
number
random
vari-
ables
potential
functions
using
ﬁrst-order
predicate
logic
using
exact
lifted
inference
methods
one
perform
inference
tasks
directly
rela-
tional
model
solving
many
tasks
previously
considered
intractable
date
ﬁrst-order
mpe
query
perceived
deriva-
tive
methods
since
computational
structure
similar
computing
partition
function
ﬁrst-order
model
exception
maxing-out
random
variables
instead
summing-out
laid
braz
paper
introduce
method
simpliﬁes
many
ﬁrst-order
mpe
tasks
utilizing
properties
speciﬁc
maximization
operator
allowing
solve
models
computing
partition
function
complicated
even
intractable
mpe
property
capitalize
called
uni-
form
assignment
brieﬂy
existence
group
random
variables
assigned
identically
mpe
solution
relational
models
groups
cor-
respond
sets
ground
atoms
derived
atomic
formula
group
recognized
uniformly
assigned
replaced
single
representative
sub-
stantially
simplifying
model
relational
models
replacement
corresponds
arity
reduction
re-
moval
logical
variable
relevant
atomic
formula
suitable
care
mpe
probability
new
model
original
model
mpe
original
model
easily
derived
mpe
new
model
key
contribution
paper
computationally
efﬁ-
cient
procedure
ﬁnding
set
uniform
assignments
given
model
purpose
deﬁne
set
purely
symbolic
operators
anchoring
model
alignment
sym-
bolic
fusion
based
standard
lifted
infer-
ence
tools
fusion
propositionalization
applied
repeatedly
three
symbolic
operators
serve
structure
analysis
tool
result
compact
representa-
tion
property
expressing
logical
variables
removed
atomic
formulas
uniform
assignments
detected
proceed
sim-
plify
model
applying
reduction
procedure
called
uniform
assignment
reduction
uar
procedure
re-
duces
arity
relevant
atomic
formulas
suitably
modiﬁes
table
entries
model
ensuring
mpe
probability
modiﬁed
model
remains
equal
original
steps
detection
reduction
prepro-
cessing
steps
often
result
much
smaller
model
incur
low
computational
overhead
independent
domain
sizes
totally
agnostic
mpe
algo-
rithm
later
applied
demonstrate
effort
uar
reduction
small
w.r.t
complexity
underlying
inference
task
incurs
virtually
overhead
even
simpliﬁcation
achieved
finally
smaller
simpli-
ﬁed
model
passed
favorite
mpe
engine
computed
mpe
mpe
original
model
easily
extracted
detection
method
general
applied
mlns
parfactor
models
however
de-
tection
naturally
formulated
parfactors
since
utilizes
symbolic
fusion
operator
com-
monly
applied
mlns
therefore
start
back-
ground
parfactor
model
introducing
con-
cepts
method
walk-through
section
formal
def-
initions
complete
algorithm
formulation
presented
next
followed
extension
recursive
condi-
tioning
presentation
experimental
results
conclusion
section
background
review
properties
parfactor
model
intro-
duced
poole
later
extended
braz
milch
readers
familiar
model
safely
skip
following
walk-through
section
2.1
model
representation
parfactor
model
ﬁrst-order
representation
fac-
tor
network
bayesian
markov
network
random
variables
model
correspond
ground
atomic
formulas
aka
ground
atoms
form
predicate
assignment
range
range
constant
symbols
un-
der
set
assignments
random
variables
notation
α|v
used
depict
values
assigned
whether
ground
atom
set
ground
atoms
factor
pair
consisting
set
ground
atoms
i=1
potential
function
i=1
range
set
assignments
weight
fac-
tor
cid:0
α1|v
αm|v
cid:1
abbreviation
used
denote
factor
potential
table
respective
set
ground
atoms
example
2.1.
let
factor
consist
following
smokes
alice
drinks
bob
riends
alice
bob
hence
table
entries
represent
various
chances
alice
bob
friends
depending
whether
alice
bob
drinkers/smokers
whereas
factor
networks
modeled
set
factors
core
representation
unit
model
parameter-
ized
factor
aka
parfactor
ﬁrst-order
extension
fac-
tor
reviewing
properties
deﬁne
notions
atoms
logical
variables
substitutions
constraints
atomic
formula
aka
atom
formula
form
constant
logical
variable
logical
variable
domain
dom
car-
dinality
|x|
instance
smokes
denotes
atomic
formula
logical
variable
running
ex-
ample
domain
contains
alice
bob
set
logical
variables
referred
formula
set
formulas
substitution
set
logical
variables
maps
variable
constant
symbol
logical
variable
result
applying
ground
substitution
substitution
logical
variables
constants
instance
substitution
applied
riends
results
riends
ground
substitution
x/alice
applied
atom
smokes
results
ground
atom
smokes
alice
range
atom
denoted
range
deﬁned
range
ground
atom
obtained
ground
substitution
constraint
set
formulas
set
logical
variables
deﬁning
set
legal
substitutions
applica-
ble
instance
constraint
deﬁnes
substitution
substitutions
identical
illegal
use
depict
set
random
variables
obtained
legal
substi-
tution
deﬁned
set
legal
ground
substitutions
applied
constraint
used
depict
size
set
use
depict
projection
set
logical
variables
constraint
similarly
require
constraints
model
normal
form
logical
variable
ﬁxed
value
regardless
binding
logical
variables
lastly
parfactor
tuple
comprised
set
logical
variables
constraint
set
atoms
potential
function
qα∈a
range
applying
substitution
parfactor
results
obtained
applying
substitution
logical
variables
drop-
ping
mapped
constants
parfactors
com-
pactly
model
set
factors
upon
grounding
namely
upon
applying
legal
ground
substitutions
deﬁned
operator
depicts
set
legal
ground
substitutions
abbreviation
used
describe
parfactor
set
atoms
constraint
formula
explicit
set
logical
variables
example
2.2.
let
parfactor
consist
following
smokes
drinks
riends
cx6=y
world
domain
equals
grounding
entails
two
factors
alice
bob
smokes
alice
drinks
bob
riends
alice
bob
smokes
bob
drinks
alice
riends
bob
alice
weight
deﬁned
∈gr
assignment
ground
atoms
random
variables
entailed
grounding
set
random
variables
conveniently
denoted
probable
explanation
ﬁrst-order
model
pair
s.t
argmaxv′
normalization
factor
paper
address
task
obtaining
unnormalized
mpe
walk-through
simplifying
mpe
task
3.1
motivation
2.2
shattering
fusion
propositionalization
consider
following
single-parfactor
model
let
model
set
parfactors
let
denote
atom
denote
parfactor
constraint
say
completely
shattered
sets
random
variables
denoted
ei-
ther
disjoint
equal
hence
shattering
procedure
takes
model
produces
completely
shattered
model
s.t
set
ground
factors
entailed
equal
eliminate
possible
ambiguity
refer
atoms
completely
shattered
model
unique
predicate
symbol
example
2.3.
let
model
consist
two
parfactors
shattering
replaces
ﬁrst
parfactor
two
new
parfactors
consisting
potential
follows
cx6=y
fusion
procedure
merging
two
parfactors
unifying
logical
variables
maintain-
ing
model
weight
given
assign-
since
several
ways
unify
logical
ment
inference
engines
apply
fusion
according
variables
strategy
instance
consider
fusion
two
possible
fusions
many
φf1
φf2
inference
engine
must
choose
one
apply
paper
fusion
used
symbolically
aka
symbolic
fusion
means
structure
analysis
result
table
entries
never
examined
fusion
procedure
never
blows
propositionalization
operation
partially
grounding
parfactor
set
logical
variables
thereby
eliminating
variables
resulting
set
example
propositionalization
parfactor
dom
re-
sults
two
parfactors
2.3
first-order
mpe
deﬁne
mpe
task
given
set
parfactors
combined
weight
assignment
g∈g
g∈g
∈gr
riends
riends
knows
model
chance
two
people
knowing
depends
mutual
friends
although
sim-
ple
model
existing
methods
fail
lift
task
computing
partition
function
speciﬁcally
in-
version
elimination
fails
since
atom
contains
logical
variables
counting
conversion
par-
tial
inversion
fail
since
logical
variables
occu-
pied
least
two
atoms
never
three
re-
cursive
conditioning
splitting
atoms
fails
since
atoms
contain
single
logical
variable
finally
additional
elimination
model
restructuring
rules
fail
assist
well
however
obtaining
mpe
model
demonstrate
polynomial
population
size
course
achieved
simple
modiﬁcation
lifted
methods
rather
exploiting
prop-
erty
unique
mpe
uniform
assignments
understand
property
derived
framework
shall
study
three
model
prototypes
single-parfactor
recurring
formulas
namely
atomic
formula
ap-
pears
single-parfactor
recurring
formulas
multiple-parfactors
3.1.1
single
parfactor
recurring
formulas
consider
model
computing
partition
function
model
polynomial
do-
main
size
ﬁnding
mpe
even
easier
let
entry
maximum
entry
table
assign-
ment
maximal
potential
obtained
assigning
grounds
atoms
uniformly
respectively
refer
uniformly
assigned
formulas
wish
exploit
property
way
may
seem
redundant
moment
applying
procedure
called
uniform
assignment
reduction
uar
uar
modiﬁes
model
preserving
mpe
probability
producing
simpler
mpe
task
example
modiﬁed
arity-reduced
atoms
assignment
range
original
counterparts
exponentiation
compensates
reduced
number
ground
factors
post
modiﬁcation
mpe
modiﬁed
model
ob-
tained
simple
table
lookup
mpe
assignments
immediately
derived
3.1.2
single
parfactor
recurring
formulas
return
friends/knows
example
discussed
earlier
riends
knows
unlike
previous
case
sim-
ple
table
lookup
resolve
model
mpe
since
assignment
one
ground
inevitably
affects
ta-
ble
entries
two
table
positions
ﬁrst
step
identify
overlap
set
model
different
logical
variables
occupying
position
predicate
intuitively
overlap
set
obstruction
mpe
task
solved
simple
table
lookup
hence
next
logical
step
would
eliminate
obstacle
assume
propositionalize
domain
result
opera-
tion
set
parfactors
residing
set
atoms
fuse
par-
factors
together
without
applying
name
change
logical
variables
obtain
single
parfactor
recurring
formulas
thus
previous
case
ap-
plies
detected
uniformly
assigned
every
possible
value
value
assigned
mpe
similarly
every
possible
value
value
assigned
mpe
etc
course
maximizing
value
may
different
interestingly
refer
table
entries
procedure
words
property
detected
set
purely
symbolic
operations
encapsulate
sequence
operations
within
new
operator
called
anchoring
denoted
ap-
plies
set
symbolic
propositionalizations
fusions
example
called
anchored
formulas
emphasize
anchor-
ing
symbolic
operation
require
actually
carrying
explicit
propositionalization
fusion
equivalent
semantically
thus
anchoring
allows
an-
alyze
model
structure
regardless
domain
size
simplify
depiction
uniform
assignments
namely
anchored
formula
carries
information
uniformly
assigned
essen-
tially
says
mpe
every
value
every
possible
substitution
thus
depends
alone
use
denote
instead
sum
thus
far
identiﬁed
overlap
set
applied
anchoring
obtained
set
anchored
formulas
last
step
wish
exploit
property
implied
anchored
formulas
return
uar
pro-
cedure
introduced
previously
however
arity
reductions
applied
discriminately
non-
anchored
logical
variables
remaining
an-
chored
formulas
removed
model
hence
eliminated
uar
procedure
producing
φ|x|
mpe
resolved
existing
inference
engine
3.1.3
multiple
parfactors
study
model
consisting
two
parfactors
wish
detect
uas
apply
uar
pro-
cedure
however
detection
case
some-
complicated
involves
sequence
opera-
tions
anchoring
alignment
symbolic
fusion
start
identifying
overlap
set
ﬁrst
parfac-
tor
followed
anchoring
φf1
stage
form
consistent
among
different
par-
factors
model
since
second
parfactor
contains
non-anchored
address
inconsistent
form
must
align
model
anchoring
logical
variable
second
parfactor
completed
second
par-
factor
replaced
φf2
next
step
invokes
symbolic
fusion
two
an-
chored
parfactors
consisting
φf1
φf2
pro-
ducing
general
symbolic
fusions
may
produce
additional
overlaps
simple
case
overlaps
introduced
hence
anchored
formulas
carry
property
finally
uar
applied
in-
dependently
original
parfactors
producing
|z|
hav-
ing
introduced
core
concepts
algorithm
move
formal
representation
|z|
formal
deﬁnitions
4.1
overlap
set
anchoring
alignment
position
logical
variable
formula
loca-
tion
formula
predicate
argument
list
ordering
positions
respectively
overlap
set
parfactor
set
logical
vari-
ables
occupy
positions
instances
formulas
example
4.1.
parfactor
overlap
set
effect
scope
set
logical
variables
parfac-
tor
denoted
lef
set
logical
variables
whose
set
substitutions
dependent
binding
formally
lef
deﬁned
mini-
mal
set
logical
variables
lef
∀θ1
lef
lef
cθ1
lef
cθ2
constraint-less
parfactors
always
case
lef
example
4.2.
effect
scope
parfactor
4.3
uniform
assignment
reduction
uniform
assignment
reduction
uar
applied
parfac-
tor
formula
denoted
operation
applying
followed
exponentiating
potential
combined
domain
size
removed
logical
variables
formally
operation
yields
fol-
lowing
properties
example
4.3.
effect
scope
parfactor
|cx6=y
6=z
l\l′
cθ′|
anchoring
parfactor
set
logical
variables
denoted
two
step
procedure
propositionalization
lef
ef-
fect
scope
followed
symbolic
fusion
result
set
parfactors
ﬁnal
result
parfactor
contains
following
properties
lef
lef
refrain
actually
computing
context
positions
propositionalized
logical
variables
anchoring
called
anchored
positions
use
substitution
sx∈lef
x/∗
set
logical
variables
depict
result
anchoring
alignment
parfactor
according
parfactor
denoted
align
anchoring
con-
sists
logical
variables
occupy
positions
anchored
predicates
mutual
instance
aligning
accord-
ing
yields
deﬁne
align
applying
align
repeatedly
re-aligning
new
content
instances
predicate
anchored
consistently
4.2
uniform
assignments
arity
reduction
uniform
assignment
formula
assignment
constant
every
ground
range
partially
uniform
assignment
formula
relation
set
logical
variables
uniform
assignment
ground
substitution
namely
partially
uniform
assignment
w.r.t
implies
dom
dom
uniformly
assigned
enable
application
uniform
assignments
model
deﬁne
arity
reduction
operator
atomic
formulas
predicate
symbol
new
predicate
obtained
remov-
ing
positions
anchored
instance
formulas
differ
predicate
symbol
ground
substitution
con-
straint
example
4.4.
let
let
hence
φ|y
example
4.5.
let
cx6=y
let
hence
φ|x|−1
since
cx6=y
|x|
binding
example
4.6.
set
logical
variables
re-
mains
exponentiation
required
simpliﬁed
first-order
mpe
model
simpliﬁcation
algorithm
comprised
two
phases
detecting
uniform
assignments
applying
uniform
assignment
reduction
follows
algorithm
detect-uniform-assignments
input
ginput
completely
shattered
model
output
set
anchored
formulas
ginput
∃lo
s.t
overlap
set
align
anchoring
alignment
∃g1
s.t
symbolicfusion
return
detect-uniform-assignments
else
return
formulas
5.1
detecting
uniform
assignments
detection
procedure
algorithm
purely
symbolic
hence
set
formulas
examined
whereas
ta-
ble
entries
completely
ignored
detection
starts
identifying
overlap
sets
model
accommodated
anchoring
result
set
parfactors
recur-
ring
formulas
entire
model
aligned
accord-
algorithm
simplify-fompe
original
model
input
completely
shattered
model
output
simpliﬁed
model
detect-uniform-assignments
foreach
foreach
return
ingly
making
sure
following
manipulations
operate
completely
shattered
model
next
two
parfactors
chosen
symbolic
fusion
turn
may
generate
new
overlap
set
cycle
overlap
set
detection
anchor-
ing
symbolic
fusion
repeated
two
parfactors
share
formula
left
procedure
returns
set
anchored
formulas
depicting
set
detected
uas
one
issue
remains
unsolved
reapply
symbolic
fusion
procedure
order
produce
many
ar-
ity
reductions
possible
use
greedy
fusion
scheme
logical
variables
formulas
maximum
ar-
ity
matched
ﬁrst
course
guarantee
optimal
sequence
fusions
leave
study
better
fusion
selection
strategies
future
work
proposition
given
completely
shattered
model
al-
gorithm
produces
set
anchored
formulas
exists
mpe
solution
formulas
partially
uniformly
assigned
w.r.t
logi-
cal
variables
anchored
positions
proof
outline
algorithm
applies
symbolically
stan-
dard
lifted
inference
tools
fusion
followed
anchoring
namely
elimination
overlapping
log-
ical
variables
parfactors
merged
single
parfactor
overlap
sets
mpe
solution
triv-
ially
obtained
assigning
atomic
formulas
uniformly
according
remaining
logical
variables
5.2
uar
algorithm
invoking
detect-uniform-assignments
detects
uniform
assignments
model
uniform
assignment
reduction
applied
parfactor
pro-
ducing
simpliﬁed
model
proposition
algorithm
produces
simpliﬁed
model
mpe
probability
proof
outline
formal
proof
found
appendix
idea
pair
original
parfactor
uar
result
show
following
assignment
model
exists
assignment
model
probabilistic
weights
pairs
equal
optimal
assignment
formulas
uniformly
assigned
according
exists
assignment
s.t
probabilistic
weights
pairs
equal
denotes
set
anchored
formulas
yielded
overlap
overlap
anchoring
model
alignment
symbolic
fusion
reduction
|x|·|y
|x|·|y
figure
example
model
simpliﬁcation
5.2.1
uar
example
cover
example
figure
let
model
consist
start
detecting
overlap
set
followed
subsequent
an-
align-
choring
ment
result-
next
symbolic
fusion
applied
ing
re-
maining
formulas
passed
simplify-
fompe
procedure
consecutive
uniform
assignment
reductions
yield
|x|·|y
|x|·|y
5.3
complexity
analysis
let
denote
properties
original
model
number
table
entries
number
atoms
maximum
arity
predicate
number
parfactors
complexity
simplify-
fompe
simply
detect-uniform-
assignments
position
atom
aligned
thus
upper
bound
number
anchored
positions
maximal
num-
ber
symbolic
fusions
combined
total
complexity
upper
bound
symbolic
fusion
depends
fusion
strategy
example
greedy
fusion
strategy
takes
time
polynomial
time
strategies
possible
typical
models
dominating
elements
get
complexity
linear
polynomial
complexity
independent
domain
sizes
recursive
conditioning
demonstrated
property
heavily
dependent
structure
model
one
interesting
aspect
recur-
sive
conditioning
structure
modiﬁcation
induced
conditioning
operator
splitting
singleton
atom
allows
non
formulas
split
uniformly
as-
signed
groups
property
referred
condi-
tional
consequently
scope
uniform
assignments
extended
beyond
role
preprocessing
presented
far
since
various
conditioning
contexts
introduce
opportunities
exploiting
property
consider
model
boolean
domain
size
since
possible
fusions
result
overlap
e.g
model
con-
tains
uniform
assignments
however
condition-
ing
atom
ground
atoms
split
two
uniformly
assigned
groups
demonstrate
fol-
lows
let
...
depict
number
ground
atoms
assigned
hence
binding
do-
main
split
two
parts
set
four
logical
vari-
ables
introduced
deﬁnition
assigned
thus
random
vari-
ground
ables
predicate
eliminated
expression
dom
dom
formally
max
max
max
≡φx
≡φy
n−k
result
set
four
parfactors
follows
iii
uniformly
assigned
namely
set
parfac-
formation
easy
detect
tors
simpliﬁed
iii
n−k
n−k
note
basic
example
mpe
efﬁciently
solved
without
resorting
uar
however
con-
ditional
principle
applies
model
thus
sym-
bolic
simpliﬁcation
becomes
quite
efﬁcient
consider-
ing
computation
repeated
em-
bedding
uar
recursive
conditioning
inference
engine
may
indeed
accelerate
many
lifted
mpe
tasks
experimental
evaluation
present
six
sets
experiments
highlight
fact
method
independent
inference
engine
used
effective
different
engines
used
two
uniform
assignment
lifted
inference
engines
c-fove
wfomc
without
reduction
engines
obtained
http
//people
csail.mit.edu/milch/blog/index.html
dtai.cs.kuleuven.be/ml/systems/wfomc
respectively
modiﬁed
support
max-
product
queries
replacing
sum
operators
max
ignoring
number
counting
permutations
wfomc
speciﬁcally
modiﬁcation
corresponds
changing
code
nnf
node
subclasses
times
shown
log
scale
computation
time
uar
added
overall
time
results
since
wfomc
accepts
weighted
ﬁrst-order
formulas
in-
put
parfactor
passed
wfomc
weighted
ﬁrst-order
formula
form
.∧pn−1
xn−1
unlike
variants
belief
propagation
table
entries
affect
runtime
algorithm
runtime
wfomc
c-fove
models
exclusively
consist
non-zero
non-one
entries
agnostic
actual
numerical
val-
ues
hence
table
entries
models
presented
arbitrarily
set
non-zero
non-one
figures
show
results
two
models
pre-
viously
discussed
paper
demonstrating
uar
extends
scope
known
tractable
models
two
ﬁgures
see
c-fove
wfomc
quickly
fail
lift
inference
task
resort
propositional
inference
uar
applied
solve
mpe
query
efﬁciently
figure
introduces
model
solvable
polynomial
time
becomes
much
easier
solve
uar
symbol
denotes
logical
variable
eliminated
uar
three
ﬁgures
uar
computation
never
exceeds
milliseconds
result
course
consistent
complexity
analysis
demonstrating
detection
negligible
effect
overall
performance
given
mpe
computationally
demanding
exponential
worst-case
one
could
hardly
lose
attempting
run
uar
every
mpe
task
figure
presents
results
running
wfomc
without
uar
random
models
varying
number
parfactors
parfactor
n-parfactor
randomized
model
consists
atoms
atom
obtained
ran-
domly
uniformly
distributed
pool
unary
pred-
icates
set
maximum
logical
variables
per
par-
factor
randomization
guarantees
polynomially
tractable
model
evaluate
effectiveness
uar
however
even
small
domain
sizes
solving
mpe
still
computationally
demanding
tested
random
models
three
domain
sizes
50.
results
average
randomized
sets
figure
shows
unsuccessful
attempt
uar
sim-
plify
friends
smokers
model
since
uar
com-
105
104
103
102
101
c−fove
wfomc
cfove
uar
wfomc
uar
104
103
102
c−fove
wfomc
cfove
uar
wfomc
uar
domain
size
101
domain
size
106
105
104
103
102
101
c−fove
wfomc
cfove
uar
wfomc
uar
200
400
600
domain
size
800
1000
1200
figure
riends
figure
riends
knows
figure
uar
uar
uar
106
105
104
103
104
three
domain
sizes
wfomc
wfomc
uar
103
102
number
parfactors
102
domain
size
104
105
104
103
102
101
c−fove
wfomc
cfove
uar
wfomc
uar
500
1000
domain
size
1500
2000
figure
wfomc
random
models
figure
friends
smokers
figure
students
professors
putation
incurs
little
overhead
milliseconds
case
effect
result
negligible
figure
how-
ever
uar
able
simplify
students
professors
link
prediction
model
s.t
computation
becomes
domain-size
independent
conclusion
introduced
model
simpliﬁcation
method
nar-
rows
assignment
space
ﬁrst-order
mpe
queries
batching
together
sets
random
variables
refrain-
ing
table
lookups
suggested
method
in-
tegrated
existing
lifted
inference
engines
serve
preprocessing
algorithm
adding
low
computational
over-
head
compared
non-simpliﬁed
queries
thus
even
cases
uar
fails
penalty
running
pro-
cedure
negligible
note
property
restricted
spe-
ciﬁc
detection
method
presented
paper
exam-
ple
although
refrained
analyzing
content
potential
tables
detecting
uniform
assignments
one
leverage
speciﬁc
maximizing
assignments
ob-
tain
farther
reductions
consider
example
atom
contained
exclusively
parfactor
overlap
set
two
instances
empty
general
requires
anchoring
alignment
however
maximal
entries
assign
instances
value
e.g.
etc
treated
uniformly
assigned
namely
parfactor
simpliﬁed
φ|y
|·|z|
applying
uar
idea
adapted
approximation
algorithms
may
force
uniform
assignments
cases
guaranteed
finally
third
parties
may
also
wish
assert
uniform
assignments
part
user
constraints
purposes
uar
serves
valid
reduction
acknowledgments
authors
partially
supported
isf
grant
8254320
paul
ivanier
center
robotics
research
produc-
tion
management
lynn
william
frankel
cen-
ter
computer
science
appendix
uar
proof
let
completely
shattered
model
let
sg∈g
set
post-uar
parfactors
anchored
formula
wlog
properties
parfactor
properties
l\l′
cθ′|
constraint
ground
substitution
denote
set
logical
context
parfactor
let
variables
occupy
positions
anchored
let
depict
set
logical
variables
deﬁne
followed
set
logical
variables
occupy
positions
unanchored
contained
exclusively
instances
note
since
weights
assignments
α1θ+θ−
αnθ+θ−
βθ+θ−
wg′
1θ′
|v′
nθ′
|v′
βθ′
|v′
|l\l′
cθ′|
proposition
given
optimal
assignment
argmaxv
uniformly
assigned
exists
wg′
proof
first
pick
one
instances
par-
factor
uniform
assignment
property
depicted
follows
∀θ∗
∀θ1
cθ∗
αiθ∗θ1
αiθ∗θ2
next
construct
follows
∀θ∗
cθ∗
|v′
αiθ∗θ|v
iθ∗
enabled
uniform
assignment
property
ψ|v′
ψ|v
previously
weights
expressed
function
ground
substitutions
wg′
wg′
consequently
wg′
maxv
propositions
follows
maxv′wg′
maxvwg
hence
correctness
uar
references
qθ+
qθ−
qθ′
abbreviations
qθ+∈gr
qθ−∈gr
cθ+
qθ′∈gr
proposition
wg′
exists
proof
pick
one
instances
parfactor
construct
follows
∀θ∗
αiθ∗θ|v
iθ∗
|v′
cθ∗
ψ|v
ψ|v′
meaning
assignment
variables
mu-
tual
copied
weights
counterpart
expressed
follows
αnθ+θ−
α1θ+θ−
βθ+θ−
α1θ+θ−
|v′
αnθ+θ−
|v′
βθ+θ−
|v′
1θ+
|v′
nθ+
|v′
βθ+
|v′
1θ′
wg′
|v′
nθ′
|v′
βθ′
|v′
|l\l′
cθ′|
since
full
weights
product
parfactor
weights
follows
wg′
apsel
brafman
extended
lifted
inference
joint
formulas
proceedings
twenty-
seventh
conference
annual
conference
uncer-
tainty
artiﬁcial
intelligence
uai-11
pages
11–
18.
auai
press
2011
salvo
braz
amir
roth
lifted
ﬁrst-
order
probabilistic
inference
ijcai
pages
1319–
1325
2005
salvo
braz
amir
roth
mpe
partial
inversion
lifted
probabilistic
variable
elimi-
nation
aaai
aaai
press
2006
den
broeck
taghipour
meert
davis
raedt
lifted
probabilistic
inference
ﬁrst-order
knowledge
compilation
ijcai
pages
2178–2185
2011
getoor
friedman
koller
pfeffer
taskar
getoor
taskar
editors
introduction
sta-
tistical
relational
learning
mit
press
2007.
probabilistic
relational
models
gogate
domingos
probabilistic
theorem
proving
proceedings
twenty-seventh
con-
ference
annual
conference
uncertainty
arti-
ﬁcial
intelligence
uai-11
pages
256–265
auai
press
2011
jha
gogate
meliou
suciu
lifted
inference
seen
side
tractable
fea-
tures
advances
neural
information
processing
systems
2010
kersting
massaoudi
hadiji
ah-
madi
informed
lifting
message-passing
aaai
2010
milch
zettlemoyer
kersting
haimes
kaelbling
lifted
probabilistic
inference
counting
formulas
aaai
pages
1062–1068
2008
pearl
probabilistic
reasoning
intelligent
sys-
tems
networks
plausible
inference
morgan
kauf-
mann
1988
poole
first-order
probabilistic
inference
gottlob
walsh
editors
ijcai
pages
985–
991.
morgan
kaufmann
2003
poole
bacchus
kisynski
towards
com-
pletely
lifted
search-based
probabilistic
inference
corr
abs/1107.4035
2011
richardson
domingos
markov
logic
net-
works
machine
learning
1-2
:107–136
2006
singla
domingos
lifted
ﬁrst-order
belief
propagation
aaai
pages
1094–1099
2008
