design
analysis
sparsifying
dictionaries
fir
mimo
equalizers
abubakr
al-abbasi
student
member
ieee
ridha
hamila
senior
member
ieee
waheed
bajwa
senior
member
ieee
naofal
al-dhahir
fellow
ieee
abstract—in
paper
propose
general
framework
transforms
problems
designing
sparse
ﬁnite-impulse-
response
linear
equalizers
non-linear
decision-feedback
equalizers
multiple
antenna
systems
problem
sparsest-approximation
vector
different
dictionaries
addition
investigate
several
choices
sparsifying
dictionaries
framework
furthermore
worst-case
coherences
dictionaries
determine
sparsify-
ing
effectiveness
analytically
and/or
numerically
evaluated
moreover
show
reduce
computational
complexity
designed
sparse
equalizer
ﬁlters
exploiting
asymp-
totic
equivalence
toeplitz
circulant
matrices
finally
superiority
proposed
framework
conventional
methods
demonstrated
numerical
experiments
index
terms—decision-feedback
equalizers
linear
equaliz-
ers
mimo
sparse
approximation
worst-case
coherence
introduction
single-carrier
transmission
broadband
channels
long
ﬁnite
impulse
response
fir
equalizers
typically
implemented
high
sampling
rates
combat
channel
frequency
selectivity
however
implementation
equal-
izers
prohibitively
expensive
design
complexity
fir
equalizers
grows
proportional
square
number
nonzero
taps
ﬁlter
sparse
equalization
nonzero
coefﬁcients
employed
widely-used
technique
reduce
complexity
cost
tolerable
per-
formance
loss
nevertheless
reliably
determining
locations
nonzero
coefﬁcients
often
challenging
recently
sparse
equalizers
investigated
practical
theoretical
perspectives
reduce
implementation
cost
long
fir
ﬁlters
direct-adaptive
scheme
used
designing
sparse
fir
ﬁlters
multi-channel
turbo
equalization
underwater
acoustic
communications
however
proposed
approach
limited
case
single-input
linear
equalizer
authors
exploit
sparsity
ionospheric
high
frequency
communications
systems
formulating
equalization
paper
made
possible
grant
number
nprp
06-070-2-024
qatar
national
research
fund
member
qatar
foundation
statements
made
herein
solely
responsibility
authors
work
presented
part
2015
ieee
global
conference
signal
information
processing
globalsip
abubakr
al-abbasi
purdue
university
usa
e-mail
aalab-
bas
purdue.edu
ridha
hamila
qatar
university
qatar
e-mail
hamila
qu.edu.qa
waheed
bajwa
rutgers
university
state
university
new
jersey
usa
e-mail
waheed.bajwa
rutgers.edu
naofal
al-dhahir
university
texas
dallas
usa
e-mail
aldhahir
utdallas.edu
receiver
sparse
signal
recovery
problem
however
resulting
solution
exactly
sparse
additional
heuristic
optimization
step
applied
eliminate
small
nonzero
entries
general
optimization
problem
designing
sparse
ﬁlter
formulated
involves
quadratic
constraint
ﬁlter
performance
nonetheless
number
iterations
proposed
algorithm
becomes
large
desired
sparsity
level
ﬁlter
increases
addition
approach
also
involves
inversion
large
matrix
case
long
channel
impulse
response
cir
sparse
ﬁlters
also
designed
using
integer
programming
meth-
ods
however
design
process
computationally
complex
number
nonzero
coefﬁcients
reduced
selecting
signiﬁcant
taps
equalizer
nonethe-
less
knowledge
complete
equalizer
tap
vector
still
required
increases
computational
complexity
ℓ1-norm
minimization
problem
formulated
design
sparse
ﬁlter
however
since
resulting
ﬁlter
taps
exactly
sparse
thresholding
step
required
force
nonzero
taps
algorithm
called
sparse
chip
equalizer
ﬁnding
locations
sparse
equalizer
taps
presented
approach
assumes
cir
sparse
algorithm
designing
decision
feedback
equalizer
dfe
proposed
feedforward
ﬁlter
fff
taps
designed
equalize
channel
taps
highest
signal-to-noise
ratios
snrs
number
fff
feedback
ﬁlter
fbf
taps
optimized
however
since
sparsity
constraints
imposed
design
ﬁnal
solution
guaranteed
low
implementation
complexity
multiple-input
multiple-output
mimo
equalizers
optimally
designed
however
design
com-
plexity
equalizers
proportional
product
number
input
output
streams
sparsity
channel
models
e.g.
exploited
reduce
number
equalizer
taps
new
matching-pursuit-type
algorithm
dfe
adaptation
pro-
posed
direct-adaptive
sparse
equalization
problem
investigated
compressive
sensing
perspective
however
algorithm
exploits
inherent
channel
characteristics
sparsity
i.e.
cir
assumed
large
delay
spread
dominant
taps
framework
designing
sparse
fir
equalizers
proposed
using
greedy
algorithms
proposed
framework
achieved
better
perfor-
mance
choosing
largest
taps
minimum
mean
square
error
mmse
equalizer
however
approach
involves
inversion
large
matrices
cholesky
factorization
whose
computational
cost
could
large
channels
large
delay
spreads
addition
theoretical
sparse
approximation
guarantees
provided
paper
develop
general
framework
design
sparse
fir
mimo
linear
equalizers
les
dfes
transforms
original
problem
one
sparse
approxi-
mation
vector
using
different
dictionaries
developed
framework
trivially
specializes
case
single-input
single-input
siso
systems
cases
framework
used
ﬁnd
sparsifying
dictionary
leads
sparsest
fir
ﬁlter
subject
approximation
constraint
moreover
investigate
coherence
sparsifying
dictionaries
propose
part
analysis
identify
one
dictionary
small
coherence
use
simulations
validate
dictionary
smallest
coherence
results
sparsest
fir
design
design
problems
propose
reduced-complexity
sparse
fir
ﬁlter
de-
signs
exploiting
asymptotic
equivalence
toeplitz
circulant
matrices
matrix
factorizations
involved
design
analysis
carried
efﬁciently
using
fast
fourier
transform
fft
inverse
fft
negligible
performance
loss
number
ﬁlter
taps
increases
finally
numerical
results
demonstrate
signiﬁcance
approach
compared
conventional
sparse
ﬁlter
designs
e.g.
terms
performance
computational
complexity1
remainder
paper
organized
follows
introducing
system
model
section
formulate
sparse
equalization
problem
mimo
les
dfes
systems
section
iii
proposed
uniﬁed
framework
described
section
numerical
results
presented
section
finally
paper
concluded
section
notations
use
following
standard
notation
paper
denotes
identity
matrix
size
upper-
lower-case
bold
letters
denote
matrices
vectors
respectively
underlined
upper-case
bold
letters
e.g.
denote
frequency-domain
vectors
notations
denote
matrix
inverse
ma-
trix
element
complex
conjugate
matrix
transpose
complex-conjugate
transpose
operations
respectively
denotes
expected
value
operator
k.kℓ
k.kf
denote
ℓ-norm
frobenius
norm
respectively
denotes
kronecker
product
matrices
components
vector
starting
ending
given
subscripts
vector
separated
colon
i.e.
xk1
system
model
consider
linear
time-invariant
mimo
inter-symbol
interference
isi
channel
inputs
outputs
key
matrices
used
paper
summarized
table
received
sample
rth
output
antenna
time
expressed
1the
design
analysis
methods
developed
paper
applicable
wider
class
fir
mmse
wiener
ﬁlters
e.g.
echo
cancellers
noise
rejection
front-end
ﬁlters
co-channel
interference
canceller
etc
limited
equalizers
channel
equalization
notation
key
matrices
used
paper
table
notation
rxx
rxy
ryy
rnn
meaning
channel
matrix
input
auto-correlation
matrix
input-output
cross-correlation
matrix
output
auto-correlation
matrix
noise
auto-correlation
matrix
rxx
rxy
r−1
ryx
fff
matrix
cofﬁcients
fbf
matrix
cofﬁcients
size
nonf
cid:0
cid:1
cid:0
cid:1
cid:0
cid:1
nonf
nonf
nonf
nonf
cid:0
cid:1
cid:0
cid:1
cid:0
cid:1
nonf
nixi=1
xl=0
k−l
rth
channel
output
cir
ith
input
rth
output
whose
memory
length
noise
rth
output
antenna
received
samples
channel
outputs
sample
time
grouped
column
vector
follows
vxl=0
lxk−l
lth
channel
matrix
coefﬁcient
dimension
xk−l
size
input
vector
time
parameter
maximum
order
noni
cirs
i.e.
max
block
output
samples
input-output
relation
written
compactly
k−nf
k−nf
−v+1
k−nf
i.e.
cid:2
yk−1
k−nf
k−nf
−v+1
k−nf
column
vectors
grouping
received
transmitted
noise
samples
respectively
recall
k−nf
vector
length
nonf
tionally
block
toeplitz
matrix
whose
ﬁrst
block
l=0
followed
zero
matrices
row
formed
l=v
useful
shown
sequel
deﬁne
output
auto-correlation
input-output
cross-correlation
matrices
based
block
length
using
input
correlation
nonf
nonf
noise
correlation
matrices
respectively
de-
yk−nf
cid:3
addi-
ﬁned
rxx
ehxk
k−nf
−v+1xh
ehnk
k−nf
+1nh
k−nf
−v+1i
rnn
k−nf
+1i
input
noise
pro-
cesses
assumed
white
hence
auto-correlation
matrices
assumed
multiples
identity
matrix
i.e.
rxx
rnn
nonf
moreover
output-input
cross-correlation
output
auto-correlation
matrices
respectively
deﬁned
ryx
ehyk
k−nf
+1xh
ryy
ehyk
k−nf
+1yh
k−nf
−v+1i=
hrxx
k−nf
+1i=
hrxxh
h+rnn
iii
sparse
fir
equalization
section
formulate
sparse
fir
equalizer
design
problems
mimo
les
dfes
sparse
fir
mimo
received
samples
passed
mimo
fir
ﬁlter
length
nonf
equalization
deﬁne
kth
equalization
error
sample
vector
mimo
setting
cid:2
ek,1
ek,2
cid:3
equalization
error
ith
input
stream
resulting
kth
error
sample
ith
input
stream
expressed
xk−∆
ˆxk
xk−∆
k−nf
decision
delay
typically
denotes
equalizer
taps
vector
ith
input
stream
whose
dimension
nonf
mse
i.e.
ith
input
stream
written
r−1
ryy
r−1
k−∆
ξex
ir−1
ehx2
ryx1∆
ni∆
-th
column
clearly
optimum
choice
mmse
sense
complex
non-sparse
solution
wopt
r−1
however
general
wopt.i
sparse
implemen-
tation
complexity
increases
proportional
nonf
computationally
expensive
however
choice
wopt
increases
results
performance
loss
suggests
use
excess
error
ξex
design
constraint
achieve
desirable
performance-complexity
tradeoff
speciﬁcally
formulate
following
problem
design
sparse
fir
mimo
bws
argmin
wi∈cnonf
kwik0
subject
ξex
δeq
kwik0
number
nonzero
elements
ar-
gument
δeq
chosen
function
noise
variance
solve
propose
general
framework
presented
sequel
sparsely
design
fir
mimo
les
performance
loss
exceed
pre-speciﬁed
limit
conclude
section
pointing
setup
easily
specialized
case
sparse
fir
siso
les
...
...




sparse
fir
mimo
dfe
fir
mimo-dfe
consists
two
ﬁlters
fff
matrix
matrix
taps
matrix
equal
size
fbf
taps
size
therefore
ebi
forms
1,1
...
no,1
1,1
...
no,1
ebi
deﬁning
size
matrix
0ni×ni∆
decision
delay
satisﬁes
condition
shown
mse
error
vector
time
i.e.
k−nf
−v+1
k−nf
given
tracenbh
r⊥bo
trace
cid:8
ryys
cid:9
ξex
rxx
rxyr−1
ryx
rxyr−1
second
term
mse
equal
zero
case
optimum
fff
matrix
ﬁlter
coefﬁcients
i.e.
=bh
rxyr−1
resulting
mse
cid:17
expressed
follows2
cid:16
deﬁning
a⊥bo
cid:13
cid:13
cid:13
a⊥b
cid:13
cid:13
cid:13
tracenbh
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
a⊥b
cid:13
cid:13
cid:13
cid:13
a⊥b
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
ith
column
hence
compute
fbf
matrix
ﬁlter
taps
minimize
minimize
identity
tap
constraint
itc
i.e.
restrict
equal
identity
matrix
i.e.
towards
goal
rewrite
follows
nixi=1
cid:13
cid:13
cid:13
\ni∆+i
i\ni∆+i
ani∆+i
cid:13
cid:13
cid:13
2we
express
square-root
matrix
spectral-norm
sense
results
cholesky
eigen
decompositions
\ni∆+i
formed
columns
except
ni∆
column
i.e.
ani∆+i
i\ni∆+i
formed
except
ni∆
entry
elements
forced
unit
value
formulate
following
problem
design
sparse
fbf
matrix
ﬁlter
taps
i\ni∆+i
subject
γeq
cid:13
cid:13
cid:13
\ni∆+ni
wherebb
argmin
cid:13
cid:13
cid:13
i\ni∆+i
cid:13
cid:13
cid:13
i\ni∆+i
ani∆+i
cid:13
cid:13
cid:13
estimate
oncebb
calculated
insert
identity
matrix
ﬁrst
location
form
sparse
fbf
matrix
coefﬁcients
i.e.
note
γeq
used
provide
different
quality
service
qos
levels
small
values
assigned
users/streams
demand
high
qos
levels
optimum
fff
matrix
taps
mmse
sense
determined
i\ni∆+i
opt
r−1
ryxbs
r−1
since
opt
sparse
general
propose
sparse
implementation
fff
matrix
follows
computing
mse
function
cid:17
expressed
cid:16
deﬁning
ryy
cid:17
cid:0
w−r−1
cid:13
cid:13
cid:13
ayw
a−h
cid:13
cid:13
cid:13
tracen
cid:16
h−β
r−1
cid:1
ξex
minimizing
ξex
minimize
mse
achieved
reformulation
ξex
get
vector
form
follows
ξex
vec
−vec
a−h
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:16
cid:17
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
vec
operator
maps
matrix
vector
stacking
columns
matrix
afterward
solve
following
problem
compute
fff
matrix
ﬁlter
taps
bws
argmin
kwf
subject
ξex
γeq
γeq
used
control
performance-complexity
tradeoff
conclude
section
noting
fir
les
follow
special
case
fir
dfes
setting
0ni×ni
addition
mse
matrix
dfe
weighted
version
moreover
setup
easily
specialized
case
sparse
fir
siso
dfes
setting
numbers
inputs
outputs
one
proposed
sparse
approximation
framework
unlike
earlier
works
including
one
one
co-
authors
provide
general
framework
designing
sparse
fir
ﬁlters
multiple
antenna
systems
considered
problem
sparse
approximation
using
different
dictionaries
mathematically
framework
poses
fir
ﬁlter
design
problem
follows
bzs
argmin
kzk0
subject
dictionary
used
sparsely
approximate
known
matrix
known
data
vector
change
depending
upon
sparsifying
dictionary
notice
bzs
corresponds
one
elements
bws
bws
corresponding
element
cid:8
δeq
γeq
γeq
cid:9
design
problems
perform
suitable
transformation
reduce
problem
one
shown
instance
complete
square
reduce
formulation
given
hence
one
use
factorization
ryy
e.g.
e.g.
formulate
sparse
approximation
problem
using
cholesky
eigen
decomposition
ryy
different
choices
instance
deﬁning
cholesky
factorization
l⊥lh
equivalent
form
⊥σ⊥p
lower-triangular
matrix
lower-unit-triangular
unitriangular
matrix
diagonal
matrix
assuming
matrix
reduces
vector
problem
respectively
take
one
forms
shown
ω⊥ωh
min
+v−1
kbk0
b∈c
min
+v−1
kbk0
b∈c
s.t
cid:13
cid:13
cid:13
cid:16
s.t
cid:13
cid:13
cid:13
cid:16
l∆+1
cid:17
cid:13
cid:13
cid:13
p∆+1
cid:17
cid:13
cid:13
cid:13
γeq,1
γeq,1
cid:16
cid:16
cid:17
cid:16
cid:17
formed
columns
note
except
column
l∆+1
cid:0
p∆+1
cid:1
cid:17
formed
entries
column
except
unity
entry
similarly
writing
cholesky
factorization
ryy
ryy
lylh
eigen
decomposition
ryy
ryy
ydyu
formulate
problem
follows
min
wi∈c
nonf
kwik0
kwik0
s.t
cid:13
cid:13
cid:13
cid:13
kwik0
min
wi∈c
nonf
min
wi∈c
nonf
s.t
cid:13
cid:13
l−1
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
ryywi
cid:13
cid:13
δeq
δeq
2≤δeq
s.t
cid:13
cid:13
l−1
sparsifying
dictionaries
note
ryy
respectively
furthermore
matrix
identity
matrix
cases
except
equal
l−1
additionally
possible
sparsifying
dictionaries
used
design
sparse
examples
different
sparsifying
dictionaries
used
design
given
table
factorization
type
ryy
l−1
ryy
ryy
ryy
ydy
ryy
vec
l−1
vec
vec
vec
vec
fff
matrix
ﬁlter
given
shown
table
worth
pointing
several
sparsifying
dictionaries
used
sparsely
design
fir
les
fbf
fff
matrix
taps
interest
space
presented
design
problems
possible
choices
sparsifying
dictionaries
choices
derived
applying
suitable
transformations
given
design
problem
far
shown
problem
designing
sparse
fir
ﬁlters
cast
one
sparse
approximation
vector
ﬁxed
dictionary
general
form
problem
given
solve
problem
use
well-
known
orthogonal
matching
pursuit
omp
greedy
algorithm
estimates
bzs
iteratively
selecting
set
sparsifying
dictionary
columns
i.e.
atoms
correlated
data
vector
solving
restricted
least-squares
problem
using
selected
atoms
omp
stopping
criterion
either
predeﬁned
sparsity
level
number
nonzero
entries
upper-bound
norm
residual
error
work
latter
case
problem
change
stopping
criterion
upper-
bound
norm
residual
error
upper-bound
norm
projected
residual
error
pre
i.e.
note
stopping
criterion
becomes
function
hence
value
passed
omp
algorithm
determine
i.e.
bzs
omp
computations
involved
omp
algorithm
well
documented
sparse
approximation
literature
e.g.
omitted
sake
brevity
note
unlike
conventional
compressive
sensing
tech-
niques
measurement
matrix
fat
matrix
sparsifying
dictionary
framework
either
tall
matrix
fewer
columns
rows
full
column
rank
square
one
full
rank
however
omp
similar
methods
still
used
obtaining
bzs
ryy
decomposed
data
vector
compressible
next
challenge
determine
best
sparsifying
dictionary
use
framework
know
sparse
approximation
literature
sparsity
omp
solution
tends
inversely
proportional
worst-case
coherence
notice
max
i6=j
next
investigate
coherence
dictionaries
involved
setup
|hφi
φji|
kφik2kφjk2
worst-case
coherence
analysis
carry
coherence
metric
analysis
gain
in-
sights
performance
different
sparsifying
dictionaries
behavior
resulting
sparse
fir
ﬁlters
first
foremost
concerned
analyzing
ensure
approach
proposed
sparsifying
dictionaries
addition
interested
identifying
smallest
coherence
hence
gives
sparsest
fir
design
many
sparsifying
dictionaries
ryy
factors
involved
analysis
classify
two
groups
ﬁrst
group
dictionaries
resulting
factorization
posterior
error
covariance
matrix
second
group
either
output
auto-correlation
matrix
ryy
factors
matrices
ﬁrst
group
considered
asymptotically
stationary
toeplitz
matrices
shown
section
iv-b
second
group
ryy
hermitian
positive-deﬁnite
square
toeplitz
block
toeplitz
matrix
proceed
follows
characterize
upper-bounds
kind
dictionary
obtain
upper
bounds
worst-case
coherence
ryy
separately
evaluate
closeness
demonstrate
heuristically
simulation
coherence
factors
ryy
less
smaller
ryy
respectively
notice
dictionaries
result
decomposing
ryy
considered
square
roots
spectral-
covariance
matrix
expressed
com-
pactly
terms
snr
cir
coefﬁcients
shows
low
snr
noise
dominates
i.e.
cid:13
cid:13
cid:13
lylh
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
⊥d⊥u
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
d1/2
cid:13
cid:13
cid:13
nnhi−1
snr
cid:16
cid:17
i−1
norm
sense
example
cid:13
cid:13
cid:13
ryy
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
hr−1
consequently
cid:16
cid:17
snr
increases
makes
cid:16
cid:17
converge
constant
typically
noise
effect
decreases
cir
effect
starts
appear
constant
shown
simulations
approach
r−1
hand
ryy
well-structured
hermitian
toeplitz
closed-form
terms
cir
coefﬁcients
ﬁlter
time
span
snr
i.e.
ryy
also
square
matrix
full
rank
due
presence
noise
expressed
matrix
form
ryy
toeplitz
i=0
cid:0
cid:2
|hi|2
snr
cid:3
cid:1
i=j
hih∗
i−j
showed
worst
cir
vector
used
estimate
upper-bound
ryy
given
channel
length
derived
solving
following
optimization
problem
argmax
cid:12
cid:12
cid:12
cid:12
cid:12
cid:12
subject
cid:2
cid:3
length-
cir
vector
matrix
ones
along
super
sub-diagonals
known
solution
eigenvector
corresponding
maximum
eigenvalue
eigenvalues
eigenvectors
matrix
following
simple
closed-forms
cos
cid:18
cid:19
sin
cid:16
jπs
v+2
cid:17
numerically
evaluating
maximum
|λs|
ﬁnd
worst-case
coherence
ryy
sufﬁciently
less
observation
points
likely
success
omp
providing
sparsest
solution
bzs
corresponds
dictionary
smallest
ryy
next
propose
novel
approach
perform
involved
matrix
factorizations
reduced-
complexity
fashion
reduced-complexity
design
section
propose
reduced-complexity
designs
fir
ﬁlters
discussed
including
les
dfes
mimo
systems
proposed
designs
section
iii
involve
cholesky
factorization
and/or
eigen
decomposition
whose
computational
costs
could
large
channels
large
delay
spreads
toeplitz
matrix
efﬁcient
algorithms
cholesky
factorization
levinson
schur
algorithms
involve
computations
matrix
dimension
contrast
since
circulant
matrix
asymptotically
equivalent
toeplitz
matrix
reasonably
large
dimension
eigen
decomposition
circulant
matrix
computed
efﬁciently
using
fast
fourier
transform
fft
inverse
log2
operations3
use
asymptotic
equivalence
toeplitz
circulant
matrices
carry
computations
needed
ryy
factorizations
efﬁciently
using
fft
inverse
fft
addition
direct
matrix
inversion
avoided
computing
coefﬁcients
ﬁlters
approximation
turns
quite
accurate
simulations
shown
later
well
known
circulant
matrix
discrete
fourier
transform
dft
basis
vectors
eigenvectors
dft
ﬁrst
column
eigenvalues
thus
circulant
matrix
decomposed
λcf
dft
matrix
e−j2πkl/m
diagonal
matrix
whose
diagonal
elements
-point
dft
i=m−1
ﬁrst
column
circulant
matrix
orthogonality
dft
basis
functions
matrix
instead
cid:2
cid:3
cid:2
cid:3
3toeplitz
circulant
matrices
asymptotic
output
block
length
equal
time
span
number
nonzero
taps
fff
asymptotic
equivalence
implies
eigenvalues
two
matrices
behave
similarly
furthermore
also
implies
factors
products
inverses
behave
similarly
i=0
denote
ryy
ryx
circulant
approxi-
mations
matrices
ryy
ryx
respectively
addition
denote
noiseless
channel
output
vector
i.e.
ﬁrst
derive
circulant
approximation
block
toeplitz
matrix
ryy
case
siso
systems
follows
special
case
block
toeplitz
case
setting
autocorrelation
matrix
ryy
computed
ryy
eykeyk
reyey
approximate
block
toeplitz
ryy
circulant
matrix
assume
eyk
cyclic
hence
eykeyk
approximated
time-averaged
autocorrelation
function
follows
deﬁning
nonf
reyey
cid:19
cid:3
blocks
−1xk=0
eykeyh
λey
cid:19
cid:18
cid:18
cid:2
...
λey
h
...
λey
dft
matrix
size
dft
λey
matrix
size
column
vector
l-point
dft
ey1
eyt
eyt
subvector
i.e.
eyi
output
vector
circ
ey1
circ
denotes
circulant
matrix
whose
ﬁrst
column
ey1
ryy
reyey
noσ2
ninonf
λey
h
...
λey
cid:16
cid:17
σσh
eyt
nolσ2
noσ2
ith
nil
using
matrix
inversion
lemma
inverse
ryy
cid:26
cid:16
nolσ2
cid:17
cid:27
cid:16
nolσ2
cid:17
cid:16
λ−1
nolσ2
cid:17
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
noxi=1
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
+nolσ2
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
deﬁned
element-wise
norm
square
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
cid:2
anf
cid:3
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
pno
|a0|2
cid:12
cid:12
anf
cid:12
cid:12
2ih
i=1
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
i=1
cid:12
cid:12
cid:13
cid:13
cid:13
cid:13
cid:12
cid:12
output
sequence
eyk
discrete
frequency
domain
without
loss
generality
write
noiseless
channel
column
vector
follows
pno
notice
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
denotes
element-wise
⊙fx
cid:3
vector
cid:2
dft
cirs
cid:2
illustrate
ryy
reduces
e−j2π
∆/nf
cid:3
multiplication
dft
e−j2π∆/nf
data
ryy
reyey
λ̺1
qqh
|khk|2
nnf
1nf
-point
dft
manipulations
expressed
cir
similarly
algebraic
λ̺
cid:19
cid:2
cid:3
i
...
θθh
cid:19
denotes
element-wise
division
notice
special
case
siso
systems
i.e.
expressed
follows
yxr
ryx
rxx
rxy
cid:26
cid:26
cid:17
cid:27
cid:16
λey
λ−1
cid:17
cid:27
cid:16
λey
λ−1
cid:16
cid:19
cid:17
cid:16
cid:19
cid:17
cid:12
cid:12
cid:12
cid:13
cid:13
cid:13
cid:13
cid:13
cid:13
cid:12
cid:12
cid:12
cid:3
eyt
eyt
dft
matrix
note
dft
matrix
-point
dft
cid:2
eyt
ﬁlters
involves
following
steps
summary
proposed
design
method
sparse
fir
estimate
channel
input
output
actual
transmission
channel
obtained
matrices
deﬁned
table
computed
required
matrices
involved
design
i.e.
r⊥or
ryy
factorized
using
reduced-complexity
design
discussed
section
based
desired
performance-complexity
tradeoff
computed
afterward
dictionary
smallest
coherence
selected
use
designing
sparse
fir
ﬁlter
parameters
jointly
used
estimate
locations
weights
ﬁlter
taps
using
omp
algorithm
conclude
section
noting
using
low-
complexity
fast
computation
matrix
factorization
approach
able
design
fir
ﬁlters
reduced-complexity
manner
neither
cholesky
eigen
factorization
needed
furthermore
direct
inversion
matrices
involved
design
ﬁlters
avoided
complexity
analysis
section
evaluate
computation
complexity
various
ﬁlter
designs
terms
complex
multiplica-
tions/additions
cm/a
proposed
sparse
mimo
les
dfes
main
computational
tasks
factorizations
matrices
ryy
omp
computations
noted
computation
cost
cm/a
omp
size
equalizer
vec-
tor/matrix
number
nonzero
entries
note
additional
cid:0
cid:1
cm/a
computations
required
obtain
restricted
least
squares
estimate
hence
total
cost
estimate
using
proposed
design
method
sum
factiorization
cost
involved
matrices
fir
ﬁlter
design
omp
cost
restricted
typically
much
lower
computational
complexity
least
squares
cost
i.e.
cid:0
log
cid:1
cid:0
cid:1
convex-optimization-based
approaches
furthermore
cost
proposed
method
much
smaller
cost
required
estimate
optimum
fir
equalizers
given
complexity
proposed
design
method
compared
optimum
equalizers
sparse
designs
literature
summarized
table
iii
next
report
results
numerical
experiments
evaluate
performance
proposed
framework
considering
different
fir
ﬁlter
designs
using
different
sparsifying
dictionaries
design
numerical
results
investigate
performance
proposed
frame-
work
cirs
used
numerical
results
unit-energy
symbol-spaced
fir
ﬁlters
taps
generated
zero-
mean
unit-variance
uncorrelated
complex
gaussian
random
variables
cir
taps
assumed
uniform
power-
delay-proﬁle4
updp
note
type
channel
rather
4this
type
cirs
considered
wrost-case
assumption
since
inherent
sparsity
channel
models
e.g.
lead
reduce
number
equalizer
taps
i.e.
sparser
equalizers
computational
complexity
various
equalizer
designs
table
iii
equalizer
type
optimum
fir
les
optimum
fir
dfes
sparse
fir
les
sparse
fir
dfes
proposed
sparse
fir
les
proposed
sparse
fir
dfes
design
complexity
cid:17
cid:1
cid:1
cid:16
nonf
fbf
cid:0
fff
cid:0
nonf
cid:0
nonf
noninf
cid:1
fbf
cid:0
cid:1
fff
cid:0
nonf
nonf
cid:1
cid:0
nonf
log
nonf
noninf
cid:1
fbf
cid:0
log
fff
cid:0
nonf
log
nonf
nonf
cid:1
cid:1
difﬁcult
equalize
pdp
uniform
non-sparse
performance
results
calculated
averaging
5000
channel
realizations
error
bars
used
show
conﬁ-
dence
intervals
data
i.e.
standard
deviation
along
curve
use
notation
refer
designed
using
sparsifying
dictionary
used
refer
fbf
designed
using
sparsifying
dictionary
fff
designed
using
sparsifying
dictionary
note
follows
special
case
proposed
design
method
choosing
classical
cholesky
form
llh
factorization
method
keeping
parameter
always
equal
identity
matrix
e.g.
l−1
hence
results
implicitly
compared
approach
proposed
setting
used
quantify
accuracy
approximating
toeplitz
matri-
ces
e.g.
ryy
equivalent
circulant
matrices
respectively
plot
optimal
output
e.g
ryy
snr
output
snr
obtained
circulant
approx-
imation
versus
number
fff
taps
figure
gap
optimal
output
snr
output
snr
circulant
approximation
approaches
zero
number
fff
taps
increases
expected
good
rule
thumb
obtain
accurate
approximation
would
investigate
coherence
sparsifying
dictionaries
used
analysis
plot
worst-case
coherence
versus
⊥eu
formed
columns
input
snr
figure
sparsifying
dictionaries
el⊥
except
column
generated
note
smaller
value
indicates
sparser
approximation
likely
sparsifying
dictionaries
strictly
less
similarly
figure
plot
worst-case
coherence
proposed
sparsifying
dictionaries
used
design
sparse
mimo-les
mimo-dfes
high
snr
levels
noise
effects
negligible
hence
sparsifying
dictionaries
e.g.
ryy
depend
snr
result
coherence
converges
constant
hand
low
snr
noise
effects
dominate
channel
effects
hence
channel
approximated
memoryless
i.e.
tap
channel
dictionaries
e.g.
ryy
approximated
multiple
snr
optimal
solution
snr
proposed
circulant
approx
number
fff
taps
figure
performance
circulant
approximation
based
approach
updp
channel
input
snr
0.8
0.6
0.4
0.2
−40
−20
snr
d1/2
versus
input
snr
updp
80.
note
figure
worst-case
coherence
sparsifying
dictionaries
el⊥
estimate
cid:18
⊥eu
cid:17
removing
column
discussed
moreover
changing
location
insigniﬁcant
effect
show
cid:19
cid:16
⊥eu
identity
matrix
i.e.
next
compare
different
sparse
fir
dfe
designs
based
different
sparsifying
dictionaries
study
effect
performance
omp
algorithm
used
compute
sparse
approximations
omp
stopping
crite-
rion
set
predeﬁned
sparsity
level
number
nonzero
entries
function
pre
performance
loss
computed
based
acceptable
ηmax
zopt
cid:17
log10
cid:16
log10
cid:16
bzs
cid:17
ηmax
coefﬁcients
bzs
computed
percentage
active
taps
calculated
ratio
number
nonzero
taps
total
number
ﬁlter
taps
mmse
equalizer
none
coefﬁcients
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
−40
−20
snr
100
10−1
10−2
10−3
10−4
d1/2
wopt
ryy
d1/2
significant
taps
snr
figure
worst-case
coherence
sparsifying
dictionaries
ryy
versus
input
snr
updp
80.
solid
lines
represent
coherence
corresponding
circulant
approximation
i.e.
ryy
i.e.
ryy
=σσh
figure
ser
comparison
non-sparse
mmse
mimo-les
proposed
sparse
mimo-les
ryy
signiﬁcant
taps
based
proposed
sparsity
level
16-qam
modulation
100
−20
d1/2
significant
taps
snr
100
fff
equalization
taps
snr
0.5
snr
loss
1.5
2.5
max
0.5
3.5
1.5
snr
loss
max
2.5
figure
percentage
active
taps
versus
performance
loss
ηmax
sparse
mimo-les
snr
80.
typically
zero
number
active
ﬁlter
taps
equal
ﬁlter
span
decision
delay
les
set
dfes
set
optimum
figure
plots
percentage
active
taps
versus
performance
loss
ηmax
proposed
sparse
fir
mimo-
les
proposed
approach
refer
signiﬁcant
taps
approach
approach
fir
ﬁlter
taps
computed
ν-signiﬁcant
ones
retained
observe
lower
active
taps
percentage
obtained
coherence
sparsifying
dictionary
small
instance
allowing
0.25
snr
loss
results
signiﬁcant
reduction
number
active
taps
approximately
two-thirds
respectively
two-ﬁfths
taps
snr
equal
eliminated
using
figure
percentage
active
fff
taps
versus
performance
loss
ηmax
sparse
dfe
designs
snr
respectively
sparse
mimo-le
designed
based
ryy
needs
active
taps
maintain
snr
loss
sparse
mimo-les
due
higher
coher-
ence
suggests
smaller
worst-case
coherence
dictionary
setup
sparser
equalizer
moreover
lower
sparsity
level
active
taps
percentage
achieved
higher
snr
levels
consistent
previous
ﬁndings
e.g.
furthermore
reducing
number
active
taps
decreases
ﬁlter
equalization
design
complexity
consequently
power
consumption
since
smaller
number
complex
multiply-and-add
operations
required
figure
compare
symbol
error
rate
ser
performance
proposed
sparse
fir
mimo-les
signiﬁcant
taps
approached
proposed
assuming
sparsity
level
sparse
les
achieve
lowest
ser
followed
ryy
1,2,4,6,10
feed−forward
filter
taps
100
120
140
figure
maximum
output
snr
versus
fff
taps
updp
cir
snr
solid
lines
represent
approach
dashed
lines
represent
signiﬁcant
taps
approach
proposed
10−1
10−2
10−3
siso−dfe
mimo−dfe
0.00
max
max
0.25
0.25
max
max
0.25
snr
ser
comparison
mmse
non-sparse
dfes
i.e.
figure
ηmax
proposed
sparse
dfes
ryy
siso
mimo
systems
ηmax
0.25
16-qam
modulation
signiﬁcant
taps
performs
worst
addition
performance
gain
complexity
proposed
sparse
les
less
signiﬁcant-taps
since
inversion
matrix
required
signiﬁcant-taps
approach
number
nonzero
taps
although
les
achieve
almost
ser
former
lower
decomposition
complexity
since
computation
done
efﬁciently
using
fft
inverse
effect
sparse
fff
fbf
fir
ﬁlter
designs
siso
dfes
performance
shown
figure
plot
active
non-zero
fff
taps
percentage
total
fff
span
versus
maximum
loss
output
snr
allowing
higher
loss
output
snr
yields
bigger
reduction
number
active
fff
taps
moreover
active
fff
taps
percentage
increases
decreases
equalizer
needs
taps
equalize
cir
also
observe
allowing
maximum
0.25
snr
loss
results
substantial
reduction
number
fff
active
taps
equalizer
equalize
channel
using
taps
figure
compare
proposed
sparse
fbf
design
i.e.
signiﬁcant
taps
approach
terms
output
snr
plot
output
snr
versus
fff
taps
updp
channel
vary
number
fbf
taps
lower
curve
upper
curve
output
snr
increases
increases
fbf
designs
expected
sparse
fbf
outperforms
scenarios
proposed
approach
notice
increases
sparse
fbf
becomes
efﬁcient
removing
isi
previously-detected
symbols
resulting
higher
snr
figure
study
ser
performance
pro-
posed
sparse
siso-dfes
mimo-dfes
versus
in-
put
snr
based
different
design
criteria
using
dif-
ferent
sparsifying
dictionaries
assuming
maximum
snr
loss
0.25
sparse
siso/mimo
dfes
designs
achieve
lowest
ser
followed
ryy
note
ηmax
corresponds
optimum
non-sparse
mmse
design
equalizer
taps
active
additionally
high
snr
diversity
gains
mimo-dfes
siso-dfes
noticed
resulting
better
performance
conclusions
paper
proposed
general
framework
de-
signing
sparse
fir
mimo
les
dfes
based
sparse
approximation
formulation
using
different
dictionaries
based
asymptotic
equivalence
toeplitz
circulant
ma-
trices
also
proposed
reduced-complexity
designs
proposed
fir
ﬁlters
matrix
factorizations
carried
efﬁciently
using
fft
inverse
fft
negligible
performance
loss
number
ﬁlter
taps
increases
addi-
tion
analyzed
coherence
proposed
dictionaries
involved
design
showed
dictionary
smallest
coherence
gives
sparsest
ﬁlter
design
finally
signiﬁcance
approach
shown
analytically
quantiﬁed
simulations
references
zhu
sparse
linear
equalizers
turbo
equal-
izations
underwater
acoustic
communication
oceans
2015
mts/ieee
washington
oct
2015
1–6
ribeiro
marques
paiva
galdino
sparsity-
aware
direct
decision-feedback
equalization
ionospheric
chan-
nels
ieee
military
communications
conference
milcom
2015
1467–1472
wei
sestok
oppenheim
sparse
ﬁlter
design
quadratic
constraint
low-complexity
algorithms
ieee
trans
sig
processing
vol
857–870
2013
wei
oppenheim
branch-and-bound
algorithm
quadratically-constrained
sparse
ﬁlter
design
ieee
trans
sig
processing
vol
1006–1018
2013
al-dhahir
ciofﬁ
mmse
decision-feedback
equalizers
ﬁnite-
length
results
ieee
trans
info
theory
vol
961–975
jul
1995
kutz
raphaeli
determination
tap
positions
sparse
equalizers
ieee
trans
commun.
vol
1712–1724
2007
melvasalo
janis
koivunen
sparse
equalization
high
data
rate
wcdma
systems
ieee
8th
spawc
2007
1–5
baran
wei
oppenheim
linear
programming
algorithms
sparse
ﬁlter
design
ieee
trans
sig
processing
vol
1605–1617
2010
kutz
chass
sparse
chip
equalizer
ds-cdma
downlink
receivers
ieee
commun
letters
vol
10–12
2005
ariyavisitakul
sollenberger
greenstein
tap-
selectable
decision
feedback
equalization
communications
1997.
icc
montreal
towards
knowledge
millennium
1997
ieee
international
conference
vol
ieee
1997
1521–1526
al-dhahir
fragouli
choose
number
taps
dfe
ieee
annual
conference
information
sciences
systems
ciss
2002
arni-conf-2007-011
2002
al-dhahir
sayed
ﬁnite-length
multi-input
multi-output
mmse-dfe
ieee
trans
sig
processing
vol
2921–
2936
oct
2000
guidelines
evaluation
radio
transmission
technologies
imt-2000
available
online
recommendation
itu-r
m.1225
1997
ieee-p802.15
tg3c
channel
modeling
sub-committee
final
report
2009
lee
mclane
design
nonuniformly
spaced
tapped-
delay-line
equalizers
sparse
multipath
channels
ieee
trans
commun.
vol
530–535
2004
vlachos
lalos
berberidis
stochastic
gradient
pursuit
adaptive
equalization
sparse
multipath
channels
ieee
journal
emerging
selected
topics
circuits
systems
vol
413–423
2012
gomaa
al-dhahir
new
design
framework
sparse
fir
mimo
equalizers
ieee
trans
commun.
vol
2132–
2140
2011
roy
duman
mcdonald
error
rate
improvement
underwater
mimo
communications
using
sparse
partial
response
equalization
ieee
journal
oceanic
engineering
vol
181–201
2009
proakis
salehi
digital
communications
5th
edition
new
york
usa
mcgraw-hill
2007
al-dhahir
fir
channel-shortening
equalizers
mimo
isi
chan-
nels
ieee
trans
commun.
vol
213–218
2001
al-abbasi
hamila
bajwa
al-dhahir
sparsi-
fying
dictionary
analysis
mimo
channel-shortening
equalizers
2016
ieee
17th
international
workshop
signal
processing
advances
wireless
communications
spawc
2016
1–6
horn
johnson
eds.
matrix
analysis
new
york
usa
cambridge
university
press
1986
xing
gao
zhou
framework
transceiver
designs
multi-hop
communications
covariance
shaping
constraints
ieee
transactions
signal
processing
vol
aug
2015
al-abbasi
hamila
bajwa
al-dhahir
design
ieee
analysis
framework
sparse
fir
channel
shortening.
icc
conference
2016
1–7
tropp
gilbert
signal
recovery
random
measurements
via
orthogonal
matching
pursuit
ieee
trans
info
theory
vol
4655–4666
2007
donoho
compressed
sensing
ieee
trans
info
theory
vol
1289–1306
2006
feng
al.
sparse
equalizer
ﬁlter
design
multi-path
channels
master
thesis
massachusetts
institute
technology
2012
bajwa
pezeshki
finite
frames
sparse
signal
process-
ing
finite
frames
springer
2013
tropp
greed
good
algorithmic
results
sparse
approximation
ieee
trans
info
theory
vol
2231–2242
2004
al-abbasi
hamila
bajwa
al-dhahir
general
framework
design
analysis
sparse
fir
linear
equalizers.
ieee
globalsip
conference
2015
1–5
golub
cme
302
eigenvalues
tridiagonal
toeplitz
matrices
stanford
university
usa
hayes
statistical
digital
signal
processing
modeling
1st
new
york
usa
john
wiley
sons
inc.
1996
pearl
coding
ﬁltering
stationary
signals
discrete
fourier
transforms
corresp
ieee
trans
info
theory
vol
229–232
1973
gray
asymptotic
eigenvalue
distribution
toeplitz
matrices
ieee
trans
info
theory
vol
725–730
1972
ciofﬁ
ee379a
notes
chapter
stanford
university
usa
