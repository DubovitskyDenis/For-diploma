polar
codes
polar
lattices
heegard-berger
problem
jinwen
shi
ling
liu
deniz
gÃ¼ndÃ¼z
senior
member
ieee
cong
ling
member
ieee
abstract
explicit
coding
schemes
proposed
achieve
rate-distortion
function
heegard-berger
problem
using
polar
codes
speciï¬cally
nested
polar
code
construction
employed
achieve
rate-distortion
function
doubly-symmetric
binary
sources
side
information
may
absent
nested
structure
contains
two
optimal
polar
codes
lossy
source
coding
channel
coding
respectively
moreover
similar
nested
polar
lattice
construction
employed
source
side
information
jointly
gaussian
proposed
polar
lattice
constructed
nesting
quantization
polar
lattice
capacity-achieving
polar
lattice
additive
white
gaussian
noise
channel
heegard-berger
problem
source
coding
lattices
index
terms
introduction
well-known
wyner-ziv
problem
lossy
source
coding
problem
source
sequence
reconstructed
presence
correlated
side
information
decoder
interesting
question
whether
reconstruction
non-trivial
distortion
quality
still
obtained
absence
side
information
equivalent
coding
system
contains
two
decoders
one
side
information
without
shown
fig
1985
heegard
berger
characterized
rate-distortion
function
rhb
scenario
distortion
achieved
without
side
information
distortion
jinwen
shi
ling
liu
deniz
gÃ¼ndÃ¼z
cong
ling
dept
electronic
electrical
engineering
imperial
college
london
sw7
2az
e-mails
jinwen.shi12
l.liu12
d.gunduz
imperial.ac.uk
cling
ieee.org
figure
illustration
heegard-berger
rate-distortion
problem
achieved
rhb
denotes
minimum
rate
required
achieve
distortion
pair
also
gave
explicit
expression
quadratic
gaussian
case
kerpez
provided
upper
lower
bounds
heegard-berger
rate-distortion
function
hbrdf
binary
case
later
explicit
expression
rhb
binary
case
derived
together
corresponding
optimal
test
channel
goal
paper
propose
explicit
coding
schemes
achieve
hbrdf
binary
gaussian
distributions
heegard-berger
problem
generalization
classical
wyner-ziv
problem
source
sequence
reproduced
decoder
within
certain
distortion
target
side
information
available
decoder
available
encoder
nested
construction
polar
codes
presented
achieve
binary
wyner-ziv
rate-distortion
function
gaussian
sources
polar
lattice
achieve
standard
wyner-ziv
rate-distortion
functions
proposed
different
solutions
wyner-ziv
problem
need
consider
requirements
two
decoders
jointly
therefore
make
use
low-ï¬delity
reconstruction
decoder
combine
original
source
side
information
form
nested
structure
achieves
optimal
distortion
decoder
optimality
polar
codes
lossy
compression
nonuniform
sources
shown
employ
scheme
part
solution
since
optimal
forward
test
channel
may
asymmetric
binary
heegard-berger
problem
furthermore
shown
polar
codes
optimal
general
distributed
hierarchical
source
coding
problems
heegard-
berger
problem
also
considered
successive
reï¬nement
problem
paper
propose
explicit
coding
schemes
using
polar
codes
polar
lattices
achieve
theoretical
performance
bound
heegard-berger
problem
practical
codes
gaussian
heegard-
berger
problem
also
developed
hybridize
trellis
low-density
parity-check
codes
however
optimality
scheme
achieve
hbrdf
shown
contributions
paper
summarized
follows
propose
nested
construction
polar
codes
non-degenerate
region
binary
ğ‘‹11
ğ‘‹21
ğ‘ğ‘Œ1
ğ‘ğ‘‹1
ğ‘encoderdecoder
1decoder
22ğ‘ğ‘…bits
heegard-berger
problem
prove
achieve
hbrdf
doubly
symmetric
binary
sources
dsbs
consider
reconstruction
source
sequence
decoder
i.e.
decoder
without
side
information
denoted
original
source
sequence
combined
source
combine
reconstruction
original
side
information
obtain
combined
side
information
argument
obtain
another
nested
construction
polar
codes
achieves
hbrdf
entire
non-
degenerate
region
addition
present
explicit
coding
scheme
using
two-level
polar
codes
achieve
hbrdf
whose
forward
test
channel
may
asymmetric
finally
prove
polar
codes
achieve
exponentially
decaying
block
error
probability
excess
distortion
decoders
binary
heegard-berger
problem
consider
gaussian
heegard-berger
problem
propose
polar
lattice
con-
struction
consists
two
nested
polar
lattices
one
additive
white
gaus-
sian
noise
awgn
capacity-achieving
gaussian
rate-distortion
function
achieving
construction
similar
one
proposed
gaussian
wyner-ziv
problem
however
heegard-berger
problem
setting
need
treat
difference
original
source
reconstruction
decoder
new
source
difference
original
side
information
reconstruction
decoder
new
side
information
result
obtain
optimal
test
channel
connects
new
source
new
side
information
using
additive
gaussian
noises
according
test
channel
construct
two
nested
polar
lattices
achieve
gaussian
hbrdf
entire
non-degenerate
region
organization
paper
organized
follows
section
presents
background
binary
gaussian
heegard-berger
problems
construction
polar
codes
achieve
hbrdf
dsbs
investigated
section
iii
section
polar
code
construction
gaussian
heegard-berger
problem
addressed
paper
concluded
section
notation
random
variables
denoted
capital
letters
sets
denoted
capital
letters
calligraphic
font
denotes
probability
distribution
random
variable
taking
values
set
two
positive
integers
denotes
vector
represents
realizations
random
variables
set
positive
integers
denotes
subvector
iâˆˆf
gaussian
case
construct
polar
codes
multiple
levels
denotes
random
variable
level
denotes
iâˆˆf
l-th
level
|f|
vector
cid:0
denotes
subvector
i-th
realization
cid:1
denote
complement
cardinality
set
respectively
positive
integer
deï¬ne
cid:44
denotes
indicator
function
equals
otherwise
let
denote
mutual
information
paper
logarithms
base
two
information
measured
bits
problem
statement
heegard-berger
problem
let
pxy
discrete
memoryless
sources
dmss
characterized
random
vari-
ables
generic
joint
distribution
pxy
ï¬nite
alphabets
deï¬nition
heegard-berger
code
source
side
information
consists
encoder
two
decoders
Ë†x1
Ë†x2
ï¬nite
reconstruction
alphabets
cid:34
cid:88
j=1
cid:16
cid:17
cid:35
expectation
operation
per-letter
distortion
measure
paper
set
hamming
distortion
binary
sources
squared
error
distortion
gaussian
sources
deï¬nition
rate
said
achievable
every
sufï¬ciently
large
exists
code
log
hbrdf
rhb
deï¬ned
inï¬mum
-achievable
rates
single-
letter
expression
rhb
given
following
theorem
theorem
theorem
rhb
min
u2|u1
set
auxiliary
random
variables
jointly
distributed
generic
random
variables
form
markov
chain
|u1|
|x|
|u2|
|x|
iii
exist
functions
figure
illustration
hbrdf
regions
dsbs
critical
distortion
doubly
symmetric
binary
sources
let
binary
dms
i.e.
uniform
distribution
binary
side
information
speciï¬ed
independent
bernoulli
random
variable
0.5
denotes
modulo
two
addition
hbrdf
dsbs
characterized
four
regions
region
0.5
min
non-degenerate
region
rhb
function
region
0.5
degenerate
region
heegard-berger
problem
boils
wyner-ziv
problem
second
decoder
region
iii
0.5
min
also
degenerate
since
problem
boils
standard
lossy
compression
problem
ï¬rst
decoder
region
0.5
trivially
achieved
without
coding
four
regions
depicted
fig
note
hbrdf
degenerate
regions
iii
achieved
using
polar
codes
described
focus
non-degenerate
region
explicit
calculation
hbrdf
dsbs
region
given
follows
deï¬ne
function
sd1
cid:44
Î¸1g
0dcp1d20.51
d1region
iregion
iiregion
iiiregion
ivi-bi-a
Î¸1Âµ
Î¸1Âµ
table
joint
distribution
ï£±ï£´ï£²ï£´ï£³
d1âˆ’
Î¸âˆ’Î¸1
1âˆ’Î±
âˆ’Î¸1Âµ
1âˆ’Î¸
cid:44
cid:54
domain
following
theorem
characterizes
hbrdf
region
0.5
theorem
theorem
0.5
min
rhb
min
sd1
minimization
variables
satisfy
Î¸1Âµ
corresponding
forward
test
channel
structure
also
given
reproduced
table
constructs
random
variables
joint
distribution
satisfy
u2|u1
sd1
next
recall
function
cid:44
deï¬ned
domain
binary
entropy
function
cid:44
log
log
binary
convolution
deï¬ned
cid:44
recall
deï¬nition
critical
distortion
wyner-ziv
problem
dsbs
dcâˆ’p
cid:48
following
corollary
speciï¬es
explicit
characterization
hbrdf
dsbs
region
i-b
fig
speciï¬ed
min
0.5.
corollary
corollary
distortion
pairs
satisfying
0.5
min
i.e.
region
i-b
fig
rhb
optimal
forward
test
channel
region
i-b
given
cascade
two
binary
symmetric
channels
bscs
depicted
fig
figure
optimal
forward
test
channel
region
i-b
crossover
probability
bsc
satisï¬es
section
iii
ï¬rst
propose
polar
code
design
achieves
hbrdf
region
i-b
dsbss
provide
general
polar
code
construction
achieving
hbrdf
entire
region
gaussian
sources
respectively
i.e.
suppose
independent
zero-mean
gaussian
random
variables
explicit
variances
expression
rhb
case
given
optimal
test
channels
given
independent
zero-mean
gaussian
random
variables
d1Ïƒ2
cid:18
d1+Ïƒ2
d1+Ïƒ2
problem
degenerates
classical
lossy
compression
problem
degenerates
wyner-ziv
coding
problem
decoder
problem
decoder
hbrdf
given
rhb
d1Ïƒ2
rhb
d1Ïƒ2
requires
coding
polar
lattice
codes
meet
classical
wyner-ziv
rate-
distortion
functions
gaussian
sources
introduced
used
achieve
hbrdf
degenerate
regions
non-degenerate
distortion
region
speciï¬ed
d1Ïƒ2
hbrdf
region
given
region
speciï¬ed
+Ïƒ2
d1+Ïƒ2
cid:19
log
log
cid:16
cid:17
d1+Ïƒ2
cid:18
cid:19
rhb
log
xÏƒ2
focus
construction
polar
lattice
codes
achieve
hbrdf
section
iii
polar
codes
dsbs
section
present
construction
polar
codes
achieves
rhb
dsbs
region
first
give
brief
overview
polar
codes
bsc
bsc
bsc
xyğ‘ˆ2ğ‘ˆ1
let
cid:44
deï¬ne
cid:44
gâŠ—n
cid:110
cid:111
generator
matrix
polar
codes
length
denotes
kronecker
product
polar
code
linear
code
deï¬ned
|f|
referred
frozen
set
code
constructed
ï¬xing
varying
values
moreover
frozen
set
determined
bhattacharyya
parameter
binary
memoryless
asymmetric
channel
input
output
bhattacharyya
parameter
deï¬ned
x|y
cid:44
cid:80
cid:112
polar
code
construction
region
i-b
observe
proof
theorem
auxiliary
random
variable
considered
output
bsc
crossover
probability
input
therefore
region
i-b
minimum
rate
decoder
achieve
target
distortion
shown
theorem
polar
codes
achieve
rate-
distortion
function
binary
symmetric
sources
explicit
code
construction
also
provided
considering
source
sequence
independent
identically
distributed
i.i.d
copies
know
theorem
decoder
recover
reconstruction
asymptotically
close
becomes
sufï¬ciently
large
therefore
assume
decoder
decoder
obtain
following
reconstructed
decoder
observes
side
information
addition
considered
side
using
method
decoder
hence
information
decoder
achieve
distortion
therefore
problem
decoder
similar
wyner-ziv
coding
except
decoder
observes
extra
side
information
recall
achieving
wyner-ziv
rate-distortion
function
using
polar
codes
based
nested
code
structure
proposed
consider
wyner-ziv
problem
consisting
compressing
source
presence
correlated
side
information
using
polar
codes
dsbs
code
corresponding
frozen
set
designed
good
source
code
distortion
code
corresponding
frozen
set
designed
good
channel
code
bsc
shown
test
channel
bsc
degraded
respect
bsc
case
encoder
transmits
decoder
sub-vector
belongs
index
set
fc\fs
optimality
scheme
proven
similarly
optimal
rate-distortion
performance
decoder
heegard-berger
prob-
lem
also
achieved
using
nested
polar
codes
u2|u1
output
cid:0
source
pair
cid:0
cid:1
reconstruction
second
equality
holds
since
form
markov
chain
motivated
code
cs2
corresponding
frozen
set
fs2
designed
good
source
code
denotes
test
channel
source
code
additionally
code
cc2
corresponding
frozen
set
fc2
designed
good
channel
code
test
channel
input
lemma
4.7
order
show
nested
structure
cs2
cc2
sufï¬cient
show
stochastically
degraded
respect
deï¬nition
channel
degradation
let
two
binary
discrete
memoryless
channels
say
stochastically
degraded
respect
exists
discrete
memoryless
channel
px|u
x|u
y|x
cid:1
according
y|u
cid:88
xâˆˆx
proposition
stochastically
degraded
respect
random
variables
agree
forward
test
channel
shown
fig
proof
test
channel
structure
fig
form
markov
chain
deï¬nition
u1|u2
u1|u2
px|u2
x|u2
pu1|u2
u1|u2
also
u1|u2
u1|u2
|u2
y|u2
pu1|u2
u1|u2
cid:88
cid:88
cid:88
|u2
y|u2
pu1|u2
u1|u2
px|u2
x|u2
y|x
pu1|u2
u1|u2
u1|u2
u1|u2
y|x
completing
proof
therefore
claim
fc2
fs2
lemma
4.7
rather
sending
entire
encoder
sends
sub-vector
belongs
available
vector
belongs
index
set
fc2\fs2
decoder
since
decoder
extract
information
side
information
cid:0
cid:1
result
polar
code
construction
heegard-berger
problem
region
i-b
given
follows
s1|
cid:111
decoders
encoder
also
able
recover
struction
wfs1
cid:110
applies
lossy
compression
jointly
sources
cid:0
encoding
encoder
ï¬rst
applies
lossy
compression
source
sequence
recon-
corresponding
average
distortion
construct
code
cs1
fs1
encoder
transmits
compressed
sequence
cs1
next
encoder
target
distortion
construct
cs2
fs2
finally
encoder
applies
channel
coding
symmetric
test
channel
input
derive
cc2
deï¬ned
ufs2
|fc2\fs2|
encoder
sends
sub-vector
ufc2\fs2
decoding
decoder
receives
cid:1
reconstruction
output
cid:0
cid:1
ufc2
moreover
decoder
also
recover
decoder
applies
successive
cancellation
decoding
algorithm
obtain
outputs
reconstruction
sequence
hence
derive
ufc2
cid:0
fc2
ufc2
ufc2\fs2
decoders
decoder
receives
ufc2\fs2
codeword
realizations
cid:0
cid:1
cid:1
next
present
rates
achieved
proposed
scheme
polarization
theorem
lossy
source
coding
know
reliable
decoding
decoder
achieved
high
probability
s1|
polarization
theorems
source
channel
coding
code
rate
required
nâ†’âˆâˆ’âˆ’âˆ’â†’
reliable
decoding
decoder
derived
|fc2|
|fs2|
nâ†’âˆâˆ’âˆ’âˆ’â†’i
therefore
total
rate
asymptotically
given
region
i-b
s1|+|fc2|âˆ’|fs2|
nâ†’âˆâˆ’âˆ’âˆ’â†’
furthermore
according
expected
distortions
asymptotically
approach
target
values
decoders
respectively
becomes
sufï¬ciently
large
encoding
decoding
complexity
scheme
log
note
scheme
performance
decoder
challenging
decoder
thus
simulation
conducted
ï¬xing
0.35
0.4
varying
min
settings
satisfy
requirements
region
i-b
performance
figure
simulation
performance
rhb
corresponding
region
i-b
curves
shown
fig
18.
shows
performances
achieved
polar
codes
approaches
hbrdf
increases
coding
scheme
entire
region
theorem
deï¬nes
rhb
entire
region
present
coding
scheme
achieve
hbrdf
entire
region
note
rhb
region
i-b
explicitly
calculated
corollary
therefore
also
achieve
region
i-b
straightforwardly
shown
section
iii-a
optimal
test
channel
structure
shown
table
ternary
random
variable
i.e.
therefore
express
two
binary
random
variables
2ub
i.e.
decoder
apply
scheme
speciï¬ed
previous
subsection
achieve
considered
side
information
decoder
rate
required
transmit
evaluated
u2|u1
ub|u1
ua|u1
ub|u1
accordingly
design
two
separate
coding
schemes
achieve
rates
ua|u1
ub|u1
respectively
since
form
markov
chain
ua|u1
test
channel
tca
degraded
respect
tsa
observe
table
nonuniform
00.050.10.150.20.250.30.350.10.20.30.40.50.60.70.80.91d2rhb
rhb
polar
codes
n=210polar
codes
n=212polar
codes
n=214polar
codes
n=216polar
codes
n=218
let
0.5
frozen
set
fsa
fca
information
set
isa
ica
shaping
set
ssa
sca
identiï¬ed
fsa
isa
ssa
fca
ica
sca
cid:1
2âˆ’n
cid:111
cid:110
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
cid:110
cid:110
cid:0
i|k
iâˆ’1
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
cid:110
cid:110
cid:1
2âˆ’n
cid:111
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
cid:110
cid:110
cid:0
i|k
iâˆ’1
cid:110
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
cid:110
2âˆ’n
cid:0
i|k
iâˆ’1
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
cid:1
2âˆ’n
cid:111
lemma
4.7
channel
degradation
fsa
fca
ica
isa
ssa
sca
addition
observe
sca\ssa
written
sca\ssa
cid:110
cid:110
:2âˆ’n
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
2âˆ’n
cid:0
i|k
iâˆ’1
cid:1
2âˆ’n
cid:111
therefore
proportion
|sca\ssa|
encoding
encoder
ï¬rst
applies
lossy
compression
target
distortion
cid:1
joint
source
sequence
evaluate
kisa
randomized
obtain
rounding
respect
pki|k1
iâˆ’1
cid:0
0|k1
iâˆ’1
cid:0
1|k1
iâˆ’1
cid:1
cid:1
isa
i.e.
treats
cid:0
ï£±ï£´ï£²ï£´ï£³0
w.p
pki|k1
iâˆ’1
ï£±ï£´ï£²ï£´ï£³Ëœki
w.p
pki|k1
iâˆ’1
arg
maxk
pki|k1
iâˆ’1
k|k1
iâˆ’1
fsa
ssa
w.p.
abbreviation
probability
Ëœki
chosen
uniformly
shared
encoder
decoders
lossy
compression
also
note
second
formula
fact
maximum
posteriori
map
decision
ssa
encoder
sends
kisa\ica
decoders
decoding
using
pre-shared
kfsa
received
kisa\ica
decoder
recovers
kica
kssa
side
information
sequences
decoding
algorithm
map
rule
respectively
hence
obtain
kicaâˆªssa
ksca\ssa
recovered
vanishing
error
probability
since
bhattacharyya
parameters
arbitrarily
small
therefore
reconstruction
given
theorem
theorem
let
qk1
let
pk1
uses
cid:48
0.5
satisfying
ua|u1
denote
resulting
joint
distribution
derived
denote
joint
distribution
result
another
encoder
|isa\ica|
cid:17
cid:16
2âˆ’n
cid:48
cid:17
pk1
qk1
|px
denotes
variational
distance
distribu-
cid:16
cid:80
cid:44
tions
note
ksca
covered
pre-shared
random
mapping
achieve
however
shown
theorem
replacing
random
mapping
map
decision
kssa
preserves
optimality
thus
utilize
map
decoder
ssa
scheme
terms
second
level
encoder
decoder
ï¬rst
recover
consequently
encoder
treats
cid:0
cid:1
joint
source
decoder
treats
cid:0
cid:1
joint
side
information
likewise
according
ub|u1
test
channel
tcb
degraded
respect
tsb
similar
ï¬rst
level
let
frozen
set
fsb
fcb
information
set
isb
icb
shaping
set
ssb
scb
adopted
replacing
respectively
result
fsb
fcb
icb
isb
ssb
scb
lemma
4.7
channel
degradation
encoder
evaluates
pre-shared
wisb
random
bits
uniformly
chosen
wssb
determined
map
decoder
deï¬ned
arg
maxw
i|w
iâˆ’1
w|w1
iâˆ’1
encoder
sends
wisb
decoders
decoder
recovers
wicb
reconstruction
given
side
information
cid:0
randomized
rounding
respect
i|w
iâˆ’1
cid:1
finally
using
pre-shared
wfsb
wfsb
âˆªssb
\icb
cid:16
cid:17
cid:16
2âˆ’n
cid:48
cid:17
let
denote
joint
distribution
encoder
performs
compression
according
coding
scheme
presented
paragraph
let
denote
resulting
joint
distribution
encoder
using
randomized
rounding
respect
means
encoder
dose
perform
compres-
ub|u1
i|w
iâˆ’1
sion
similarly
theorem
cid:48
0.5
\icb|
|isb
note
based
ua|u1
satisï¬ed
thus
u2|u1
regard
decoder
state
following
theorem
theorem
consider
target
distortion
min
dsbs
side
information
available
decoder
cid:48
0.5
exists
two-level
polar
code
rate
arbitrarily
close
u2|u1
expected
distortion
decoder
satisï¬es
2âˆ’n
cid:48
cid:17
cid:16
proof
see
appendix
decoder
know
always
taken
output
bsc
crossover
probability
input
hence
according
theorem
theorem
coding
scheme
achieve
optimal
hbrdf
long
optimal
parameters
achieve
minimum
value
sd1
speciï¬ed
finally
state
achievability
hbrdf
dsbs
entire
region
following
theorem
theorem
10.
consider
target
distortions
0.5
min
dsbs
side
information
available
decoder
cid:48
0.5
rate
min
sd1
exist
polar
code
rate
two-level
polar
code
rate
u2|u1
together
achieve
expected
distortions
decoder
respectively
given
table
decoder
2âˆ’n
cid:17
cid:16
cid:16
proof
shown
theorem
exists
polar
code
rate
arbitrarily
close
achieves
expected
distortion
theorem
shows
two-level
polar
code
rate
arbitrarily
close
u2|u1
achieves
decoder
finally
total
rate
u2|u1
2âˆ’n
cid:48
cid:17
cid:16
2âˆ’n
cid:48
cid:17
2âˆ’n
cid:17
cid:16
min
sd1
last
equality
holds
joint
distribution
given
table
finally
observe
encoding
decoding
complexity
coding
scheme
log
polar
lattices
gaussian
sources
shown
polar
lattices
achieve
optimal
rate-distortion
performance
standard
wyner-ziv
compression
gaussian
sources
squared-error
distortion
wyner-ziv
problem
gaussian
case
solved
nested
code
structure
combines
awgn
capacity
achieving
polar
lattices
rate-distortion
optimal
ones
show
hbrdf
non-degenerate
region
speciï¬ed
also
achieved
similar
nested
code
structure
start
basic
introduction
polar
lattices
n-dimensional
lattice
discrete
subgroup
described
full
rank
generator
matrix
gaussian
distribution
variance
centered
deï¬ned
2Ï€Ïƒ
cid:107
xâˆ’c
cid:107
2Ïƒ2
let
fÏƒ,0
short
Î»-periodic
function
deï¬ned
cid:88
Î»âˆˆÎ»
cid:88
Î»âˆˆÎ»
2Ï€Ïƒ
cid:107
xâˆ’Î»
cid:107
2Ïƒ2
note
restricted
fundamental
region
actually
probability
density
function
pdf
Î»-aliased
gaussian
noise
ï¬‚atness
factor
lattice
deï¬ned
cid:44
max
xâˆˆr
|det
denotes
volume
fundamental
region
interpreted
maximum
variation
respect
uniform
distribution
fundamental
region
deï¬ne
discrete
gaussian
distribution
centered
discrete
distribution
taking
values
cid:80
Î»âˆˆÎ»
convenience
write
Ïƒ,0
shown
lattice
gaussian
distribution
preserves
many
properties
continuous
gaussian
distribution
ï¬‚atness
factor
negligible
keep
notations
simple
always
set
sublattice
cid:48
induces
partition
denoted
Î»/Î»
cid:48
equivalence
groups
modulo
cid:48
order
partition
equals
number
cosets
order
two
call
binary
partition
let
/Î»1/Â·Â·Â·
/Î»râˆ’1/Î»
cid:48
n-dimensional
lattice
partition
chain
partition
Î»lâˆ’1/Î»l
code
Î»lâˆ’1/Î»l
selects
sequence
coset
representatives
set
representatives
cosets
construction
requires
set
nested
linear
binary
codes
block
length
dimension
information
bits
Â·Â·Â·
gaussian
heegard-berger
problem
let
chosen
speciï¬ed
section
ii-c.
given
side
information
decoder
hbrdf
given
achieve
hbrdf
decoder
design
quantization
polar
lattice
source
target
distortion
result
target
distortion
rate
variance
x/d1
exists
multilevel
polar
lattice
rate
average
distortion
asymptotically
close
length
number
levels
log
log
theorem
therefore
decoders
recover
regarded
side
information
decoder
cid:0
cid:1
log
decoder
ï¬rst
need
code
achieves
rate-distortion
requirement
source
cid:48
cid:44
gaussian
reconstruction
alphabet
cid:48
fact
cid:48
gaussian
independent
let
cid:44
d1Ïƒ2
d1Ïƒ2
consider
auxiliary
gaussian
random
variable
cid:48
deï¬ned
cid:48
cid:48
Î³d2
moreover
deï¬ne
cid:48
cid:44
cid:48
cid:48
cid:48
apply
minimum
mean
square
error
mmse
rescaling
parameter
d1+Ïƒ2
result
obtain
cid:48
cid:48
Î±Ïƒ2
also
write
cid:48
cid:48
figure
test
channel
gaussian
heegard-berger
problem
decoder
using
continuous
gaussian
cid:48
Î³d2
Î±Ïƒ2
cid:48
test
channel
depicted
fig
requires
awgn
capacity-achieving
code
cid:48
ï¬nal
reconstruction
decoder
given
Ë†x2
cid:48
cid:48
cid:48
note
cid:48
cid:48
scaled
version
independent
cid:48
thus
variance
therefore
cid:48
cid:18
Ë†x2
desired
furthermore
required
data
rate
decoder
given
cid:48
cid:48
cid:48
cid:48
cid:48
cid:48
Î±d1
Î³d2
Î±Ïƒ2
cid:19
d1Ïƒ2
note
cid:48
continuous
gaussian
random
variable
impractical
design
polar
lattices
hence
use
discrete
gaussian
distribution
cid:48
replace
need
perform
mmse
rescaling
cid:48
test
channels
cid:48
cid:48
cid:48
cid:48
scales
respectively
consequently
reversed
version
test
channel
fig
derived
depicted
fig
d1+Ïƒ2
log
cid:48
cid:48
d2Ïƒ2
d2Ïƒ2
reconstruction
decoder
given
following
proposition
proposition
11.
use
reversed
test
channel
shown
fig
reconstruction
decoder
given
Ë†x2
Î±qu
cid:48
cid:48
Î±qu
cid:48
cid:19
cid:18
proof
sufï¬ces
prove
Ë†x2
since
cid:48
illustrated
fig
showing
Ë†x2
Î±qu
cid:48
Î±qd
cid:48
Î±qu
cid:48
Î±qd
cid:48
rate-distortion-achieving
codexâ€²~n0
d1uâ€²~n0
d1+d2â€²Î±yâ€²~n0
d12d1+Ïƒz2â¨â¨z4~n0
d2â€²z3~n0
d1Ïƒz2d1+Ïƒz2capacity-achieving
code
figure
reversed
solution
test
channels
order
construct
polar
lattices
would
complete
proof
see
fig
zero
mean
variance
Î±qd
cid:48
independent
cid:48
also
cid:48
Î±qu
cid:48
gaussian
distributed
Î±qd
cid:48
cid:18
Î±qd
cid:48
desired
d2Ïƒ2
d1d2Ïƒ2
d1Ïƒ2
cid:19
cid:18
cid:19
cid:18
d2Ïƒ2
cid:19
d1Ïƒ2
cid:17
also
deï¬ne
cid:44
cid:48
cid:48
cid:16
based
reversed
test
channel
replace
continuous
gaussian
random
variable
Î±qu
cid:48
discrete
gaussian
distributed
variable
cid:48
let
cid:48
cid:44
Î±qd
cid:48
cid:48
whose
variance
cid:48
lemma
distributions
cid:48
cid:48
made
arbitrarily
Î±2Ïƒ2
close
distributions
cid:48
cid:48
respectively
therefore
polar
lattices
designed
source
cid:48
side
information
cid:48
decoder
speciï¬cally
rate-distortion
bound-
achieving
polar
lattice
constructed
source
cid:48
distortion
Î±qd
cid:48
awgn
capacity-achieving
polar
lattice
constructed
channel
cid:48
shown
fig
end
reconstruction
decoder
Ë‡x2
cid:0
cid:1
even
though
qÏƒ2
quantization
noise
exact
gaussian
distribution
shown
theorem
rate-distortion-achieving
xâ€²Î±ğ‘Î±ğ‘Î±
yâ€²â¨â¨z4â€²z3â€²capacity-achieving
ğ¿2xâ€²~n0
d1Î±ğ‘uâ€²Î±ğ‘Î±ğ‘Î±yâ€²â¨â¨z4â€²~n0
Î±ğ‘d2â€²z3â€²~n0
Î±ğ‘Î±ğ‘Ïƒz32ğ´~ğ·Î»
Ïƒğ‘2
two
distributions
arbitrarily
close
sufï¬ciently
large
therefore
treated
gaussian
noise
independent
proposition
scales
Î±qd
cid:48
lemma
distributions
Ë‡x2
Ë†x2
arbitrarily
close
gives
average
distortion
close
according
lemma
equivalently
constructed
mmse-
rescaled
channel
gaussian
noise
variances
ËœÏƒ2
Î±qd
cid:48
ËœÏƒ2
Î±qd
cid:48
cid:18
cid:19
aÏƒ2
zd2
aÏƒ4
coding
strategy
adapted
section
brieï¬‚y
describe
ï¬‚atness
factor
ËœÏƒ2
completeness
first
choose
good
constellation
negligible
let
Î»/Î»1/Â·Â·Â·
/Î»râˆ’1/Î»r/Â·Â·Â·
denote
one-dimensional
binary
partition
chain
labeled
bits
a1/a2/Â·Â·Â·
/arâˆ’1/ar/Â·Â·Â·
therefore
pa1
approaches
respectively
consider
i.i.d
copies
let
level
0.5
frozen
set
respectively
replacing
cid:48
cid:1
shaping
set
cid:1
level
adapted
equation
equation
cid:1
information
set
cid:0
cid:0
cid:0
cid:44
therefore
furthermore
according
lemma
nested
within
i.e.
fact
ËœÏƒ2
ËœÏƒ2
degraded
respect
one
noise
variance
ËœÏƒ2
deï¬nition
shaping
set
observe
lemma
partition
channel
Î»lâˆ’1/Î»l
noise
variance
ËœÏƒ2
encoder
recover
auxiliary
codeword
decoder
obtains
real-
izations
cid:48
cid:0
cid:48
cid:1
cid:48
cid:0
cid:48
variables
cid:0
cid:1
respectively
encoder
recovers
successively
according
random
rounding
quantization
rules
given
equations
note
cid:48
realization
cid:48
acceptable
since
distributions
cid:48
cid:48
arbitrarily
close
also
according
theorem
replacing
random
rounding
rule
map
decision
obtain
affect
theorem
theorem
consequently
coding
scheme
decoder
gaussian
heegard-berger
problem
summarized
following
cid:1
given
realizations
encoding
n-dimensional
i.i.d
source
vector
encoder
recovers
aux-
employing
quantization
polar
lattice
source
variance
random
iliary
codeword
distortion
obtains
cid:48
cid:48
next
encoder
evaluates
rounding
sends
decoders
\ic
decoding
pre-shared
received
decoder
recovers
\ic
side
information
Â¯b1
vanishing
error
probability
using
decoding
gaussian
channels
level
decoder
obtains
recovered
according
equation
finally
reconstruction
decoder
cid:0
Â¯b1
cid:1
Ë‡x2
according
lemma
encoding
decoding
complexities
polar
lattices
remain
log
cid:16
cid:17
transmission
rate
scheme
rate
decoder
arbitrarily
close
according
theorem
argument
rate
rl1
ï¬‚atness
factor
negligible
theorem
arbitrarily
close
cid:16
log
cid:17
log
Î±qd
cid:48
rate
rl2
capacity-achieving
lattice
arbitrarily
close
negligible
ï¬‚atness
factor
since
rate
decoder
tedious
calculations
given
log
Î±qd
cid:48
cid:18
cid:19
rl1
rl2
log
log
cid:18
cid:18
d2Ïƒ2
d1Ïƒ2
cid:19
cid:19
log
cid:18
cid:19
total
rate
gaussian
heegard-berger
problem
log
xÏƒ2
cid:18
cid:19
next
give
main
theorem
gaussian
heegard-berger
problem
non-
degenerate
region
theorem
12.
let
speciï¬ed
section
ii-c.
rate
exists
polar
lattice
code
rate
sufï¬ciently
large
blocklength
whose
expected
distortion
arbitrarily
close
number
partition
levels
log
log
let
Î»/Î»1/Â·Â·Â·
/Î»râˆ’1/Î»r
one-dimensional
binary
partition
chain
lattice
ËœÏƒ2
log
cid:16
cid:17
2âˆ’âˆš
cid:17
cid:16
rate
spread
rl1
rl2
arbitrarily
close
expected
distortion
dq2
satisï¬es
dq2
log
cid:48
0.5
exist
nested
polar
lattices
2âˆ’n
cid:48
cid:17
d1+Ïƒ2
cid:18
cid:19
log
cid:16
d1Ïƒ2
proof
achievability
rate-distortion
function
decoder
follows
theorem
proof
achievability
decoder
adapted
theorem
considering
test
channel
depicted
fig
reconstruction
given
worth
mentioning
requirements
ËœÏƒ2
log
given
proposition
guarantee
sub-exponentially
decaying
error
probability
lattice
design
decoder
cid:16
2âˆ’âˆš
cid:17
conclusion
presented
nested
polar
codes
polar
lattices
achieve
rate-distortion
function
binary
gaussian
heegard-berger
problems
respectively
different
code
constructions
wyner-ziv
problem
took
advantage
reconstruction
decoder
build
nested
structure
achieves
rate-distortion
function
decoder
proposed
schemes
achieve
hbrdf
entire
non-degenerate
regions
dsbs
gaussian
sources
finally
kaspi
problem
regarded
generalization
heegard-berger
problem
encoder
may
also
access
side
information
explicit
rate-
distortion
functions
kaspi
problem
gaussian
binary
sources
given
respectively
study
construction
polar
codes
polar
lattices
kaspi
problem
future
work
appendix
proof
theorem
first
show
distortion
achieved
since
gives
one-
to-one
mapping
expression
equivalent
coding
scheme
presented
section
iii-b
assume
kica
wicb
rectly
decoded
using
side
information
kssa
wssb
cor-
recovered
map
rule
cid:17
cid:16
2âˆ’n
cid:48
cid:17
cid:16
joint
distribution
therefore
decoder
recover
resulting
distribution
encoder
performs
com-
denote
denote
pression
level
i.e.
compresses
wisb
joint
distribution
encoder
perform
compression
simplicity
denote
random
variables
let
cid:17
cid:16
cid:88
cid:88
cid:12
cid:12
cid:0
cid:12
cid:12
cid:0
cid:1
cid:0
cid:1
cid:0
n|u1
cid:1
cid:12
cid:12
cid:1
cid:0
cid:1
cid:0
n|u1
cid:1
cid:12
cid:12
according
markov
chain
cid:0
n|u1
cid:1
cid:0
n|u1
cid:16
cid:1
cid:0
n|x1
cid:1
cid:16
cid:17
cid:17
therefore
cid:16
2âˆ’n
cid:48
cid:17
reconstructions
two
levels
i.e.
denoted
average
given
cid:1
cid:0
cid:0
cid:1
cid:0
cid:1
cid:0
cid:1
distortion
achieved
cid:88
cid:88
cid:88
pua
note
last
equality
holds
due
constrains
Î¸1Âµ
theorem
reasonable
achieved
encoder
perform
compression
combined
expected
distortion
achieved
satisï¬es
cid:88
cid:16
cid:88
cid:16
dmax
2âˆ’n
cid:48
cid:17
cid:12
cid:12
cid:12
cid:17
cid:0
cid:1
cid:12
cid:12
cid:12
next
show
decoder
recover
iâˆˆica
iâˆˆicb
sub-exponentially
decaying
block
error
probability
cid:16
cid:17
cid:88
cid:12
cid:12
cid:0
cid:1
cid:12
cid:12
cid:1
cid:0
cid:12
cid:12
cid:12
cid:12
cid:12
cid:88
cid:88
cid:2
cid:0
cid:1
cid:0
cid:88
cid:88
cid:12
cid:12
cid:0
cid:1
cid:0
2âˆ’n
cid:48
cid:17
cid:16
cid:1
cid:3
cid:12
cid:12
cid:12
cid:12
cid:12
cid:1
cid:12
cid:12
let
level
respectively
take
probability
let
denote
set
random
variables
cid:0
denote
expectation
error
probability
result
distribution
example
show
decaying
error
cid:1
decoding
error
occurred
ith
bit
hence
block
error
event
deï¬ned
cid:44
âˆªiâˆˆicb
expectation
decoding
block
error
probability
random
mapping
given
cid:0
cid:1
cid:2
cid:0
cid:1
cid:3
cid:88
cid:88
cid:88
cid:88
iâˆˆicb
iâˆˆicb
iâˆˆicb
âˆªssb
cid:0
cid:16
2âˆ’n
cid:48
cid:17
âˆªssb
âˆªssb
cid:88
cid:0
cid:1
cid:2
cid:0
cid:88
cid:0
iâˆ’1
cid:1
cid:0
cid:1
cid:0
cid:2
cid:0
cid:88
cid:1
cid:0
cid:0
iâˆ’1
cid:115
cid:1
cid:0
cid:0
cid:1
cid:1
1|u1
iâˆ’1
b|u1
iâˆ’1
b|u1
iâˆ’1
b|u
iâˆ’1
cid:3
cid:1
cid:1
cid:1
1|u1
iâˆ’1
b|u1
iâˆ’1
b|u1
iâˆ’1
cid:1
cid:3
cid:16
2âˆ’n
cid:48
cid:17
cid:16
2âˆ’n
cid:48
cid:17
following
arguments
also
bound
obtain
two-stage
decoding
block
error
probability
therefore
union
\ssb
iâˆˆscb
iâˆˆfcb
iâˆˆsca\ssa
level
let
denote
let
ehb
denote
expectation
error
probability
caused
average
choices
iâˆˆfca
cid:1
decoding
error
occurs
set
random
variables
cid:0
cid:88
cid:1
cid:3
cid:1
cid:0
cid:0
cid:0
cid:16
2âˆ’n
cid:48
cid:17
cid:16
cid:1
cid:1
cid:2
cid:0
ehb
cid:17
rates
|isa|
nâ†’âˆâˆ’âˆ’âˆ’â†’
|ica|
nâ†’âˆâˆ’âˆ’âˆ’â†’
ï¬rst
level
therefore
|isa|
|ica|
nâ†’âˆâˆ’âˆ’âˆ’â†’
ua|u1
nâ†’âˆâˆ’âˆ’âˆ’â†’
thus
second
level
|isb|
nâ†’âˆâˆ’âˆ’âˆ’â†’
|icb|
|isb|
|icb|
nâ†’âˆâˆ’âˆ’âˆ’â†’
ub|u1
finally
rate
decoder
|isa|
|ica|
|isb|
|icb|
nâ†’âˆâˆ’âˆ’âˆ’â†’
u2|u1
references
wyner
ziv
rate-distortion
function
source
coding
side
information
decoder
ieee
trans
inf
theory
vol
1â€“10
jan
1976
heegard
berger
rate
distortion
side
information
may
absent
ieee
trans
inf
theory
vol
727â€“734
1985
kerpez
rate-distortion
function
binary
symmetric
source
side
information
may
absent
ieee
trans
inf
theory
vol
448â€“452
may
1987
tian
diggavi
calculation
heegard-berger
rate-distortion
function
binary
source
proc
2006
ieee
inform
theory
workshop
oct
2006
342â€“346
korada
polar
codes
channel
source
coding
ph.d.
dissertation
ecole
polytechnique
fÃ©dÃ©rale
lausanne
lausanne
switzerland
2009
liu
ling
polar
lattices
lossy
compression
jan.
2015
online
available
http
//arxiv.org/abs/1501.05683
honda
yamamoto
polar
coding
without
alphabet
extension
asymmetric
models
ieee
trans
inf
theory
vol
7829â€“7838
dec.
2013
barg
polar
codes
distributed
hierarchical
source
coding
advances
mathematics
communications
vol
87â€“103
2015
ramanan
walsh
practical
codes
lossy
compression
side
information
may
absent
proc
ieee
int
conf
acoustics
speech
signal
processing
3048â€“3051
may
2011
korada
urbanke
polar
codes
optimal
lossy
source
coding
ieee
trans
inf
theory
vol
1751â€“1768
2010
yan
liu
ling
construction
capacity-achieving
lattice
codes
polar
lattices
nov.
2014
online
available
http
//arxiv.org/abs/1411.0187
forney
jr.
trott
s.-y
chung
sphere-bound-achieving
coset
codes
multilevel
coset
codes
ieee
trans
inf
theory
vol
820â€“850
may
2000
ling
j.-c.
belï¬ore
achieving
awgn
channel
capacity
lattice
gaussian
coding
ieee
trans
inf
theory
vol
5918â€“5929
oct.
2014
kaspi
rate-distortion
function
side-information
may
present
decoder
ieee
trans
inf
theory
vol
2031â€“2034
1994
perron
diggavi
telatar
kaspi
rate-distortion
problem
encoder
side-information
gaussian
case
nov
2005
online
available
https
//infoscience.epï¬‚.ch/record/59938
kaspi
rate-distortion
problem
encoder
side-information
binary
erasure
case
2006
online
available
https
//infoscience.epï¬‚.ch/record/96000
