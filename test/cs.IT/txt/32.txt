relationship
correct
probability
estimation
correlated
data
mutual
information
yasutada
oohama
abstract—let
two
correlated
discrete
random
vari-
ables
consider
estimation
encoded
data
encoder
function
derive
inequality
describing
relation
correct
probability
estimation
mutual
information
inequality
may
useful
secure
analysis
crypto
system
use
success
probability
estimating
secret
data
security
criterion
also
provides
intuitive
meaning
secrecy
exponent
strong
secrecy
criterion
introduction
well
known
mutual
information
important
quantity
evaluation
security
commu-
nication
system
crypto
system
introduced
shannon
perfect
secrecy
deﬁned
condition
mutual
information
secret
data
encrypted
data
vanishes
wiretap
channel
investigated
wyner
broadcast
channel
conﬁdential
messages
investigated
csisz´ar
k¨orner
perfect
secrecy
deﬁned
asymptotically
vanishing
mutual
information
rate
per
channel
use
secret
messages
channel
outputs
obtained
unauthorized
user
several
recent
researches
information
theo-
rytical
security
strong
secrecy
condition
value
mutual
information
asymptotically
zero
well
used
speciﬁcally
hayashi
derived
relevant
secrecy
exponent
function
specify
exponentially
decreasing
speed
i.e.
exponent
leaked
information
average
secrecy
criterion
cost
constraint
considered
han
extend
result
case
cost
constraint
secrecy
condition
used
wyner
csisz´ar
k¨orner
called
weak
secrecy
condition
clear
intuitive
meaning
leak
inforamtion
rate
secret
messages
asymptotically
zero
hand
strong
secrecy
criterion
intuitive
meaning
secrecy
exponent
function
seem
clear
paper
consider
problem
related
intuitive
meaning
secrecy
exponent
problem
follows
let
two
correlated
discrete
random
variables
consider
estimation
encoded
data
encoder
function
derive
inequality
describing
relation
correct
probability
estimation
mutual
information
inequality
may
useful
secure
analysis
❅❅❘✲
fig
case
side
information
helps
estimation
fig
case
one
side
information
avairable
estimater
case
information
avairable
estimater
crypto
system
use
success
probability
estimating
secret
data
security
criterion
also
provides
intuitive
meaning
secrecy
exponent
strong
secrecy
criterion
problem
statement
results
data
estimation
correlated
data
let
discrete
sets
admit
case
countably
inﬁnite
let
disrete
random
pair
taking
vaules
probability
distribution
pxy
pxy
consider
source
estimation
system
depicted
fig
data
sequences
separately
encoded
sent
information
processing
center
center
estimater
observes
output
estimation
encoder
functions
deﬁned
|m|
|l|
estimater
deﬁned
oohama
university
electro-communications
1-5-1
chofu-
gaoka
chofu-shi
tokyo
182-8585
japan
error
probability
estimation
main
results
ψ|pxy
prn
correct
probability
esti-
mation
ψ|pxy
ψ|pxy
prn
condsier
following
three
cases
case
side
information
serves
helper
estimate
case
case
helper
avairable
estimation
case
case
corresponds
case
|m|
constant
function
given
decoder
function
case
given
case
information
avairable
estimation
case
case
corresponds
case
|m|
|l|
constant
functions
given
decoer
function
case
given
let
correct
probability
estimation
case
denoted
ψ|pxy
let
correct
probability
estimation
case
denoted
ψ|pxy
set
max
pxy
ψ|pxy
max
y→l
m×l→x
max
pxy
max
y→l
l→x
ψ|pxy
max
pxy
max
ψ|pxy
subsection
sate
main
result
ﬁrst
give
proposition
plays
key
role
deriving
main
results
set
joint
distribution
pxy
given
pxy
pxy
ps|y
s|y
obvious
random
variables
form
markov
chain
following
proposition
providing
upper
bound
max
pxy
useful
derive
main
result
proposition
ψ|pxy
psx
cid:26
log
|m|
log
px|s
x|s
cid:27
2−η
speciﬁcally
max
pxy
psx
cid:26
log
|m|
log
px|s
x|s
cid:27
2−η
proof
proposition
given
next
section
using
proposition
obtain
following
result
theorem
log
pmax
max
pxy
pmax
proof
theorem
given
next
section
theorem
following
corollary
corollary
min
log
pmax
aim
clarify
relationships
three
quantities
deﬁnition
obvious
max
pxy
pmax
max
pxy
max
pxy
max
pxy
set
pmax
max
x∈x
max
pxy
max
x∈x
max
pmax
particularly
interested
difference
max
pxy
max
pxy
difference
quantities
side
information
use
estimate
paper
derive
inequality
stating
difference
upper
bounded
mutual
information
side
information
source
iii
proofs
results
section
prove
proposition
theorem
ﬁrst
prove
proposition
prove
proposition
prepare
lemma
set
px|s
x|s
1/|m|
2−η
following
lemma
lemma
psxy
2−η
proof
ﬁrst
observe
y|s
following
chain
inequalities
psxy
y|s
xs∈l
px|s
x|s
1/|m|
2−η
px|y
x|y
xs∈l
xs∈l
xs∈l
|m|
|m|
px|s
x|s
px|s
x|s
1/|m|
2−η
2−η
2−η|m|
2−η
step
follows
number
correctly
decoded
exceed
|m|
proof
proposition
deﬁnition
psxy
psx
cid:26
log
|m|
log
px|s
x|s
cid:27
hence
sufﬁces
show
since
cid:27
2−η
px|s
x|s
cid:21
cid:27
cid:21
cid:27
2−η
max
pxy
psx
cid:26
cid:20
log
psx
cid:26
cid:20
log
psx
cid:26
log
cid:21
px|s
x|s
px|s
x|s
cid:20
log
px|s
x|s
cid:21
px|s
x|s
cid:20
log
cid:27
cid:26
log
psx
cid:26
log
cid:26
log
epsx
cid:20
log
cid:26
log
px|s
x|s
cid:27
2−η
px|s
x|s
cid:27
cid:21
2−η
cid:27
2−η
step
use
proposition
|m|
step
follows
markov
inequality
choose
log
pmax
min
x∈x
log
log
pmax
ψ|pxy
psxy
2−η
must
satisfy
log
pmax
chooice
prove
proposition
deﬁnition
ψ|pxy
psxy
following
ψ|pxy
psxy
psxy
psxy
psxy
2−η
psxy
psxy
step
follows
lemma
proof
theorem
following
chain
inequalities
cid:26
log
cid:27
2−η
pmax
bound
theorem
references
shannon
communication
theory
secrecy
systems
bell
sys
tech
journal
vol
656-715
1949
wyner
wire-tap
channel
bell
sys
tech
journal
vol
1355-1387
1975.
csisz´ar
k¨orner
broadcast
channels
conﬁdential
mes-
sages
ieee
trans
inform
theory
vol
it-24
339-348
1978
hayashi
exponential
decreasing
rate
leaked
information
universal
random
privacy
ampliﬁcation
ieee
trans
inf
theory
vol
3989-4001
jun
2011
t.s
han
endo
sasaki
reliability
secrecy
functions
wiretap
channel
cost
constraint
ieee
trans
inf
theory
vol
6819-6843
nov.
2014
