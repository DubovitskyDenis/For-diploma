throughput
delay
analysis
wireless
caching
helper
systems
random
availability
nikolaos
pappas
member
ieee
zheng
chen
member
ieee
ioannis
dimitriou
abstract—in
paper
investigate
effect
bursty
trafﬁc
random
availability
caching
helpers
wireless
caching
system
explicitly
consider
general
system
consisting
caching
helper
dedicated
user
proximity
another
non-dedicated
user
requesting
content
non-dedicated
user
helper
limited
storage
capabilities
user
able
locate
requested
content
cache
request
shall
served
either
caching
helper
large
data
center
assuming
bursty
request
arrivals
caching
helper
dedicated
destination
availability
serve
users
affected
request
rate
affect
system
throughput
delay
experienced
non-dedicated
user
characterize
maximum
weighted
throughput
average
delay
per
packet
considered
system
taking
account
request
arrival
rate
caching
helper
request
probability
user
availability
data
center
results
provide
fundamental
insights
throughput
delay
behavior
systems
essential
investigation
larger
topologies
index
terms—caching
random
access
throughout
delay
queueing
introduction
driven
development
information-centric
applica-
tions
wireless
caching
emerged
promising
concept
cope
exponential
growth
data
trafﬁc
video
content
dominant
source
caching
network
edge
also
exploits
high
degree
asynchronous
content
reuse
among
users
share
similar
content
preferences
local
areas
introducing
caching
capabilities
network
edge
including
small
cells
femto
access
points
user
devices
caching
popular
content
closer
end
users
requested
cellular
trafﬁc
load
latency
signiﬁcantly
reduced
literature
wireless
caching
various
types
content
placement
strategies
investigated
discussed
cache
popular
content
everywhere
ran-
dom/probabilistic
caching
cooperative
caching
based
speciﬁc
caching
schemes
considera-
tion
different
network
performance
metrics
studied
optimized
cache
hit
ratio
cache-aide
throughout
energy
efﬁciency
etc
cooperation-
based
scheme
proposed
aims
min-
imizing
average
energy
consumption
incurred
user
pappas
department
science
technology
link¨oping
university
norrk¨oping
se-60174
sweden
e-mail
nikolaos.pappas
liu.se
chen
department
electrical
engineering
link¨oping
univer-
sity
link¨oping
sweden
e-mail
zheng.chen
liu.se
dimitriou
department
mathematics
university
patras
patra
peloponnese
greece
e-mail
idimit
math.upatras.gr
equipment
order
obtain
desired
content
transmission
cost
edge
caching
minimized
taking
account
trafﬁc
ofﬂoading
via
device-to-device
communications
users
quality
experience
qos
considered
algorithm
proposed
improve
user
qos
reduce
network
trafﬁc
using
machine
learning
approach
algorithm
considers
users
behavior
properties
cellular
network
concept
caching-as-a-service
proposed
based
cloud
radio
access
networks
virtualized
evolved
packet
core
provides
reliable
ﬂexible
cache
service
high
elasticity
adaptivity
social-aware
edge
caching
techniques
fog
radio
access
networks
investigated
modeling
impact
edge
caching
schemes
performance
content
diffusion
sharing
related
work
early
studies
wireless
caching
systems
cache
hit
probability
density
successful
receptions
commonly
used
evaluate
performance
certain
wireless
caching
systems/schemes
recently
growing
interest
delay
analysis
combination
throughput
delay
analysis
cache-enabled
wireless
networks
extend
research
area
towards
another
perspective
nevertheless
delay
analysis
liter-
ature
focuses
either
backhaul
delay
transmission
delay
saturated
trafﬁc/requests
assumption
based
queueing
theory
consideration
bursty
trafﬁc
model
provides
new
insights
easily
seen
saturated
trafﬁc
assumption
stable
throughput
delay
performance
single
bottleneck
caching
networks
studied
considering
stochastic
arrivals
requests
different
nodes
another
common
assumption
studies
wireless
caching
systems
caching
helper
able
serve
user
request
whenever
requested
ﬁle
cached
reality
caching
helper
might
available
assist
requests
nearby
users
destinations
serve
instance
femtocaching
network
femto
base
station
fbs
dedicated
users
requesting
content
random
manner
another
random
user
falling
inside
coverage
area
probably
served
immediately
even
fbs
requested
ﬁle
cached
inside
bursty
trafﬁc
caching
helper
affect
availability
response
time
non-dedicated
user
waiting
served
case
throughput
delay
depend
downloading
delay
often
related
channel
condition
also
response
time
caching
helper
whose
availability
affected
request
arrival
rate
dedicated
users
contributions
paper
investigate
effect
bursty
trafﬁc
throughput
delay
performance
wireless
caching
helper
network
consider
case
source
helper
limited
cache
storage
bursty
trafﬁc
transmit
intended
destination
source
stores
trafﬁc
queue
addition
another
user
requesting
content
user
also
limited
storage
capability
content
located
cache
user
seek
assistance
either
helper
distant
data
center
however
since
helper
also
limited
storage
capability
cache
miss
occur
even
available
assist
user
data
center
contains
ﬁles
requested
user
always
available
due
congestion
based
random
access
scheme
user
caching
helper
dedicated
destination
characterize
performance
network
terms
throughput
delay
speciﬁcally
characterize
network-wide
throughput
cases
queue
source
helper
stable
unstable
addition
optimize
maximum
weighted
network
throughput
stability
constraints
source/helper
furthermore
derive
average
delay
seen
user
requesting
content
located
storage
finally
provide
numerical
evaluation
presented
results
analysis
builds
simple
network
model
four
nodes
general
conditions
random
access
proba-
bilities
capture
many
speciﬁc
types
caching
network
structures
different
access
criteria
related
channel
condition
request
load
backhaul
availability
etc
analysis
used
investigation
larger
topologies
best
knowledge
similar
results
work
reported
literature
organization
paper
section
present
considered
system
model
in-
cluding
network
model
caching
policies
transmis-
sion
model
physical
layer
considerations
section
iii
analytical
results
regarding
throughput
derived
including
cases
stable
unstable
queue
helper
average
delay
performance
derived
section
section
evaluate
numerically
theoretical
results
finally
conclude
paper
section
system
model
network
model
consider
following
network
model
caching
helper
bursty
packets
need
transmitted
dedicated
user
helper
equipped
inﬁnite
queue
size
packet
arrival
modeled
bernoulli
process
average
arrival
rate
study
assume
slotted
time
transmission
packet
requires
one
timeslot
assume
another
non-dedicated
random
user
falls
inside
service
range
caching
helper
depicted
fig
timeslot
user
requests
ﬁle
probability
locate
ﬁle
storage
thus
request
ﬁle
externally
helper
certain
conditions
assist
requests
explicitly
timeslot
queue
empty
transmit
probability
probability
available
assist
transmitting
including
cases
non-empty
empty
queues
assist
request
probability
note
probabilities
considered
model
cover
many
different
aspects
uncertainty/variation
wireless
caching
system
mentioned
probability
describes
activity
user
terms
often
user
requesting
external
content
include
case
user
limited
storage
capabilities
related
probability
requested
content
located
storage
needs
delivered
external
sources
thus
denotes
case
user
storage
capabilities
seek
content
either
helper
data
center
another
case
represented
cache
contains
obsolete/outdated
content
requested
content
user
located
storage
unit
thus
need
assistance
neither
helper
data
center
details
given
section
ii-b
probability
related
random
access
probability
potentially
needs
optimized
case
many
concurrent
caching
helpers
sharing
frequency/time
resources
probability
might
come
cache
updating
process
inside
caching
helper
distinction
dedicated
non-dedicated
users
capture
possibility
users
different
priorities
recall
non-dedicated
user
requesting
ﬁle
probability
served
available
probability
request
directed
large
data
server
denoted
assumed
every
available
content
stored
result
timeslot
probability
user
request
ﬁle
request
served
queue
empty
due
limited
storage
capacity
helper
requested
ﬁle
user
probability
cached
within
helper
thus
probability
1−ph
ﬁnd
requested
content
request
depends
caching
strategy
user
request
pattern
operation
caching
helper
summarized
ﬂowchart
fig
operation
device
regarding
possible
cases
ﬁnding
requested
content
given
fig
operation
considered
system
rather
complicated
even
simple
topology
request
distribution
caching
policy
consider
ﬁnite
content
library
···
user
requests
i-th
popular
ﬁle
library
size
ﬁles
assumed
equal
+mu
cid:88
table
notation
table
probability
description
ph/pm
request
content
outside
storage
transmit
queue
empty
assisted
cache
available
cache
hit/miss
probability
cache
available
serve
since
nodes
store
independently
popular
ﬁles
case
miss
happens
probability
requested
content
among
ﬁrst
ﬁles
aslo
consider
variation
mpc
collaborative
mpc
cmpc
user
stores
ﬁrst
popular
ﬁles
helper
knowing
store
next
popular
ﬁles
case
similar
merging
two
storage
elements
one
probability
user
request
ﬁle
cached
within
cache
given
cache
hit
probability
caching
helper
i=mu
however
cmpc
requires
exchange
information
devices
storage
size
collab-
orative
decisions
content
placement
device
helper
fig
evaluate
cache
hit
probability
caching
helper
probability
user
request
ﬁle
found
cache
terms
difference
small
thus
remainder
paper
consider
mpc
scheme
results
obtained
work
general
hold
possible
request
distributions
caching
policies
long
one
replace
appropriate
expressions
transmission
model
caching
helper
transmitting
destination
user
seek
requested
information
directly
available
serve
two
parallel
transmissions
one
interfering
considering
might
congested
users
requests
model
availability
factor
models
probability
available
timeslot
serve
either
exist
network
heavily
congested
thus
available
always
available
user
aforementioned
probabilities
summarized
table
figs
provide
ﬂowcharts
describing
operation
respectively
fig
example
system
model
caching
helper
femto
access
point
fap
storage
capabilities
dedicated
connected
user
randomly
generating
requests
multimedia
content
time
mobile
device
proximity
requests
external
content
probability
time
slot
device
also
access
data
center
connection
problematic
due
congestion
preferred
served
possible
size
normalized
one
use
standard
zipf
law
popularity
distribution
meaning
request
probability
i-th
popular
ﬁle
cid:32
cid:80
j−δ
cid:33
normalization
factor
j=1
shape
parameter
zipf
law
deﬁnes
correlation
level
user
requests
high
values
means
requests
generated
popular
ﬁles
user
making
random
request
seen
probability
requested
ﬁle
assume
user
device
caching
helper
cache
storage
capacity
equal
ﬁles
ﬁles
respectively
literature
content
caching
wireless
networks
several
proactive
caching
policies
used
policy
cache
popular
content
mpc
policy
node
independently
stores
ﬁles
highest
popularity
extensively
used
literature
mpc
strategy
gives
optimal
performance
non-overlapping
sbs
cover-
age
isolated
caches
strategy
user
stores
popular
ﬁles
cache
caching
helper
stores
popular
ﬁles
probability
user
request
ﬁle
cached
within
cache
cache
hit
probability
caching
helper
cid:88
cid:88
i=1
i=mu
sdudatacenter cache
denote
pij/i
success
probability
link
transmitter
active
pij/i
snrij
exp
similarly
denote
pij/i
success
probability
link
transmitters
active
thus
cid:33
cid:32
θjηjrγ
cid:16
cid:16
rij
cid:17
cid:17
cid:105
cid:104
exp
rkj
pij/i
sinrij
expression
success
probabilities
obtained
rayleigh
fading
results
obtained
work
hold
wireless
channels
well
one
needs
connect
expressions
success
probabilities
apply
results
presented
next
sections
iii
system
throughput
analysis
optimization
section
focus
throughput
analysis
system
depicted
fig
explicitly
intend
derive
optimize
weighted
sum
throughput
helper
throughput
seen
user
deﬁne
weighted
sum
throughput
wts
1−w
represent
cases
interested
helper
user
respectively
average
service
rate
caching
helper
destination
psd/s
qsqu
apsd/s
proceeding
next
step
provide
formal
deﬁnition
queue
stability
follows
deﬁnition
denote
length
queue
beginning
time
slot
queue
said
stable
limt→∞
limx→∞
although
make
explicit
use
deﬁnition
use
corollary
consequence
loynes
theorem
states
arrival
service
processes
queue
strictly
jointly
stationary
average
arrival
rate
less
average
service
rate
queue
stable
considered
network
model
queue
stable
stability
queue
implies
ﬁnite
queuing
delay
adding
constraint
achieve
ﬁnite
queueing
delay
stability
implies
also
packets
enter
queue
eventually
transmitted
successfully
destination
denote
throughput
link
depending
whether
queue
stable
queue
stable
queue
unstable
thus
indicator
function
throughput
seen
depends
status
queue
queue
empty
probability
requests
ﬁle
probability
0.5
0.9.
fig
depict
cases
mpc
cmpc
schemes
applied
several
values
scenario
content
library
contains
10000
ﬁles
capacity
cache
source
2000
shape
parameter
zipf
law
left
y-axis
values
right
y-axis
values
physical
layer
model
denote
psd/s
success
probability
link
active
psd/s
success
probability
link
transmitting
consider
success
probability
link
based
received
signal-to-interference-plus-noise
ratio
sinr
sinrij
cid:80
pi|hi
j|2r
k∈t\
pk|hk
j|2r
denotes
set
active
transmitters
denotes
transmission
power
node
denotes
small-
scale
channel
fading
transmitter
receiver
follows
rayleigh
fading
denotes
distance
transmitter
receiver
denotes
background
thermal
noise
power
received
50100150200250300cache
size
user
u0.250.30.350.40.450.50.550.6ph0.30.40.50.60.70.80.91quph
mpcph
cmpcqu50100150200250300cache
size
user
u0.10.20.30.40.50.60.7ph0.10.20.30.40.50.60.70.80.91quph
mpcph
cmpcqu
fig
operation
user
described
protocol
unable
locate
requested
content
cache
fig
operation
source
described
protocol
directed
probability
throughput
qcphpsu/s
αpdc/dc
queue
non-empty
probability
cid:54
active
probability
available
probability
seek
content
probability
probability
1−qc
ﬁrst
case
achieved
through-
put
qcphpsu/s
latter
case
throughput
seen
αpdc/dc
available
transmitting
packet
probability
throughput
seen
qsqu
αpdc/s
combining
cases
achieved
throughput
=qsp
cid:54
αpdc/s
qsp
cid:54
cid:2
qcphpsu/s
qcph
αpdc/dc
cid:3
depending
whether
queue
stable
expression
different
remainder
section
analyze
optimize
weighted
sum
throughput
wts
cases
stable
unstable
queue
respectively
requests
ﬁleoperation
uyesq=0noyesnos
assist
uyesnoredirect
dcs
transmit
dnoyesredirect
dcs
assist
uyesendis
ﬁle
cached
sis
ﬁle
cached
snoyesyesnonodc
availableuu
try
next
slotnodc
transmit
requested
ﬁleu
receives
successfully
requested
ﬁleis
transmission
successful
yesnodc
availableuu
try
next
slotnodc
transmit
requested
ﬁleyesu
receives
successfully
requested
ﬁleis
transmission
successful
yesnos
transmit
requested
ﬁleuu
try
next
slotu
receives
successfully
requested
ﬁleis
transmission
successful
yesnooperation
sq=0noyess
transmit
dyesnos
assist
unoendyess
assist
unoyesends
transmit
packet
queueuthe
packet
retransmitted
future
slotd
receives
successfully
packetis
transmission
successful
yesnois
ﬁle
cached
syess
transmit
requested
ﬁlenoend
success/failure
transmissionis
ﬁle
cached
syess
transmit
requested
ﬁleend
success/failure
transmissionno
queue
stable
queue
caching
helper
stable
probability
queue
size
empty
given
cid:54
psd/s
qsqu
αpsd/s
replacing
following
expression
throughput
αλpdc/s
psd/s
αpsd/s
psd/s
αpsd/s
psd/s
αpsd/s
αpdc/dc
qcph
psu/s
αpdc/dc
note
independent
queue
stable
deﬁne
following
optimization
problem
aims
optimizing
probabilities
weighed
sum
throughput
maximized
max
s.t
psd/s
apsd/s
cid:54
1−qu
psd/s
+qu
αpsd/s
ﬁrst
constraint
ensures
stability
helper
queue
result
previous
optimization
problem
thus
objective
function
independent
ob-
jective
function
linear
respect
stated
previous
section
depend
directly
psu/s
αpdc/dc
objective
function
increasing
function
thus
maximum
achieved
objective
function
psu/s
αpdc/dc
decreasing
function
coefﬁcient
psu/s−αpdc/dc
indication
channel
helper
user
availability
channel
note
choice
affect
optimal
solution
lies
interval
keeps
queue
stable
thus
queue
unstable
queue
unstable
means
arrival
rate
greater
service
rate
equivalent
disregard
bursty
trafﬁc
consider
saturated
queue
network
queue
unstable
packet
dropping
policy
applied
order
stabilize
system
however
system
stabilized
packet
dropping
results
stable
queue
still
hold
case
arrival
rate
cid:48
arrival
rate
applying
packet
dropping
queue
unstable
throughput
seen
user
cid:48
given
cid:48
cid:48
=qsqu
αpdc/s
dc+
cid:2
qcphpsu/s
qcph
αpdc/dc
cid:3
weighted
sum
throughput
optimization
problem
becomes
max
s.t
cid:48
objective
function
re-written
qsb2
αpdc/dc
psu/s
αpdc/dc
αqu
pdc/s
pdc/dc
psd/s
αqu
psd/s
optimization
problem
stated
non-linear
how-
ever
applying
karush
kuhn
tucker
kkt
conditions
obtain
solution
depends
signs
ordering
thus
sake
presentation
omit
enumeration
possible
solutions
based
possible
optimal
values
1/2
maximize
objective
function
1/2
section
provide
numerical
solutions
speciﬁc
cases
delay
analysis
apart
system
throughput
delay
experienced
user
another
critical
metric
performance
wireless
caching
systems
delay-sensitive
applications
section
study
delay
experienced
user
time
requests
external
content
time
content
received
take
account
delay
access
requested
content
stored
cache
since
occur
instantaneously
recall
consider
slotted
transmission
work
delay
user
received
requested
ﬁle
one
slot
one
following
events
happen
user
locate
requested
ﬁle
within
helper
storage
helper
available
assist
user
transmission
helper
user
successful
available
requested
content
helper
user
within
slot
re-directed
data
center
data
center
available
transmission
data
center
user
successful
cases
instance
helper
cache
contains
requested
ﬁle
transmission
fails
next
time
slot
user
request
ﬁle
helper
helper
available
assist
otherwise
user
re-directed
data
center
content
available
helper
transmission
data
center
fails
next
time
slot
user
seek
content
directly
data
center
based
aforementioned
cases
applying
regenerative
method
derive
delay
experienced
user
queue
helper
stable
unstable
respectively
numerical
results
section
provide
numerical
evaluation
results
presented
previous
sections
assume
10−11
path-loss
exponent
transmission
powers
ptx
ptx
distances
links
rsd
50m
rsu
40m
rdcd
100m
rdcu
80m
respectively
obtain
following
success
probabilities
psd/s
0.939
psd/s
0.578
psu/s
0.975
pdc/dc
0.96
pdc/s
0.369.
note
values
success
probabilities
speciﬁc
implications
numerical
evaluation
general
remarks
section
valid
parameter
values
well
also
assume
total
number
available
ﬁles
10000
shape
parameter
zipf
law
0.5
cache
size
source
2000.
furthermore
data
center
available
probability
0.7.
helper
user
apply
mpc
policy
described
section
maximum
weighted
sum
throughput
effect
arrival
rate
consider
scenario
capacity
cache
user
200.
thus
replacing
values
obtain
0.31
0.86.
fig
weighted
sum
throughput
vs.
arrival
rate
helper
presented
three
different
values
1/4
represents
case
important
maximum
weighted
sum
throughput
decreasing
function
1/4
1/2
3/4
maximum
weighted
sum
throughput
increasing
function
maximum
weighted
sum
throughput
always
achieved
speciﬁc
setup
however
values
achieve
maximum
weighted
sum
throughput
different
presented
table
note
values
independent
expected
increases
increases
order
keep
queue
stable
thus
queue
stable
average
delay
user
experiences
receive
requested
ﬁle
qsp
cid:54
phqc
phqc
psd/s
ds+
αpdc/dc
1−ph
αpdc/dc
ddc
1−qc
αpdc/dc
1−qc
1−αpdc/dc
+ds
qsp
cid:54
αpdc/s
αpdc/s
cid:54
given
ddc
given
qsp
cid:54
αpdc/dc
αpdc/dc
qsp
cid:54
cid:2
psd/s
psd/s
cid:3
qsp
cid:54
cid:2
αpdc/s
1−αpdc/s
1+ds
cid:3
ddc
cid:2
αqsp
cid:54
pdc/s
cid:3
qsp
cid:54
pdc/dc
manipulations
becomes
qsp
cid:54
αpdc/s
qsp
cid:54
qcpsd/s
αpdc/dc
average
delay
manipulations
qsp
cid:54
ddc
qsp
cid:54
αpdc/s
written
ddc
=phqc
psd/s
αpdc/dc
ddc
αpdc/dc
queue
unstable
queue
helper
unstable
helper
saturated
trafﬁc
average
delay
user
found
replacing
cid:54
previous
expressions
thus
ddc
αpdc/s
ddc
given
expressions
ddc
given
cid:2
qsαpdc/s
dc+
ddc
cid:2
cid:2
qspdc/s
pdc/dc
qcpsd/s
αpdc/dc
cid:3
cid:3
cid:3
fig
maximum
weighted
sum
throughput
vs.
0.10.150.20.250.30.350.40.20.250.30.350.40.45max
weighted
sum
throughputw=1/4w=1/2w=3/4
table
values
achieve
maximum
weighted
sum
throughput
presented
fig
0.1
0.2
0.3
0.4
0.209639
0.41927
0.628917
0.838556
case
queue
unstable
arrival
rate
greater
average
service
rate
maximum
weighted
sum
throughput
values
presented
table
iii
maximum
weighted
sum
throughput
values
case
unstable
queue
table
iii
1/4
1/2
3/4
max
0.496229
0.350238
0.413624
maximum
weighted
sum
throughput
effect
capacity
cache
user
study
effect
storage
capacity
maximum
weighted
sum
throughput
consider
several
values
connection
summarized
table
fig
maximum
weighted
sum
throughput
vs.
0.7
0.4.
case
2000
thus
case
helper
actually
assist
user
content
values
achieve
maximum
weighted
sum
throughput
presented
fig
different
values
table
values
obtained
different
values
cache
capacity
user
table
0.56
0.623
0.6
0.649
0.72
0.723
0.81
0.787
0.86
0.839
0.91
0.88
100
0.91
0.35
200
0.86
0.31
400
0.81
0.25
800
0.72
0.17
1600
0.6
0.05
2000
0.56
observe
increases
decreases
likely
user
ﬁnd
requested
content
cache
since
assumed
mpc
scheme
increases
decreases
fig
maximum
weighted
sum
throughput
vs.
presented
0.7
0.4
queue
stable
used
values
described
table
increases
due
decrease
storage
capacity
improvement
maximum
weighted
sum
throughput
profound
case
1/4
throughput
seen
important
increase
also
explained
fact
trafﬁc
inside
network
increases
increases
achieve
maximum
weighted
sum
throughput
given
table
expected
user
higher
probability
request
external
content
transmission
probability
source
destination
increases
order
sustain
stability
source
likely
assist
user
0.56
also
overcome
interference
caused
transmission
data
center
user
observe
values
fig
maximum
weighted
sum
throughput
pre-
sented
queue
source
unstable
source
saturated
trafﬁc
1/4
1/2
3/4
values
achieve
maximum
given
tables
vii
vii
viii
1/4
1/2
3/4
respectively
1/2
3/4
maximum
weighted
sum
throughput
decreasing
function
since
saturated
throughput
achieved
decreasing
due
increase
requests
1/4
throughput
achieved
impor-
tant
thus
maximum
weighted
sum
throughput
increases
increases
however
0.91
observe
maximum
smaller
one
achieved
0.839
increase
trafﬁc
network
increased
interference
makes
performance
slightly
worse
values
achieve
maximum
given
table
0.56
observe
interpreted
beneﬁcial
network
performance
helper
serve
solely
user
available
0.56
thus
better
silent
helper
order
allow
interference
free
transmission
data
center
user
requested
achieve
maximum
given
tables
vii
viii
1/2
3/4
values
0.550.60.650.70.750.80.850.9qu0.260.280.30.320.340.360.380.4max
weighted
sum
throughputw=1/4w=1/2w=3/4
average
delay
experienced
seeking
external
content
present
numerical
results
based
analysis
section
regarding
delay
experienced
user
retrieve
requested
external
content
figs
illustrate
effect
average
delay
plots
0.5
0.31
0.86.
fig
average
delay
versus
arrival
rate
helper
depicted
0.7
0.9.
see
arrival
rate
helper
increases
delay
increases
non-
linearly
stopping
value
obtained
stability
condition
fig
average
delay
vs.
0.7
0.9.
fig
present
average
delay
versus
availability
data
center
cases
stable
unstable
queue
helper
consider
two
cases
arrival
rate
0.2
0.4.
starting
points
ﬁgures
stable
case
obtained
stability
condition
observe
delay
lower
queue
stable
since
chances
user
ﬁnd
available
helper
however
case
requirement
higher
value
order
sustain
stable
queue
profound
case
0.4.
fig
show
average
delay
versus
0.2
0.4.
consider
two
cases
regarding
queue
helper
unstable
queue
see
increasing
trend
delay
increases
expected
since
chances
user
ﬁnding
available
helper
smaller
interesting
case
stable
queue
delay
user
insensitive
reason
behind
product
qsp
cid:54
independent
meaning
availability
helper
constant
depend
whenever
queue
stable
case
0.4
minimum
value
sustain
stable
queue
higher
0.2.
helper
needs
transmit
frequently
destination
order
stabilize
queue
fig
maximum
weighted
sum
throughput
vs.
0.7
queue
helper
saturated/unstable
values
sum
throughput
presented
fig
different
achieve
maximum
weighted
table
1/4
0.56
0.6
0.72
0.81
0.86
0.91
1/2
3/4
respectively
maximum
achieved
values
case
3/4
case
transmission
source
destination
signiﬁcant
thus
user
assist
possible
requests
user
means
beneﬁcial
source
transmit
probability
destination
user
seek
content
directly
result
1/2
0.86.
however
0.91
maximum
achieved
values
sum
throughput
presented
fig
different
achieve
maximum
weighted
table
vii
1/2
0.56
0.6
0.72
0.81
0.86
0.91
values
sum
throughput
presented
fig
different
achieve
maximum
weighted
table
viii
3/4
0.56
0.6
0.72
0.81
0.86
0.91
0.550.60.650.70.750.80.850.9qu0.30.350.40.450.50.55max
weighted
sum
throughput
saturatedw=1/4w=1/2w=3/400.050.10.150.20.250.30.350.40.451.41.61.822.22.42.62.833.2delay
queue
stable
0.2
0.2
0.4
0.4.
fig
average
delay
vs.
0.9
cases
stable
unstable
queue
fig
10.
average
delay
vs.
0.7
cases
stable
unstable
queue
next
study
effect
delay
storage
capacity
user
capacity
user
affects
request
probability
external
content
table
provide
connection
cache
capacity
request
probability
several
cases
fig
depict
average
delay
versus
two
values
ﬁgures
also
illustrate
case
queue
helper
unstable
congestion
helper
low
0.2
effect
storage
user
affect
delay
signiﬁcantly
congestion
increases
example
case
0.4
increasing
storage
capacity
user
decreases
average
delay
recall
increases
storage
decreases
thus
likely
user
able
ﬁnd
requested
content
storage
queue
unstable
recall
average
delay
depend
directly
however
increase
decrease
storage
affects
also
see
table
explains
slight
decrease
delay
due
increase
conclusions
work
effect
bursty
trafﬁc
random
avail-
ability
caching
helper
wireless
caching
system
investigated
studied
throughput
wireless
caching
system
consisting
caching
helper
dedicated
user
another
non-dedicated
user
proximity
whose
requests
shall
served
either
caching
helper
data
center
purpose
throughput
maximization
optimized
request
probability
user
served
helper
probability
helper
transmit
information
dedicated
destination
addition
derived
average
delay
experienced
user
time
request
placed
time
content
received
results
provide
fundamental
insights
throughput
delay
behavior
helper-based
wireless
caching
systems
0.20.30.40.50.60.70.80.91a
availability
1234567891011delay
ustable
sunstable
s0.20.30.40.50.60.70.80.91a
availability
1234567891011delay
ustable
sunstable
s00.10.20.30.40.50.60.70.80.91qs11.522.533.54delay
ustable
sunstable
s00.10.20.30.40.50.60.70.80.91qs11.522.533.54delay
ustable
sunstable
blaszczyszyn
giovanidis
optimal
geographic
caching
cellular
networks
proc.
ieee
intl
conf
communications
icc
london
jun
2015
3358–3363
chae
quek
choi
content
placement
wireless
cooperative
caching
helpers
tradeoff
cooperative
gain
content
diversity
gain
ieee
transactions
wireless
communications
vol
1–1
2017
chen
lee
quek
kountouris
cooperative
caching
transmission
design
cluster-centric
small
cell
networks
ieee
transactions
wireless
communications
vol
3401–
3415
may
2017
wang
fan
cooperation-based
caching
scheme
heterogeneous
networks
ieee
access
vol
013–15
020
2017
chen
pappas
kountouris
probabilistic
caching
wireless
d2d
networks
cache
hit
optimal
versus
throughput
optimal
ieee
communications
letters
vol
584–587
mar
2017
liu
yang
energy
efﬁciency
downlink
networks
caching
base
stations
ieee
journal
sel
areas
commun.
vol
907–922
apr
2016
wang
lan
huang
zhang
edge
caching
base
stations
device-to-device
ofﬂoading
ieee
access
vol
6399–6410
2017
tanzil
hoiles
krishnamurthy
adaptive
scheme
caching
youtube
content
cellular
network
machine
learning
approach
ieee
access
vol
5870–5881
2017
wang
leung
caas
caching
service
networks
ieee
access
vol
5982–5993
2017
wang
leng
yang
social-aware
edge
caching
fog
radio
access
networks
ieee
access
vol
8492–8501
2017
karamchandani
diggavi
caire
shamai
rate
delay
coded
caching
carrier
aggregation
proc.
ieee
intl
symp
inform
theory
isit
july
2016
2724–2728
bastug
kountouris
bennis
debbah
delay
geographical
caching
methods
two-tiered
heterogeneous
networks
proc.
ieee
signal
proc
adv
wireless
comm
spawc
july
2016
1–5
wang
tao
zhang
mao
joint
caching
placement
user
association
minimizing
user
download
delay
ieee
access
vol
8625–8633
2016
ephremides
hajek
information
theory
communication
networks
unconsummated
union
ieee
trans
inform
theory
vol
2416–2434
oct
1998
rezaei
khalaj
stability
rate
delay
analysis
single
bottleneck
caching
networks
ieee
trans
communications
vol
300–313
jan
2016
szpankowski
stability
conditions
distributed
systems
buffered
random
access
systems
advances
applied
probability
vol
498–515
jun
1994
loynes
stability
queue
non-independent
inter-arrival
service
times
proc
camb
philos
soc
vol
497–520
1962
walrand
communication
networks
first
course
2nd
mcgraw-hill
professional
1998
0.2
0.4.
fig
11.
average
delay
vs.
0.9
cases
stable
unstable
queue
essential
investigation
topic
larger
topologies
future
direction
work
lies
case
multiple
users
competing
assistance
set
sources
references
shanmugam
golrezaei
dimakis
molisch
caire
femtocaching
wireless
content
delivery
distributed
caching
helpers
ieee
trans
inform
theory
vol
8402–8413
dec.
2013
paschos
bastug
land
caire
debbah
wireless
caching
technical
misconceptions
business
barriers
ieee
com-
munications
mag.
vol
16–22
aug.
2016
carlsson
eager
ephemeral
content
popularity
edge
implications
on-demand
caching
ieee
trans
parallel
distributed
systems
vol
1621–1634
june
2017
chen
kountouris
d2d
caching
vs.
small
cell
caching
cache
content
wireless
network
ieee
17th
international
workshop
signal
processing
advances
wireless
communications
spawc
july
2016
1–6
0.550.60.650.70.750.80.850.90.95qu1.822.22.42.62.833.23.4delay
ustable
sunstable
s0.550.60.650.70.750.80.850.90.95qu2.42.52.62.72.82.933.13.23.33.4delay
ustable
sunstable
