sub-optimality
single-letter
coding
multi-terminal
communications
farhad
shirani
chaharsooghi
electrical
engineering
computer
science
university
michigan
ann
arbor
michigan
48105
email
fshirani
umich.edu
sandeep
pradhan
electrical
engineering
computer
science
university
michigan
ann
arbor
michigan
48105
email
pradhanv
umich.edu
abstract—we
investigate
binary
block-codes
bbc
bbc
deﬁned
vector
boolean
functions
consider
bbcs
generated
randomly
using
single-letter
distributions
characterize
vector
dependency
spectrums
bbcs
use
vector
upper-bound
correlation
outputs
two
distributed
bbcs
finally
upper-bound
used
show
large
blocklength
single-letter
coding
schemes
literature
sub-optimal
multiterminal
communication
settings
introduction
paper
mathematical
theory
communications
often
regarded
magna
carta
digital
commu-
nications
shannon
pointed
order
exploit
redundancy
source
data
compression
necessary
compress
large
blocks
source
simultaneously
precisely
optimality
approached
eﬀective
length
encoding
functions
approaches
inﬁnity
context
eﬀective
length
encoding
function
interpreted
average
number
input
elements
necessary
estimate
output
element
encoding
function
high
accuracy
observation
made
case
point-to-
point
ptp
channel
coding
result
common
feature
coding
schemes
used
ptp
communication
large
eﬀective
lengths
loosely
speaking
means
output
element
schemes
function
entire
input
sequence
length
input
sequence
asymptotically
large
source
coding
problem
compressing
large
blocks
time
one
exploit
redundancy
source
channel
coding
problem
transmitting
input
message
large
blocks
allows
decoder
exploit
typicality
noise
vector
large
blocklength
gains
due
typicality
noise
vector
channel
coding
source
vector
source
coding
also
present
coding
networks
however
multiterminal
communication
often
desirable
maintain
correlation
among
output
sequences
diﬀerent
nodes
requirement
due
explicit
constraints
problem
statement
joint
distortion
measures
multi-
terminal
source
coding
due
implicit
factors
need
interference
reduction
multi-terminal
channel
coding
due
nature
shared
communication
channel
latter
case
correlation
outputs
necessary
means
cooperation
among
transmitters
paper
show
pairs
encoding
functions
large
eﬀective
lengths
ineﬃcient
coordinating
outputs
due
fact
encoding
functions
unable
produce
highly
correlated
outputs
highly
correlated
inputs
loss
correlation
undermines
encoders
ability
cooperate
take
ad-
vantage
multi-terminal
nature
problem
ptp
communication
problems
one
transmitter
necessity
cooperation
manifest
reason
although
encoders
asymptotically
large
eﬀective
lengths
optimal
ptp
communications
sub-
optimal
network
communication
case
worth
men-
tioning
subtle
diﬀerence
eﬀective
length
mentioned
blocklength
encoding
function
eﬀective
length
encoding
function
interpreted
average
number
input
elements
necessary
estimate
output
element
high
precision
whereas
blocklength
length
sequence
input
encoding
function
well-known
performance
block-codes
super-additive
respect
blocklength
meaning
best
performance
block-codes
certain
length
increasing
function
blocklength
however
performance
function
eﬀective
length
code
necessarily
super-additive
loss
correlation
caused
application
large
eﬀective-length
codes
causes
discontinuity
perfor-
mance
codes
multi-terminal
problems
ﬁrst
observed
problem
distributed
source
coding
berger-tung
coding
strategy
noted
common
information
available
two
encoders
distributed
source
coding
problem
performance
discontinuously
better
common
information
replaced
highly
correlated
components
argued
discontinuity
performance
due
fact
encoding
functions
berger-tung
scheme
preserve
common
information
unable
preserve
correlation
highly
correlated
components
proposed
new
coding
scheme
derived
improved
achievable
rate-
distortion
region
two
user
distributed
source
coding
problem
new
strategy
uses
concatenated
coding
scheme
consists
one
layer
codes
ﬁnite
eﬀective
length
one
layer
codes
asymptotically
large
eﬀective
lengths
paper
prove
assertion
dis-
continuity
correlation
preserving
abilities
encoding
functions
produced
using
single-letter
coding
schemes
berger-tung
scheme
single-letter
coding
schemes
considered
work
general
include
shannon
point-to-point
source
coding
scheme
berger-tung
scheme
zhang-berger
scheme
proof
involves
several
steps
make
extensive
use
mathematical
machinery
developed
provide
bound
correlation
outputs
two
arbitrary
boolean
functions
bound
presented
function
dependency
spectrum
boolean
functions
dependency
spectrum
general-
ization
eﬀective
length
boolean
function
explained
detail
next
sections
consider
two
arbitrary
binary
block
codes
bbc
deﬁned
two
encoding
functions
applied
two
correlated
discrete
memoryless
sources
dms
deﬁne
correlation
outputs
encoding
functions
average
prob-
ability
two
output-bits
equal
average
elements
output
vector
using
bound
show
codes
generated
large
blocklength
single-letter
coding
schemes
incapable
producing
highly
correlated
outputs
highly
correlated
inputs
pre-
cisely
show
block-length
increases
outputs
quantizers
terminal
become
less
correlated
leads
conjecture
schemes
sub-optimal
network
communication
problems
provide
one
example
problem
lossless
transmission
correlated
sources
interference
channel
prove
example
single-letter
coding
schemes
sub-optimal
rest
paper
organized
follows
section
gives
notation
used
work
section
iii
includes
summary
mathematical
tools
used
section
derive
probabilistic
bound
correlation
outputs
encoding
functions
pro-
duced
using
single-letter
coding
schemes
section
includes
example
show
sub-optimality
single-letter
schemes
speciﬁc
multi-termianal
problem
section
concludes
paper
notation
section
introduce
notation
used
paper
represent
random
variables
capital
letters
sets
denoted
calligraphic
letters
random
variable
corresponding
proba-
bility
space
underlying
ﬁeld
set
subsets
written
three
diﬀerent
notations
used
diﬀerent
classes
vectors
random
variables
n-length
vector
···
denoted
vector
functions
···
use
notation
binary
string
···
written
example
set
functions
set
n-length
vectors
functions
···
operating
vector
···
indexed
n-length
binary
string
···
vector
binary
strings
···
denotes
standard
basis
dimensional
space
e.g
···
vector
random
variables
···
cid:44
example
take
denoted
vector
denoted
x101
vector
also
x110
particularly
all-ones
vector
two
binary
strings
write
binary
string
deﬁne
cid:44
denotes
hamming
weight
lastly
vector
element-wise
complement
iii
correlation
dependency
spectrum
recently
introduced
eﬀective
length
ad-
ditive
boolean
function
extension
dependency
spectrum
general
boolean
function
used
dependency
spectrum
bound
correlation
outputs
functions
sequences
random
variables
loosely
speaking
boolean
function
dependency
spectrum
vector
characterizes
corre-
lation
output
subsequences
input
sequence
work
make
extensive
use
upper-bound
well
mathematical
apparatus
developed
hence
provide
concise
review
material
let
boolean
function
following
method
presented
convert
problem
analyzing
boolean
function
one
encoder
binary
real-valued
function
mapping
discrete-valued
function
real-valued
one
crucial
since
allows
use
rich
set
tools
available
functional
analysis
assume
corresponding
real
function
deﬁned
1
otherwise
following
gives
deﬁnition
additive
decompo-
sition
cid:80
deﬁnition
vector
real
functions
˜ei
0,1
called
additive
decomposition
˜ei
exn|xi
˜e|xi
˜ej
cid:80
remark
deﬁnition
follows
0,1
˜ei
following
proposition
describes
properties
components
additive
decomposition
proposition
deﬁne
variance
˜ei
following
hold
exn|xj
˜ei|xk
˜ei
exn
˜ei
˜ek
cid:44
exn|xk
˜ei|xk
˜e2
following
lemma
gives
formula
calculating
lemma
arbitrary
let
corre-
sponding
real
function
variance
component
˜ei
additive
decomposition
given
following
recursive
formula
var
˜ei
exi
cid:44
˜e|xi
cid:80
xn|xi
dependency
spectrum
function
deﬁned
deﬁnition
dependency
spectrum
boolean
function
vector
variances
0,1
called
dependency
spectrum
let
pair
dms
consider
two
arbitrary
boolean
functions
let
cid:44
cid:44
cid:44
cid:44
also
additive
decomposition
functions
theorem
following
bound
holds
cid:80
let
cid:80
cid:115
cid:88
cid:115
cid:88
cid:115
cid:88
cid:88
cid:115
cid:88
cip
cid:44
cid:88
cip
cid:44
real
function
corresponding
variance
˜ei
˜fi
ﬁnally
cid:44
correlation
preservation
single-letter
bbcs
section
provide
deﬁnition
coding
scheme
identify
three
properties
shared
among
many
coding
schemes
available
multi-terminal
com-
munications
call
group
coding
schemes
share
properties
single-letter
random
coding
schemes
slcs
coding
schemes
include
shannon
ptp
source
coding
scheme
berger-tung
coding
scheme
distributed
source
coding
zhang-berger
multiple-descriptions
coding
scheme
use
results
previous
section
bound
correlation
outputs
two
encoding
functions
produced
using
slcs
proof
involves
sev-
eral
steps
first
shown
slcss
produce
encoding
functions
variance
either
single-letter
components
dependency
spectrum
components
asymptotically
large
blocklengths
along
theorem
used
prove
schemes
ineﬃcient
preserving
correlation
following
deﬁnes
coding
scheme
deﬁnition
scheme
characterized
probability
cid:83
···
cid:83
···
dr|e1
···
cid:83
measure
coding
fig
point-to-point
source
coding
example
set
encoding
functions
decoding
functions
example
shannon
point-to-point
coding
schemes
de-
termine
cid:83
cid:83
d|e
using
single-letter
distribution
assign
probabilities
codebooks
using
typicality
encoding
decoding
rules
determine
encoding
decoding
functions
whenever
choice
coding
scheme
clear
denote
distribution
pd|e
d|e
following
deﬁnes
slcss
deﬁnition
coding
scheme
characterized
cid:83
called
slcs
following
constraints
satisﬁed
arbitrary
let
∀xn
∃δx
pxn
2−nδx
∀yn
cid:60
cid:51
∀xm
cid:83
v|xm
cid:83
v|xi
π−1
symmetric
group
length
remark
ﬁrst
condition
interpreted
follows
arbitrary
sequence
let
set
sequences
set
encoding
functions
map
sequence
non-zero
probability
respect
measure
cid:83
e.g
typicality
encoding
requires
jointly
typical
based
ﬁxed
distribution
condition
requires
probability
set
goes
exponentially
furthermore
cid:60
mapped
codeword
chosen
independent
i.e
codewords
chosen
pairwise
independently
remark
second
condition
interpreted
follows
joint
distribution
input
sequence
output
sequence
encoding
function
averaged
possible
encoding
functions
approaches
product
distribution
variational
distance
remark
explanation
third
condition
probability
vector
mapped
depends
joint
type
equal
probability
permuted
sequence
mapped
example
condition
holds
typicality
encoding
next
example
show
shannon
coding
scheme
point-to-point
source
coding
satisfy
conditions
example
consider
ptp
source
coding
problem
depicted
figure
discrete
memoryless
source
fed
fx1
···
xnge
uni−1
munencoderdecoder
means
cid:80
encoder
encoder
utilizes
mapping
compress
source
sequence
image
indexed
bijection
|im
index
cid:44
sent
decoder
decoder
reconstructs
com-
pressed
sequence
cid:44
i−1
eﬃciency
reconstruction
evaluated
based
separable
distortion
criteria
separability
property
assume
alphabets
binary
rate
transmission
log|im
average
distortion
deﬁned
cid:44
deﬁned
goal
choose
rate-distortion
tradeoﬀ
optimized
note
choice
bijection
irrelevant
performance
system
following
lemma
gives
achievable
region
setup
lemma
source
distortion
criteria
conditional
distribution
pu|x
u|x
rate-distortion
pair
cid:0
cid:1
achievable
cid:44
cid:12
cid:12
cid:12
proof
order
verify
properties
slcs
coding
scheme
used
problem
give
scheme
fix
deﬁne
outline
pu|x
u|x
proving
achievability
equivalent
showing
existence
suitable
encoding
function
randomly
generated
encoding
function
constructed
aid
set
vectors
called
codebook
assignment
rule
called
typicality
encoding
construct
codebook
follows
let
−pu
set
n-length
binary
vectors
-typical
respect
choose
cid:100
2nr
cid:101
vectors
randomly
uniformly
let
set
vectors
encoder
constructs
encoding
function
follows
arbitrary
sequence
deﬁne
u|xn
set
vectors
jointly
-typical
based
pu|x
vector
chosen
randomly
uniformly
u|xn
probabilistic
choice
codewords
well
quantization
puts
distribution
random
function
shown
becomes
larger
codes
produced
based
distribution
achieve
rate-
distortion
vector
probability
approaching
one
remark
well-known
scheme
codebook
generation
process
could
altered
following
way
instead
choosing
codewords
randomly
uni-
formly
set
typical
sequences
encoder
produce
codeword
independent
others
distribution
pun
πi∈
however
discussion
follows
remains
unchanged
regardless
codebook
generation
methods
used
codewords
chosen
pairwise
independently
v|yn
two
input
sequences
given
two
vectors
mapped
codeword
hence
mapped
independently
generated
codewords
i.e
chosen
independently
u|xn
∩an
becomes
large
ith
output
element
correlated
input
sequence
ith
input
element
∀xm
cid:83
v|xm
cid:83
v|xi
proof
ﬁxed
quantization
function
function
however
without
knowledge
encoding
function
used
related
words
averaged
encoding
functions
eﬀects
rest
elements
diminishes
provide
proof
statement
first
required
provide
deﬁnitions
relating
joint
type
pairs
sequences
binary
strings
deﬁne
b|um
cid:44
j|u
number
indices
value
pair
deﬁne
cid:44
t|um
vector
l0,0
l0,1
l1,0
l1,1
called
joint
type
ﬁxed
set
sequences
l0,0
l0,1
l1,0
l1,1
um|n
t|um
set
vectors
joint
type
l0,0
l0,1
l1,0
l1,1
sequence
fix
deﬁne
cid:44
l0,0
l0,1
l1,0
l1,1
conditional
typical
set
u|xm
deﬁned
write
u|xm
l0,0
l0,1
l1,0
l1,1
∈l
l0,0
l0,1
l1,0
l1,1
um|u1
u|xm
l0,0
l0,1
l1,0
l1,1
∈l
um|um
l0,0
l0,1
l1,0
l1,1
type
denoted
deﬁned
similar
manner
since
chosen
uniformly
set
u|xm
u|xm
cid:80
cid:83
v|xm
cid:80
l0,0
l0,1
l1,0
l1,1
∈l
um|u1
l0,0
l0,1
l1,0
l1,1
cid:80
cid:80
cid:80
cid:80
cid:80
l0,0
l0,1
l1,0
l1,1
∈l
l0,0
l0,1
l1,0
l1,1
∈l
l0,0
l0,1
l1,0
l1,1
∈l
lu1
lu1
x1−1
lx1−lu1
lu1
lx1−lu1
um|um
cid:17
cid:16
lx1−1
cid:17
cid:16
¯x1
cid:17
cid:16
¯x1
cid:16
lx1
lu1
¯x1
¯x1−lu1
¯x1
lu1
¯x1
¯x1−lu1
¯x1
lu1
¯x1
lx1−1
lu1
x1−1
lu1
¯x1
cid:17
¯x1
lx1
¯x1
l0,0
l0,1
l1,0
l1,1
∈l
l0,0
l0,1
l1,0
l1,1
∈l
lu1
lx1
l0,0
l0,1
l1,0
l1,1
∈l
cid:80
lu1
¯x1
¯x1−lu1
¯x1
lu1
¯x1
¯x1−lu1
¯x1
lu1
lx1−lu1
lu1
lx1−lu1
cid:83
v|xm
cid:83
v|xm
pu|x
u1|x1
use
fact
ﬁxed
lx1
¯x1
ﬁxed
simplify
numerators
used
jointly
typical
-sequences
lu1
lx1
encoder
insensitive
permutations
due
typicality
encoding
probability
vector
mapped
depends
joint
type
equal
probability
mapped
kth
element
˜ek
cid:80
goal
analyze
correlation
preserving
proper-
ties
slcs
precisely
investigate
two
encoding
functions
generated
using
slcs
bound
correlation
outputs
two
functions
randomly
generated
encoding
function
···
denote
additive
decomposition
real
function
corresponding
˜ek
let
variance
˜ek
next
theorem
shows
slcss
produce
encoding
functions
variance
either
single-letter
components
dependency
spectrum
components
asymptotically
large
blocklengths
cid:83
cid:80
theorem
ni≤m
cid:44
kth
standard
basis
element
proof
please
refer
appendix
theorem
shows
slcs
distribute
˜ek
˜ek
operate
asymptotically
variance
large
blocks
input
single-letter
component
˜ek
hence
encoders
generated
using
schemes
high
expected
variance
decomposition
elements
large
eﬀective
lengths
along
theorem
gives
upper
bound
correlation
preserving
properties
slcs
following
theorem
states
upper
bound
main
result
section
theorem
let
pair
dms
also
assume
pair
produced
using
slcs
characterized
cid:83
deﬁne
cid:44
cid:18
cid:44
pxn
cid:44
cid:83
cid:44
var
˜ei
cid:44
var
˜fi
cid:44
var
cid:44
var
2−2
cid:19
proof
please
refer
appendix
remark
result
theorem
also
valid
case
slcs
sets
produced
based
cid:83
i.e
encoders
use
encoding
function.
order
increase
correlation
outputs
encoding
functions
produced
using
slcss
variance
˜ek
needs
increase
turn
increases
single-letter
mutual
information
input
output
encoder
would
require
higher
rates
example
consider
extreme
case
var
˜ek
set
maximum
i.e
var
˜ek
var
˜ek
requires
order
achieve
maximum
correlation
encoder
must
use
uncoded
transmission
theorem
shows
discontinuity
correlation
preserving
ability
slcss
function
joint
distribution
particularly
common-information
available
encoders
encoders
use
encoding
function
outputs
would
equal
probability
one
whereas
fig
iccs
example
slcss
suboptiomal
non-zero
output
correlation
bounded
away
bound
provided
theorem
probability
equal
outputs
approach
correlation
outputs
encoding
functions
discontinuous
function
special
case
phenomenon
observed
distributed
source
coding
problem
used
prove
sub-optimality
berger-tung
strategy
multi-terminal
communication
examples
section
provide
example
multi-terminal
communication
setup
slcss
suboptimal
perfor-
mance
use
discontinuity
mentioned
previous
section
show
sub-optimality
slcss
consider
problem
transmission
correlated
sources
interference
channel
iccs
described
examine
speciﬁc
iccs
setup
shown
figure
sources
bernoulli
random
variables
parameters
q-ary
random
variable
distribution
independent
also
independent
finally
correlated
cid:44
random
variable
bernoulli
parameter
ﬁrst
transmitter
transmits
binary
input
second
transmitter
transmits
pair
inputs
x21
x22
x21
q-ary
x22
binary
receiver
receives
receiver
receives
given
x22
otherwise
x21
second
channel
outputs
x21
noiselessly
second
encoder
guesses
ﬁrst
encoder
output
correctly
i.e
x22
otherwise
erasure
produced
following
proposition
gives
set
suﬃcient
conditions
trans-
mission
correlated
sources
interference
channel
cid:32
cid:33
proposition
sources
transmissible
exist
cid:33
cid:32
q−1
cid:33
cid:17
cid:32
cid:16
log
binary
entropy
function
1−δ
log2
1−δ
channel
dispersion
rate-dispersion
enc.1enc.2x1x21x22nδy1y20101ϵ
cid:16
cid:17
function
gaussian
complementary
cumulative
distribution
function
ﬁxed
denote
set
pairs
satisfy
bounds
d+γ
1−hb
proof
first
provide
outline
coding
strategy
fix
cid:28
let
encoders
send
bits
compressed
input
block
transmission
ﬁrst
encoder
transmits
source
two
steps
first
uses
ﬁxed
blocklength
source-channel
code
parameters
code
maps
k-length
blocks
source
n-length
blocks
channel
input
average
distortion
resulting
code
less
step
encoder
transmits
source
blocks
length
total
channel
uses
needed
note
second
step
encoder
uses
large
blocklength
code
correct
errors
previous
step
code
rate
close
γ+d
1−hb
input
length
equal
second
encoder
transmits
messages
ﬁrst
step
transmission
uses
ﬁxed
blocklength
code
ﬁrst
encoder
source
sequence
estimate
outcome
ﬁrst
encoder
sends
estimate
22.
since
ﬁrst
encoder
output
conclude
equal
least
probability
encoder
sends
source
using
x21
resulting
q-ary
erasure
channel
probability
erasure
following
provides
detailed
descriptions
coding
strategy
codebook
generation
fix
let
let
optimal
source-channel
code
parameters
point-to-point
transmission
binary
source
binary
symmetric
channel
described
code
transmits
k-length
blocks
source
using
n-length
blocks
channel
input
guarantees
resulting
distortion
block
less
probability
i.e
ˆxn
reconstruction
binary
source
decoder
shown
parameters
code
satisfy
d+γ
1−hb
cid:17
cid:16
cid:112
q−1
log
since
ˆxn
straightforward
show
average
distortion
less
equal
also
construct
family
good
channel
codes
cid:48
binary
symmetric
channel
rate
next
construct
family
q-ary
erasure
channel
good
channel
codes
cid:48
cid:48
rate
klog
finally
randomly
uniformly
bin
space
binary
vectors
length
rate
cid:48
d+γ
precisely
generate
binning
function
kmr
cid:48
mapping
vector
value
chosen
uniformly
kmr
cid:48
encoding
fix
block
encoders
transmit
symbols
source
input
let
source
sequences
denoted
broken
source
vectors
blocks
length
notation
ith
element
jth
block
jth
block
step
encoder
uses
code
transmit
blocks
decoder
second
encoder
ﬁnds
output
code
fed
code
transmits
output
vector
x22
encoder
uses
interleaving
method
similar
one
transmit
sequence
ﬁnds
output
cid:48
cid:48
step
ﬁrst
encoder
transmits
decoder
losslessly
using
cid:48
kmr
cid:48
decoding
ﬁrst
step
ﬁrst
decoder
reconstructs
average
distortion
second
step
using
bin
number
losslessly
reconstruct
source
since
cid:48
kmr
cid:48
good
channel
code
decoder
also
recovers
losslessly
using
since
cid:48
cid:48
input
transmits
x21
good
channel
code
conditions
successful
transmission
given
follows
cid:112
q−1
log
klog
simplifying
conditions
replacing
proves
proposition
bound
provided
proposition
calculable
with-
exact
characterization
log
term
however
use
bound
prove
sub-optimality
slcss
first
argue
transmissible
region
continuous
function
note
sources
parameters
log
transmissible
region
proposition
continuous
sense
approaches
pairs
neighborhood
log
satisfy
bounds
given
proposition
i.e
corresponding
sources
transmissible
proposition
exist
log
arbitrary
encoding
scheme
operating
blocks
length
let
encoding
functions
follows
e21
e22
follow-
ing
lemma
gives
outer
bound
function
correlation
outputs
e21
lemma
coding
scheme
encoding
functions
e21
e22
following
holds
cid:16
d+γ
1−hb
cid:17
e22
cid:88
i=1
proof
since
reconstructed
losslessly
decoder
zn|en
fano
inequality
following
holds
cid:88
cid:88
i=1
e22
log
e22
log
i=1
deﬁned
indicator
function
event
used
equation
used
fact
binary
using
theorem
show
encoding
functions
generated
using
slcss
e22
discontinuous
next
proposition
shows
slcss
sub-optimal
proposition
exists
sources
log
transmissible
using
slcss
x22n
e22
encoding
functions
used
two
encoders
generate
x22
log
must
e22
almost
indices
theorem
requires
re-
however
quires
uncoded
transmission
i.e
uncoded
transmission
contradicts
lossless
reconstruction
source
ﬁrst
decoder
proof
let
proof
restricted
particular
scheme
rather
shows
slcs
would
sub-optimal
performance
conclusion
characterized
set
properties
shared
slcss
used
literature
showed
schemes
properties
produce
encoding
func-
tions
ineﬃcient
preserving
correlation
de-
rived
probabilistic
upper-bound
correlation
outputs
random
encoders
generated
using
slcss
showed
correlation
outputs
encoders
discontinuous
respect
input
distribution
used
discontinuity
show
slcss
sub-
optimal
speciﬁc
multi-terminal
communications
problem
involving
transmission
correlated
source
inter-
ference
channel
acknowledgements
authors
grateful
dr.
neuhoﬀ
stimulat-
ing
discussions
helpful
comments
appendix
proof
theorem
bility
cid:83
cid:80
proposition
cid:80
proof
proof
following
proposition
shows
proba-
ni≤m
cid:44
independent
index
due
property
deﬁnition
slcs
ni≤m
cid:44
00···01
constant
fix
cid:48
deﬁne
permutation
πk→k
cid:48
permutation
switches
kth
cid:48
elements
ﬁxes
elements
also
let
cid:69
set
mappings
cid:88
cid:88
cid:88
cid:69
cid:83
ni≤m
cid:44
cid:88
cid:88
cid:88
cid:88
cid:69
cid:69
cid:69
cid:83
cid:83
cid:83
eπk→k
cid:48
cid:83
ni≤m
cid:44
ik|e
γ|e
pπk→k
cid:48
πk→k
cid:48
γ|g
cid:48
γ|g
cid:83
ni≤m
cid:44
cid:88
cid:88
ni≤m
cid:44
nl≤m
cid:44
πk→k
cid:48
cid:88
ni≤m
cid:44
cid:48
cid:48
used
property
deﬁnition
deﬁned
cid:44
eπk→k
cid:48
used
k→k
cid:48
using
previous
proposition
enough
show
theorem
holds
ease
notation
drop
subscript
rest
proof
denote
markov
inequality
following
cid:88
cid:83
ni≤m
cid:44
cid:80
ni≤m
cid:44
cid:83
need
show
cid:80
ni≤m
cid:44
cid:83
goes
ﬁxed
ﬁrst
prove
following
claim
claim
fix
following
holds
xn|xi
˜e|xi
exi
xn|xi
˜e|xi
e−nδx
proof
cid:88
cid:88
cid:88
x∼i
x∼i
y∼i
y∼i
y∼i
x∼i
yi=xi
x∼i
yi=xi
y∼i
yi=xi
cid:60
yi=xi
yn∈bn
cid:88
cid:88
cid:88
cid:88
cid:88
cid:88
cid:88
|yi
xn|xi
˜e|xi
cid:88
cid:88
cid:88
cid:88
cid:88
cid:88
cid:88
cid:88
e−nδx
cid:88
cid:88
yi=xi
cid:60
e−nδx
|yi
e−nδx
exi
yi=xi
cid:60
yi=xi
yn∈bn
˜e|xi
yi=xi
cid:60
cid:88
cid:88
y∼i
yi=xi
x∼i
xn|xi
y∼i
y∼i
x∼i
y∼i
y∼i
use
fact
deﬁnition
follows
property
deﬁnition
deﬁne
¯ei
˜ei
˜e|xi
˜e|xi
cid:80
¯ej
also
deﬁne
¯pi
cid:44
var
¯ei
using
claim
cid:88
2mo
e−nδx
cid:80
ni≤m
cid:44
cid:83
cid:80
ni≤m
cid:83
¯pi
cid:83
¯pi1
ni≤m
cid:44
cid:83
using
arguments
proof
proposition
see
properties
stated
proposition
hold
¯ei
well
using
results
lemma
cid:80
cid:88
cid:83
ni≤m
cid:44
ni≤m
cid:83
¯pi
cid:83
¯pi1
0,1
¯pi
¯p1
following
calculations
2mo
e−nδx
cid:80
2mo
e−nδx
cid:80
0,1
cid:83
¯pi
cid:83
¯pi1
2mo
e−nδx
cid:83
cid:80
0,1
¯pi
cid:83
¯pi1
cid:18
˜e|xn
|xn
2mo
e−nδx
exn
2mo
e−nδx
cid:83
¯pi1
cid:83
¯pi1
2mo
e−nδx
cid:19
cid:83
¯pi1
last
inequality
used
second
property
deﬁnition
last
line
goes
completes
proof
proof
theorem
proof
theorem
cip
cid:44
cid:88
ni≤m
cid:44
theorem
cid:88
cid:83
note
cid:88
cid:88
cid:88
ni≤m
cid:44
pi1
ni≤m
cid:44
cid:88
ni≤m
cid:44
cid:83
qi1
cip
converges
also
decreasing
goes
choose
small
enough
large
enough
pi1
cid:18
qi1
equations
gives
pxn
cid:44
equivalent
statement
theorem
cid:83
cid:19
references
shannon
mathematical
theory
communication
bell
system
technical
journal
vol
379–423
july
1948
wagner
kelly
altug
distributed
rate-distortion
common
components
ieee
transactions
information
theory
vol
4035–4057
july
2011
chaharsooghi
sahebi
pradhan
distributed
source
coding
absence
common
components
information
theory
proceedings
isit
2013
ieee
international
symposium
july
2013
1362–1366
shirani
pradhan
finite
block-length
gains
distributed
source
coding
information
theory
proceedings
isit
2014
ieee
international
symposium
july
2014
1702-1706
tung
multiterminal
source
coding
ph.d.
dissertation
cornell
university
ithaca
1978
gacs
körner
common
information
far
less
mutual
information
problems
control
information
theory
vol
119–162
1972
witsenhausen
sequences
pair
dependent
random
vari-
ables
siam
journal
applied
mathematics
vol
100–113
1975
zhang
berger
new
results
binary
multiple
descriptions
ieee
transactions
information
theory
vol
502–521
jul
1987
salehi
kurtas
interference
channels
correlated
sources
proceedings
ieee
international
symposium
information
theory
jan
1993
208–208
kostina
verdú
lossy
joint
source-channel
coding
finite
blocklength
regime
ieee
transactions
information
theory
vol
2545-2575
may
2013
shirani
pradhan
correlation
boolean
functions
sequences
random
variables
arxiv.org
jan
2017
