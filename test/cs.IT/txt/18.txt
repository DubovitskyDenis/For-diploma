complexity-aware
scheduling
ldpc
encoded
c-ran
uplink
kyle
whetzel
matthew
valenti
lane
dept
comp
sci
elect
eng
west
virginia
university
morgantown
26506–6109
email
valenti
ieee.org
abstract—centralized
radio
access
network
c-ran
new
paradigm
wireless
networks
centralizes
signal
processing
computing
cloud
allowing
commodity
computa-
tional
resources
pooled
c-ran
improves
utilization
efﬁciency
computational
load
occasionally
exceeds
available
resources
creating
computational
outage
paper
provides
mathematical
characterization
computational
outage
probability
low-density
parity
check
ldpc
codes
common
class
error-correcting
codes
tractability
binary
erasures
channel
assumed
using
concept
density
evolution
computational
demand
determined
given
ensemble
codes
function
erasure
probability
analysis
reveals
trade-off
aggressively
signaling
high
rate
stresses
computing
pool
conservatively
backing-off
rate
avoid
computational
outages
motivated
trade-
effective
computationally
aware
scheduling
algorithm
developed
balances
demands
high
throughput
low
outage
rates
introduction
fifth-generation
networks
expected
much
denser
offer
higher
operating
frequencies
pre-
decessors
implication
densiﬁcation
many
base
stations
higher
variability
trafﬁc
signal
processing
techniques
used
wireless
networks
get
sophisticated
digital
baseband
proces-
sors
continue
dominate
price
footprint
power
requirements
wireless
network
recent
trend
wireless
networking
consol-
idate
baseband
processing
multiple
access
points
early
version
consolidation
distributed
antenna
systems
recent
concept
c-ran
whereby
baseband
processors
several
base
stations
colocated
central
processing
farm
beneﬁts
c-ran
numerous
stem
sharing
commodity
hardware
base
stations
diverse
processing
needs
moreover
ran
allows
sophisticated
collaborative
signal
processing
instance
performing
multiuser
detection
across
base
stations
transmitting
distributed
space-time
codes
performing
network
mimo
processing
shared
limited
pool
resources
chance
instantaneous
processing
demands
met
given
resources
happens
outage
occurs
outages
similar
outage
caused
channel
impairments
fading
interference
outages
data
need
retransmitted
assuming
presence
hybrid-arq
retransmission
protocol
paper
explore
computational
requirements
typical
wireless
uplink
focus
transmission
mobile
unit
base
station
known
uplink
transmissions
assumed
encoded
low-
density
parity
check
ldpc
codes
common
class
error-
correcting
codes
tractability
binary
erasures
channel
bec
assumed
using
concept
density
evolution
computational
demand
determined
given
ensemble
codes
function
erasure
probability
analysis
reveals
trade-off
aggressively
signaling
high
rate
stresses
computing
pool
conservatively
backing-off
rate
avoid
computational
outages
motivated
trade-off
effective
computationally
aware
scheduling
algorithm
developed
balances
demands
high
throughput
low
outage
rates
simulation
results
show
beneﬁts
using
computationally
aware
scheduling
algorithm
remainder
paper
organized
follows
sec-
tion
gives
overview
c-ran
concept
section
iii
reviews
salient
points
ldpc
codes
providing
mathematical
framework
describing
complexity
ldpc
codes
used
bec
section
discusses
rate-optimized
ldpc
codes
identiﬁed
shows
complexity
function
erasure
probability
section
discusses
various
schedulers
considered
section
provides
results
simulation-based
analysis
schedulers
finally
section
vii
concludes
paper
discusses
potential
future
work
overview
c-ran
components
cellular
base
station
grouped
two
main
entities
part
analog-domain
processing
e.g.
power
ampliﬁcation
circuitry
digital
baseband
processor
traditional
cellular
network
components
packaged
together
single
unit
per
base
station
however
technology
improved
analog
components
became
lighter
cheaper
allowing
placed
close
antenna
top
towers
digital
equipment
called
baseband
unit
bbu
left
base
towers
equipment
shack
separation
bbu
several
beneﬁts
first
foremost
antenna
feed
line
major
source
loss
made
short
also
baseband
equipment
placed
controlled
enclosure
temperature
control
plentiful
power
analog
digital
conversion
adc
performed
atop
tower
sampled
signal
fed
though
high
speed
optical
cable
bbu
link
component
bbu
known
fronthaul
link
common
public
radio
interface
cpri
protocol
used
link
cpri
transmits
constant
bit
rate
gbps
allows
link
kilometers
latency
0.1
ms.
distance
allows
bbus
multiple
cells
consolidated
called
baseband
hotel
lends
cost
effectiveness
less
infrastructure
needed
delivering
power
temperature
control
network
links
bbus
baseband
hotels
also
allow
joint
processing
sharing
computing
resources
sharing
resources
creates
statistical
multiplexing
gain
gain
comes
exploiting
temporal
spatial
trafﬁc
ﬂuctuations
inherent
cellular
networks
time
hard
deadline
mobile
networks
hard
real-time
systems
tight
timing
protocol
constraints
c-ran
sampled
data
must
quickly
transmitted
fronthaul
processed
real
possible
capacity
fronthaul
link
sufﬁcient
meet
deadlines
also
ﬁnite
computing
resources
baseband
hotel
possible
computational
load
de-
manded
network
greater
processing
resources
available
either
situations
arise
computational
outage
said
occur
computational
outages
detrimental
wireless
systems
outages
caused
fading
interference
tasks
handled
bbus
forward
error
control
fec
amongst
one
computationally
intensive
fec
aims
add
redundancy
transmitted
data
recover
errors
occurred
transmission
adding
redundancy
data
rate
compromised
lot
literature
focused
maximizing
code
rate
approach
shannon
limit
however
signaling
higher
data
rates
requires
computational
resources
decoding
trade-off
becomes
important
c-ran
systems
objective
c-ran
scheduler
select
coding
scheme
real
time
best
meet
demands
system
iii
complexity
ldpc
codes
ldpc
codes
use
iterative
decoder
deﬁned
tanner
graph
decoding
complexity
depends
number
decoding
iterations
layout
graph
number
decoder
iterations
predicted
using
concept
known
density
evolution
ease
exposition
focus
density
evolution
bec
paper
though
work
could
extended
channels
including
binary
symmetric
channel
bsc
additive
white
gaussian
noise
awgn
channels
bec
input
may
data
data
output
may
data
data
erasure
probability
called
erasure
probability
bit
erased
case
channel
outputs
erasure
probability
bit
received
correctly
erasure
probability
shannon
capacity
meaning
code
exists
enables
reliable
communication
rate
close
shannon
capacity
erasure
channel
reached
using
ldpc
codes
input
ldpc
encoder
message
length
bits
encoder
maps
message
codeword
length
bits
ratio
message
bits
total
number
bits
codeword
k/n
called
code
rate
code
denoted
set
codewords
describing
ldpc
codes
ldpc
code
may
described
parity-check
matrix
rank
matrix
whose
rows
span
dual
code
set
length-n
binary
vectors
orthogonal
every
vector
parity
check
matrix
usually
full
rank
case
rows
rows
hence
orthogonal
every
codeword
follows
ldpc
code
characterized
sparse
parity-check
matrix
i.e.
large
matrix
containing
ones
sparseness
results
low
decoder
complexity
even
code
length
becomes
long
necessary
approach
shannon
capacity
example
parity-check
matrix
follows


expanding
set
parity-check
equations
may
found
one
row
instance
parity-
check
equations
matrix
code
bit
said
participate
ith
parity-check
equation
position
tanner
graph
bipartite
graph
represents
matrix
tanner
graphs
two
independent
sets
vertices
called
check
nodes
variable
nodes
check
nodes
represent
parity-check
equations
variable
nodes
represent
code
bits
entry
parity-
check
matrix
ith
check
node
connected
jth
variable
node
thus
tanner
graph
pictorial
representation
showing
code
bits
participate
parity-check
equations
fig
shows
tanner
graph
parity
check
matrix
given
decoding
performed
using
tanner
graph
first
variable
nodes
loaded
observed
code
bits
fig
example
received
message
containing
erasures
0.4
0.35
0.3
0.25
fig
example
tanner
graph
cid:1
0.2
shown
check
node
examines
incident
edges
see
connected
single
variable
node
containing
erasure
case
check
nodes
correct
erasure
using
logic
single
parity-check
code
process
checking
incident
edges
check
node
iterated
erasures
corrected
possible
corrections
made
degree
check
node
number
incident
edges
connected
number
equal
number
ones
hamming
weight
corresponding
row
matrix
complexity
decoding
using
parity-
check
matrix
dependent
degree
check
nodes
therefore
desired
matrices
low
row
weight
rows
ldpc
parity-check
matrix
constant
weight
constant
check-node
degree
code
said
check
regular
hamming
weight
columns
ldpc
parity-check
matrix
also
constant
variable-node
degree
constant
code
said
regular
brevity
shorthand
used
specify
regular
code
variable-node
degree
check-node
degree
although
regular
codes
simple
perform
moderately
well
capable
achieving
capacity
irregular
ldpc
codes
without
constant
degree
properly
designed
capable
achieving
capacity
designing
irregular
ldpc
codes
variable
node
distribution
constant
check
node
degree
however
typically
held
constant
close
design
irregular
ldpc
codes
consists
choosing
proper
degree
distribution
let
denote
fraction
edges
touching
degree
check
nodes
denote
fraction
edges
touching
degree
variable
nodes
degree
distribu-
tions
described
polynomial
form
ρixi−1
distribution
check
nodes
λixi−1
variable
nodes
rate
code
found
terms
polynomial
form
degree
distributions
0.15
0.1
0.05
100
iteration
150
200
fig
density
evolution
3,6
regular
code
threshold
code
one
plot
0.43
0.429
0.4294
initial
erasure
probability
error
correcting
performed
code
said
converge
erasure
probability
reduced
certain
threshold
sufﬁciently
large
number
iterations
let
convergence
threshold
denoted
ǫthresh
criteria
convergence
erasure
probability
constantly
decreasing
i.e.
ǫℓ−1
ǫthresh
requirement
ǫℓ−1
ǫ0λ
ǫℓ−1
ǫℓ−1
performing
change
variable
ǫℓ−1
deﬁning
function
ǫ0λ
found
decoder
convergence
possible
ǫthresh
useful
ﬁnd
largest
code
converges
initial
erasure
probability
threshold
denoted
fig
shows
density
evolution
code
rearranging
using
yields
ﬁnd
largest
value
must
determined
function
convex
function
minimum
value
follows
min
density
evolution
density
evolution
tool
predicting
erasure
prob-
ability
function
number
decoder
iterations
ldpc
code
bec
states
probability
variable-node
remains
erased
ℓth
iteration
ǫ0λ
ǫℓ−1
ldpc
code
complexity
complexity
decoder
amount
processing
resources
required
successfully
decode
received
message
let
complexity
requried
per
codeword
equal
number
decoder
iterations
multiplied
number
edges
tanner
graph
assuming
check-regular
ldpc
code
ℓdc
get
better
understanding
complexity
versus
through-
put
information
would
beneﬁcial
know
required
work
per
data
bit
let
complexity
per
data
bit
ﬁnd
normalized
dividing
number
data
bits
i.e.
ℓdc
n−k
knowing
k/n
complexity
per
code
bit
written
terms
code
rate
ℓdc
rate
optimized
codes
palette
codes
required
use
complexity-
aware
scheduler
codes
designed
constraining
check-regular
ﬁnding
variable-node
degree
maximizes
code
valid
must
meet
following
constraints
dmax
dmax
i=1
dmax
i=1
dmax
largest
allowable
variable
node
degree
found
performance
enhanced
avoiding
degree-
variable
nodes
accomplished
changing
dmax
dmax
200
eight
codes
developed
denote
rate
erasure
threshold
rates
let
pair
code
developed
codes
pairs
1/5
0.728
1/4
0.708
1/3
0.657
2/5
0.589
1/2
0.478
3/5
0.367
2/3
0.274
3/4
0.167
thus
largest
erasure
probability
handled
codes
0.728.
situation
initial
erasure
probability
greater
result
failure
decode
message
using
complexity
calculated
various
values
using
density
evolution
described
section
iii-b
convergence
threshold
set
ǫthresh
10−3
max
number
iterations
set
103.
initial
erasure
probability
varied
threshold
code
resulting
complexities
shown
fig
initial
erasure
probability
approaches
threshold
code
computational
complexity
spikes
shows
desirability
complexity
aware
scheduling
systems
operating
near
computation
load
lowered
dramatically
switching
lower
coding
rate
complexity
aware
scheduling
c-ran
four
different
scheduling
algorithms
considered
c-ran
system
include
complexity
unaware
com-
plexity
aware
methods
let
cserver
total
computational
complexity
resources
available
computing
cluster
size
let
computational
complexity
required
base
station
user
within
computing
cluster
rate
code
rate
assigned
user
throughput
10000
9000
8000
7000
6000
5000
4000
3000
2000
1000
max=200
r=1/5
r=1/4
r=1/3
r=2/5
r=1/2
r=3/5
r=2/3
r=3/4
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
initial
erasure
probability
fig
complexity
required
convergence
note
spike
complexity
values
near
codes
deﬁned
average
assigned
code
rates
contained
computing
cluster
max
rate
selection
mrs
algorithm
user
cluster
assigned
maximum
code
rate
available
based
base
station
codes
pool
decoding
performed
certain
user
set
complexity
calculated
user
within
computing
cluster
batch
process
κ=1
cserver
computational
outage
occurs
rate
set
zero
users
resulting
zero
throughput
easiest
job
first
ejf
algorithm
initializes
per-
forming
mrs
code
selection
scheme
κ=1
cserver
scheduler
selects
user
lowest
complexity
value
easiest
job
minimum
com-
plexity
cej
cserver
decoding
performed
user
cej
added
sum
complexities
already
decoded
csum
csum
set
decoding
occurred
process
repeats
selecting
easiest
job
remaining
decoded
long
csum
cserver
local
limit
algorithm
starts
selecting
highest
possible
code
rate
user
mrs
algorithm
sets
limit
cloc
computational
resources
allocated
one
user
user
demands
decoder
complexity
greater
cloc
bumped
lower
rate
code
one
exists
complexity
recalculated
process
reiterated
κ=1
cserver
lower
rate
codes
recede
case
latter
codes
available
computational
outage
occurred
scheduling
complexity
cutoff
scc
algorithm
also
initializes
setting
rates
maximum
possible
mrs
scheme
checks
κ=1
cserver
case
user
chosen
cκ∗
maximum
code
rate
user
rκ∗
decreased
next
lower
coding
rate
one
exists
lower
rate
code
exist
user
next
highest
chosen
κ=1
recalculated
new
coding
rate
sum
less
cserver
decoding
commences
else
process
recursed
updated
selected
recursion
proceeds
complexity
constraint
met
lower
rate
codes
available
simulation
results
illustrate
efﬁcacy
scheduling
algorithms
simulation
study
conducted
simulations
110
base
stations
placed
hexagonal
grid
pattern
mobile
units
randomly
dropped
system
one
active
mobile
per
base
station
cell
number
cells
users
channel
utilization
computing
cluster
central
group
adjacent
cells
pooled
computing
resources
let
indicate
set
placed
locations
given
connected
particular
base
station
denoted
set
placed
signal-
to-interference-and-noise
ratio
sinr
calculated
base
station
computing
cluster
sinr
basestation
|yj
xj|α
s−1
γ−1
pi6=j
|yj
xi|−α|yi
xi|sα
|yj
xi|
distance
base
station
path-loss
exponent
compensation
factor
fractional
power
control
snr
unit
distance
summation
interferers
power
control
factor
set
0.1
value
maximizes
throughput
sinr
calculated
base
station
computing
cluster
corresponding
erasure
probability
found
using
complementary
cumulative
distribution
function
ccdf
sinrs
obtained
ccdf
makes
use
sinrs
obtained
default
simulation
values
deﬁnition
cdf
random
variable
evaluated
probability
less
since
probability
value
ranges
high
sinr
values
need
mapped
low
initial
erasure
probability
values
ccdf
used
complementary
cumulative
distribution
function
ccdf=1-cdf
exponential
curve
ﬁtted
ccdf
unless
otherwise
speciﬁed
simulations
used
default
values
simulation
parameters
follows
path-loss
exponent
utilization
100
cluster
size
snr
unit
distance
number
monte
carlo
trials
set
105.
ﬁrst
simulation
explores
impact
path-loss
expo-
nent
independent
variable
varied
corresponding
free-space
larger
path-losses
corresponding
rough
terrain
blockage
fig
shows
effect
varying
pathloss
exponent
throughput
different
scheduling
algorithms
throughput
schedulers
low
due
0.6
0.55
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
mrs
ejf
local
limit
scc
2.5
3.5
4.5
pathloss
exponent
fig
throughput
versus
path-loss
exponent
varied
value
free
space
corresponds
rough
terrain
high
blockage
computing
cluster
size
held
constant
channel
utilization
constant
100
mrs
ejf
local
limit
scc
0.4
0.38
0.36
0.34
0.32
0.3
0.28
0.26
percent
utilization
100
fig
throughput
versus
channel
utilization
user
computing
cluster
cell
throughput
cell
set
zero
pathloss
exponent
held
constant
computing
cluster
size
high
interference
get
sufﬁciently
attenuated
free
space
second
simulation
explored
effect
channel
utiliza-
tion
channel
usage
varied
0.6
fig
displays
throughput
varying
channel
utilization
randomly
placing
mobile
units
guarantee
user
placed
every
cell
computing
cluster
throughput
lower
lower
channel
utilization
data
transmitted
user
cell
last
simulation
explored
effect
computing
cluster
size
varying
range
10.
fig
shows
throughput
varying
computing
cluster
size
ﬁrst
data
point
cluster
size
set
one
traditional
cellular
network
processing
mrs
ejf
local
limit
scc
0.42
0.4
0.38
0.36
0.34
0.32
0.3
0.28
computing
cluster
size
fig
throughput
versus
computing
cluster
size
pathloss
exponent
constant
channel
utilization
held
constant
100
resources
shared
plot
see
increasing
cluster
size
increases
throughput
complexity
aware
algorithms
looking
simulations
seen
complexity
aware
schemes
always
outperform
complexity
unaware
mrs.
terms
throughput
sophisticated
scc
good
better
values
variables
varied
vii
conclusions
advancements
technology
made
feasible
process
baseband
signals
wireless
networks
central
processing
pool
network
paradigm
shift
known
c-ran
creates
many
beneﬁts
include
ability
share
computing
resources
among
multiple
cells
centralizing
manage-
ment
system
infrastructure
beneﬁts
come
along
challenges
primary
load
imposed
front
haul
connection
risk
demand
computing
resources
exceeds
capacity
either
fronthaul
capacity
sufﬁcient
processing
center
sufﬁcient
computation
resources
outage
occurs
provider
perspective
outage
different
traditional
impairment
fading
interference
paper
provided
analysis
computational
requirements
c-ran
uplink
developed
analyzed
computationally
aware
scheduling
algorithms
c-ran
order
perform
mathematically
precise
tractable
analysis
assumed
transmissions
encoded
ldpc
codes
sent
bec
channel
allows
per-bit
complexity
accurately
predicted
future
work
extend
analysis
kinds
channels
another
possible
future
direction
create
ldpc
codes
complexity
aware
i.e.
designed
additional
constraint
attempts
reduce
complexity
rather
minimize
convergence
threshold
finally
sophisticated
complexity
aware
algorithms
could
developed
references
boccardi
heath
lozano
marzetta
popovski
five
disruptive
technology
directions
communications
maga-
zine
ieee
vol
74–80
2014
torrieri
talarico
valenti
analysis
frequency-
hopping
millimeter-wave
cellular
uplink
ieee
transactions
wire-
less
communications
vol
7089–7098
oct
2016
saleh
rustako
roman
distributed
antennas
indoor
radio
communications
ieee
transactions
communications
vol
1245–1251
1987
checko
christiansen
yan
scolari
kardaras
berger
dittmann
cloud
ran
mobile
networks-a
tech-
nology
overview
ieee
communications
surveys
tutorials
vol
405–426
firstquarter
2015
valenti
woerner
iterative
multiuser
detection
macro-
diversity
combining
decoding
tdma
cellular
uplink
ieee
journal
selected
areas
communications
vol
1570–1583
aug
2001
tang
valenti
coded
transmit
macrodiversity
block
space-time
codes
distributed
antennas
proceedings
ieee
vts
53rd
vehicular
technology
conference
vol
1435–1438
2001
park
chae
bahk
large-scale
antenna
operation
heterogeneous
cloud
radio
access
networks
partial
centralization
approach
ieee
wireless
communications
vol
32–40
june
2015
zhou
fronthaul
compression
transmit
beamforming
optimization
multi-antenna
uplink
c-ran
ieee
transactions
signal
processing
vol
4138–4151
aug
2016
valenti
talarico
rost
role
computational
outage
dense
cloud-based
centralized
radio
access
networks
ieee
global
conference
communications
austin
usa
december
2014
rost
talarico
valenti
complexity
rate
tradeoff
centralized
radio
access
networks
ieee
transactions
wireless
communications
vol
6164–6176
nov
2015
rost
maeder
valenti
talarico
computationally
aware
sum-rate
optimal
scheduling
centralized
radio
access
net-
works
ieee
global
communications
conference
globecom
dec
2015
schlegel
trellis
turbo
coding
piscataway
hoboken
ieee
press
wiley-interscience
2004
coupechoux
kelif
set
fractional
power
control
compensation
factor
lte
34th
ieee
sarnoff
symposium
may
2011
