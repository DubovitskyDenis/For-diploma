representation
big
data
dimension
reduction
a.g.ramm
van
department
mathematics
kansas
state
university
manhattan
66506
usa
ramm
math.ksu.edu
congvan
math.ksu.edu
abstract
suppose
data
consist
set
points
distributed
bounded
domain
large
numbers
paper
algorithm
proposed
checking
whether
exists
manifold
low
dimension
near
many
points
lie
ﬁnding
exists
many
dimension
reduction
algorithms
linear
non-linear
algorithm
simple
implement
advantages
compared
known
algorithms
manifold
low
dimension
near
data
points
lie
proposed
algorithm
ﬁnd
numerical
results
presented
illustrating
algorithm
analyzing
performance
compared
classical
pca
principal
component
analysis
isomap
introduction
large
literature
dimension
reduction
without
trying
describe
published
results
refer
reader
reviews
references
therein
algorithm
simple
easy
implement
advantages
known
algorithms
compare
performance
pca
isomap
algorithms
main
point
short
paper
new
algorithm
computing
manifold
low
dimension
neighborhood
data
points
lie
ﬁnding
manifold
section
describe
details
proposed
algorithm
section
analyze
performance
algorithm
compare
performance
pca
isomap
algorithms
performances
section
show
numerical
results
description
algorithm
let
set
data
points
unit
cube
large
divide
unit
cube
grid
step
size
let
number
intervals
side
unit
cube
let
upper
limit
total
volume
small
cubes
lower
limit
number
data
points
near
manifold
lower
limit
number
data
points
small
cube
side
manifold
paper
union
piecewise-smooth
manifolds
meant
smooth
manifold
deﬁned
smooth
lower-dimensional
domain
example
line
plane
one-dimensional
manifold
construct
union
piecewise-linear
curves
linear
curve
line
let
describe
algorithm
development
idea
steps
algorithm
take
take
number
small
cubes
side
denote
small
cubes
scan
data
set
moving
small
cube
step
size
calculating
number
points
cube
position
cube
points
lie
cube
let
number
points
neglect
small
cubes
chosen
lower
limit
number
data
points
small
cube
one
chooses
cid:28
|s|
example
0.005|s|
|s|
number
data
points
let
total
volume
cubes
keep
set
2a1
cid:112
|s|
conclude
conclude
manifold
found
manifold
found
otherwise
repeat
steps
denote
cid:28
small
cubes
keep
denote
centers
let
total
number
points
less
chosen
lower
limit
number
data
points
near
manifold
conclude
manifold
found
k=1ck
otherwise
set
small
cubes
cid:28
side
total
volume
less
number
data
points
given
set
small
cubes
one
build
sets
dimension
cid:28
neighborhood
maximal
amount
points
lie
ex-
ample
build
one
start
point
small
cube
closest
origin
join
small
cube
closest
continuing
joining
small
cubes
one
gets
one-dimensional
piecewise-linear
manifold
build
one
considers
triangles
vertices
yk+1
yk+2
union
forms
two-dimensional
manifold
similarly
one
build
s-dimensional
manifold
set
building
manifolds
one
construct
several
manifolds
closest
ci−1
cube
may
non-unique
however
constructed
man-
ifolds
contains
small
cubes
totally
least
data
points
example
0.9|s|
manifolds
contains
least
0.9|s|
data
points
course
could
manifold
containing
0.99|s|
another
one
containing
0.9|s|
goal
include
many
data
points
possible
experimenter
increase
example
0.95|s|
choice
idea
algorithm
ﬁnd
region
containing
data
points
small
volume
neglecting
small
cubes
data
points
depending
sparse
data
set
one
choose
appropriate
data
set
small
number
outliers
outlier
observation
point
distant
observations
one
choose
0.9|s|
ﬁrst
numerical
experiment
section
data
set
sparse
one
choose
0.8|s|
second
numerical
experiment
section
general
experimenter
know
sparse
data
one
try
0.95|s|
0.9|s|
0.8|s|
one
choose
big
example
0.5
make
sense
manifold
big
volume
one
choose
small
either
one
ﬁnd
manifold
number
small
cubes
number
data
points
authors
suggest
0.3
0.4
volume
original
unit
cube
data
points
value
used
decide
whether
one
neglect
small
cubes
recommended
choose
|s|
numerical
experiments
show
0.005|s|
works
well
experimenter
also
try
smaller
values
compu-
tation
time
needed
performance
analysis
algorithm
one
doubles
time
cid:112
|s|
main
step
runs
log
cid:112
|s|
cid:0
|s|
log
|s|
cid:1
|s|
log
|s|
since
|s|
worst
case
log
|s|
times
one
calculates
number
points
data
set
small
cubes
total
computational
time
|s|
log
|s|
-dimensional
space
calculating
distance
two
points
takes
operations
thus
asymptotic
speed
algorithm
asymptotic
speed
|s|2
log
|s|
one
compares
algorithm
principal
component
analysis
pca
algo-
rithm
asymptotic
speed
|s|3
one
sees
algorithm
much
faster
pca
algorithm
pca
theory
presented
paper
fastest
algorithm
ﬁnding
manifold
lower
dimension
contain-
ing
many
points
called
isomap
asymptotic
speed
|s|
log
|s|
assumed
dimension
manifold
number
landmarks
however
isomap
algorithm
one
use
priori
assumed
dimension
manifold
known
priori
algorithm
ﬁnds
manifold
dimension
also
isomap
algorithm
one
specify
landmarks
arbitrarily
located
domain
algorithm
simpler
implement
isomap
algorithm
large
|s|
one
make
algorithm
faster
putting
upper
limit
example
instead
cid:112
|s|
one
require
cid:112
|s|
numerical
results
following
numerical
experiments
use
diﬀerent
data
sets
paper
apply
proposed
algorithm
data
set
get
results
shown
pictures
ﬁrst
picture
data
set
shows
original
data
points
blue
points
found
small
cubes
red
points
second
picture
data
set
shows
found
manifold
consider
data
set
paper
2-dimensional
set
containing
|s|
308
points
2-dimensional
cartesian
coordinate
system
take
integer
value
nearest
larger
/2/2
figure
data
set
paper
|s|
308
0.005|s|
1.56
/2/2
figure
data
set
paper
|s|
308
0.005|s|
1.56
run
algorithm
0.5
i.e
ﬁnal
set
total
volume
less
0.5
0.9
|s|
manifold
contains
least
initial
data
points
0.005|s|
1.56
take
neglect
small
cubes
point
one
ﬁnds
manifold
1/16
number
small
cubes
total
volume
0.35
contains
0.92|s|
data
points
consider
another
data
set
paper
set
|s|
296
data
points
/2/2
figure
another
data
set
paper
|s|
296
0.005|s|
1.5
/2/2
figure
another
data
set
paper
|s|
296
0.005|s|
1.5
run
algorithm
0.5
i.e
ﬁnal
set
total
volume
less
0.5
0.8
|s|
since
part
data
uniformly
distributed
0.005|s|
1.5
take
neglect
small
cubes
point
one
ﬁnds
manifold
1/16
number
small
cubes
total
volume
0.3
contains
0.83|s|
data
points
use
data
set
paper
second
experiment
experiment
used
show
one
try
diﬀerent
values
besides
suggested
one
0.005|s|
may
ﬁnd
manifold
smaller
number
small
cubes
/2/2
figure
another
data
set
paper
|s|
296
/2/2
figure
another
data
set
paper
|s|
296
choose
0.5
0.8×|s|
one
ﬁnds
manifold
1/8
number
small
cubes
less
experiment
total
volume
0.47
total
number
points
0.89|s|
conclusion
one
try
diﬀerent
values
diﬀerent
manifolds
consider
data
set
paper
figure
figure
data
set
paper
|s|
235
run
algorithm
0.5
0.8
|s|
let
run
10.
one
ﬁnd
set
total
volume
contains
least
0.8|s|
data
points
data
set
manifold
lower
dimension
neighborhood
data
points
lie
consider
data
set
paper
set
|s|
373
data
points
/2/2
figure
data
set
paper
|s|
373
/2/2
figure
data
set
paper
|s|
373
run
algorithm
0.5
i.e
ﬁnal
set
total
volume
less
0.5
0.8
|s|
since
part
data
uniformly
distributed
neglect
small
cubes
points
one
ﬁnds
manifold
1/8
number
small
cubes
use
data
set
paper
ﬁfth
experiment
experiment
used
show
one
try
diﬀerent
values
besides
suggested
one
may
ﬁnd
diﬀerent
manifold
/2/2
figure
data
set
paper
|s|
373
/2/2
figure
data
set
paper
|s|
373
choose
0.5
0.8
|s|
one
ﬁnds
manifold
1/16
number
small
cubes
72.
conclusion
one
try
diﬀerent
values
diﬀerent
manifolds
conclusion
conclude
proposed
algorithm
compute
manifold
low
dimension
neighborhood
data
points
lie
ﬁnd
manifold
algorithm
simple
easy
implement
advantages
known
algorithms
pca
isomap
references
cayton
algorithms
manifold
learning
2005
chang
yeung
robust
path-based
spectral
clustering
pattern
recogni-
tion
2008
191-203
fodor
survey
dimension
reduction
techniques
2002.
www.researchgate.net/publication/2860580
medico
flame
novel
fuzzy
clustering
method
analysis
dna
microarray
data
bmc
bioinformatics
2007
jolitle
principal
component
analysis
springer
new
york
1986
jain
law
data
clustering
user
dilemma
lecture
notes
com-
puter
science
2005
3776
1-10
van
der
maaten
postma
van
der
herik
dimensionality
reduction
comparative
review
2009.
http
//www.uvt.nl/ticc
ramm
2009
arxiv:0902.4389
